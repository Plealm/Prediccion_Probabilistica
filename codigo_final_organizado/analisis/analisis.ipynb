{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86610207",
   "metadata": {},
   "source": [
    "# Analisis General"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc245af6",
   "metadata": {},
   "source": [
    "## Pre-procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "378a602a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TABLA COMPARATIVA DE MODELOS POR ESCENARIO\n",
      "(Promedio de amplitud de intervalos de predicci√≥n)\n",
      "================================================================================\n",
      "             Modelo   ARMA   ARIMA  SETAR Mejor_Escenario\n",
      "              AREPD 0.9722  9.7604 0.6955           SETAR\n",
      "            AV-MCPS 0.7103  3.0618 0.6706           SETAR\n",
      "Block Bootstrapping 0.9172 10.9690 0.6460           SETAR\n",
      "             DeepAR 0.5779  3.1462 0.6249            ARMA\n",
      "         EnCQR-LSTM 1.0382  5.8306 0.8408           SETAR\n",
      "               LSPM 0.7696  1.1140 0.6751           SETAR\n",
      "              LSPMW 1.0604  3.5094 0.6868           SETAR\n",
      "               MCPS 0.7222  2.8994 0.6916           SETAR\n",
      "    Sieve Bootstrap 0.5547  0.5479 0.6304           ARIMA\n",
      "================================================================================\n",
      "\n",
      "Tabla comparativa guardada en 'Tabla_Comparativa_Modelos.xlsx'\n",
      "\n",
      "Archivo 'Base_140_3_escenarios.xlsx' creado exitosamente!\n",
      "\n",
      "Total de filas: 5040\n",
      "- ARMA: 1680 filas\n",
      "- ARIMA: 1680 filas\n",
      "- SETAR: 1680 filas\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Leer los tres archivos\n",
    "arma_df = pd.read_excel(\"./datos/resultados_140_FINAL_ARMA.xlsx\")\n",
    "arima_df = pd.read_excel(\"./datos/resultados_140_ARIMA_FINAL.xlsx\")\n",
    "setar_df = pd.read_excel(\"./datos/resultados_140_SETAR_FINAL.xlsx\")\n",
    "\n",
    "# Filtrar los que no tienen \"Promedio\" en la columna \"Paso\"\n",
    "arma_df = arma_df[arma_df['Paso'] != 'Promedio']\n",
    "arima_df = arima_df[arima_df['Paso'] != 'Promedio']\n",
    "setar_df = setar_df[setar_df['Paso'] != 'Promedio']\n",
    "\n",
    "# Lista de modelos (columnas a promediar)\n",
    "modelos = ['AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR',\n",
    "           'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
    "\n",
    "# Crear tabla comparativa\n",
    "comparacion = []\n",
    "\n",
    "for modelo in modelos:\n",
    "    fila = {'Modelo': modelo}\n",
    "    \n",
    "    # Calcular promedio para cada escenario (de la columna del modelo)\n",
    "    arma_promedio = arma_df[modelo].mean() if modelo in arma_df.columns else np.nan\n",
    "    arima_promedio = arima_df[modelo].mean() if modelo in arima_df.columns else np.nan\n",
    "    setar_promedio = setar_df[modelo].mean() if modelo in setar_df.columns else np.nan\n",
    "    \n",
    "    fila['ARMA'] = arma_promedio\n",
    "    fila['ARIMA'] = arima_promedio\n",
    "    fila['SETAR'] = setar_promedio\n",
    "    \n",
    "    # Determinar mejor escenario (menor promedio)\n",
    "    promedios = {\n",
    "        'ARMA': arma_promedio,\n",
    "        'ARIMA': arima_promedio,\n",
    "        'SETAR': setar_promedio\n",
    "    }\n",
    "    \n",
    "    # Filtrar NaN si existen\n",
    "    promedios_validos = {k: v for k, v in promedios.items() if not pd.isna(v)}\n",
    "    \n",
    "    if promedios_validos:\n",
    "        mejor_escenario = min(promedios_validos, key=promedios_validos.get)\n",
    "        fila['Mejor_Escenario'] = mejor_escenario\n",
    "    else:\n",
    "        fila['Mejor_Escenario'] = 'N/A'\n",
    "    \n",
    "    comparacion.append(fila)\n",
    "\n",
    "# Crear DataFrame con la tabla comparativa\n",
    "tabla_comparativa = pd.DataFrame(comparacion)\n",
    "\n",
    "# Redondear valores para mejor visualizaci√≥n\n",
    "columnas_numericas = ['ARMA', 'ARIMA', 'SETAR']\n",
    "tabla_comparativa[columnas_numericas] = tabla_comparativa[columnas_numericas].round(4)\n",
    "\n",
    "# Mostrar tabla comparativa\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TABLA COMPARATIVA DE MODELOS POR ESCENARIO\")\n",
    "print(\"(Promedio de amplitud de intervalos de predicci√≥n)\")\n",
    "print(\"=\"*80)\n",
    "print(tabla_comparativa.to_string(index=False))\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Guardar tabla comparativa en Excel\n",
    "tabla_comparativa.to_excel(\"Tabla_Comparativa_Modelos.xlsx\", index=False)\n",
    "print(\"Tabla comparativa guardada en 'Tabla_Comparativa_Modelos.xlsx'\")\n",
    "\n",
    "# Procesamiento especial para SETAR\n",
    "if 'Descripci√≥n' in setar_df.columns:\n",
    "    setar_df = setar_df.drop('Descripci√≥n', axis=1)\n",
    "\n",
    "# Agregar columna ESCENARIO a cada DataFrame antes de concatenar\n",
    "arma_df['ESCENARIO'] = 'Lineal - estacionario'\n",
    "arima_df['ESCENARIO'] = 'Lineal - NO estacionario'\n",
    "setar_df['ESCENARIO'] = 'NO lineal - estacionario'\n",
    "\n",
    "# Concatenar los tres dataframes\n",
    "base_consolidada = pd.concat([arma_df, arima_df, setar_df], ignore_index=True)\n",
    "\n",
    "# Guardar en un archivo Excel\n",
    "base_consolidada.to_excel(\"Base_140_3_escenarios.xlsx\", index=False)\n",
    "\n",
    "print(\"\\nArchivo 'Base_140_3_escenarios.xlsx' creado exitosamente!\")\n",
    "print(f\"\\nTotal de filas: {len(base_consolidada)}\")\n",
    "print(f\"- ARMA: {len(arma_df)} filas\")\n",
    "print(f\"- ARIMA: {len(arima_df)} filas\")\n",
    "print(f\"- SETAR: {len(setar_df)} filas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abc9573",
   "metadata": {},
   "source": [
    "## Analisis general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07f7f9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "INICIANDO AN√ÅLISIS ESTAD√çSTICO ROBUSTO (GENERAL + DESAGREGADO + EXCEL)\n",
      "================================================================================\n",
      "\n",
      "‚úì Datos cargados: 5040 filas\n",
      "‚úì Directorio: resultados_generales_robustos\n",
      "\n",
      "================================================================================\n",
      "\n",
      "1Ô∏è‚É£  Analizando Escenarios (M√©tricas Robustas)...\n",
      "3Ô∏è‚É£  Analizando Modelo Generador (IQR)...\n",
      "4Ô∏è‚É£  Analizando Distribuci√≥n...\n",
      "5Ô∏è‚É£  Analizando Varianza (Pendiente Theil-Sen)...\n",
      "6Ô∏è‚É£  Analizando Horizonte (Pendiente Theil-Sen)...\n",
      "7Ô∏è‚É£  Analizando Robustez (QCD)...\n",
      "8Ô∏è‚É£  Analizando Significancia DM y Generando Excel...\n",
      "\n",
      "   ============================================================\n",
      "   Procesando: General\n",
      "   ============================================================\n",
      "\n",
      "================================================================================\n",
      "üîç VERIFICACI√ìN COMPLETA DE RESULTADOS DM\n",
      "================================================================================\n",
      "\n",
      "üìä ESTAD√çSTICAS DESCRIPTIVAS (ECRPS - menor = mejor):\n",
      "                         mean       50%       std       IQR\n",
      "AREPD                3.809377  0.949502  8.880501  2.568691\n",
      "AV-MCPS              1.480903  0.593915  3.222711  1.010705\n",
      "Block Bootstrapping  4.177433  0.907520  9.686845  2.912166\n",
      "DeepAR               1.449646  0.498318  4.592738  0.730393\n",
      "EnCQR-LSTM           2.569865  1.161221  4.526081  1.953390\n",
      "LSPM                 0.852910  0.513936  0.997760  0.755655\n",
      "LSPMW                1.752187  0.672946  3.337202  1.352199\n",
      "MCPS                 1.437725  0.585542  3.184190  1.009153\n",
      "Sieve Bootstrap      0.577684  0.382186  0.631037  0.488377\n",
      "\n",
      "üèÜ RANKING POR MEDIANA:\n",
      "   1. Sieve Bootstrap     : 0.382186\n",
      "   2. DeepAR              : 0.498318\n",
      "   3. LSPM                : 0.513936\n",
      "   4. MCPS                : 0.585542\n",
      "   5. AV-MCPS             : 0.593915\n",
      "   6. LSPMW               : 0.672946\n",
      "   7. Block Bootstrapping : 0.907520\n",
      "   8. AREPD               : 0.949502\n",
      "   9. EnCQR-LSTM          : 1.161221\n",
      "\n",
      "üìà REALIZANDO TEST DIEBOLD-MARIANO...\n",
      "üîç Realizando 36 comparaciones con Œ±=0.001389\n",
      "‚úÖ Comparaciones completadas: 36/36\n",
      "\n",
      "üèÜ RANKING SEG√öN TEST DM (Œ±=0.001389):\n",
      "   1. Sieve Bootstrap      (Score:   8, Victorias:  8/ 8)\n",
      "   2. LSPM                 (Score:   6, Victorias:  7/ 8)\n",
      "   3. AV-MCPS              (Score:   2, Victorias:  4/ 8)\n",
      "\n",
      "üîç VERIFICACI√ìN DE CONSISTENCIA:\n",
      "  ‚ö†Ô∏è Consistencia PARCIAL: 2/3 coincidencias\n",
      "     - Solo en Top DM: {'AV-MCPS'}\n",
      "     - Solo en Top Mediana: {'DeepAR'}\n",
      "\n",
      "üìã RESUMEN COMPARACIONES SIGNIFICATIVAS:\n",
      "  ‚úÖ AV-MCPS es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ AREPD es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ DeepAR es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ EnCQR-LSTM es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ LSPM es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ LSPMW es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ MCPS es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ Sieve Bootstrap es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ AV-MCPS es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ AV-MCPS es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ LSPM es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ AV-MCPS es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ Sieve Bootstrap es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ DeepAR es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ EnCQR-LSTM es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ LSPM es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ LSPMW es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ MCPS es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ Sieve Bootstrap es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ DeepAR es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ LSPM es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ DeepAR es significativamente mejor (p=0.000006)\n",
      "  ‚úÖ Sieve Bootstrap es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ LSPM es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ LSPMW es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ MCPS es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ Sieve Bootstrap es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ LSPM es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ LSPM es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ Sieve Bootstrap es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ MCPS es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ Sieve Bootstrap es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ Sieve Bootstrap es significativamente mejor (p=0.000000)\n",
      "\n",
      "================================================================================\n",
      "\n",
      "   ============================================================\n",
      "   Procesando: Estacionario - Lineal (ARMA)\n",
      "   ============================================================\n",
      "\n",
      "================================================================================\n",
      "üîç VERIFICACI√ìN COMPLETA DE RESULTADOS DM\n",
      "================================================================================\n",
      "\n",
      "üìä ESTAD√çSTICAS DESCRIPTIVAS (ECRPS - menor = mejor):\n",
      "                         mean       50%       std       IQR\n",
      "AREPD                0.972212  0.565917  1.143739  0.956882\n",
      "AV-MCPS              0.710315  0.436308  0.789561  0.614051\n",
      "Block Bootstrapping  0.917247  0.582340  1.035806  0.744609\n",
      "DeepAR               0.577869  0.394038  0.619649  0.478819\n",
      "EnCQR-LSTM           1.038191  0.837532  0.681073  0.803520\n",
      "LSPM                 0.769619  0.473518  0.851594  0.691548\n",
      "LSPMW                1.060377  0.569470  1.336531  0.968867\n",
      "MCPS                 0.722224  0.463777  0.785874  0.671501\n",
      "Sieve Bootstrap      0.554748  0.375774  0.608167  0.453963\n",
      "\n",
      "üèÜ RANKING POR MEDIANA:\n",
      "   1. Sieve Bootstrap     : 0.375774\n",
      "   2. DeepAR              : 0.394038\n",
      "   3. AV-MCPS             : 0.436308\n",
      "   4. MCPS                : 0.463777\n",
      "   5. LSPM                : 0.473518\n",
      "   6. AREPD               : 0.565917\n",
      "   7. LSPMW               : 0.569470\n",
      "   8. Block Bootstrapping : 0.582340\n",
      "   9. EnCQR-LSTM          : 0.837532\n",
      "\n",
      "üìà REALIZANDO TEST DIEBOLD-MARIANO...\n",
      "üîç Realizando 36 comparaciones con Œ±=0.001389\n",
      "‚úÖ Comparaciones completadas: 36/36\n",
      "\n",
      "üèÜ RANKING SEG√öN TEST DM (Œ±=0.001389):\n",
      "   1. Sieve Bootstrap      (Score:   8, Victorias:  8/ 8)\n",
      "   2. DeepAR               (Score:   6, Victorias:  7/ 8)\n",
      "   3. AV-MCPS              (Score:   3, Victorias:  5/ 8)\n",
      "\n",
      "üîç VERIFICACI√ìN DE CONSISTENCIA:\n",
      "  ‚úÖ Consistencia PERFECTA entre DM y medianas\n",
      "\n",
      "üìã RESUMEN COMPARACIONES SIGNIFICATIVAS:\n",
      "  ‚úÖ AV-MCPS es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ Block Bootstrapping es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ DeepAR es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ AREPD es significativamente mejor (p=0.000505)\n",
      "  ‚úÖ LSPM es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ AREPD es significativamente mejor (p=0.000162)\n",
      "  ‚úÖ MCPS es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ Sieve Bootstrap es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ AV-MCPS es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ DeepAR es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ AV-MCPS es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ AV-MCPS es significativamente mejor (p=0.000425)\n",
      "  ‚úÖ AV-MCPS es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ Sieve Bootstrap es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ DeepAR es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ Block Bootstrapping es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ LSPM es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ Block Bootstrapping es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ MCPS es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ Sieve Bootstrap es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ DeepAR es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ DeepAR es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ DeepAR es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ DeepAR es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ Sieve Bootstrap es significativamente mejor (p=0.000047)\n",
      "  ‚úÖ LSPM es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ MCPS es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ Sieve Bootstrap es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ LSPM es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ Sieve Bootstrap es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ MCPS es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ Sieve Bootstrap es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ Sieve Bootstrap es significativamente mejor (p=0.000000)\n",
      "\n",
      "================================================================================\n",
      "\n",
      "   ============================================================\n",
      "   Procesando: Estacionario - No Lineal (SETAR)\n",
      "   ============================================================\n",
      "\n",
      "================================================================================\n",
      "üîç VERIFICACI√ìN COMPLETA DE RESULTADOS DM\n",
      "================================================================================\n",
      "\n",
      "üìä ESTAD√çSTICAS DESCRIPTIVAS (ECRPS - menor = mejor):\n",
      "                         mean       50%       std       IQR\n",
      "AREPD                0.695530  0.420178  0.786652  0.642448\n",
      "AV-MCPS              0.670594  0.437211  0.706477  0.579118\n",
      "Block Bootstrapping  0.646036  0.429878  0.680516  0.535672\n",
      "DeepAR               0.624871  0.418300  0.659890  0.523678\n",
      "EnCQR-LSTM           0.840811  0.692620  0.542462  0.618625\n",
      "LSPM                 0.675068  0.445879  0.712784  0.589074\n",
      "LSPMW                0.686772  0.453731  0.723938  0.592426\n",
      "MCPS                 0.691578  0.442462  0.738804  0.608433\n",
      "Sieve Bootstrap      0.630433  0.411955  0.680158  0.546469\n",
      "\n",
      "üèÜ RANKING POR MEDIANA:\n",
      "   1. Sieve Bootstrap     : 0.411955\n",
      "   2. DeepAR              : 0.418300\n",
      "   3. AREPD               : 0.420178\n",
      "   4. Block Bootstrapping : 0.429878\n",
      "   5. AV-MCPS             : 0.437211\n",
      "   6. MCPS                : 0.442462\n",
      "   7. LSPM                : 0.445879\n",
      "   8. LSPMW               : 0.453731\n",
      "   9. EnCQR-LSTM          : 0.692620\n",
      "\n",
      "üìà REALIZANDO TEST DIEBOLD-MARIANO...\n",
      "üîç Realizando 36 comparaciones con Œ±=0.001389\n",
      "‚úÖ Comparaciones completadas: 36/36\n",
      "\n",
      "üèÜ RANKING SEG√öN TEST DM (Œ±=0.001389):\n",
      "   1. DeepAR               (Score:   6, Victorias:  6/ 8)\n",
      "   2. Sieve Bootstrap      (Score:   6, Victorias:  6/ 8)\n",
      "   3. Block Bootstrapping  (Score:   5, Victorias:  5/ 8)\n",
      "\n",
      "üîç VERIFICACI√ìN DE CONSISTENCIA:\n",
      "  ‚ö†Ô∏è Consistencia PARCIAL: 2/3 coincidencias\n",
      "     - Solo en Top DM: {'Block Bootstrapping'}\n",
      "     - Solo en Top Mediana: {'AREPD'}\n",
      "\n",
      "üìã RESUMEN COMPARACIONES SIGNIFICATIVAS:\n",
      "  ‚úÖ Block Bootstrapping es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ DeepAR es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ AREPD es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ Sieve Bootstrap es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ DeepAR es significativamente mejor (p=0.000010)\n",
      "  ‚úÖ AV-MCPS es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ Sieve Bootstrap es significativamente mejor (p=0.000014)\n",
      "  ‚úÖ Block Bootstrapping es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ Block Bootstrapping es significativamente mejor (p=0.000005)\n",
      "  ‚úÖ Block Bootstrapping es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ Block Bootstrapping es significativamente mejor (p=0.000021)\n",
      "  ‚úÖ DeepAR es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ DeepAR es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ DeepAR es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ DeepAR es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ LSPM es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ LSPMW es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ MCPS es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ Sieve Bootstrap es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ Sieve Bootstrap es significativamente mejor (p=0.000001)\n",
      "  ‚úÖ Sieve Bootstrap es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ Sieve Bootstrap es significativamente mejor (p=0.000000)\n",
      "\n",
      "================================================================================\n",
      "\n",
      "   ============================================================\n",
      "   Procesando: No Estacionario - Lineal (ARIMA)\n",
      "   ============================================================\n",
      "\n",
      "================================================================================\n",
      "üîç VERIFICACI√ìN COMPLETA DE RESULTADOS DM\n",
      "================================================================================\n",
      "\n",
      "üìä ESTAD√çSTICAS DESCRIPTIVAS (ECRPS - menor = mejor):\n",
      "                          mean       50%        std       IQR\n",
      "AREPD                 9.760389  5.200554  13.474609  9.187236\n",
      "AV-MCPS               3.061802  1.219232   5.127921  2.552126\n",
      "Block Bootstrapping  10.969016  6.211990  14.519445  9.958103\n",
      "DeepAR                3.146198  0.829496   7.626554  2.095535\n",
      "EnCQR-LSTM            5.830592  3.838096   6.689171  5.184172\n",
      "LSPM                  1.114044  0.655571   1.283614  1.089217\n",
      "LSPMW                 3.509412  1.620760   5.138995  3.774457\n",
      "MCPS                  2.899372  1.184453   5.104787  2.270580\n",
      "Sieve Bootstrap       0.547869  0.370937   0.598677  0.457842\n",
      "\n",
      "üèÜ RANKING POR MEDIANA:\n",
      "   1. Sieve Bootstrap     : 0.370937\n",
      "   2. LSPM                : 0.655571\n",
      "   3. DeepAR              : 0.829496\n",
      "   4. MCPS                : 1.184453\n",
      "   5. AV-MCPS             : 1.219232\n",
      "   6. LSPMW               : 1.620760\n",
      "   7. EnCQR-LSTM          : 3.838096\n",
      "   8. AREPD               : 5.200554\n",
      "   9. Block Bootstrapping : 6.211990\n",
      "\n",
      "üìà REALIZANDO TEST DIEBOLD-MARIANO...\n",
      "üîç Realizando 36 comparaciones con Œ±=0.001389\n",
      "‚úÖ Comparaciones completadas: 36/36\n",
      "\n",
      "üèÜ RANKING SEG√öN TEST DM (Œ±=0.001389):\n",
      "   1. Sieve Bootstrap      (Score:   8, Victorias:  8/ 8)\n",
      "   2. LSPM                 (Score:   6, Victorias:  7/ 8)\n",
      "   3. AV-MCPS              (Score:   2, Victorias:  4/ 8)\n",
      "\n",
      "üîç VERIFICACI√ìN DE CONSISTENCIA:\n",
      "  ‚ö†Ô∏è Consistencia PARCIAL: 2/3 coincidencias\n",
      "     - Solo en Top DM: {'AV-MCPS'}\n",
      "     - Solo en Top Mediana: {'DeepAR'}\n",
      "\n",
      "üìã RESUMEN COMPARACIONES SIGNIFICATIVAS:\n",
      "  ‚úÖ AV-MCPS es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ AREPD es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ DeepAR es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ EnCQR-LSTM es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ LSPM es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ LSPMW es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ MCPS es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ Sieve Bootstrap es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ AV-MCPS es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ AV-MCPS es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ LSPM es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ AV-MCPS es significativamente mejor (p=0.000065)\n",
      "  ‚úÖ Sieve Bootstrap es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ DeepAR es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ EnCQR-LSTM es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ LSPM es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ LSPMW es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ MCPS es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ Sieve Bootstrap es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ DeepAR es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ LSPM es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ Sieve Bootstrap es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ LSPM es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ LSPMW es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ MCPS es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ Sieve Bootstrap es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ LSPM es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ LSPM es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ Sieve Bootstrap es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ MCPS es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ Sieve Bootstrap es significativamente mejor (p=0.000000)\n",
      "  ‚úÖ Sieve Bootstrap es significativamente mejor (p=0.000000)\n",
      "\n",
      "================================================================================\n",
      "\n",
      "   üìä Excel corregido generado: resultados_generales_robustos\\Tabla_Victorias_DM_CORREGIDO.xlsx\n",
      "\n",
      "‚úÖ AN√ÅLISIS FINALIZADO\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from itertools import combinations\n",
    "import warnings\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuraci√≥n de estilo\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURACI√ìN GLOBAL\n",
    "# ============================================================================\n",
    "\n",
    "RUTA_DATOS = \"./Base_140_3_escenarios.xlsx\"\n",
    "DIR_SALIDA = \"./resultados_generales_robustos\"\n",
    "\n",
    "MODELOS = ['AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR',\n",
    "           'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
    "\n",
    "COLORES_MODELOS = {\n",
    "    'AREPD': '#e41a1c',\n",
    "    'AV-MCPS': '#377eb8',\n",
    "    'Block Bootstrapping': '#4daf4a',\n",
    "    'DeepAR': '#984ea3',\n",
    "    'EnCQR-LSTM': '#ff7f00',\n",
    "    'LSPM': '#ffff33',\n",
    "    'LSPMW': '#a65628',\n",
    "    'MCPS': '#f781bf',\n",
    "    'Sieve Bootstrap': '#999999'\n",
    "}\n",
    "\n",
    "CARACTERISTICAS_META_MODELO = [\n",
    "    'Estacionario', 'Lineal', 'Tipo de Modelo',\n",
    "    'Distribuci√≥n', 'Varianza error', 'Paso'\n",
    "]\n",
    "CARACTERISTICAS_NUMERICAS_META_MODELO = ['Varianza error', 'Paso']\n",
    "CARACTERISTICAS_CATEGORICAS_META_MODELO = [\n",
    "    'Estacionario', 'Lineal', 'Tipo de Modelo', 'Distribuci√≥n'\n",
    "]\n",
    "\n",
    "# ============================================================================\n",
    "# FUNCIONES AUXILIARES - TEST DIEBOLD-MARIANO\n",
    "# ============================================================================\n",
    "\n",
    "def diebold_mariano_test(errores1, errores2, h=1, alternative='two-sided', \n",
    "                         loss_function='squared'):\n",
    "    \"\"\"\n",
    "    CORRECCI√ìN: Para ECRPS, usar 'none' como loss_function\n",
    "    \"\"\"\n",
    "    e1 = np.asarray(errores1)\n",
    "    e2 = np.asarray(errores2)\n",
    "    \n",
    "    if len(e1) != len(e2):\n",
    "        raise ValueError(\"Los vectores de errores deben tener la misma longitud\")\n",
    "    \n",
    "    n = len(e1)\n",
    "    \n",
    "    # ‚úÖ CORRECCI√ìN: Manejo correcto de funciones de p√©rdida\n",
    "    if loss_function == 'squared':\n",
    "        loss1 = e1 ** 2\n",
    "        loss2 = e2 ** 2\n",
    "    elif loss_function == 'absolute':\n",
    "        loss1 = np.abs(e1)\n",
    "        loss2 = np.abs(e2)\n",
    "    elif loss_function == 'none':\n",
    "        # Para ECRPS - ya son medidas de p√©rdida directas\n",
    "        loss1 = e1\n",
    "        loss2 = e2\n",
    "    else:\n",
    "        raise ValueError(\"loss_function debe ser 'squared', 'absolute' o 'none'\")\n",
    "    \n",
    "    # Diferencia de p√©rdidas\n",
    "    d = loss1 - loss2\n",
    "    d_mean = np.mean(d)\n",
    "    \n",
    "    # ‚úÖ CORRECCI√ìN: C√°lculo robusto de la varianza HAC\n",
    "    # Para h=1 (pron√≥stico un paso adelante), no necesitamos correcci√≥n por autocorrelaci√≥n\n",
    "    if h == 1:\n",
    "        var_d = np.var(d, ddof=1) / n\n",
    "    else:\n",
    "        # Correcci√≥n HAC para h > 1\n",
    "        gamma_0 = np.var(d, ddof=1)\n",
    "        gamma_sum = 0\n",
    "        max_lags = min(h-1, n-1)  # No m√°s lags que observaciones\n",
    "        for k in range(1, max_lags + 1):\n",
    "            if k < n:\n",
    "                gamma_k = np.cov(d[:-k], d[k:], ddof=1)[0,1] if len(d) > k else 0\n",
    "                gamma_sum += (1 - k/(max_lags+1)) * gamma_k  # Kernel de Bartlett\n",
    "        \n",
    "        var_d = (gamma_0 + 2 * gamma_sum) / n\n",
    "    \n",
    "    # ‚úÖ CORRECCI√ìN: Solo aplicar correcci√≥n HLN si h > 1\n",
    "    if h > 1:\n",
    "        hlnc = np.sqrt((n + 1 - 2 * h + h * (h - 1) / n) / n)\n",
    "    else:\n",
    "        hlnc = 1.0\n",
    "    \n",
    "    if var_d > 0:\n",
    "        dm_stat = d_mean / np.sqrt(var_d)\n",
    "        dm_stat_corrected = dm_stat * hlnc\n",
    "    else:\n",
    "        dm_stat = 0\n",
    "        dm_stat_corrected = 0\n",
    "    \n",
    "    # C√°lculo de p-value (usando distribuci√≥n normal asint√≥tica)\n",
    "    if alternative == 'two-sided':\n",
    "        p_value = 2 * (1 - stats.norm.cdf(abs(dm_stat_corrected)))\n",
    "    elif alternative == 'less':\n",
    "        p_value = stats.norm.cdf(dm_stat_corrected)\n",
    "    elif alternative == 'greater':\n",
    "        p_value = 1 - stats.norm.cdf(dm_stat_corrected)\n",
    "    else:\n",
    "        raise ValueError(\"alternative debe ser 'two-sided', 'less' o 'greater'\")\n",
    "\n",
    "    return {\n",
    "        'dm_statistic': dm_stat,\n",
    "        'dm_statistic_corrected': dm_stat_corrected,\n",
    "        'p_value': p_value,\n",
    "        'mean_diff': d_mean,\n",
    "        'modelo1_mejor': d_mean < 0  # d_mean < 0 significa modelo1 es mejor\n",
    "    }\n",
    "\n",
    "\n",
    "def comparaciones_multiples_dm(df, modelos, alpha=0.05, loss_function='none'):\n",
    "    \"\"\"\n",
    "    CORRECCI√ìN: Manejo robusto de comparaciones m√∫ltiples\n",
    "    \"\"\"\n",
    "    resultados = []\n",
    "    modelos_validos = [m for m in modelos if m in df.columns]\n",
    "    \n",
    "    if len(modelos_validos) < 2:\n",
    "        print(\"‚ö†Ô∏è No hay suficientes modelos v√°lidos para comparar\")\n",
    "        return pd.DataFrame(), alpha\n",
    "    \n",
    "    n_comparaciones = len(list(combinations(modelos_validos, 2)))\n",
    "    if n_comparaciones == 0:\n",
    "        return pd.DataFrame(), alpha\n",
    "        \n",
    "    # ‚úÖ CORRECCI√ìN: Bonferroni-Holm (m√°s potente que Bonferroni simple)\n",
    "    alpha_bonferroni = alpha / n_comparaciones\n",
    "    \n",
    "    print(f\"üîç Realizando {n_comparaciones} comparaciones con Œ±={alpha_bonferroni:.6f}\")\n",
    "\n",
    "    for modelo1, modelo2 in combinations(modelos_validos, 2):\n",
    "        try:\n",
    "            # Verificar que hay datos suficientes\n",
    "            data1 = df[modelo1].dropna()\n",
    "            data2 = df[modelo2].dropna()\n",
    "            \n",
    "            if len(data1) < 10 or len(data2) < 10:\n",
    "                print(f\"‚ö†Ô∏è Datos insuficientes para {modelo1} vs {modelo2}\")\n",
    "                continue\n",
    "            \n",
    "            dm_result = diebold_mariano_test(\n",
    "                data1.values,\n",
    "                data2.values,\n",
    "                h=1,\n",
    "                alternative='two-sided',\n",
    "                loss_function=loss_function\n",
    "            )\n",
    "            \n",
    "            significativo = dm_result['p_value'] < alpha_bonferroni\n",
    "            \n",
    "            # ‚úÖ CORRECCI√ìN: Interpretaci√≥n m√°s precisa\n",
    "            if significativo:\n",
    "                if dm_result['mean_diff'] < 0:\n",
    "                    ganador = modelo1\n",
    "                    explicacion = f\"{modelo1} es significativamente mejor (p={dm_result['p_value']:.6f})\"\n",
    "                else:\n",
    "                    ganador = modelo2\n",
    "                    explicacion = f\"{modelo2} es significativamente mejor (p={dm_result['p_value']:.6f})\"\n",
    "            else:\n",
    "                ganador = \"Empate\"\n",
    "                explicacion = f\"No hay diferencia significativa (p={dm_result['p_value']:.3f})\"\n",
    "\n",
    "            resultados.append({\n",
    "                'Modelo_1': modelo1,\n",
    "                'Modelo_2': modelo2,\n",
    "                'DM_Statistic': dm_result['dm_statistic_corrected'],\n",
    "                'p_value': dm_result['p_value'],\n",
    "                'Mean_Diff': dm_result['mean_diff'],\n",
    "                'Significativo': significativo,\n",
    "                'Ganador': ganador,\n",
    "                'Explicacion': explicacion\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error comparando {modelo1} vs {modelo2}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    df_resultados = pd.DataFrame(resultados)\n",
    "    \n",
    "    if not df_resultados.empty:\n",
    "        print(f\"‚úÖ Comparaciones completadas: {len(df_resultados)}/{n_comparaciones}\")\n",
    "    else:\n",
    "        print(\"‚ùå No se pudo realizar ninguna comparaci√≥n\")\n",
    "    \n",
    "    return df_resultados, alpha_bonferroni\n",
    "\n",
    "\n",
    "def calcular_ranking_dm(df_comparaciones, modelos):\n",
    "    \"\"\"\n",
    "    CORRECCI√ìN: Ranking basado en victorias netas y porcentaje de victorias\n",
    "    \"\"\"\n",
    "    if df_comparaciones.empty:\n",
    "        print(\"‚ö†Ô∏è No hay datos de comparaciones para calcular ranking\")\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "    \n",
    "    # Inicializar matriz de resultados\n",
    "    n = len(modelos)\n",
    "    matriz_victorias = pd.DataFrame(0, index=modelos, columns=modelos, dtype=int)\n",
    "    matriz_comparaciones = pd.DataFrame(0, index=modelos, columns=modelos, dtype=int)\n",
    "    \n",
    "    # Llenar matrices con resultados de comparaciones\n",
    "    for _, row in df_comparaciones.iterrows():\n",
    "        m1, m2 = row['Modelo_1'], row['Modelo_2']\n",
    "        \n",
    "        if m1 in modelos and m2 in modelos:\n",
    "            matriz_comparaciones.loc[m1, m2] += 1\n",
    "            matriz_comparaciones.loc[m2, m1] += 1\n",
    "            \n",
    "            if row['Significativo']:\n",
    "                if row['Ganador'] == m1:\n",
    "                    matriz_victorias.loc[m1, m2] += 1\n",
    "                elif row['Ganador'] == m2:\n",
    "                    matriz_victorias.loc[m2, m1] += 1\n",
    "                # Empates no a√±aden victorias\n",
    "    \n",
    "    # ‚úÖ CORRECCI√ìN: Calcular m√©tricas de ranking mejoradas\n",
    "    ranking_data = []\n",
    "    for modelo in modelos:\n",
    "        victorias = matriz_victorias.loc[modelo].sum()\n",
    "        comparaciones_totales = matriz_comparaciones.loc[modelo].sum()\n",
    "        \n",
    "        # Evitar divisi√≥n por cero\n",
    "        if comparaciones_totales > 0:\n",
    "            porcentaje_victorias = (victorias / comparaciones_totales) * 100\n",
    "        else:\n",
    "            porcentaje_victorias = 0\n",
    "        \n",
    "        # Calcular score basado en victorias netas\n",
    "        derrotas = matriz_victorias.loc[:, modelo].sum()  # Victorias de otros sobre este modelo\n",
    "        score_neto = victorias - derrotas\n",
    "        \n",
    "        ranking_data.append({\n",
    "            'Modelo': modelo,\n",
    "            'Victorias': int(victorias),\n",
    "            'Derrotas': int(derrotas),\n",
    "            'Comparaciones_Totales': int(comparaciones_totales),\n",
    "            'Porcentaje_Victorias': round(porcentaje_victorias, 2),\n",
    "            'Score_Neto': int(score_neto)\n",
    "        })\n",
    "    \n",
    "    df_ranking = pd.DataFrame(ranking_data)\n",
    "    \n",
    "    # ‚úÖ CORRECCI√ìN: Ordenar por m√∫ltiples criterios\n",
    "    df_ranking = df_ranking.sort_values(\n",
    "        ['Score_Neto', 'Porcentaje_Victorias', 'Victorias'], \n",
    "        ascending=[False, False, False]\n",
    "    ).reset_index(drop=True)\n",
    "    \n",
    "    df_ranking['Rank'] = range(1, len(df_ranking) + 1)\n",
    "    \n",
    "    # Reordenar columnas\n",
    "    column_order = ['Rank', 'Modelo', 'Score_Neto', 'Porcentaje_Victorias', \n",
    "                   'Victorias', 'Derrotas', 'Comparaciones_Totales']\n",
    "    df_ranking = df_ranking[column_order]\n",
    "    \n",
    "    return df_ranking, matriz_victorias\n",
    "\n",
    "def verificar_resultados_dm(df, modelos, top_n=3):\n",
    "    \"\"\"\n",
    "    CORRECCI√ìN: Verificaci√≥n m√°s completa y robusta\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üîç VERIFICACI√ìN COMPLETA DE RESULTADOS DM\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # 1. Estad√≠sticas descriptivas robustas\n",
    "    print(\"\\nüìä ESTAD√çSTICAS DESCRIPTIVAS (ECRPS - menor = mejor):\")\n",
    "    stats_df = df[modelos].describe(percentiles=[.25, .5, .75]).T\n",
    "    stats_df['IQR'] = stats_df['75%'] - stats_df['25%']\n",
    "    \n",
    "    print(stats_df[['mean', '50%', 'std', 'IQR']].round(6))\n",
    "    \n",
    "    # 2. Ranking por mediana\n",
    "    medianas = df[modelos].median().sort_values()\n",
    "    print(f\"\\nüèÜ RANKING POR MEDIANA:\")\n",
    "    for i, (modelo, mediana) in enumerate(medianas.items(), 1):\n",
    "        print(f\"  {i:2d}. {modelo:20s}: {mediana:.6f}\")\n",
    "    \n",
    "    # 3. Test DM y ranking\n",
    "    print(f\"\\nüìà REALIZANDO TEST DIEBOLD-MARIANO...\")\n",
    "    df_comp, alpha_bonf = comparaciones_multiples_dm(df, modelos, loss_function='none')\n",
    "    \n",
    "    if df_comp.empty:\n",
    "        print(\"‚ùå No se pudieron realizar comparaciones DM\")\n",
    "        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "    \n",
    "    df_ranking, matriz = calcular_ranking_dm(df_comp, modelos)\n",
    "    \n",
    "    print(f\"\\nüèÜ RANKING SEG√öN TEST DM (Œ±={alpha_bonf:.6f}):\")\n",
    "    for _, row in df_ranking.head(top_n).iterrows():\n",
    "        print(f\"  {row['Rank']:2d}. {row['Modelo']:20s} \"\n",
    "              f\"(Score: {row['Score_Neto']:3d}, Victorias: {row['Victorias']:2d}/{row['Comparaciones_Totales']:2d})\")\n",
    "    \n",
    "    # 4. Verificar consistencia entre m√©todos\n",
    "    print(\"\\nüîç VERIFICACI√ìN DE CONSISTENCIA:\")\n",
    "    top_dm = set(df_ranking.head(top_n)['Modelo'])\n",
    "    top_mediana = set(medianas.head(top_n).index)\n",
    "    \n",
    "    coincidencias = top_dm.intersection(top_mediana)\n",
    "    if len(coincidencias) == top_n:\n",
    "        print(\"  ‚úÖ Consistencia PERFECTA entre DM y medianas\")\n",
    "    else:\n",
    "        print(f\"  ‚ö†Ô∏è Consistencia PARCIAL: {len(coincidencias)}/{top_n} coincidencias\")\n",
    "        if top_dm - top_mediana:\n",
    "            print(f\"     - Solo en Top DM: {top_dm - top_mediana}\")\n",
    "        if top_mediana - top_dm:\n",
    "            print(f\"     - Solo en Top Mediana: {top_mediana - top_dm}\")\n",
    "    \n",
    "    # 5. Resumen de comparaciones significativas\n",
    "    print(f\"\\nüìã RESUMEN COMPARACIONES SIGNIFICATIVAS:\")\n",
    "    sig_comparisons = df_comp[df_comp['Significativo']]\n",
    "    if not sig_comparisons.empty:\n",
    "        for _, row in sig_comparisons.iterrows():\n",
    "            print(f\"  ‚úÖ {row['Explicacion']}\")\n",
    "    else:\n",
    "        print(\"  ‚ö†Ô∏è No hay comparaciones significativas\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "    return df_ranking, matriz, df_comp\n",
    "\n",
    "# ============================================================================\n",
    "# CLASE PRINCIPAL DE AN√ÅLISIS\n",
    "# ============================================================================\n",
    "\n",
    "class AnalizadorBaseCompleta:\n",
    "\n",
    "    def __init__(self, ruta_datos):\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"INICIANDO AN√ÅLISIS ESTAD√çSTICO ROBUSTO (GENERAL + DESAGREGADO + EXCEL)\")\n",
    "        print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "        self.df = pd.read_excel(ruta_datos)\n",
    "        \n",
    "        if 'proces_simulacion' in self.df.columns:\n",
    "            self.df['Tipo de Modelo'] = self.df['proces_simulacion']\n",
    "        else:\n",
    "            raise ValueError(\"No se encontr√≥ 'proces_simulacion' en el Excel.\")\n",
    "\n",
    "        self.modelos = MODELOS\n",
    "        self.dir_salida = Path(DIR_SALIDA)\n",
    "        self.dir_salida.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        self._extraer_caracteristicas()\n",
    "        self._preparar_escenarios()\n",
    "        self.preprocessor, self.X_processed = self._preprocess_meta_features()\n",
    "        self.meta_models = {} \n",
    "\n",
    "        print(f\"‚úì Datos cargados: {self.df.shape[0]} filas\")\n",
    "        print(f\"‚úì Directorio: {self.dir_salida}\")\n",
    "        print(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
    "\n",
    "    def _extraer_caracteristicas(self):\n",
    "        grupo_a = ['AR(1)', 'AR(2)', 'MA(1)', 'MA(2)', 'ARMA(1,1)', 'ARMA(2,2)', 'ARMA(2,1)']\n",
    "        grupo_b = ['ARIMA(0,1,0)', 'ARIMA(1,1,0)', 'ARIMA(2,1,0)', 'ARIMA(0,1,1)', 'ARIMA(0,1,2)', 'ARIMA(1,1,1)', 'ARIMA(2,1,2)']\n",
    "        grupo_c = ['SETAR-1', 'SETAR-2', 'SETAR-3', 'SETAR-4', 'SETAR-5', 'SETAR-6', 'SETAR-7']\n",
    "\n",
    "        def clasificar_est(m):\n",
    "            m = str(m).strip()\n",
    "            if m in grupo_a or m in grupo_c: return 'Estacionario'\n",
    "            elif m in grupo_b: return 'No Estacionario'\n",
    "            return 'Desconocido'\n",
    "\n",
    "        def clasificar_lin(m):\n",
    "            m = str(m).strip()\n",
    "            if m in grupo_a or m in grupo_b: return 'Lineal'\n",
    "            elif m in grupo_c: return 'No Lineal'\n",
    "            return 'Desconocido'\n",
    "\n",
    "        self.df['Estacionario'] = self.df['Tipo de Modelo'].apply(clasificar_est)\n",
    "        self.df['Lineal'] = self.df['Tipo de Modelo'].apply(clasificar_lin)\n",
    "\n",
    "    def _preparar_escenarios(self):\n",
    "        self.df['Escenario_Combinado'] = self.df['Estacionario'] + ' - ' + self.df['Lineal']\n",
    "        mapa_nombres = {\n",
    "            'Estacionario - Lineal': 'Estacionario - Lineal (ARMA)',\n",
    "            'No Estacionario - Lineal': 'No Estacionario - Lineal (ARIMA)',\n",
    "            'Estacionario - No Lineal': 'Estacionario - No Lineal (SETAR)'\n",
    "        }\n",
    "        self.df['Escenario_Combinado'] = self.df['Escenario_Combinado'].replace(mapa_nombres)\n",
    "        self.escenarios_unicos = sorted(self.df['Escenario_Combinado'].unique())\n",
    "\n",
    "    def _preprocess_meta_features(self):\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', 'passthrough', CARACTERISTICAS_NUMERICAS_META_MODELO),\n",
    "                ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), CARACTERISTICAS_CATEGORICAS_META_MODELO)\n",
    "            ], remainder='drop'\n",
    "        )\n",
    "        X = self.df[CARACTERISTICAS_META_MODELO]\n",
    "        X_processed = preprocessor.fit_transform(X)\n",
    "        try:\n",
    "            names = list(CARACTERISTICAS_NUMERICAS_META_MODELO) + list(preprocessor.named_transformers_['cat'].get_feature_names_out())\n",
    "        except:\n",
    "            names = list(CARACTERISTICAS_NUMERICAS_META_MODELO) + list(preprocessor.named_transformers_['cat'].get_feature_names())\n",
    "        return preprocessor, pd.DataFrame(X_processed, columns=names)\n",
    "\n",
    "    def ejecutar_analisis_completo(self):\n",
    "        print(\"1Ô∏è‚É£  Analizando Escenarios (M√©tricas Robustas)...\")\n",
    "        self._analisis_estacionariedad() \n",
    "\n",
    "        print(\"3Ô∏è‚É£  Analizando Modelo Generador (IQR)...\")\n",
    "        self._analisis_modelo_generador()\n",
    "\n",
    "        print(\"4Ô∏è‚É£  Analizando Distribuci√≥n...\")\n",
    "        self._analisis_distribucion()\n",
    "\n",
    "        print(\"5Ô∏è‚É£  Analizando Varianza (Pendiente Theil-Sen)...\")\n",
    "        self._analisis_varianza()\n",
    "\n",
    "        print(\"6Ô∏è‚É£  Analizando Horizonte (Pendiente Theil-Sen)...\")\n",
    "        self._analisis_horizonte()\n",
    "\n",
    "        print(\"7Ô∏è‚É£  Analizando Robustez (QCD)...\")\n",
    "        self._analisis_robustez()\n",
    "\n",
    "        print(\"8Ô∏è‚É£  Analizando Significancia DM y Generando Excel...\")\n",
    "        self._analisis_significancia()\n",
    "\n",
    "        print(\"\\n‚úÖ AN√ÅLISIS FINALIZADO\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # 1. ESCENARIOS \n",
    "    # ========================================================================\n",
    "    def _analisis_estacionariedad(self):\n",
    "        stats_esc = []\n",
    "        for modelo in self.modelos:\n",
    "            for esc in self.escenarios_unicos:\n",
    "                df_subset = self.df[self.df['Escenario_Combinado'] == esc]\n",
    "                if not df_subset.empty:\n",
    "                    stats_esc.append({\n",
    "                        'Modelo': modelo, 'Escenario': esc,\n",
    "                        'Mediana': df_subset[modelo].median() \n",
    "                    })\n",
    "        \n",
    "        df_stats = pd.DataFrame(stats_esc)\n",
    "        if df_stats.empty: return\n",
    "\n",
    "        # 1.1 Rendimiento\n",
    "        fig, ax = plt.subplots(figsize=(16, 9))\n",
    "        pivot_mediana = df_stats.pivot(index='Modelo', columns='Escenario', values='Mediana')\n",
    "        colores = {'Estacionario - Lineal (ARMA)': '#2E7D32', 'Estacionario - No Lineal (SETAR)': '#66BB6A', 'No Estacionario - Lineal (ARIMA)': '#F57C00'}\n",
    "        pivot_mediana.plot(kind='bar', ax=ax, width=0.8, color=[colores.get(c, '#333') for c in pivot_mediana.columns])\n",
    "        ax.set_title('1.1 Rendimiento por Escenario (Mediana ECRPS - Robusto)', fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '1_1_escenarios_rendimiento_mediana.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        # 1.2 Relativo\n",
    "        baseline = 'Estacionario - Lineal (ARMA)'\n",
    "        if baseline in pivot_mediana.columns and pivot_mediana.shape[1] > 1:\n",
    "            fig, ax = plt.subplots(figsize=(14, 10))\n",
    "            df_rel = pivot_mediana.copy()\n",
    "            for col in df_rel.columns:\n",
    "                base_val = pivot_mediana[baseline]\n",
    "                df_rel[col] = np.where(base_val > 1e-6, (df_rel[col] - base_val) / base_val * 100, 0)\n",
    "            df_rel = df_rel.drop(columns=[baseline], errors='ignore')\n",
    "            df_rel.plot(kind='barh', ax=ax, width=0.7)\n",
    "            ax.set_title('1.2 Deterioro Relativo de la Mediana vs Base (%)', fontweight='bold')\n",
    "            ax.axvline(0, color='k')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(self.dir_salida / '1_2_escenarios_cambio_relativo_robusto.png', dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "    def _analisis_linealidad(self): pass\n",
    "\n",
    "    # ========================================================================\n",
    "    # 3. MODELO GENERADOR\n",
    "    # ========================================================================\n",
    "    def _analisis_modelo_generador(self):\n",
    "        def plot_mg(df_curr, suffix):\n",
    "            if df_curr.empty: return\n",
    "            pivot_vals = df_curr.groupby('Tipo de Modelo')[self.modelos].median()\n",
    "            tipos = df_curr['Tipo de Modelo'].unique()\n",
    "            if len(tipos) < 1: return\n",
    "\n",
    "            # 3.2 Z-Score\n",
    "            fig, ax = plt.subplots(figsize=(18, 10))\n",
    "            row_medians = pivot_vals.T.median(axis=1)\n",
    "            row_stds = pivot_vals.T.std(axis=1)\n",
    "            row_stds[row_stds == 0] = 1 \n",
    "            pivot_norm = pivot_vals.T.sub(row_medians, axis=0).div(row_stds, axis=0)\n",
    "            sns.heatmap(pivot_norm, annot=True, fmt='.2f', cmap='RdBu_r', center=0, ax=ax)\n",
    "            ax.set_title(f'3.2 Z-Score Rendimiento Mediano ({suffix})', fontweight='bold')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(self.dir_salida / f'3_2_modelo_generador_zscore_{suffix}.png', dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "            # 3.3 Variabilidad\n",
    "            fig, ax = plt.subplots(figsize=(12, 8))\n",
    "            iqr_data = []\n",
    "            for t in tipos:\n",
    "                data_tipo = df_curr[df_curr['Tipo de Modelo'] == t][self.modelos]\n",
    "                iqrs_modelos = []\n",
    "                for mod in self.modelos:\n",
    "                    q75, q25 = np.percentile(data_tipo[mod].dropna(), [75 ,25])\n",
    "                    iqrs_modelos.append(q75 - q25)\n",
    "                iqr_data.append({'Tipo': t, 'IQR_Promedio': np.mean(iqrs_modelos)})\n",
    "            if iqr_data:\n",
    "                df_iqr = pd.DataFrame(iqr_data).sort_values('IQR_Promedio')\n",
    "                ax.barh(df_iqr['Tipo'], df_iqr['IQR_Promedio'], color='steelblue', alpha=0.7)\n",
    "                ax.set_title(f'3.3 Variabilidad Robusta (IQR Promedio) ({suffix})', fontweight='bold')\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(self.dir_salida / f'3_3_modelo_generador_variabilidad_iqr_{suffix}.png', dpi=300)\n",
    "                plt.close()\n",
    "\n",
    "        plot_mg(self.df, \"General\")\n",
    "        for esc in self.escenarios_unicos:\n",
    "            df_esc = self.df[self.df['Escenario_Combinado'] == esc]\n",
    "            clean_name = esc.replace(' ', '_').replace('(', '').replace(')', '').replace('-', '')\n",
    "            plot_mg(df_esc, clean_name)\n",
    "\n",
    "    # ========================================================================\n",
    "    # 4. DISTRIBUCI√ìN\n",
    "    # ========================================================================\n",
    "    def _analisis_distribucion(self):\n",
    "        def plot_dist(df_curr, suffix):\n",
    "            if df_curr.empty: return\n",
    "            pivot_med = df_curr.groupby('Distribuci√≥n')[self.modelos].median()\n",
    "            pivot_iqr = pd.DataFrame(index=df_curr['Distribuci√≥n'].unique(), columns=self.modelos)\n",
    "            for dist in pivot_iqr.index:\n",
    "                for mod in self.modelos:\n",
    "                    subset = df_curr[df_curr['Distribuci√≥n'] == dist][mod].dropna()\n",
    "                    if not subset.empty:\n",
    "                        q75, q25 = np.percentile(subset, [75, 25])\n",
    "                        pivot_iqr.loc[dist, mod] = q75 - q25\n",
    "            pivot_iqr = pivot_iqr.astype(float)\n",
    "            if pivot_med.empty: return\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(14, 10))\n",
    "            sns.heatmap(pivot_med.T, annot=True, fmt='.3f', cmap='RdYlGn_r', ax=ax)\n",
    "            ax.set_title(f'4.1 Mediana ECRPS por Distribuci√≥n ({suffix})', fontweight='bold')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(self.dir_salida / f'4_1_distribucion_heatmap_rendimiento_{suffix}.png', dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(14, 10))\n",
    "            sns.heatmap(pivot_iqr.T, annot=True, fmt='.3f', cmap='YlOrRd', ax=ax)\n",
    "            ax.set_title(f'4.2 Variabilidad Robusta (IQR) por Distribuci√≥n ({suffix})', fontweight='bold')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(self.dir_salida / f'4_2_distribucion_heatmap_variabilidad_{suffix}.png', dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "        plot_dist(self.df, \"General\")\n",
    "        for esc in self.escenarios_unicos:\n",
    "            df_esc = self.df[self.df['Escenario_Combinado'] == esc]\n",
    "            clean_name = esc.replace(' ', '_').replace('(', '').replace(')', '').replace('-', '')\n",
    "            plot_dist(df_esc, clean_name)\n",
    "\n",
    "    # ========================================================================\n",
    "    # 5. VARIANZA\n",
    "    # ========================================================================\n",
    "    def _analisis_varianza(self):\n",
    "        varianzas = sorted(self.df['Varianza error'].unique())\n",
    "        \n",
    "        def plot_varianza(df_curr, suffix, title_extra):\n",
    "            if df_curr.empty: return\n",
    "            \n",
    "            # 5.1 Tendencias\n",
    "            fig, ax = plt.subplots(figsize=(14, 8))\n",
    "            for modelo in self.modelos:\n",
    "                medianas = []\n",
    "                vars_presentes = []\n",
    "                for v in varianzas:\n",
    "                    subset = df_curr[df_curr['Varianza error'] == v][modelo]\n",
    "                    if not subset.empty:\n",
    "                        medianas.append(subset.median())\n",
    "                        vars_presentes.append(v)\n",
    "                if medianas:\n",
    "                    ax.plot(vars_presentes, medianas, marker='o', label=modelo, color=COLORES_MODELOS[modelo])\n",
    "            ax.set_title(f'5.1 Deterioro Varianza (Mediana) - {title_extra}', fontweight='bold')\n",
    "            ax.legend(bbox_to_anchor=(1.01, 1))\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(self.dir_salida / f'5_1_varianza_tendencias_{suffix}.png', dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "            # 5.2 Tasas\n",
    "            fig, ax = plt.subplots(figsize=(12, 8))\n",
    "            tasas_theil = {}\n",
    "            for modelo in self.modelos:\n",
    "                datos_mod = df_curr[['Varianza error', modelo]].dropna()\n",
    "                if len(datos_mod) > 2:\n",
    "                    x = datos_mod['Varianza error'].values\n",
    "                    y = datos_mod[modelo].values\n",
    "                    res = stats.theilslopes(y, x, alpha=0.95)\n",
    "                    tasas_theil[modelo] = res[0]\n",
    "            if tasas_theil:\n",
    "                tasas_theil = dict(sorted(tasas_theil.items(), key=lambda x: x[1]))\n",
    "                vals = list(tasas_theil.values())\n",
    "                median_slope = np.median(vals)\n",
    "                colors = ['green' if v < median_slope else 'red' for v in vals]\n",
    "                ax.barh(list(tasas_theil.keys()), vals, color=colors, alpha=0.7, edgecolor='k')\n",
    "                ax.set_title(f'5.2 Sensibilidad Ruido (Pendiente Theil-Sen) - {title_extra}', fontweight='bold')\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(self.dir_salida / f'5_2_varianza_tasa_{suffix}.png', dpi=300)\n",
    "                plt.close()\n",
    "\n",
    "        plot_varianza(self.df, \"General\", \"Todos los datos\")\n",
    "        for esc in self.escenarios_unicos:\n",
    "            df_esc = self.df[self.df['Escenario_Combinado'] == esc]\n",
    "            clean_name = esc.replace(' ', '_').replace('(', '').replace(')', '').replace('-', '')\n",
    "            plot_varianza(df_esc, clean_name, esc)\n",
    "\n",
    "    # ========================================================================\n",
    "    # 6. HORIZONTE\n",
    "    # ========================================================================\n",
    "    def _analisis_horizonte(self):\n",
    "        def plot_horizonte(df_curr, suffix, title_extra):\n",
    "            if df_curr.empty: return\n",
    "            \n",
    "            # 6.1 Evoluci√≥n\n",
    "            fig, ax = plt.subplots(figsize=(14, 8))\n",
    "            for modelo in self.modelos:\n",
    "                medianas = df_curr.groupby('Paso')[modelo].median()\n",
    "                ax.plot(medianas.index, medianas.values, marker='o', label=modelo, color=COLORES_MODELOS[modelo], linewidth=2)\n",
    "            ax.set_title(f'6.1 Evoluci√≥n por Horizonte (Mediana) ({title_extra})', fontweight='bold')\n",
    "            ax.legend(bbox_to_anchor=(1.01, 1))\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(self.dir_salida / f'6_1_horizonte_evolucion_{suffix}.png', dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "            # 6.2 Deterioro\n",
    "            fig, ax = plt.subplots(figsize=(12, 8))\n",
    "            deterioros = {}\n",
    "            for modelo in self.modelos:\n",
    "                datos_mod = df_curr[['Paso', modelo]].dropna()\n",
    "                if len(datos_mod) > 5: \n",
    "                    x = datos_mod['Paso'].values\n",
    "                    y = datos_mod[modelo].values\n",
    "                    res = stats.theilslopes(y, x, alpha=0.95)\n",
    "                    deterioros[modelo] = res[0]\n",
    "            if deterioros:\n",
    "                deterioros = dict(sorted(deterioros.items(), key=lambda x: x[1]))\n",
    "                median_val = np.median(list(deterioros.values()))\n",
    "                colors = ['green' if v < median_val else 'red' for v in deterioros.values()]\n",
    "                ax.barh(list(deterioros.keys()), list(deterioros.values()), color=colors, alpha=0.7, edgecolor='k')\n",
    "                ax.set_title(f'6.2 Velocidad de Deterioro (Pendiente Theil-Sen) ({title_extra})', fontweight='bold')\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(self.dir_salida / f'6_2_horizonte_tasa_{suffix}.png', dpi=300)\n",
    "                plt.close()\n",
    "\n",
    "        plot_horizonte(self.df, \"General\", \"Todos los datos\")\n",
    "        for esc in self.escenarios_unicos:\n",
    "            df_esc = self.df[self.df['Escenario_Combinado'] == esc]\n",
    "            clean_name = esc.replace(' ', '_').replace('(', '').replace(')', '').replace('-', '')\n",
    "            plot_horizonte(df_esc, clean_name, esc)\n",
    "\n",
    "    # ========================================================================\n",
    "    # 7. ROBUSTEZ\n",
    "    # ========================================================================\n",
    "    def _analisis_robustez(self):\n",
    "        metricas = []\n",
    "        for modelo in self.modelos:\n",
    "            datos = self.df[modelo].dropna()\n",
    "            if len(datos) > 0:\n",
    "                q75, q25 = np.percentile(datos, [75, 25])\n",
    "                if (q75 + q25) > 0:\n",
    "                    qcd = (q75 - q25) / (q75 + q25)\n",
    "                    metricas.append({'Modelo': modelo, 'QCD': qcd})\n",
    "        df_r = pd.DataFrame(metricas).sort_values('QCD')\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        colors = plt.cm.RdYlGn(np.linspace(0.8, 0.2, len(df_r)))\n",
    "        bars = ax.barh(df_r['Modelo'], df_r['QCD'], color=colors, edgecolor='k')\n",
    "        for i, (bar, val) in enumerate(zip(bars, df_r['QCD'])):\n",
    "            ax.text(val, i, f'{val:.3f}', va='center', fontweight='bold')\n",
    "        ax.set_title('7.2 Robustez (Coeficiente de Dispersi√≥n por Cuartiles - QCD)', fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '7_2_robustez_general_qcd.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    # ========================================================================\n",
    "    # 8. SIGNIFICANCIA (HEATMAP + EXCEL)\n",
    "    # ========================================================================\n",
    "    def _analisis_significancia(self):\n",
    "        \"\"\"Versi√≥n corregida del an√°lisis de significancia\"\"\"\n",
    "        \n",
    "        nombre_excel = self.dir_salida / \"Tabla_Victorias_DM_CORREGIDO.xlsx\"\n",
    "        \n",
    "        sheet_mapping = {\n",
    "            'General': 'General',\n",
    "            'Estacionario - Lineal (ARMA)': 'Est_Lin_ARMA',\n",
    "            'No Estacionario - Lineal (ARIMA)': 'NoEst_Lin_ARIMA',\n",
    "            'Estacionario - No Lineal (SETAR)': 'Est_NoLin_SETAR'\n",
    "        }\n",
    "\n",
    "        with pd.ExcelWriter(nombre_excel, engine='openpyxl') as writer:\n",
    "            \n",
    "            def procesar_dm(df_curr, suffix, sheet_name_full):\n",
    "                if df_curr.empty or len(df_curr) < 10: \n",
    "                    print(f\"   ‚ö†Ô∏è Saltando DM para {suffix} (Datos insuficientes)\")\n",
    "                    return\n",
    "\n",
    "                print(f\"\\n   {'='*60}\")\n",
    "                print(f\"   Procesando: {suffix}\")\n",
    "                print(f\"   {'='*60}\")\n",
    "                \n",
    "                # ‚úÖ USAR FUNCI√ìN DE VERIFICACI√ìN\n",
    "                df_ranking, matriz, df_comp = verificar_resultados_dm(\n",
    "                    df_curr, self.modelos, top_n=3\n",
    "                )\n",
    "                \n",
    "                if df_comp.empty: \n",
    "                    print(f\"   ‚ö†Ô∏è No se pudieron realizar comparaciones para {suffix}\")\n",
    "                    return\n",
    "                \n",
    "                # Guardar en Excel\n",
    "                safe_sheet_name = sheet_mapping.get(sheet_name_full, suffix[:30])\n",
    "                df_ranking.to_excel(writer, sheet_name=safe_sheet_name, index=False)\n",
    "                \n",
    "                # Matriz de superioridad\n",
    "                fig, ax = plt.subplots(figsize=(12, 10))\n",
    "                sns.heatmap(matriz, annot=True, fmt='.0f', cmap='RdYlGn', center=0, ax=ax,\n",
    "                            cbar_kws={'label': 'Superioridad (1=Gana Fila, -1=Gana Col)'})\n",
    "                ax.set_title(f'Matriz Superioridad DM ({suffix})', fontweight='bold')\n",
    "                plt.tight_layout()\n",
    "                clean_filename = suffix.replace(' ', '_').replace('(', '').replace(')', '').replace('-', '')\n",
    "                plt.savefig(self.dir_salida / f'8_2_significancia_matriz_{clean_filename}.png', dpi=300)\n",
    "                plt.close()\n",
    "\n",
    "            # Procesar general y desagregado\n",
    "            procesar_dm(self.df, \"General\", \"General\")\n",
    "            \n",
    "            for esc in self.escenarios_unicos:\n",
    "                df_esc = self.df[self.df['Escenario_Combinado'] == esc]\n",
    "                procesar_dm(df_esc, esc, esc)\n",
    "        \n",
    "        print(f\"\\n   üìä Excel corregido generado: {nombre_excel}\")\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN\n",
    "# ============================================================================\n",
    "def main():\n",
    "    try:\n",
    "        analizador = AnalizadorBaseCompleta(RUTA_DATOS)\n",
    "        analizador.ejecutar_analisis_completo()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"\\n‚ùå ERROR: No archivo {RUTA_DATOS}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå ERROR: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac856124",
   "metadata": {},
   "source": [
    "## Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60de153b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos...\n",
      "Modelos a comparar: ['AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', 'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
      "Escenarios encontrados: ['Lineal - estacionario' 'Lineal - NO estacionario'\n",
      " 'NO lineal - estacionario']\n",
      "\n",
      "================================================================================\n",
      "PROCESANDO AN√ÅLISIS GENERAL (TODOS LOS ESCENARIOS)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "DM - Procesando: General\n",
      "Observaciones: 5040\n",
      "Alpha (Bonferroni): 0.001389\n",
      "\n",
      "================================================================================\n",
      "MEDIA - Procesando: General\n",
      "Observaciones: 5040\n",
      "\n",
      "================================================================================\n",
      "DM - Procesando: Lineal - estacionario (ARMA)\n",
      "Observaciones: 1680\n",
      "Alpha (Bonferroni): 0.001389\n",
      "\n",
      "================================================================================\n",
      "MEDIA - Procesando: Lineal - estacionario (ARMA)\n",
      "Observaciones: 1680\n",
      "\n",
      "================================================================================\n",
      "DM - Procesando: Lineal - NO estacionario (ARIMA)\n",
      "Observaciones: 1680\n",
      "Alpha (Bonferroni): 0.001389\n",
      "\n",
      "================================================================================\n",
      "MEDIA - Procesando: Lineal - NO estacionario (ARIMA)\n",
      "Observaciones: 1680\n",
      "\n",
      "================================================================================\n",
      "DM - Procesando: NO lineal - estacionario (SETAR)\n",
      "Observaciones: 1680\n",
      "Alpha (Bonferroni): 0.001389\n",
      "\n",
      "================================================================================\n",
      "MEDIA - Procesando: NO lineal - estacionario (SETAR)\n",
      "Observaciones: 1680\n",
      "\n",
      "================================================================================\n",
      "GUARDANDO RESULTADOS EN EXCEL\n",
      "================================================================================\n",
      "Rankings DM guardados en: resultados_rankings_comparacion\\ranking_modelos_DM.xlsx\n",
      "Rankings MEDIA guardados en: resultados_rankings_comparacion\\ranking_modelos_MEDIA.xlsx\n",
      "\n",
      "================================================================================\n",
      "GENERANDO VISUALIZACIONES - HEATMAPS INDIVIDUALES\n",
      "================================================================================\n",
      "Heatmap DM guardado: resultados_rankings_comparacion\\matriz_DM_General.png\n",
      "Heatmap DM guardado: resultados_rankings_comparacion\\matriz_DM_Lineal_-_estacionario_ARMA.png\n",
      "Heatmap DM guardado: resultados_rankings_comparacion\\matriz_DM_Lineal_-_NO_estacionario_ARIMA.png\n",
      "Heatmap DM guardado: resultados_rankings_comparacion\\matriz_DM_NO_lineal_-_estacionario_SETAR.png\n",
      "Heatmap MEDIA guardado: resultados_rankings_comparacion\\matriz_MEDIA_General.png\n",
      "Heatmap MEDIA guardado: resultados_rankings_comparacion\\matriz_MEDIA_Lineal_-_estacionario_ARMA.png\n",
      "Heatmap MEDIA guardado: resultados_rankings_comparacion\\matriz_MEDIA_Lineal_-_NO_estacionario_ARIMA.png\n",
      "Heatmap MEDIA guardado: resultados_rankings_comparacion\\matriz_MEDIA_NO_lineal_-_estacionario_SETAR.png\n",
      "\n",
      "================================================================================\n",
      "RESUMEN FINAL - COMPARACI√ìN DE M√âTODOS\n",
      "================================================================================\n",
      "\n",
      "General:\n",
      "  Top 3 - Diebold-Mariano:\n",
      "    1. Sieve Bootstrap: Score=8, V=8, E=0, D=0 (100.0%)\n",
      "    2. LSPM: Score=6, V=7, E=0, D=1 (87.5%)\n",
      "    3. MCPS: Score=2, V=4, E=2, D=2 (50.0%)\n",
      "  Top 3 - Media Simple:\n",
      "    1. Sieve Bootstrap: Score=8, V=8, E=0, D=0 (100.0%)\n",
      "    2. LSPM: Score=6, V=7, E=0, D=1 (87.5%)\n",
      "    3. MCPS: Score=4, V=6, E=0, D=2 (75.0%)\n",
      "\n",
      "Lineal - estacionario (ARMA):\n",
      "  Top 3 - Diebold-Mariano:\n",
      "    1. DeepAR: Score=7, V=7, E=1, D=0 (87.5%)\n",
      "    2. Sieve Bootstrap: Score=7, V=7, E=1, D=0 (87.5%)\n",
      "    3. MCPS: Score=2, V=4, E=2, D=2 (50.0%)\n",
      "  Top 3 - Media Simple:\n",
      "    1. Sieve Bootstrap: Score=8, V=8, E=0, D=0 (100.0%)\n",
      "    2. DeepAR: Score=6, V=7, E=0, D=1 (87.5%)\n",
      "    3. AV-MCPS: Score=4, V=6, E=0, D=2 (75.0%)\n",
      "\n",
      "Lineal - NO estacionario (ARIMA):\n",
      "  Top 3 - Diebold-Mariano:\n",
      "    1. Sieve Bootstrap: Score=8, V=8, E=0, D=0 (100.0%)\n",
      "    2. LSPM: Score=6, V=7, E=0, D=1 (87.5%)\n",
      "    3. MCPS: Score=2, V=4, E=2, D=2 (50.0%)\n",
      "  Top 3 - Media Simple:\n",
      "    1. Sieve Bootstrap: Score=8, V=8, E=0, D=0 (100.0%)\n",
      "    2. LSPM: Score=6, V=7, E=0, D=1 (87.5%)\n",
      "    3. MCPS: Score=4, V=6, E=0, D=2 (75.0%)\n",
      "\n",
      "NO lineal - estacionario (SETAR):\n",
      "  Top 3 - Diebold-Mariano:\n",
      "    1. Block Bootstrapping: Score=5, V=5, E=3, D=0 (62.5%)\n",
      "    2. DeepAR: Score=5, V=5, E=3, D=0 (62.5%)\n",
      "    3. Sieve Bootstrap: Score=4, V=4, E=4, D=0 (50.0%)\n",
      "  Top 3 - Media Simple:\n",
      "    1. DeepAR: Score=8, V=8, E=0, D=0 (100.0%)\n",
      "    2. Sieve Bootstrap: Score=6, V=7, E=0, D=1 (87.5%)\n",
      "    3. Block Bootstrapping: Score=4, V=6, E=0, D=2 (75.0%)\n",
      "\n",
      "================================================================================\n",
      "ARCHIVOS GENERADOS\n",
      "================================================================================\n",
      "üìÅ Directorio: resultados_rankings_comparacion\n",
      "üìä Excel DM: ranking_modelos_DM.xlsx (4 hojas)\n",
      "üìä Excel MEDIA: ranking_modelos_MEDIA.xlsx (4 hojas)\n",
      "üñºÔ∏è  Heatmaps DM individuales: matriz_DM_[escenario].png (4 archivos)\n",
      "üñºÔ∏è  Heatmaps MEDIA individuales: matriz_MEDIA_[escenario].png (4 archivos)\n",
      "   Total: 8 heatmaps individuales\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Crear carpeta de resultados si no existe\n",
    "output_dir = Path(\"./resultados_rankings_comparacion\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Configuraci√≥n\n",
    "archivo_excel = \"./Base_140_3_escenarios.xlsx\"\n",
    "MODELOS = ['AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR',\n",
    "           'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
    "\n",
    "# Mapeo de nombres de escenarios\n",
    "ESCENARIOS_MAP = {\n",
    "    'Lineal - estacionario': 'Lineal - estacionario (ARMA)',\n",
    "    'Lineal - NO estacionario': 'Lineal - NO estacionario (ARIMA)',\n",
    "    'NO lineal - estacionario': 'NO lineal - estacionario (SETAR)'\n",
    "}\n",
    "\n",
    "# Cargar datos\n",
    "print(\"Cargando datos...\")\n",
    "df = pd.read_excel(archivo_excel)\n",
    "\n",
    "# Verificar columnas\n",
    "columnas_faltantes = [modelo for modelo in MODELOS if modelo not in df.columns]\n",
    "if columnas_faltantes:\n",
    "    print(f\"Advertencia: Las siguientes columnas no se encontraron: {columnas_faltantes}\")\n",
    "    MODELOS = [m for m in MODELOS if m in df.columns]\n",
    "\n",
    "if 'ESCENARIO' not in df.columns:\n",
    "    raise ValueError(\"La columna 'ESCENARIO' no se encontr√≥ en el archivo Excel\")\n",
    "\n",
    "print(f\"Modelos a comparar: {MODELOS}\")\n",
    "print(f\"Escenarios encontrados: {df['ESCENARIO'].unique()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# FUNCIONES PARA AN√ÅLISIS CON DIEBOLD-MARIANO (CON SIGNIFICANCIA)\n",
    "# ============================================================================\n",
    "\n",
    "def diebold_mariano_test(errors1, errors2):\n",
    "    \"\"\"Test de Diebold-Mariano para comparar dos series de errores.\"\"\"\n",
    "    d = errors1**2 - errors2**2\n",
    "    d = d.dropna()\n",
    "    \n",
    "    if len(d) < 2:\n",
    "        return np.nan, np.nan\n",
    "    \n",
    "    d_mean = d.mean()\n",
    "    n = len(d)\n",
    "    d_var = d.var() / n\n",
    "    \n",
    "    if d_var <= 0:\n",
    "        return np.nan, np.nan\n",
    "    \n",
    "    dm_stat = d_mean / np.sqrt(d_var)\n",
    "    p_value = 2 * (1 - stats.norm.cdf(abs(dm_stat)))\n",
    "    \n",
    "    return dm_stat, p_value\n",
    "\n",
    "def procesar_escenario_DM(df_filtrado, nombre_escenario, MODELOS):\n",
    "    \"\"\"Procesa un escenario con test DM y correcci√≥n de Bonferroni.\"\"\"\n",
    "    n_modelos = len(MODELOS)\n",
    "    matriz_resultados = np.zeros((n_modelos, n_modelos))\n",
    "    \n",
    "    n_comparaciones = n_modelos * (n_modelos - 1) / 2\n",
    "    alpha_corregido = 0.05 / n_comparaciones\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"DM - Procesando: {nombre_escenario}\")\n",
    "    print(f\"Observaciones: {len(df_filtrado)}\")\n",
    "    print(f\"Alpha (Bonferroni): {alpha_corregido:.6f}\")\n",
    "    \n",
    "    # Realizar comparaciones\n",
    "    for i, modelo1 in enumerate(MODELOS):\n",
    "        for j, modelo2 in enumerate(MODELOS):\n",
    "            if i == j:\n",
    "                matriz_resultados[i, j] = 0\n",
    "            elif i < j:\n",
    "                errors1 = df_filtrado[modelo1]\n",
    "                errors2 = df_filtrado[modelo2]\n",
    "                \n",
    "                dm_stat, p_value = diebold_mariano_test(errors1, errors2)\n",
    "                \n",
    "                if np.isnan(p_value):\n",
    "                    matriz_resultados[i, j] = 0\n",
    "                    matriz_resultados[j, i] = 0\n",
    "                elif p_value < alpha_corregido:\n",
    "                    mean1 = abs(errors1).mean()\n",
    "                    mean2 = abs(errors2).mean()\n",
    "                    \n",
    "                    if mean1 < mean2:\n",
    "                        matriz_resultados[i, j] = 1\n",
    "                        matriz_resultados[j, i] = -1\n",
    "                    else:\n",
    "                        matriz_resultados[i, j] = -1\n",
    "                        matriz_resultados[j, i] = 1\n",
    "                else:\n",
    "                    matriz_resultados[i, j] = 0\n",
    "                    matriz_resultados[j, i] = 0\n",
    "    \n",
    "    # Calcular ranking\n",
    "    resultados_ranking = []\n",
    "    for i, modelo in enumerate(MODELOS):\n",
    "        victorias = np.sum(matriz_resultados[i, :] == 1)\n",
    "        derrotas = np.sum(matriz_resultados[i, :] == -1)\n",
    "        empates = np.sum(matriz_resultados[i, :] == 0) - 1  # -1 para excluir diagonal\n",
    "        score_neto = victorias - derrotas\n",
    "        comparaciones_totales = n_modelos - 1\n",
    "        porcentaje_victorias = (victorias / comparaciones_totales) * 100\n",
    "        \n",
    "        resultados_ranking.append({\n",
    "            'Modelo': modelo,\n",
    "            'Victorias': int(victorias),\n",
    "            'Empates': int(empates),\n",
    "            'Derrotas': int(derrotas),\n",
    "            'Score': int(score_neto),\n",
    "            '% Victorias': round(porcentaje_victorias, 2)\n",
    "        })\n",
    "    \n",
    "    df_ranking = pd.DataFrame(resultados_ranking)\n",
    "    df_ranking = df_ranking.sort_values('Score', ascending=False).reset_index(drop=True)\n",
    "    df_ranking.insert(0, 'Rank', range(1, len(df_ranking) + 1))\n",
    "    \n",
    "    return df_ranking\n",
    "\n",
    "# ============================================================================\n",
    "# FUNCIONES PARA AN√ÅLISIS POR MEDIA SIMPLE (SIN SIGNIFICANCIA)\n",
    "# ============================================================================\n",
    "\n",
    "def procesar_escenario_MEDIA(df_filtrado, nombre_escenario, MODELOS):\n",
    "    \"\"\"Procesa un escenario comparando directamente las medias sin test de significancia.\"\"\"\n",
    "    n_modelos = len(MODELOS)\n",
    "    matriz_resultados = np.zeros((n_modelos, n_modelos))\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"MEDIA - Procesando: {nombre_escenario}\")\n",
    "    print(f\"Observaciones: {len(df_filtrado)}\")\n",
    "    \n",
    "    # Calcular medias\n",
    "    medias = {}\n",
    "    for modelo in MODELOS:\n",
    "        medias[modelo] = abs(df_filtrado[modelo]).mean()\n",
    "    \n",
    "    # Comparar todas las parejas por media\n",
    "    for i, modelo1 in enumerate(MODELOS):\n",
    "        for j, modelo2 in enumerate(MODELOS):\n",
    "            if i == j:\n",
    "                matriz_resultados[i, j] = 0\n",
    "            else:\n",
    "                if medias[modelo1] < medias[modelo2]:\n",
    "                    matriz_resultados[i, j] = 1\n",
    "                elif medias[modelo1] > medias[modelo2]:\n",
    "                    matriz_resultados[i, j] = -1\n",
    "                else:\n",
    "                    matriz_resultados[i, j] = 0\n",
    "    \n",
    "    # Calcular ranking\n",
    "    resultados_ranking = []\n",
    "    for i, modelo in enumerate(MODELOS):\n",
    "        victorias = np.sum(matriz_resultados[i, :] == 1)\n",
    "        derrotas = np.sum(matriz_resultados[i, :] == -1)\n",
    "        empates = np.sum(matriz_resultados[i, :] == 0) - 1  # -1 para excluir diagonal\n",
    "        score_neto = victorias - derrotas\n",
    "        comparaciones_totales = n_modelos - 1\n",
    "        porcentaje_victorias = (victorias / comparaciones_totales) * 100\n",
    "        \n",
    "        resultados_ranking.append({\n",
    "            'Modelo': modelo,\n",
    "            'Victorias': int(victorias),\n",
    "            'Empates': int(empates),\n",
    "            'Derrotas': int(derrotas),\n",
    "            'Score': int(score_neto),\n",
    "            '% Victorias': round(porcentaje_victorias, 2)\n",
    "        })\n",
    "    \n",
    "    df_ranking = pd.DataFrame(resultados_ranking)\n",
    "    df_ranking = df_ranking.sort_values('Score', ascending=False).reset_index(drop=True)\n",
    "    df_ranking.insert(0, 'Rank', range(1, len(df_ranking) + 1))\n",
    "    \n",
    "    return df_ranking\n",
    "\n",
    "# ============================================================================\n",
    "# PROCESAR TODOS LOS ESCENARIOS\n",
    "# ============================================================================\n",
    "\n",
    "resultados_DM = {}\n",
    "resultados_MEDIA = {}\n",
    "\n",
    "# 1. An√°lisis General (todos los escenarios)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PROCESANDO AN√ÅLISIS GENERAL (TODOS LOS ESCENARIOS)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "resultados_DM['General'] = procesar_escenario_DM(df, \"General\", MODELOS)\n",
    "resultados_MEDIA['General'] = procesar_escenario_MEDIA(df, \"General\", MODELOS)\n",
    "\n",
    "# 2. An√°lisis por escenario espec√≠fico\n",
    "for escenario_original, escenario_nombre in ESCENARIOS_MAP.items():\n",
    "    df_filtrado = df[df['ESCENARIO'] == escenario_original].copy()\n",
    "    \n",
    "    if len(df_filtrado) > 0:\n",
    "        resultados_DM[escenario_nombre] = procesar_escenario_DM(df_filtrado, escenario_nombre, MODELOS)\n",
    "        resultados_MEDIA[escenario_nombre] = procesar_escenario_MEDIA(df_filtrado, escenario_nombre, MODELOS)\n",
    "    else:\n",
    "        print(f\"\\nAdvertencia: No se encontraron datos para '{escenario_original}'\")\n",
    "\n",
    "# ============================================================================\n",
    "# GUARDAR RESULTADOS EN EXCEL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GUARDANDO RESULTADOS EN EXCEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Excel con m√©todo Diebold-Mariano\n",
    "archivo_ranking_DM = output_dir / \"ranking_modelos_DM.xlsx\"\n",
    "with pd.ExcelWriter(archivo_ranking_DM, engine='openpyxl') as writer:\n",
    "    resultados_DM['General'].to_excel(writer, sheet_name='General', index=False)\n",
    "    \n",
    "    for escenario_nombre in ESCENARIOS_MAP.values():\n",
    "        if escenario_nombre in resultados_DM:\n",
    "            if 'ARMA' in escenario_nombre:\n",
    "                sheet_name = 'ARMA'\n",
    "            elif 'ARIMA' in escenario_nombre:\n",
    "                sheet_name = 'ARIMA'\n",
    "            elif 'SETAR' in escenario_nombre:\n",
    "                sheet_name = 'SETAR'\n",
    "            \n",
    "            resultados_DM[escenario_nombre].to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "print(f\"Rankings DM guardados en: {archivo_ranking_DM}\")\n",
    "\n",
    "# Excel con m√©todo de Media Simple\n",
    "archivo_ranking_MEDIA = output_dir / \"ranking_modelos_MEDIA.xlsx\"\n",
    "with pd.ExcelWriter(archivo_ranking_MEDIA, engine='openpyxl') as writer:\n",
    "    resultados_MEDIA['General'].to_excel(writer, sheet_name='General', index=False)\n",
    "    \n",
    "    for escenario_nombre in ESCENARIOS_MAP.values():\n",
    "        if escenario_nombre in resultados_MEDIA:\n",
    "            if 'ARMA' in escenario_nombre:\n",
    "                sheet_name = 'ARMA'\n",
    "            elif 'ARIMA' in escenario_nombre:\n",
    "                sheet_name = 'ARIMA'\n",
    "            elif 'SETAR' in escenario_nombre:\n",
    "                sheet_name = 'SETAR'\n",
    "            \n",
    "            resultados_MEDIA[escenario_nombre].to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "print(f\"Rankings MEDIA guardados en: {archivo_ranking_MEDIA}\")\n",
    "\n",
    "# ============================================================================\n",
    "# FUNCIONES PARA CREAR MATRICES DE COMPARACI√ìN\n",
    "# ============================================================================\n",
    "\n",
    "def crear_matriz_comparacion_DM(df_filtrado, MODELOS):\n",
    "    \"\"\"Crea matriz de comparaciones con test DM.\"\"\"\n",
    "    n_modelos = len(MODELOS)\n",
    "    matriz_resultados = np.zeros((n_modelos, n_modelos))\n",
    "    \n",
    "    n_comparaciones = n_modelos * (n_modelos - 1) / 2\n",
    "    alpha_corregido = 0.05 / n_comparaciones\n",
    "    \n",
    "    for i, modelo1 in enumerate(MODELOS):\n",
    "        for j, modelo2 in enumerate(MODELOS):\n",
    "            if i == j:\n",
    "                matriz_resultados[i, j] = 0\n",
    "            elif i < j:\n",
    "                errors1 = df_filtrado[modelo1]\n",
    "                errors2 = df_filtrado[modelo2]\n",
    "                \n",
    "                dm_stat, p_value = diebold_mariano_test(errors1, errors2)\n",
    "                \n",
    "                if np.isnan(p_value):\n",
    "                    matriz_resultados[i, j] = 0\n",
    "                    matriz_resultados[j, i] = 0\n",
    "                elif p_value < alpha_corregido:\n",
    "                    mean1 = abs(errors1).mean()\n",
    "                    mean2 = abs(errors2).mean()\n",
    "                    \n",
    "                    if mean1 < mean2:\n",
    "                        matriz_resultados[i, j] = 1\n",
    "                        matriz_resultados[j, i] = -1\n",
    "                    else:\n",
    "                        matriz_resultados[i, j] = -1\n",
    "                        matriz_resultados[j, i] = 1\n",
    "                else:\n",
    "                    matriz_resultados[i, j] = 0\n",
    "                    matriz_resultados[j, i] = 0\n",
    "    \n",
    "    return matriz_resultados\n",
    "\n",
    "def crear_matriz_comparacion_MEDIA(df_filtrado, MODELOS):\n",
    "    \"\"\"Crea matriz de comparaciones por media simple.\"\"\"\n",
    "    n_modelos = len(MODELOS)\n",
    "    matriz_resultados = np.zeros((n_modelos, n_modelos))\n",
    "    \n",
    "    medias = {}\n",
    "    for modelo in MODELOS:\n",
    "        medias[modelo] = abs(df_filtrado[modelo]).mean()\n",
    "    \n",
    "    for i, modelo1 in enumerate(MODELOS):\n",
    "        for j, modelo2 in enumerate(MODELOS):\n",
    "            if i == j:\n",
    "                matriz_resultados[i, j] = 0\n",
    "            else:\n",
    "                if medias[modelo1] < medias[modelo2]:\n",
    "                    matriz_resultados[i, j] = 1\n",
    "                elif medias[modelo1] > medias[modelo2]:\n",
    "                    matriz_resultados[i, j] = -1\n",
    "                else:\n",
    "                    matriz_resultados[i, j] = 0\n",
    "    \n",
    "    return matriz_resultados\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZACIONES - HEATMAPS INDIVIDUALES (8 GR√ÅFICOS)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GENERANDO VISUALIZACIONES - HEATMAPS INDIVIDUALES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "escenarios_orden = ['General'] + list(ESCENARIOS_MAP.values())\n",
    "cmap = sns.diverging_palette(10, 130, as_cmap=True)\n",
    "\n",
    "# Generar 4 heatmaps para DM\n",
    "for escenario_nombre in escenarios_orden:\n",
    "    if escenario_nombre in resultados_DM:\n",
    "        # Obtener datos seg√∫n escenario\n",
    "        if escenario_nombre == 'General':\n",
    "            df_filtrado = df\n",
    "        else:\n",
    "            escenario_original = [k for k, v in ESCENARIOS_MAP.items() if v == escenario_nombre][0]\n",
    "            df_filtrado = df[df['ESCENARIO'] == escenario_original].copy()\n",
    "        \n",
    "        matriz = crear_matriz_comparacion_DM(df_filtrado, MODELOS)\n",
    "        mask = np.eye(len(MODELOS), dtype=bool)\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 10))\n",
    "        \n",
    "        sns.heatmap(matriz,\n",
    "                    annot=True,\n",
    "                    fmt='.0f',\n",
    "                    cmap=cmap,\n",
    "                    center=0,\n",
    "                    vmin=-1,\n",
    "                    vmax=1,\n",
    "                    xticklabels=MODELOS,\n",
    "                    yticklabels=MODELOS,\n",
    "                    cbar_kws={'label': 'Resultado (1=Fila Gana, 0=Empate, -1=Fila Pierde)'},\n",
    "                    linewidths=0.5,\n",
    "                    linecolor='gray',\n",
    "                    mask=mask,\n",
    "                    ax=ax)\n",
    "        \n",
    "        plt.title(f'Matriz de Comparaciones: {escenario_nombre}\\n' +\n",
    "                  f'M√©todo: Diebold-Mariano con Correcci√≥n de Bonferroni (n={len(df_filtrado)})\\n' +\n",
    "                  'Verde=Fila Gana | Amarillo=Sin diferencia | Rojo=Fila Pierde',\n",
    "                  fontsize=12, fontweight='bold', pad=20)\n",
    "        plt.xlabel('Modelo (Columna)', fontsize=10)\n",
    "        plt.ylabel('Modelo (Fila)', fontsize=10)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        nombre_archivo = escenario_nombre.replace(' ', '_').replace('(', '').replace(')', '')\n",
    "        archivo_matriz = output_dir / f\"matriz_DM_{nombre_archivo}.png\"\n",
    "        plt.savefig(archivo_matriz, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Heatmap DM guardado: {archivo_matriz}\")\n",
    "        plt.close()\n",
    "\n",
    "# Generar 4 heatmaps para MEDIA\n",
    "for escenario_nombre in escenarios_orden:\n",
    "    if escenario_nombre in resultados_MEDIA:\n",
    "        # Obtener datos seg√∫n escenario\n",
    "        if escenario_nombre == 'General':\n",
    "            df_filtrado = df\n",
    "        else:\n",
    "            escenario_original = [k for k, v in ESCENARIOS_MAP.items() if v == escenario_nombre][0]\n",
    "            df_filtrado = df[df['ESCENARIO'] == escenario_original].copy()\n",
    "        \n",
    "        matriz = crear_matriz_comparacion_MEDIA(df_filtrado, MODELOS)\n",
    "        mask = np.eye(len(MODELOS), dtype=bool)\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 10))\n",
    "        \n",
    "        sns.heatmap(matriz,\n",
    "                    annot=True,\n",
    "                    fmt='.0f',\n",
    "                    cmap=cmap,\n",
    "                    center=0,\n",
    "                    vmin=-1,\n",
    "                    vmax=1,\n",
    "                    xticklabels=MODELOS,\n",
    "                    yticklabels=MODELOS,\n",
    "                    cbar_kws={'label': 'Resultado (1=Fila Gana, 0=Empate, -1=Fila Pierde)'},\n",
    "                    linewidths=0.5,\n",
    "                    linecolor='gray',\n",
    "                    mask=mask,\n",
    "                    ax=ax)\n",
    "        \n",
    "        plt.title(f'Matriz de Comparaciones: {escenario_nombre}\\n' +\n",
    "                  f'M√©todo: Comparaci√≥n Directa por Media (n={len(df_filtrado)})\\n' +\n",
    "                  'Verde=Fila Gana | Amarillo=Sin diferencia | Rojo=Fila Pierde',\n",
    "                  fontsize=12, fontweight='bold', pad=20)\n",
    "        plt.xlabel('Modelo (Columna)', fontsize=10)\n",
    "        plt.ylabel('Modelo (Fila)', fontsize=10)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        nombre_archivo = escenario_nombre.replace(' ', '_').replace('(', '').replace(')', '')\n",
    "        archivo_matriz = output_dir / f\"matriz_MEDIA_{nombre_archivo}.png\"\n",
    "        plt.savefig(archivo_matriz, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Heatmap MEDIA guardado: {archivo_matriz}\")\n",
    "        plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# RESUMEN FINAL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMEN FINAL - COMPARACI√ìN DE M√âTODOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for escenario_nombre in escenarios_orden:\n",
    "    if escenario_nombre in resultados_DM:\n",
    "        print(f\"\\n{escenario_nombre}:\")\n",
    "        \n",
    "        print(\"  Top 3 - Diebold-Mariano:\")\n",
    "        df_dm = resultados_DM[escenario_nombre]\n",
    "        for idx, row in df_dm.head(3).iterrows():\n",
    "            print(f\"    {int(row['Rank'])}. {row['Modelo']}: Score={int(row['Score'])}, \" +\n",
    "                  f\"V={int(row['Victorias'])}, E={int(row['Empates'])}, D={int(row['Derrotas'])} ({row['% Victorias']:.1f}%)\")\n",
    "        \n",
    "        print(\"  Top 3 - Media Simple:\")\n",
    "        df_media = resultados_MEDIA[escenario_nombre]\n",
    "        for idx, row in df_media.head(3).iterrows():\n",
    "            print(f\"    {int(row['Rank'])}. {row['Modelo']}: Score={int(row['Score'])}, \" +\n",
    "                  f\"V={int(row['Victorias'])}, E={int(row['Empates'])}, D={int(row['Derrotas'])} ({row['% Victorias']:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ARCHIVOS GENERADOS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"üìÅ Directorio: {output_dir}\")\n",
    "print(f\"üìä Excel DM: ranking_modelos_DM.xlsx (4 hojas)\")\n",
    "print(f\"üìä Excel MEDIA: ranking_modelos_MEDIA.xlsx (4 hojas)\")\n",
    "print(f\"üñºÔ∏è  Heatmaps DM individuales: matriz_DM_[escenario].png (4 archivos)\")\n",
    "print(f\"üñºÔ∏è  Heatmaps MEDIA individuales: matriz_MEDIA_[escenario].png (4 archivos)\")\n",
    "print(f\"   Total: 8 heatmaps individuales\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f71c0b0",
   "metadata": {},
   "source": [
    "# Analisis Diferenciado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b88955e",
   "metadata": {},
   "source": [
    "## Pre-procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "249b1e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TABLA COMPARATIVA DE MODELOS POR ESCENARIO\n",
      "(Promedio de amplitud de intervalos de predicci√≥n)\n",
      "================================================================================\n",
      "             Modelo   ARIMA  ARIMA_Diff Mejor_Escenario\n",
      "              AREPD  9.7604      0.7485      ARIMA_Diff\n",
      "            AV-MCPS  3.0618      0.6493      ARIMA_Diff\n",
      "Block Bootstrapping 10.9690      0.6844      ARIMA_Diff\n",
      "             DeepAR  3.1462      0.5704      ARIMA_Diff\n",
      "         EnCQR-LSTM  5.8306      0.8656      ARIMA_Diff\n",
      "               LSPM  1.1140      0.6481      ARIMA_Diff\n",
      "              LSPMW  3.5094      0.8032      ARIMA_Diff\n",
      "               MCPS  2.8994      0.6581      ARIMA_Diff\n",
      "    Sieve Bootstrap  0.5479      0.5454      ARIMA_Diff\n",
      "================================================================================\n",
      "\n",
      "Tabla comparativa guardada en 'Tabla_Comparativa_Modelos_Diff.xlsx'\n",
      "\n",
      "Archivo 'Base_140_diff_escenarios.xlsx' creado exitosamente!\n",
      "\n",
      "Total de filas: 3360\n",
      "- ARIMA: 1680 filas\n",
      "- ARIMA_Diff: 1680 filas\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Leer los tres archivos\n",
    "arima_df = pd.read_excel(\"./datos/resultados_140_ARIMA_FINAL.xlsx\")\n",
    "arima_Diff_df = pd.read_excel(\"./datos/resultados_140_ARIMA_CON_DIFERENCIACION.xlsx\")\n",
    "\n",
    "# Filtrar los que no tienen \"Promedio\" en la columna \"Paso\"\n",
    "arima_df = arima_df[arima_df['Paso'] != 'Promedio']\n",
    "arima_Diff_df = arima_Diff_df[arima_Diff_df['Paso'] != 'Promedio']\n",
    "\n",
    "# Lista de modelos (columnas a promediar)\n",
    "modelos = ['AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR',\n",
    "           'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
    "\n",
    "# Crear tabla comparativa\n",
    "comparacion = []\n",
    "\n",
    "for modelo in modelos:\n",
    "    fila = {'Modelo': modelo}\n",
    "    \n",
    "    # Calcular promedio para cada escenario (de la columna del modelo)\n",
    "    arima_promedio = arima_df[modelo].mean() if modelo in arima_df.columns else np.nan\n",
    "    arima_Diff_promedio = arima_Diff_df[modelo].mean() if modelo in arima_Diff_df.columns else np.nan\n",
    "    \n",
    "    fila['ARIMA'] = arima_promedio\n",
    "    fila['ARIMA_Diff'] = arima_Diff_promedio\n",
    "    \n",
    "    # Determinar mejor escenario (menor promedio)\n",
    "    promedios = {\n",
    "        'ARIMA': arima_promedio,\n",
    "        'ARIMA_Diff': arima_Diff_promedio\n",
    "    }\n",
    "    \n",
    "    # Filtrar NaN si existen\n",
    "    promedios_validos = {k: v for k, v in promedios.items() if not pd.isna(v)}\n",
    "    \n",
    "    if promedios_validos:\n",
    "        mejor_escenario = min(promedios_validos, key=promedios_validos.get)\n",
    "        fila['Mejor_Escenario'] = mejor_escenario\n",
    "    else:\n",
    "        fila['Mejor_Escenario'] = 'N/A'\n",
    "    \n",
    "    comparacion.append(fila)\n",
    "\n",
    "# Crear DataFrame con la tabla comparativa\n",
    "tabla_comparativa = pd.DataFrame(comparacion)\n",
    "\n",
    "# Redondear valores para mejor visualizaci√≥n\n",
    "columnas_numericas = ['ARIMA', 'ARIMA_Diff']\n",
    "tabla_comparativa[columnas_numericas] = tabla_comparativa[columnas_numericas].round(4)\n",
    "\n",
    "# Mostrar tabla comparativa\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TABLA COMPARATIVA DE MODELOS POR ESCENARIO\")\n",
    "print(\"(Promedio de amplitud de intervalos de predicci√≥n)\")\n",
    "print(\"=\"*80)\n",
    "print(tabla_comparativa.to_string(index=False))\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Guardar tabla comparativa en Excel\n",
    "tabla_comparativa.to_excel(\"Tabla_Comparativa_Modelos_Diff.xlsx\", index=False)\n",
    "print(\"Tabla comparativa guardada en 'Tabla_Comparativa_Modelos_Diff.xlsx'\")\n",
    "\n",
    "# Agregar columna ESCENARIO a cada DataFrame antes de concatenar\n",
    "arima_df['ESCENARIO'] = 'Sin diferenciaci√≥n'\n",
    "arima_Diff_df['ESCENARIO'] = 'Diferenciado'\n",
    "\n",
    "# Concatenar los tres dataframes\n",
    "base_consolidada = pd.concat([arima_df, arima_Diff_df], ignore_index=True)\n",
    "# Guardar en un archivo Excel\n",
    "base_consolidada.to_excel(\"Base_140_diff_escenarios.xlsx\", index=False)\n",
    "\n",
    "print(\"\\nArchivo 'Base_140_diff_escenarios.xlsx' creado exitosamente!\")\n",
    "print(f\"\\nTotal de filas: {len(base_consolidada)}\")\n",
    "print(f\"- ARIMA: {len(arima_df)} filas\")\n",
    "print(f\"- ARIMA_Diff: {len(arima_Diff_df)} filas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08864bc2",
   "metadata": {},
   "source": [
    "## Analisis general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba3ee6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "INICIANDO AN√ÅLISIS COMPARATIVO (AJUSTADO - BARRAS HORIZONTALES)\n",
      "================================================================================\n",
      "\n",
      "Base: Sin diferenciaci√≥n | Comparado: Diferenciado\n",
      "1Ô∏è‚É£  Comparativa Global...\n",
      "2Ô∏è‚É£  Modelo Generador...\n",
      "3Ô∏è‚É£  Variabilidad IQR (Por Tipo)...\n",
      "4Ô∏è‚É£  Distribuci√≥n...\n",
      "5Ô∏è‚É£  Varianza...\n",
      "6Ô∏è‚É£  Sensibilidad Ruido...\n",
      "7Ô∏è‚É£  Robustez (QCD)...\n",
      "8Ô∏è‚É£  Excel DM...\n",
      "   ‚úÖ Excel: resultados_escenarios_comparativos\\Comparacion_DM_Por_Modelo.xlsx\n",
      "\n",
      "‚úÖ HECHO.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "import warnings\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuraci√≥n de estilo\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURACI√ìN GLOBAL\n",
    "# ============================================================================\n",
    "\n",
    "RUTA_DATOS = \"./Base_140_diff_escenarios.xlsx\"\n",
    "DIR_SALIDA = \"./resultados_escenarios_comparativos\"\n",
    "\n",
    "MODELOS = ['AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR',\n",
    "           'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
    "\n",
    "# Colores fijos para barras comparativas\n",
    "COLOR_SIN_DIFF = '#7f7f7f'  # Gris\n",
    "COLOR_CON_DIFF = '#1f77b4'  # Azul\n",
    "\n",
    "# Paleta UNIFICADA para todos los Heatmaps\n",
    "# RdYlGn_r: Rojo (Valores altos/malos) -> Verde (Valores bajos/buenos)\n",
    "CMAP_HEATMAP = 'RdYlGn_r' \n",
    "\n",
    "# ============================================================================\n",
    "# FUNCIONES AUXILIARES\n",
    "# ============================================================================\n",
    "\n",
    "def diebold_mariano_test(errores1, errores2, h=1, alternative='two-sided', loss_function='none'):\n",
    "    \"\"\"Test DM Robusto (HAC)\"\"\"\n",
    "    e1 = np.asarray(errores1)\n",
    "    e2 = np.asarray(errores2)\n",
    "    n = len(e1)\n",
    "    \n",
    "    if loss_function == 'none':\n",
    "        d = e1 - e2\n",
    "    elif loss_function == 'squared':\n",
    "        d = e1**2 - e2**2\n",
    "    else: # absolute\n",
    "        d = np.abs(e1) - np.abs(e2)\n",
    "        \n",
    "    d_mean = np.mean(d)\n",
    "    \n",
    "    if h == 1:\n",
    "        var_d = np.var(d, ddof=1) / n\n",
    "    else:\n",
    "        gamma_0 = np.var(d, ddof=1)\n",
    "        gamma_sum = 0\n",
    "        max_lags = min(h-1, n-1)\n",
    "        for k in range(1, max_lags + 1):\n",
    "            if k < n:\n",
    "                gamma_k = np.cov(d[:-k], d[k:], ddof=1)[0,1] if len(d) > k else 0\n",
    "                gamma_sum += (1 - k/(max_lags+1)) * gamma_k\n",
    "        var_d = (gamma_0 + 2 * gamma_sum) / n\n",
    "    \n",
    "    hlnc = np.sqrt((n + 1 - 2 * h + h * (h - 1) / n) / n) if h > 1 else 1.0\n",
    "    \n",
    "    dm_stat = (d_mean / np.sqrt(var_d)) * hlnc if var_d > 0 else 0\n",
    "    p_value = 2 * (1 - stats.norm.cdf(abs(dm_stat)))\n",
    "    \n",
    "    return {'p_value': p_value, 'mean_diff': d_mean, 'dm_statistic': dm_stat}\n",
    "\n",
    "def comparar_modelo_entre_escenarios(df, modelo, esc_base, esc_diff, alpha=0.05):\n",
    "    data_base = df[df['ESCENARIO'] == esc_base][modelo].dropna()\n",
    "    data_diff = df[df['ESCENARIO'] == esc_diff][modelo].dropna()\n",
    "    \n",
    "    if len(data_base) < 10 or len(data_diff) < 10:\n",
    "        return {'Modelo': modelo, 'Conclusi√≥n': 'Datos insuficientes', 'p_value': np.nan}\n",
    "    \n",
    "    med_base = data_base.median()\n",
    "    med_diff = data_diff.median()\n",
    "    mejora_pct = ((med_base - med_diff) / med_base) * 100 if med_base != 0 else 0\n",
    "    \n",
    "    try:\n",
    "        res = diebold_mariano_test(data_base.values, data_diff.values, h=1, loss_function='none')\n",
    "        sig = res['p_value'] < alpha\n",
    "        \n",
    "        if sig:\n",
    "            conclusion = 'Diferenciaci√≥n mejora' if res['mean_diff'] > 0 else 'Sin diferenciaci√≥n es mejor'\n",
    "        else:\n",
    "            conclusion = 'Sin diferencia significativa'\n",
    "            \n",
    "        return {\n",
    "            'Modelo': modelo,\n",
    "            'ECRPS_Sin_Dif': round(med_base, 3),\n",
    "            'ECRPS_Con_Dif': round(med_diff, 3),\n",
    "            'Mejora_%': round(mejora_pct, 2),\n",
    "            'dm_statistic': round(res['dm_statistic'], 4),\n",
    "            'p_value': res['p_value'],\n",
    "            'Significativo': 'S√≠' if sig else 'No',\n",
    "            'Conclusi√≥n': conclusion\n",
    "        }\n",
    "    except:\n",
    "        return {'Modelo': modelo, 'Conclusi√≥n': 'Error'}\n",
    "\n",
    "# ============================================================================\n",
    "# CLASE PRINCIPAL\n",
    "# ============================================================================\n",
    "\n",
    "class AnalizadorBaseCompleta:\n",
    "\n",
    "    def __init__(self, ruta_datos):\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"INICIANDO AN√ÅLISIS COMPARATIVO (AJUSTADO - BARRAS HORIZONTALES)\")\n",
    "        print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "        self.df = pd.read_excel(ruta_datos)\n",
    "        \n",
    "        # Limpieza b√°sica\n",
    "        self.df['ESCENARIO'] = self.df['ESCENARIO'].astype(str).str.strip()\n",
    "        self.escenarios_unicos = sorted(self.df['ESCENARIO'].unique())\n",
    "        \n",
    "        if 'proces_simulacion' in self.df.columns:\n",
    "            self.df['Tipo de Modelo'] = self.df['proces_simulacion']\n",
    "        \n",
    "        self.modelos = [m for m in MODELOS if m in self.df.columns]\n",
    "        self.dir_salida = Path(DIR_SALIDA)\n",
    "        self.dir_salida.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Determinar base vs diff\n",
    "        if len(self.escenarios_unicos) == 2:\n",
    "            e1, e2 = self.escenarios_unicos\n",
    "            if ('sin' in e1.lower() or 'no' in e1.lower()) and not ('sin' in e2.lower()):\n",
    "                self.esc_base, self.esc_diff = e1, e2\n",
    "            elif ('sin' in e2.lower() or 'no' in e2.lower()):\n",
    "                self.esc_base, self.esc_diff = e2, e1\n",
    "            else:\n",
    "                self.esc_base, self.esc_diff = e1, e2\n",
    "        else:\n",
    "            self.esc_base = self.escenarios_unicos[0]\n",
    "            self.esc_diff = self.escenarios_unicos[-1]\n",
    "\n",
    "        print(f\"Base: {self.esc_base} | Comparado: {self.esc_diff}\")\n",
    "\n",
    "    def ejecutar_analisis_completo(self):\n",
    "        print(\"1Ô∏è‚É£  Comparativa Global...\")\n",
    "        self._1_comparativo_global()\n",
    "        print(\"2Ô∏è‚É£  Modelo Generador...\")\n",
    "        self._2_modelo_generador()\n",
    "        print(\"3Ô∏è‚É£  Variabilidad IQR (Por Tipo)...\")\n",
    "        self._3_variabilidad_iqr()\n",
    "        print(\"4Ô∏è‚É£  Distribuci√≥n...\")\n",
    "        self._4_distribucion()\n",
    "        print(\"5Ô∏è‚É£  Varianza...\")\n",
    "        self._5_varianza_tendencias()\n",
    "        print(\"6Ô∏è‚É£  Sensibilidad Ruido...\")\n",
    "        self._6_sensibilidad_ruido()\n",
    "        print(\"7Ô∏è‚É£  Robustez (QCD)...\")\n",
    "        self._7_analisis_robustez()\n",
    "        print(\"8Ô∏è‚É£  Excel DM...\")\n",
    "        self._analisis_dm_excel()\n",
    "        print(\"\\n‚úÖ HECHO.\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # 1. COMPARATIVAS GLOBALES\n",
    "    # ========================================================================\n",
    "    def _1_comparativo_global(self):\n",
    "        datos_agg = self.df.groupby(['ESCENARIO'])[self.modelos].median().T\n",
    "        \n",
    "        # 1.1 Barras HORIZONTALES (Izquierda a Derecha)\n",
    "        fig, ax = plt.subplots(figsize=(15, 10))\n",
    "        y = np.arange(len(self.modelos))\n",
    "        height = 0.35 # Altura de la barra en horizontal\n",
    "        \n",
    "        # Note: En barh, el primer argumento es Y, el segundo es width (valor X)\n",
    "        ax.barh(y - height/2, datos_agg[self.esc_base], height, label=self.esc_base, color=COLOR_SIN_DIFF)\n",
    "        ax.barh(y + height/2, datos_agg[self.esc_diff], height, label=self.esc_diff, color=COLOR_CON_DIFF)\n",
    "\n",
    "        ax.set_xlabel('Mediana ECRPS', fontweight='bold')\n",
    "        ax.set_title(f'1.1 Rendimiento: {self.esc_base} vs {self.esc_diff}', fontweight='bold')\n",
    "        ax.set_yticks(y)\n",
    "        ax.set_yticklabels(self.modelos)\n",
    "        ax.invert_yaxis() # Para que el primer modelo est√© arriba\n",
    "        ax.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '1_1_Comparacion_Barras_Horizontales.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        # 1.2 Cambio Porcentual (Ya era Horizontal)\n",
    "        cambio_pct = ((datos_agg[self.esc_diff] - datos_agg[self.esc_base]) / datos_agg[self.esc_base]) * 100\n",
    "        cambio_pct = cambio_pct.sort_values()\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        norm = plt.Normalize(cambio_pct.min(), cambio_pct.max())\n",
    "        cmap = plt.get_cmap(CMAP_HEATMAP)\n",
    "        colores = [cmap(norm(v)) for v in cambio_pct.values]\n",
    "        \n",
    "        bars = ax.barh(cambio_pct.index, cambio_pct.values, color=colores, edgecolor='k')\n",
    "        \n",
    "        ax.axvline(0, color='k', linestyle='--')\n",
    "        ax.set_xlabel('Cambio Porcentual del Error (%)', fontweight='bold')\n",
    "        ax.set_title('1.2 Impacto de la Diferenciaci√≥n (Verde = Mejora)', fontweight='bold')\n",
    "        \n",
    "        for bar in bars:\n",
    "            w = bar.get_width()\n",
    "            align = 'left' if w > 0 else 'right'\n",
    "            ax.text(w, bar.get_y() + bar.get_height()/2, f'{w:.1f}%', va='center', ha=align)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '1_2_Cambio_Porcentual.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    # ========================================================================\n",
    "    # 2. MODELO GENERADOR\n",
    "    # ========================================================================\n",
    "    def _2_modelo_generador(self):\n",
    "        if 'Tipo de Modelo' not in self.df.columns: return\n",
    "\n",
    "        df_diff = self.df[self.df['ESCENARIO'] == self.esc_diff]\n",
    "        df_base = self.df[self.df['ESCENARIO'] == self.esc_base]\n",
    "        \n",
    "        piv_diff = df_diff.groupby('Tipo de Modelo')[self.modelos].median()\n",
    "        piv_base = df_base.groupby('Tipo de Modelo')[self.modelos].median()\n",
    "\n",
    "        # 2.1 Heatmap Normalizado\n",
    "        fig, ax = plt.subplots(figsize=(16, 9))\n",
    "        row_stats = piv_diff.T.agg(['median', 'std'], axis=1)\n",
    "        zscore = piv_diff.T.sub(row_stats['median'], axis=0).div(row_stats['std'].replace(0,1), axis=0)\n",
    "        \n",
    "        sns.heatmap(zscore, annot=True, fmt='.2f', cmap=CMAP_HEATMAP, center=0, ax=ax)\n",
    "        ax.set_title(f'2.1 Z-Score Rendimiento - {self.esc_diff}', fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '2_1_MG_ZScore_Diferenciado.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        # 2.2 Cambio Absoluto\n",
    "        delta = piv_diff - piv_base\n",
    "        fig, ax = plt.subplots(figsize=(16, 9))\n",
    "        sns.heatmap(delta.T, annot=True, fmt='.3f', cmap=CMAP_HEATMAP, center=0, ax=ax)\n",
    "        ax.set_title(f'2.2 Cambio en ECRPS (Diff - Base)', fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '2_2_MG_Cambios.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    # ========================================================================\n",
    "    # 3. VARIABILIDAD IQR (AGRUPADO POR TIPO)\n",
    "    # ========================================================================\n",
    "    def _3_variabilidad_iqr(self):\n",
    "        if 'Tipo de Modelo' not in self.df.columns: return\n",
    "        \n",
    "        # --- PREPARACI√ìN DE DATOS PARA 3.1 y 3.2 ---\n",
    "        # Queremos m√©tricas agregadas por TIPO DE MODELO\n",
    "        \n",
    "        tipos_modelo = self.df['Tipo de Modelo'].dropna().unique()\n",
    "        data_resumen = []\n",
    "\n",
    "        for tipo in tipos_modelo:\n",
    "            # Funci√≥n interna para calcular promedio de IQRs de los modelos en ese tipo\n",
    "            def calcular_iqr_promedio_tipo(escenario):\n",
    "                subset = self.df[(self.df['ESCENARIO'] == escenario) & \n",
    "                                 (self.df['Tipo de Modelo'] == tipo)]\n",
    "                if subset.empty: return np.nan\n",
    "                \n",
    "                iqrs_individuales = []\n",
    "                for mod in self.modelos:\n",
    "                    vals = subset[mod].dropna()\n",
    "                    if len(vals) > 0:\n",
    "                        q75, q25 = np.percentile(vals, [75, 25])\n",
    "                        iqrs_individuales.append(q75 - q25)\n",
    "                \n",
    "                return np.mean(iqrs_individuales) if iqrs_individuales else np.nan\n",
    "\n",
    "            iqr_base = calcular_iqr_promedio_tipo(self.esc_base)\n",
    "            iqr_diff = calcular_iqr_promedio_tipo(self.esc_diff)\n",
    "            \n",
    "            if not np.isnan(iqr_diff):\n",
    "                delta = iqr_diff - iqr_base if not np.isnan(iqr_base) else np.nan\n",
    "                data_resumen.append({\n",
    "                    'Tipo': tipo, \n",
    "                    'IQR_Diff': iqr_diff,\n",
    "                    'Delta_IQR': delta\n",
    "                })\n",
    "        \n",
    "        df_resumen = pd.DataFrame(data_resumen)\n",
    "        if df_resumen.empty: return\n",
    "\n",
    "        # 3.1 Gr√°fico por TIPO DE MODELO - Nivel absoluto (Diff)\n",
    "        df_31 = df_resumen.sort_values('IQR_Diff')\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        ax.barh(df_31['Tipo'], df_31['IQR_Diff'], color=COLOR_CON_DIFF, alpha=0.8)\n",
    "        ax.set_title(f'3.1 Variabilidad Promedio (IQR) por TIPO DE MODELO - {self.esc_diff}', fontweight='bold')\n",
    "        ax.set_xlabel('IQR Promedio del Tipo')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '3_1_IQR_Diferenciado_PorTipo.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        # 3.2 Cambio IQR por TIPO DE MODELO (Delta)\n",
    "        # Aqu√≠ cumplimos el requerimiento: 3.2 ahora es sobre Tipos, no modelos individuales\n",
    "        df_32 = df_resumen.dropna(subset=['Delta_IQR']).sort_values('Delta_IQR')\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        colors = ['green' if x < 0 else 'red' for x in df_32['Delta_IQR']]\n",
    "        bars = ax.barh(df_32['Tipo'], df_32['Delta_IQR'], color=colors, alpha=0.7, edgecolor='k')\n",
    "        \n",
    "        ax.set_title('3.2 Cambio en Variabilidad (Delta IQR) por TIPO DE MODELO\\n(Verde = Menos variabilidad con diferenciaci√≥n)', fontweight='bold')\n",
    "        ax.axvline(0, color='k', linestyle='--')\n",
    "        \n",
    "        for bar in bars:\n",
    "            w = bar.get_width()\n",
    "            align = 'left' if w > 0 else 'right'\n",
    "            ax.text(w, bar.get_y() + bar.get_height()/2, f'{w:.3f}', va='center', ha=align)\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '3_2_Cambios_IQR_PorTipo.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    # ========================================================================\n",
    "    # 4. DISTRIBUCI√ìN\n",
    "    # ========================================================================\n",
    "    def _4_distribucion(self):\n",
    "        if 'Distribuci√≥n' not in self.df.columns: return\n",
    "\n",
    "        piv_diff = self.df[self.df['ESCENARIO'] == self.esc_diff].groupby('Distribuci√≥n')[self.modelos].median()\n",
    "        piv_base = self.df[self.df['ESCENARIO'] == self.esc_base].groupby('Distribuci√≥n')[self.modelos].median()\n",
    "        \n",
    "        # 4.1 Heatmap (Diff)\n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        sns.heatmap(piv_diff.T, annot=True, fmt='.3f', cmap=CMAP_HEATMAP, ax=ax)\n",
    "        ax.set_title(f'4.1 Rendimiento por Distribuci√≥n - {self.esc_diff}', fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '4_1_Dist_Heatmap_Diferenciado.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        # 4.2 Heatmap (Delta)\n",
    "        delta = piv_diff - piv_base\n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        sns.heatmap(delta.T, annot=True, fmt='.3f', cmap=CMAP_HEATMAP, center=0, ax=ax)\n",
    "        ax.set_title(f'4.2 Diferencial (Diff - Base)', fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '4_2_Dist_Heatmap_Diferencial.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    # ========================================================================\n",
    "    # 5. VARIANZA\n",
    "    # ========================================================================\n",
    "    def _5_varianza_tendencias(self):\n",
    "        if 'Varianza error' not in self.df.columns: return\n",
    "        \n",
    "        df_diff = self.df[self.df['ESCENARIO'] == self.esc_diff]\n",
    "        df_base = self.df[self.df['ESCENARIO'] == self.esc_base]\n",
    "\n",
    "        # 5.1 Tendencias Diferenciado\n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        for mod in self.modelos:\n",
    "            c = df_diff.groupby('Varianza error')[mod].median()\n",
    "            ax.plot(c.index, c.values, marker='o', label=mod)\n",
    "        ax.set_title(f'5.1 Sensibilidad a Varianza - {self.esc_diff}', fontweight='bold')\n",
    "        ax.legend(bbox_to_anchor=(1.01, 1))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '5_1_Varianza_Tendencias_Diferenciado.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        # 5.2 Cambio\n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        for mod in self.modelos:\n",
    "            c1 = df_diff.groupby('Varianza error')[mod].median()\n",
    "            c2 = df_base.groupby('Varianza error')[mod].median()\n",
    "            if not c1.empty and not c2.empty:\n",
    "                delta = c1 - c2\n",
    "                ax.plot(delta.index, delta.values, marker='o', label=mod)\n",
    "        ax.axhline(0, color='k', linestyle='--')\n",
    "        ax.set_title('5.2 Cambio de Comportamiento (Negativo = Mejora)', fontweight='bold')\n",
    "        ax.legend(bbox_to_anchor=(1.01, 1))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '5_2_Varianza_Cambio_Comportamiento.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    # ========================================================================\n",
    "    # 6. SENSIBILIDAD RUIDO\n",
    "    # ========================================================================\n",
    "    def _6_sensibilidad_ruido(self):\n",
    "        if 'Varianza error' not in self.df.columns: return\n",
    "\n",
    "        slopes = []\n",
    "        for esc in [self.esc_base, self.esc_diff]:\n",
    "            df_c = self.df[self.df['ESCENARIO'] == esc]\n",
    "            for mod in self.modelos:\n",
    "                dat = df_c[['Varianza error', mod]].dropna()\n",
    "                if len(dat) > 2:\n",
    "                    res = stats.theilslopes(dat[mod], dat['Varianza error'])\n",
    "                    slopes.append({'Modelo': mod, 'Esc': esc, 'Slope': res[0]})\n",
    "        \n",
    "        df_slopes = pd.DataFrame(slopes)\n",
    "        if df_slopes.empty: return\n",
    "\n",
    "        # 6.1 Sensibilidad Diff (Ya era Horizontal)\n",
    "        sub = df_slopes[df_slopes['Esc'] == self.esc_diff].sort_values('Slope')\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        ax.barh(sub['Modelo'], sub['Slope'], color=COLOR_CON_DIFF)\n",
    "        ax.set_title(f'6.1 Sensibilidad Ruido (Pendiente) - {self.esc_diff}', fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '6_1_Sensibilidad_Ruido_Diferenciado.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        # 6.2 Cambio Sensibilidad (Ya era Horizontal)\n",
    "        piv = df_slopes.pivot(index='Modelo', columns='Esc', values='Slope')\n",
    "        piv['Delta'] = piv[self.esc_diff] - piv[self.esc_base]\n",
    "        piv = piv.sort_values('Delta')\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        colors = ['green' if x < 0 else 'red' for x in piv['Delta']]\n",
    "        bars = ax.barh(piv.index, piv['Delta'], color=colors, edgecolor='k')\n",
    "        ax.axvline(0, color='k')\n",
    "        ax.set_title('6.2 Cambio en Sensibilidad (Verde = Menos sensible)', fontweight='bold')\n",
    "        \n",
    "        for bar in bars:\n",
    "            w = bar.get_width()\n",
    "            align = 'left' if w > 0 else 'right'\n",
    "            ax.text(w, bar.get_y() + bar.get_height()/2, f'{w:.4f}', va='center', ha=align)\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '6_2_Sensibilidad_Cambio.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    # ========================================================================\n",
    "    # 7. ROBUSTEZ (QCD) - CON COMPARACI√ìN\n",
    "    # ========================================================================\n",
    "    def _7_analisis_robustez(self):\n",
    "        # Calcular QCD para ambos escenarios\n",
    "        metricas = []\n",
    "        for esc in [self.esc_base, self.esc_diff]:\n",
    "            df_c = self.df[self.df['ESCENARIO'] == esc]\n",
    "            for mod in self.modelos:\n",
    "                dat = df_c[mod].dropna()\n",
    "                if len(dat) > 0:\n",
    "                    q75, q25 = np.percentile(dat, [75, 25])\n",
    "                    if (q75 + q25) > 0:\n",
    "                        qcd = (q75 - q25) / (q75 + q25)\n",
    "                        metricas.append({'Modelo': mod, 'Esc': esc, 'QCD': qcd})\n",
    "        \n",
    "        df_qcd = pd.DataFrame(metricas)\n",
    "        if df_qcd.empty: return\n",
    "\n",
    "        # 7.1 QCD Diferenciado (Ya era Horizontal)\n",
    "        sub_diff = df_qcd[df_qcd['Esc'] == self.esc_diff].sort_values('QCD')\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        norm = plt.Normalize(sub_diff['QCD'].min(), sub_diff['QCD'].max())\n",
    "        cmap = plt.get_cmap(CMAP_HEATMAP)\n",
    "        colors = [cmap(1 - norm(v)) for v in sub_diff['QCD']]\n",
    "\n",
    "        bars = ax.barh(sub_diff['Modelo'], sub_diff['QCD'], color=colors, edgecolor='k')\n",
    "        ax.set_title(f'7.1 Robustez (QCD) - {self.esc_diff} (Menor es mejor)', fontweight='bold')\n",
    "        \n",
    "        for bar in bars:\n",
    "            w = bar.get_width()\n",
    "            ax.text(w, bar.get_y() + bar.get_height()/2, f'{w:.3f}', va='center', ha='left')\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '7_1_Robustez_Diferenciado.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        # 7.2 COMPARACI√ìN DE ROBUSTEZ (Ya era Horizontal)\n",
    "        piv = df_qcd.pivot(index='Modelo', columns='Esc', values='QCD')\n",
    "        piv['Delta'] = piv[self.esc_diff] - piv[self.esc_base]\n",
    "        piv = piv.sort_values('Delta')\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        colors = ['green' if x < 0 else 'red' for x in piv['Delta']]\n",
    "        bars = ax.barh(piv.index, piv['Delta'], color=colors, edgecolor='k', alpha=0.8)\n",
    "        \n",
    "        ax.set_title('7.2 Cambio en Robustez (QCD)\\n(Valores negativos indican mayor robustez en diferenciado)', fontweight='bold')\n",
    "        ax.axvline(0, color='k', linestyle='--')\n",
    "        \n",
    "        for bar in bars:\n",
    "            w = bar.get_width()\n",
    "            align = 'left' if w > 0 else 'right'\n",
    "            ax.text(w, bar.get_y() + bar.get_height()/2, f'{w:.3f}', va='center', ha=align)\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '7_2_Robustez_Cambio.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    # ========================================================================\n",
    "    # 8. EXCEL\n",
    "    # ========================================================================\n",
    "    def _analisis_dm_excel(self):\n",
    "        res = [comparar_modelo_entre_escenarios(self.df, m, self.esc_base, self.esc_diff) for m in self.modelos]\n",
    "        df_res = pd.DataFrame(res)\n",
    "        nombre = self.dir_salida / \"Comparacion_DM_Por_Modelo.xlsx\"\n",
    "        df_res.to_excel(nombre, index=False)\n",
    "        print(f\"   ‚úÖ Excel: {nombre}\")\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN\n",
    "# ============================================================================\n",
    "def main():\n",
    "    try:\n",
    "        AnalizadorBaseCompleta(RUTA_DATOS).ejecutar_analisis_completo()\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e6b598",
   "metadata": {},
   "source": [
    "# Aumento d ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3b604c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS DE SENSIBILIDAD AL PAR√ÅMETRO D (ORDEN DE DIFERENCIACI√ìN)\n",
      "================================================================================\n",
      "\n",
      "üìä Valores de d: [np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(7), np.int64(10)]\n",
      "üé≠ Modalidades: ['CON_DIFF', 'SIN_DIFF']\n",
      "üìà Modelos analizados: 9\n",
      "\n",
      "üìä Generando Heatmaps Generales de Rendimiento...\n",
      "   ‚úÖ Gr√°fico guardado: 0_General_Heatmaps_ECRPS_Medio.png\n",
      "\n",
      "================================================================================\n",
      "PREGUNTA 1: ¬øQu√© modelo es m√°s sensible a los cambios en d?\n",
      "================================================================================\n",
      "   ‚úÖ Excel guardado: P1_Sensibilidad_Modelos.xlsx\n",
      "\n",
      "üî• TOP 3 MODELOS M√ÅS SENSIBLES A d:\n",
      "   Block Bootstrapping (SIN_DIFF): Score=8.23e+10\n",
      "   AREPD (SIN_DIFF): Score=8.04e+10\n",
      "   DeepAR (SIN_DIFF): Score=7.69e+10\n",
      "\n",
      "================================================================================\n",
      "PREGUNTA 2: ¬øExiste un punto de inflexi√≥n en d?\n",
      "================================================================================\n",
      "   ‚úÖ Excel guardado: P2_Puntos_Inflexion.xlsx\n",
      "\n",
      "================================================================================\n",
      "PREGUNTA 3: ¬øC√≥mo impacta d en la variabilidad?\n",
      "================================================================================\n",
      "   ‚úÖ Excel guardado: P3_Variabilidad_por_d.xlsx\n",
      "\n",
      "================================================================================\n",
      "PREGUNTA 4: ¬øLa diferenciaci√≥n previa amplifica el efecto de d?\n",
      "================================================================================\n",
      "   ‚úÖ Excel guardado: P4_Interaccion_Modalidad.xlsx\n",
      "\n",
      "================================================================================\n",
      "PREGUNTA 5: ¬øCu√°ndo es significativa la diferenciaci√≥n? (Foco: Sieve Bootstrap)\n",
      "================================================================================\n",
      "\n",
      "üîé Analizando significancia estad√≠stica (Mann-Whitney U)...\n",
      "   ‚úÖ Excel guardado: P5_Significancia_Diferenciacion.xlsx\n",
      "\n",
      "üßê AN√ÅLISIS ESPEC√çFICO: Sieve Bootstrap\n",
      "   üëâ Para Sieve Bootstrap, la diferenciaci√≥n es estad√≠sticamente significativa (p < 0.05)\n",
      "      a partir de d = 4\n",
      "\n",
      "‚úÖ AN√ÅLISIS COMPLETO FINALIZADO\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURACI√ìN GLOBAL\n",
    "# ============================================================================\n",
    "\n",
    "RUTA_DATOS = \"./datos/resultados_ARIMA_d1_a_d10_DOBLE_MODALIDAD_COMPLETO.xlsx\"\n",
    "DIR_SALIDA = \"./resultados_diff_d\"\n",
    "\n",
    "MODELOS = ['AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR',\n",
    "           'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
    "\n",
    "# Paleta de colores para modelos\n",
    "COLORES_MODELOS = plt.cm.tab10(np.linspace(0, 1, len(MODELOS)))\n",
    "COLOR_MAP_MODELOS = {mod: COLORES_MODELOS[i] for i, mod in enumerate(MODELOS)}\n",
    "\n",
    "# Colores para modalidades\n",
    "COLOR_SIN_DIFF = '#e74c3c'  # Rojo\n",
    "COLOR_CON_DIFF = '#3498db'  # Azul\n",
    "\n",
    "CMAP_HEATMAP = 'RdYlGn_r' # Rojo = Malo (Alto Error), Verde = Bueno (Bajo Error)\n",
    "\n",
    "# ============================================================================\n",
    "# CLASE PRINCIPAL\n",
    "# ============================================================================\n",
    "\n",
    "class AnalizadorSensibilidadD:\n",
    "    \n",
    "    def __init__(self, ruta_datos):\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"AN√ÅLISIS DE SENSIBILIDAD AL PAR√ÅMETRO D (ORDEN DE DIFERENCIACI√ìN)\")\n",
    "        print(\"=\" * 80 + \"\\n\")\n",
    "        \n",
    "        self.df = pd.read_excel(ruta_datos)\n",
    "        \n",
    "        # Limpieza\n",
    "        self.df['Modalidad'] = self.df['Modalidad'].astype(str).str.strip().str.upper()\n",
    "        self.df['d'] = pd.to_numeric(self.df['d'], errors='coerce')\n",
    "        \n",
    "        # Filtrar datos v√°lidos\n",
    "        self.df = self.df[self.df['d'].notna()].copy()\n",
    "        self.valores_d = sorted(self.df['d'].unique())\n",
    "        \n",
    "        self.modelos = [m for m in MODELOS if m in self.df.columns]\n",
    "        self.modalidades = sorted(self.df['Modalidad'].unique())\n",
    "        \n",
    "        self.dir_salida = Path(DIR_SALIDA)\n",
    "        self.dir_salida.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        print(f\"üìä Valores de d: {self.valores_d}\")\n",
    "        print(f\"üé≠ Modalidades: {self.modalidades}\")\n",
    "        print(f\"üìà Modelos analizados: {len(self.modelos)}\\n\")\n",
    "\n",
    "    def _fmt(self, x):\n",
    "        \"\"\"\n",
    "        Formatea n√∫meros: \n",
    "        - Usa notaci√≥n cient√≠fica si abs(x) >= 10,000 (5 d√≠gitos) o x < 0.001\n",
    "        - Usa decimales est√°ndar en caso contrario.\n",
    "        \"\"\"\n",
    "        if pd.isna(x):\n",
    "            return \"\"\n",
    "        if x == 0:\n",
    "            return \"0\"\n",
    "        # Umbral: 5 d√≠gitos enteros (10,000) o muy peque√±os\n",
    "        if abs(x) >= 10000 or (0 < abs(x) < 0.001):\n",
    "            return f\"{x:.2e}\"\n",
    "        return f\"{x:.3f}\"\n",
    "\n",
    "    def ejecutar_analisis_completo(self):\n",
    "        \"\"\"Ejecuta todas las preguntas de investigaci√≥n\"\"\"\n",
    "        \n",
    "        # --- VISUALIZACI√ìN GENERAL ---\n",
    "        self._visualizar_heatmaps_ecrps_absolutos()\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"PREGUNTA 1: ¬øQu√© modelo es m√°s sensible a los cambios en d?\")\n",
    "        print(\"=\" * 80)\n",
    "        self._pregunta1_sensibilidad_modelos()\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"PREGUNTA 2: ¬øExiste un punto de inflexi√≥n en d?\")\n",
    "        print(\"=\" * 80)\n",
    "        self._pregunta2_punto_inflexion()\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"PREGUNTA 3: ¬øC√≥mo impacta d en la variabilidad?\")\n",
    "        print(\"=\" * 80)\n",
    "        self._pregunta3_variabilidad()\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"PREGUNTA 4: ¬øLa diferenciaci√≥n previa amplifica el efecto de d?\")\n",
    "        print(\"=\" * 80)\n",
    "        self._pregunta4_interaccion_modalidad()\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"PREGUNTA 5: ¬øCu√°ndo es significativa la diferenciaci√≥n? (Foco: Sieve Bootstrap)\")\n",
    "        print(\"=\" * 80)\n",
    "        self._pregunta5_consistencia()\n",
    "        \n",
    "        print(\"\\n‚úÖ AN√ÅLISIS COMPLETO FINALIZADO\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # VISUALIZACI√ìN EXTRA: HEATMAPS DE ECRPS MEDIO (Modelo vs d)\n",
    "    # ========================================================================\n",
    "    def _visualizar_heatmaps_ecrps_absolutos(self):\n",
    "        print(\"üìä Generando Heatmaps Generales de Rendimiento...\")\n",
    "\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(24, 10))\n",
    "        \n",
    "        vmin = self.df[self.modelos].min().min()\n",
    "        vmax_robust = np.percentile(self.df[self.modelos].values, 95)\n",
    "\n",
    "        for idx, modalidad in enumerate(self.modalidades):\n",
    "            if idx >= 2: break \n",
    "            \n",
    "            ax = axes[idx]\n",
    "            df_mod = self.df[self.df['Modalidad'] == modalidad]\n",
    "            \n",
    "            heatmap_data = df_mod.groupby('d')[self.modelos].mean().T\n",
    "            \n",
    "            # Crear matriz de anotaciones formateadas\n",
    "            annot_data = heatmap_data.applymap(self._fmt)\n",
    "            \n",
    "            sns.heatmap(heatmap_data, ax=ax, cmap=CMAP_HEATMAP, \n",
    "                        annot=annot_data.values, fmt='', # fmt='' es necesario cuando pasamos strings\n",
    "                        vmin=vmin, vmax=vmax_robust, \n",
    "                        linewidths=.5, cbar_kws={'label': 'ECRPS Medio'})\n",
    "            \n",
    "            ax.set_title(f'Rendimiento Medio (ECRPS) - {modalidad}', fontweight='bold', fontsize=14)\n",
    "            ax.set_xlabel('Orden de Diferenciaci√≥n (d)', fontsize=12, fontweight='bold')\n",
    "            ax.set_ylabel('Modelo', fontsize=12, fontweight='bold')\n",
    "            ax.tick_params(axis='y', rotation=0)\n",
    "\n",
    "        plt.suptitle('Comparaci√≥n de ECRPS Medio: Modelos vs. Orden de Diferenciaci√≥n (d)', \n",
    "                     fontsize=16, fontweight='bold', y=0.98)\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        \n",
    "        nombre_archivo = \"0_General_Heatmaps_ECRPS_Medio.png\"\n",
    "        plt.savefig(self.dir_salida / nombre_archivo, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"   ‚úÖ Gr√°fico guardado: {nombre_archivo}\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # PREGUNTA 1: SENSIBILIDAD DE MODELOS A d\n",
    "    # ========================================================================\n",
    "    def _pregunta1_sensibilidad_modelos(self):\n",
    "        resultados = []\n",
    "        for modalidad in self.modalidades:\n",
    "            df_mod = self.df[self.df['Modalidad'] == modalidad]\n",
    "            for modelo in self.modelos:\n",
    "                serie = df_mod.groupby('d')[modelo].median()\n",
    "                if len(serie) > 3:\n",
    "                    slope, intercept, _, _ = stats.theilslopes(serie.values, serie.index)\n",
    "                    corr, p_value = stats.spearmanr(serie.index, serie.values)\n",
    "                    rango = serie.max() - serie.min()\n",
    "                    variacion_pct = (rango / serie.mean()) * 100 if serie.mean() != 0 else 0\n",
    "                    \n",
    "                    resultados.append({\n",
    "                        'Modelo': modelo, 'Modalidad': modalidad, 'Pendiente': slope,\n",
    "                        'Correlaci√≥n': corr, 'p_value': p_value, 'Rango': rango,\n",
    "                        'Variaci√≥n_%': variacion_pct, 'Sensibilidad_Score': abs(slope) * abs(corr)\n",
    "                    })\n",
    "        \n",
    "        df_resultados = pd.DataFrame(resultados)\n",
    "        df_resultados.to_excel(self.dir_salida / \"P1_Sensibilidad_Modelos.xlsx\", index=False)\n",
    "        print(f\"   ‚úÖ Excel guardado: P1_Sensibilidad_Modelos.xlsx\")\n",
    "        \n",
    "        self._visualizar_pregunta1(df_resultados)\n",
    "        \n",
    "        print(\"\\nüî• TOP 3 MODELOS M√ÅS SENSIBLES A d:\")\n",
    "        top_sensibles = df_resultados.nlargest(3, 'Sensibilidad_Score')\n",
    "        for idx, row in top_sensibles.iterrows():\n",
    "            print(f\"   {row['Modelo']} ({row['Modalidad']}): Score={self._fmt(row['Sensibilidad_Score'])}\")\n",
    "\n",
    "    def _visualizar_pregunta1(self, df_resultados):\n",
    "        # 1.1 Ranking\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "        for idx, modalidad in enumerate(self.modalidades):\n",
    "            if idx >= 2: break\n",
    "            df_sub = df_resultados[df_resultados['Modalidad'] == modalidad].sort_values('Sensibilidad_Score')\n",
    "            ax = axes[idx]\n",
    "            colors = [COLOR_MAP_MODELOS[m] for m in df_sub['Modelo']]\n",
    "            bars = ax.barh(df_sub['Modelo'], df_sub['Sensibilidad_Score'], color=colors, edgecolor='black', alpha=0.8)\n",
    "            ax.set_xlabel('Score de Sensibilidad', fontweight='bold')\n",
    "            ax.set_title(f'P1.1: Sensibilidad a d - {modalidad}', fontweight='bold')\n",
    "            ax.grid(axis='x', alpha=0.3)\n",
    "            \n",
    "            # Anotaci√≥n formateada\n",
    "            for bar in bars:\n",
    "                width = bar.get_width()\n",
    "                label = self._fmt(width)\n",
    "                ax.text(width, bar.get_y() + bar.get_height()/2, label, va='center', fontsize=9)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / 'P1_1_Ranking_Sensibilidad.png', dpi=300)\n",
    "        plt.close()\n",
    "        \n",
    "        # 1.2 Comparaci√≥n\n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        piv = df_resultados.pivot(index='Modelo', columns='Modalidad', values='Pendiente')\n",
    "        piv.plot(kind='bar', ax=ax, width=0.7, edgecolor='black', \n",
    "                 color=[COLOR_SIN_DIFF, COLOR_CON_DIFF] if len(piv.columns)==2 else None)\n",
    "        ax.set_ylabel('Pendiente (ECRPS vs d)')\n",
    "        ax.set_title('P1.2: Pendientes de Sensibilidad por Modalidad')\n",
    "        ax.axhline(0, color='black', linestyle='--')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / 'P1_2_Pendientes_Comparacion.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    # ========================================================================\n",
    "    # PREGUNTA 2: PUNTO DE INFLEXI√ìN\n",
    "    # ========================================================================\n",
    "    def _pregunta2_punto_inflexion(self):\n",
    "        resultados = []\n",
    "        for modalidad in self.modalidades:\n",
    "            df_mod = self.df[self.df['Modalidad'] == modalidad]\n",
    "            for modelo in self.modelos:\n",
    "                serie = df_mod.groupby('d')[modelo].median().dropna()\n",
    "                if len(serie) >= 5:\n",
    "                    x, y = serie.index.values, serie.values\n",
    "                    try:\n",
    "                        spline = UnivariateSpline(x, y, s=0.1, k=3)\n",
    "                        x_fine = np.linspace(x.min(), x.max(), 100)\n",
    "                        y_second_deriv = spline.derivative(n=2)(x_fine)\n",
    "                        d_inflexion = x_fine[np.argmax(np.abs(y_second_deriv))]\n",
    "                        resultados.append({\n",
    "                            'Modelo': modelo, 'Modalidad': modalidad, 'd_Inflexi√≥n': round(d_inflexion, 1),\n",
    "                            'Cambio_Total_%': ((serie.iloc[-1] - serie.iloc[0]) / serie.iloc[0] * 100) if serie.iloc[0] != 0 else 0\n",
    "                        })\n",
    "                    except: pass\n",
    "        \n",
    "        df_resultados = pd.DataFrame(resultados)\n",
    "        df_resultados.to_excel(self.dir_salida / \"P2_Puntos_Inflexion.xlsx\", index=False)\n",
    "        print(f\"   ‚úÖ Excel guardado: P2_Puntos_Inflexion.xlsx\")\n",
    "        self._visualizar_pregunta2(df_resultados)\n",
    "\n",
    "    def _visualizar_pregunta2(self, df_resultados):\n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        for modalidad in self.modalidades:\n",
    "            df_sub = df_resultados[df_resultados['Modalidad'] == modalidad]\n",
    "            color = COLOR_SIN_DIFF if 'SIN' in modalidad else COLOR_CON_DIFF\n",
    "            ax.scatter(df_sub['d_Inflexi√≥n'], df_sub['Modelo'], s=200, alpha=0.7, color=color, edgecolor='black', label=modalidad, marker='D')\n",
    "        ax.axvline(df_resultados['d_Inflexi√≥n'].mean(), color='gray', linestyle='--', label='Media Global')\n",
    "        ax.set_xlabel('Valor de d en Punto de Inflexi√≥n')\n",
    "        ax.set_title('P2.1: Distribuci√≥n de Puntos de Inflexi√≥n')\n",
    "        ax.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / 'P2_1_Distribucion_Inflexion.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    # ========================================================================\n",
    "    # PREGUNTA 3: IMPACTO EN VARIABILIDAD\n",
    "    # ========================================================================\n",
    "    def _pregunta3_variabilidad(self):\n",
    "        resultados = []\n",
    "        for modalidad in self.modalidades:\n",
    "            df_mod = self.df[self.df['Modalidad'] == modalidad]\n",
    "            for d_val in self.valores_d:\n",
    "                df_d = df_mod[df_mod['d'] == d_val]\n",
    "                for modelo in self.modelos:\n",
    "                    datos = df_d[modelo].dropna()\n",
    "                    if len(datos) > 5:\n",
    "                        q75, q25 = np.percentile(datos, [75, 25])\n",
    "                        resultados.append({\n",
    "                            'Modelo': modelo, 'Modalidad': modalidad, 'd': d_val,\n",
    "                            'IQR': q75 - q25,\n",
    "                            'QCD': (q75 - q25) / (q75 + q25) if (q75 + q25) > 0 else 0\n",
    "                        })\n",
    "        \n",
    "        df_resultados = pd.DataFrame(resultados)\n",
    "        df_resultados.to_excel(self.dir_salida / \"P3_Variabilidad_por_d.xlsx\", index=False)\n",
    "        print(f\"   ‚úÖ Excel guardado: P3_Variabilidad_por_d.xlsx\")\n",
    "        self._visualizar_pregunta3(df_resultados)\n",
    "\n",
    "    def _visualizar_pregunta3(self, df_resultados):\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "        for idx, modalidad in enumerate(self.modalidades):\n",
    "            if idx >= 2: break\n",
    "            df_mod = df_resultados[df_resultados['Modalidad'] == modalidad]\n",
    "            ax = axes[idx]\n",
    "            for modelo in self.modelos:\n",
    "                df_m = df_mod[df_mod['Modelo'] == modelo]\n",
    "                if not df_m.empty:\n",
    "                    ax.plot(df_m['d'], df_m['IQR'], marker='o', label=modelo, color=COLOR_MAP_MODELOS[modelo])\n",
    "            ax.set_title(f'P3.1: Evoluci√≥n IQR - {modalidad}')\n",
    "            ax.set_ylabel('IQR')\n",
    "            ax.set_xlabel('d')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / 'P3_1_Evolucion_IQR.png', dpi=300)\n",
    "        plt.close()\n",
    "        \n",
    "        # Heatmap QCD\n",
    "        for modalidad in self.modalidades:\n",
    "            piv = df_resultados[df_resultados['Modalidad'] == modalidad].pivot(index='Modelo', columns='d', values='QCD')\n",
    "            \n",
    "            # Formatear anotaciones\n",
    "            annot_qcd = piv.applymap(self._fmt)\n",
    "            \n",
    "            fig, ax = plt.subplots(figsize=(12, 6))\n",
    "            sns.heatmap(piv, annot=annot_qcd.values, fmt='', cmap=CMAP_HEATMAP, ax=ax)\n",
    "            ax.set_title(f'P3.2: Robustez Relativa (QCD) - {modalidad}')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(self.dir_salida / f'P3_2_Heatmap_QCD_{modalidad}.png', dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "    # ========================================================================\n",
    "    # PREGUNTA 4: INTERACCI√ìN MODALIDAD √ó d\n",
    "    # ========================================================================\n",
    "    def _pregunta4_interaccion_modalidad(self):\n",
    "        if len(self.modalidades) < 2: return\n",
    "        resultados = []\n",
    "        for modelo in self.modelos:\n",
    "            pendientes = {}\n",
    "            for modalidad in self.modalidades:\n",
    "                df_mod = self.df[self.df['Modalidad'] == modalidad]\n",
    "                serie = df_mod.groupby('d')[modelo].median()\n",
    "                if len(serie) > 3:\n",
    "                    slope, _, _, _ = stats.theilslopes(serie.values, serie.index)\n",
    "                    pendientes[modalidad] = slope\n",
    "            \n",
    "            if len(pendientes) == 2:\n",
    "                mod1, mod2 = self.modalidades\n",
    "                interaccion = pendientes[mod2] - pendientes[mod1]\n",
    "                resultados.append({\n",
    "                    'Modelo': modelo, 'Pendiente_Diff': pendientes.get(mod2,0), 'Pendiente_Base': pendientes.get(mod1,0),\n",
    "                    'Interacci√≥n': interaccion,\n",
    "                    'Interpretaci√≥n': 'Amplifica' if abs(pendientes[mod2]) > abs(pendientes[mod1]) else 'Modera'\n",
    "                })\n",
    "        \n",
    "        df_resultados = pd.DataFrame(resultados)\n",
    "        df_resultados.to_excel(self.dir_salida / \"P4_Interaccion_Modalidad.xlsx\", index=False)\n",
    "        print(f\"   ‚úÖ Excel guardado: P4_Interaccion_Modalidad.xlsx\")\n",
    "        self._visualizar_pregunta4(df_resultados)\n",
    "\n",
    "    def _visualizar_pregunta4(self, df_resultados):\n",
    "        df_sorted = df_resultados.sort_values('Interacci√≥n')\n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        colors = ['#27ae60' if x < 0 else '#e74c3c' for x in df_sorted['Interacci√≥n']]\n",
    "        bars = ax.barh(df_sorted['Modelo'], df_sorted['Interacci√≥n'], color=colors, edgecolor='black', alpha=0.8)\n",
    "        ax.axvline(0, color='black', linestyle='--')\n",
    "        ax.set_xlabel('Efecto de Interacci√≥n (Pendiente_Diff - Pendiente_Base)')\n",
    "        ax.set_title('P4.2: Efecto de la Diferenciaci√≥n sobre Sensibilidad a d')\n",
    "        \n",
    "        for bar in bars:\n",
    "            width = bar.get_width()\n",
    "            label = self._fmt(width)\n",
    "            ax.text(width, bar.get_y() + bar.get_height()/2, label, \n",
    "                   ha='left' if width > 0 else 'right', va='center', fontsize=9, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / 'P4_2_Efecto_Interaccion.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    # ========================================================================\n",
    "    # PREGUNTA 5: SIGNIFICANCIA DE LA DIFERENCIACI√ìN (SIEVE BOOTSTRAP)\n",
    "    # ========================================================================\n",
    "    def _pregunta5_consistencia(self):\n",
    "        print(f\"\\nüîé Analizando significancia estad√≠stica (Mann-Whitney U)...\")\n",
    "        resultados = []\n",
    "        if len(self.modalidades) < 2:\n",
    "            print(\"   ‚ö†Ô∏è  No es posible comparar (falta modalidad).\")\n",
    "            return\n",
    "\n",
    "        mod_sin = [m for m in self.modalidades if 'SIN' in m][0]\n",
    "        mod_con = [m for m in self.modalidades if 'CON' in m][0]\n",
    "\n",
    "        for modelo in self.modelos:\n",
    "            for d_val in self.valores_d:\n",
    "                datos_sin = self.df[(self.df['Modalidad'] == mod_sin) & (self.df['d'] == d_val)][modelo].dropna()\n",
    "                datos_con = self.df[(self.df['Modalidad'] == mod_con) & (self.df['d'] == d_val)][modelo].dropna()\n",
    "                \n",
    "                if len(datos_sin) > 3 and len(datos_con) > 3:\n",
    "                    stat, p_value = stats.mannwhitneyu(datos_sin, datos_con, alternative='two-sided')\n",
    "                    diff_mediana = datos_sin.median() - datos_con.median()\n",
    "                    resultados.append({\n",
    "                        'Modelo': modelo, 'd': d_val, 'p_value': p_value,\n",
    "                        'Significativo': p_value < 0.05, 'Diff_Mediana': diff_mediana\n",
    "                    })\n",
    "\n",
    "        df_resultados = pd.DataFrame(resultados)\n",
    "        df_resultados.to_excel(self.dir_salida / \"P5_Significancia_Diferenciacion.xlsx\", index=False)\n",
    "        print(f\"   ‚úÖ Excel guardado: P5_Significancia_Diferenciacion.xlsx\")\n",
    "        \n",
    "        self._visualizar_pregunta5(df_resultados)\n",
    "        \n",
    "        print(\"\\nüßê AN√ÅLISIS ESPEC√çFICO: Sieve Bootstrap\")\n",
    "        df_sb = df_resultados[df_resultados['Modelo'] == 'Sieve Bootstrap'].sort_values('d')\n",
    "        if not df_sb.empty:\n",
    "            significativos = df_sb[df_sb['Significativo']]\n",
    "            if not significativos.empty:\n",
    "                primer_d = significativos['d'].iloc[0]\n",
    "                print(f\"   üëâ Para Sieve Bootstrap, la diferenciaci√≥n es estad√≠sticamente significativa (p < 0.05)\")\n",
    "                print(f\"      a partir de d = {primer_d}\")\n",
    "            else:\n",
    "                print(\"   üëâ No se encontraron diferencias significativas para Sieve Bootstrap en ning√∫n d.\")\n",
    "        else:\n",
    "            print(\"   ‚ö†Ô∏è  Sieve Bootstrap no encontrado en los resultados.\")\n",
    "\n",
    "    def _visualizar_pregunta5(self, df_resultados):\n",
    "        piv_p = df_resultados.pivot(index='Modelo', columns='d', values='p_value')\n",
    "        log_p = -np.log10(piv_p + 1e-10) \n",
    "        \n",
    "        # Formatear P-values para anotaci√≥n\n",
    "        annot_p = piv_p.applymap(self._fmt)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        # Usamos 'magma' en min√∫sculas para evitar KeyError\n",
    "        sns.heatmap(log_p, cmap='magma', annot=annot_p.values, fmt='', \n",
    "                    cbar_kws={'label': '-log10(p-value)'}, ax=ax)\n",
    "        \n",
    "        ax.set_title('P5.1: Significancia Estad√≠stica (p-values) - Valores claros = Muy Significativo')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / 'P5_1_Heatmap_Significancia.png', dpi=300)\n",
    "        plt.close()\n",
    "        \n",
    "        # 5.2 Evoluci√≥n P-value\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        ax.axhline(0.05, color='red', linestyle='--', label='p=0.05')\n",
    "        \n",
    "        df_sb = df_resultados[df_resultados['Modelo'] == 'Sieve Bootstrap']\n",
    "        if not df_sb.empty:\n",
    "            ax.plot(df_sb['d'], df_sb['p_value'], marker='o', linewidth=3, color='#8e44ad', label='Sieve Bootstrap')\n",
    "        \n",
    "        for modelo in self.modelos:\n",
    "            if modelo != 'Sieve Bootstrap':\n",
    "                df_m = df_resultados[df_resultados['Modelo'] == modelo]\n",
    "                ax.plot(df_m['d'], df_m['p_value'], color='gray', alpha=0.15)\n",
    "        \n",
    "        ax.set_yscale('log')\n",
    "        ax.set_ylabel('P-value (Log)')\n",
    "        ax.set_title('P5.2: Evoluci√≥n de P-value para Sieve Bootstrap')\n",
    "        ax.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / 'P5_2_Sieve_Bootstrap_Significancia.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# EJECUCI√ìN\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if Path(RUTA_DATOS).exists():\n",
    "        analizador = AnalizadorSensibilidadD(RUTA_DATOS)\n",
    "        analizador.ejecutar_analisis_completo()\n",
    "    else:\n",
    "        print(f\"\\n‚õî ERROR: No se encontr√≥ el archivo: {RUTA_DATOS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b8a52b",
   "metadata": {},
   "source": [
    "# Analisis cambio de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0169f259",
   "metadata": {},
   "source": [
    "## Pre-procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfd6fb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TABLA COMPARATIVA DE MODELOS POR ESCENARIO\n",
      "(Promedio de amplitud de intervalos de predicci√≥n)\n",
      "================================================================================\n",
      "             Modelo   ARMA   ARIMA  SETAR Mejor_Escenario\n",
      "              AREPD 0.9345 13.0489 0.6971           SETAR\n",
      "            AV-MCPS 0.6768  3.5050 0.6531           SETAR\n",
      "Block Bootstrapping 0.9049 15.1183 0.6318           SETAR\n",
      "             DeepAR 0.5650  3.6998 0.5845            ARMA\n",
      "         EnCQR-LSTM 0.9515  5.9330 0.8404           SETAR\n",
      "               LSPM 0.7689  1.0868 0.6586           SETAR\n",
      "              LSPMW 0.7931  1.0870 0.6754           SETAR\n",
      "               MCPS 0.6496  3.2780 0.6325           SETAR\n",
      "    Sieve Bootstrap 0.5541  0.5583 0.6254            ARMA\n",
      "================================================================================\n",
      "\n",
      "Tabla comparativa guardada en 'Tabla_Comparativa_Modelos_tama√±o.xlsx'\n",
      "\n",
      "Archivo 'Base_Tama√±o_3_escenarios.xlsx' creado exitosamente!\n",
      "\n",
      "Total de filas: 126000\n",
      "- ARMA: 42000 filas\n",
      "- ARIMA: 42000 filas\n",
      "- SETAR: 42000 filas\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Leer los tres archivos\n",
    "arma_df = pd.read_excel(\"./datos/resultados_TAMANOS_CRECIENTES_ARMA.xlsx\")\n",
    "arima_df = pd.read_excel(\"./datos/resultados_TAMANOS_CRECIENTES_ARIMA.xlsx\")\n",
    "setar_df = pd.read_excel(\"./datos/resultados_TAMANOS_CRECIENTES_SETAR.xlsx\")\n",
    "\n",
    "# Filtrar los que no tienen \"Promedio\" en la columna \"Paso\"\n",
    "arma_df = arma_df[arma_df['Paso'] != 'Promedio']\n",
    "arima_df = arima_df[arima_df['Paso'] != 'Promedio']\n",
    "setar_df = setar_df[setar_df['Paso'] != 'Promedio']\n",
    "\n",
    "# Lista de modelos (columnas a promediar)\n",
    "modelos = ['AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR',\n",
    "           'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
    "\n",
    "# Crear tabla comparativa\n",
    "comparacion = []\n",
    "\n",
    "for modelo in modelos:\n",
    "    fila = {'Modelo': modelo}\n",
    "    \n",
    "    # Calcular promedio para cada escenario (de la columna del modelo)\n",
    "    arma_promedio = arma_df[modelo].mean() if modelo in arma_df.columns else np.nan\n",
    "    arima_promedio = arima_df[modelo].mean() if modelo in arima_df.columns else np.nan\n",
    "    setar_promedio = setar_df[modelo].mean() if modelo in setar_df.columns else np.nan\n",
    "    \n",
    "    fila['ARMA'] = arma_promedio\n",
    "    fila['ARIMA'] = arima_promedio\n",
    "    fila['SETAR'] = setar_promedio\n",
    "    \n",
    "    # Determinar mejor escenario (menor promedio)\n",
    "    promedios = {\n",
    "        'ARMA': arma_promedio,\n",
    "        'ARIMA': arima_promedio,\n",
    "        'SETAR': setar_promedio\n",
    "    }\n",
    "    \n",
    "    # Filtrar NaN si existen\n",
    "    promedios_validos = {k: v for k, v in promedios.items() if not pd.isna(v)}\n",
    "    \n",
    "    if promedios_validos:\n",
    "        mejor_escenario = min(promedios_validos, key=promedios_validos.get)\n",
    "        fila['Mejor_Escenario'] = mejor_escenario\n",
    "    else:\n",
    "        fila['Mejor_Escenario'] = 'N/A'\n",
    "    \n",
    "    comparacion.append(fila)\n",
    "\n",
    "# Crear DataFrame con la tabla comparativa\n",
    "tabla_comparativa = pd.DataFrame(comparacion)\n",
    "\n",
    "# Redondear valores para mejor visualizaci√≥n\n",
    "columnas_numericas = ['ARMA', 'ARIMA', 'SETAR']\n",
    "tabla_comparativa[columnas_numericas] = tabla_comparativa[columnas_numericas].round(4)\n",
    "\n",
    "# Mostrar tabla comparativa\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TABLA COMPARATIVA DE MODELOS POR ESCENARIO\")\n",
    "print(\"(Promedio de amplitud de intervalos de predicci√≥n)\")\n",
    "print(\"=\"*80)\n",
    "print(tabla_comparativa.to_string(index=False))\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Guardar tabla comparativa en Excel\n",
    "tabla_comparativa.to_excel(\"Tabla_Comparativa_Modelos_tama√±o.xlsx\", index=False)\n",
    "print(\"Tabla comparativa guardada en 'Tabla_Comparativa_Modelos_tama√±o.xlsx'\")\n",
    "\n",
    "# Procesamiento especial para SETAR\n",
    "if 'Descripci√≥n' in setar_df.columns:\n",
    "    setar_df = setar_df.drop('Descripci√≥n', axis=1)\n",
    "\n",
    "# Agregar columna ESCENARIO a cada DataFrame antes de concatenar\n",
    "arma_df['ESCENARIO'] = 'Lineal - estacionario'\n",
    "arima_df['ESCENARIO'] = 'Lineal - NO estacionario'\n",
    "setar_df['ESCENARIO'] = 'NO lineal - estacionario'\n",
    "\n",
    "# Concatenar los tres dataframes\n",
    "base_consolidada = pd.concat([arma_df, arima_df, setar_df], ignore_index=True)\n",
    "\n",
    "# Guardar en un archivo Excel\n",
    "base_consolidada.to_excel(\"Base_Tama√±o_3_escenarios.xlsx\", index=False)\n",
    "\n",
    "print(\"\\nArchivo 'Base_Tama√±o_3_escenarios.xlsx' creado exitosamente!\")\n",
    "print(f\"\\nTotal de filas: {len(base_consolidada)}\")\n",
    "print(f\"- ARMA: {len(arma_df)} filas\")\n",
    "print(f\"- ARIMA: {len(arima_df)} filas\")\n",
    "print(f\"- SETAR: {len(setar_df)} filas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6a6937",
   "metadata": {},
   "source": [
    "## Analisis general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "518faae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos...\n",
      "Columnas disponibles: ['Paso', 'Proceso', 'Tipo_Proceso', 'Distribuci√≥n', 'Varianza', 'N_Train', 'N_Calib', 'N_Total', 'Valor_Observado', 'AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', 'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap', 'ESCENARIO']\n",
      "N_Total √∫nicos: [np.int64(120), np.int64(140), np.int64(160), np.int64(200), np.int64(220), np.int64(240), np.int64(260), np.int64(300), np.int64(320), np.int64(340), np.int64(360), np.int64(400), np.int64(500), np.int64(520), np.int64(540), np.int64(560), np.int64(600), np.int64(700), np.int64(1020), np.int64(1040), np.int64(1060), np.int64(1100), np.int64(1200)]\n",
      "N√∫mero de observaciones: 126000\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS 1: HEATMAPS - Promedio de ECRPS por Proceso y N_Total\n",
      "================================================================================\n",
      "Heatmap guardado: resultados_analisis_ntotal\\heatmap_AREPD.png\n",
      "Heatmap guardado: resultados_analisis_ntotal\\heatmap_AV-MCPS.png\n",
      "Heatmap guardado: resultados_analisis_ntotal\\heatmap_Block_Bootstrapping.png\n",
      "Heatmap guardado: resultados_analisis_ntotal\\heatmap_DeepAR.png\n",
      "Heatmap guardado: resultados_analisis_ntotal\\heatmap_EnCQR-LSTM.png\n",
      "Heatmap guardado: resultados_analisis_ntotal\\heatmap_LSPM.png\n",
      "Heatmap guardado: resultados_analisis_ntotal\\heatmap_LSPMW.png\n",
      "Heatmap guardado: resultados_analisis_ntotal\\heatmap_MCPS.png\n",
      "Heatmap guardado: resultados_analisis_ntotal\\heatmap_Sieve_Bootstrap.png\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS 2: MEJOR N_TOTAL (Menor ECRPS Promedio)\n",
      "================================================================================\n",
      "ARMA | AREPD: N_Total=140 (ECRPS=0.8919)\n",
      "ARMA | AV-MCPS: N_Total=1200 (ECRPS=0.5962)\n",
      "ARMA | Block Bootstrapping: N_Total=400 (ECRPS=0.8428)\n",
      "ARMA | DeepAR: N_Total=400 (ECRPS=0.5341)\n",
      "ARMA | EnCQR-LSTM: N_Total=1200 (ECRPS=0.7455)\n",
      "ARMA | LSPM: N_Total=1200 (ECRPS=0.7326)\n",
      "ARMA | LSPMW: N_Total=1200 (ECRPS=0.7558)\n",
      "ARMA | MCPS: N_Total=1200 (ECRPS=0.5563)\n",
      "ARMA | Sieve Bootstrap: N_Total=1020 (ECRPS=0.5274)\n",
      "ARIMA | AREPD: N_Total=120 (ECRPS=7.8918)\n",
      "ARIMA | AV-MCPS: N_Total=320 (ECRPS=2.7402)\n",
      "ARIMA | Block Bootstrapping: N_Total=120 (ECRPS=8.7461)\n",
      "ARIMA | DeepAR: N_Total=1100 (ECRPS=2.9367)\n",
      "ARIMA | EnCQR-LSTM: N_Total=240 (ECRPS=4.3085)\n",
      "ARIMA | LSPM: N_Total=1200 (ECRPS=1.0382)\n",
      "ARIMA | LSPMW: N_Total=1200 (ECRPS=1.0354)\n",
      "ARIMA | MCPS: N_Total=160 (ECRPS=2.6655)\n",
      "ARIMA | Sieve Bootstrap: N_Total=1020 (ECRPS=0.5275)\n",
      "SETAR | AREPD: N_Total=560 (ECRPS=0.6606)\n",
      "SETAR | AV-MCPS: N_Total=1060 (ECRPS=0.6157)\n",
      "SETAR | Block Bootstrapping: N_Total=1060 (ECRPS=0.6024)\n",
      "SETAR | DeepAR: N_Total=400 (ECRPS=0.5539)\n",
      "SETAR | EnCQR-LSTM: N_Total=1100 (ECRPS=0.8152)\n",
      "SETAR | LSPM: N_Total=1100 (ECRPS=0.6293)\n",
      "SETAR | LSPMW: N_Total=1060 (ECRPS=0.6484)\n",
      "SETAR | MCPS: N_Total=1060 (ECRPS=0.5666)\n",
      "SETAR | Sieve Bootstrap: N_Total=1100 (ECRPS=0.5878)\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS 3: Comparaciones DM entre N_Totales\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS 4: Resumen Estad√≠stico (ECRPS)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS 5: Evoluci√≥n del ECRPS por Proceso\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS 5B: Tendencia Global de Modelos (ECRPS vs N_Total)\n",
      "================================================================================\n",
      "Gr√°fica de tendencia global guardada: resultados_analisis_ntotal\\tendencia_global_modelos.png\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS 6: Generando Rankings\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS 7: Variabilidad (Desviaci√≥n Est√°ndar)\n",
      "================================================================================\n",
      "Heatmap de variabilidad (STD) guardado: resultados_analisis_ntotal\\variabilidad_std_general.png\n",
      "\n",
      "‚úÖ Proceso completado. Revisa la carpeta de resultados.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8451"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from itertools import combinations\n",
    "import warnings\n",
    "import gc\n",
    "\n",
    "# Ignorar advertencias\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "# Crear carpeta de resultados\n",
    "output_dir = Path(\"./resultados_analisis_ntotal\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Configuraci√≥n\n",
    "archivo_excel = \"./Base_Tama√±o_3_escenarios.xlsx\"\n",
    "MODELOS = ['AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR',\n",
    "           'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
    "\n",
    "# Cargar datos\n",
    "print(\"Cargando datos...\")\n",
    "try:\n",
    "    df = pd.read_excel(archivo_excel)\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: No se encontr√≥ el archivo '{archivo_excel}'.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Columnas disponibles: {df.columns.tolist()}\")\n",
    "print(f\"N_Total √∫nicos: {sorted(df['N_Total'].unique())}\")\n",
    "print(f\"N√∫mero de observaciones: {len(df)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# FUNCI√ìN DIEBOLD-MARIANO\n",
    "# ============================================================================\n",
    "\n",
    "def diebold_mariano_test(series1, series2):\n",
    "    \"\"\"\n",
    "    Test de Diebold-Mariano.\n",
    "    Asumimos que las series ingresadas ya son las p√©rdidas (ECRPS), \n",
    "    por lo que comparamos d = L1 - L2 directamente o cuadr√°tica seg√∫n se desee.\n",
    "    Aqu√≠ se mantiene la l√≥gica cuadr√°tica est√°ndar del test sobre la diferencia.\n",
    "    \"\"\"\n",
    "    d = series1**2 - series2**2\n",
    "    d = d.dropna()\n",
    "    \n",
    "    if len(d) < 2:\n",
    "        return np.nan, np.nan\n",
    "    \n",
    "    d_mean = d.mean()\n",
    "    n = len(d)\n",
    "    d_var = d.var() / n\n",
    "    \n",
    "    if d_var <= 0:\n",
    "        return np.nan, np.nan\n",
    "    \n",
    "    dm_stat = d_mean / np.sqrt(d_var)\n",
    "    p_value = 2 * (1 - stats.norm.cdf(abs(dm_stat)))\n",
    "    \n",
    "    return dm_stat, p_value\n",
    "\n",
    "# ============================================================================\n",
    "# AN√ÅLISIS 1: HEATMAPS - PROMEDIO DE ECRPS POR TIPO_PROCESO Y N_TOTAL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AN√ÅLISIS 1: HEATMAPS - Promedio de ECRPS por Proceso y N_Total\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for modelo in MODELOS:\n",
    "    # Calcular promedio de ECRPS (asumiendo que el valor en excel ya es el score positivo)\n",
    "    pivot_data = df.groupby(['Proceso', 'N_Total'])[modelo].mean().reset_index()\n",
    "    pivot_table = pivot_data.pivot(index='Proceso', columns='N_Total', values=modelo)\n",
    "    \n",
    "    # Crear heatmap\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    \n",
    "    sns.heatmap(pivot_table, \n",
    "                annot=True, \n",
    "                fmt='.2f',  # <--- CAMBIO: Solo 2 d√≠gitos\n",
    "                cmap='RdYlGn_r',  # Rojo=alto ECRPS (malo), Verde=bajo ECRPS (bueno)\n",
    "                cbar_kws={'label': 'ECRPS Promedio', 'shrink': 0.7}, # Barra reducida al 70%\n",
    "                linewidths=0.5,\n",
    "                linecolor='gray',\n",
    "                ax=ax)\n",
    "    \n",
    "    plt.title(f'Heatmap: {modelo}\\nECRPS Promedio por Proceso y N_Total',\n",
    "              fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.xlabel('N_Total (Tama√±o de Muestra)', fontsize=11)\n",
    "    plt.ylabel('Tipo de Proceso', fontsize=11)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    archivo_heatmap = output_dir / f\"heatmap_{modelo.replace(' ', '_')}.png\"\n",
    "    plt.savefig(archivo_heatmap, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Heatmap guardado: {archivo_heatmap}\")\n",
    "    plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# AN√ÅLISIS 2: MEJOR N_TOTAL POR TIPO_PROCESO Y MODELO\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AN√ÅLISIS 2: MEJOR N_TOTAL (Menor ECRPS Promedio)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "resultados_mejor_ntotal = []\n",
    "\n",
    "for tipo_proceso in df['Tipo_Proceso'].unique():\n",
    "    for modelo in MODELOS:\n",
    "        df_filtrado = df[df['Tipo_Proceso'] == tipo_proceso]\n",
    "        \n",
    "        # Calcular ECRPS promedio por N_Total\n",
    "        promedios = df_filtrado.groupby('N_Total')[modelo].mean()\n",
    "        \n",
    "        mejor_ntotal = promedios.idxmin()\n",
    "        mejor_score = promedios.min()\n",
    "        \n",
    "        resultados_mejor_ntotal.append({\n",
    "            'Tipo_Proceso': tipo_proceso,\n",
    "            'Modelo': modelo,\n",
    "            'Mejor_N_Total': mejor_ntotal,\n",
    "            'ECRPS_Promedio': round(mejor_score, 4)\n",
    "        })\n",
    "        \n",
    "        print(f\"{tipo_proceso} | {modelo}: N_Total={mejor_ntotal} (ECRPS={mejor_score:.4f})\")\n",
    "\n",
    "# Guardar en Excel\n",
    "df_mejor_ntotal = pd.DataFrame(resultados_mejor_ntotal)\n",
    "archivo_mejor = output_dir / \"mejor_ntotal_por_modelo_y_tipo.xlsx\"\n",
    "df_mejor_ntotal.to_excel(archivo_mejor, index=False)\n",
    "\n",
    "# ============================================================================\n",
    "# AN√ÅLISIS 3: COMPARACI√ìN ENTRE N_TOTALES CON DIEBOLD-MARIANO\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AN√ÅLISIS 3: Comparaciones DM entre N_Totales\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "resultados_dm = []\n",
    "\n",
    "for tipo_proceso in df['Tipo_Proceso'].unique():\n",
    "    for modelo in MODELOS:\n",
    "        df_filtrado = df[df['Tipo_Proceso'] == tipo_proceso]\n",
    "        ntotales_disponibles = sorted(df_filtrado['N_Total'].unique())\n",
    "        \n",
    "        for ntotal1, ntotal2 in combinations(ntotales_disponibles, 2):\n",
    "            series1 = df_filtrado[df_filtrado['N_Total'] == ntotal1][modelo]\n",
    "            series2 = df_filtrado[df_filtrado['N_Total'] == ntotal2][modelo]\n",
    "            \n",
    "            if len(series1) > 0 and len(series2) > 0:\n",
    "                dm_stat, p_value = diebold_mariano_test(series1, series2)\n",
    "                \n",
    "                mean1 = series1.mean()\n",
    "                mean2 = series2.mean()\n",
    "                \n",
    "                es_significativo = p_value < 0.05 if not np.isnan(p_value) else False\n",
    "                \n",
    "                if es_significativo:\n",
    "                    if mean1 < mean2:\n",
    "                        ganador = ntotal1\n",
    "                        diferencia = \"N_Total={} es significativamente MEJOR\".format(ntotal1)\n",
    "                    else:\n",
    "                        ganador = ntotal2\n",
    "                        diferencia = \"N_Total={} es significativamente MEJOR\".format(ntotal2)\n",
    "                else:\n",
    "                    ganador = None\n",
    "                    diferencia = \"Sin diferencia significativa\"\n",
    "                \n",
    "                resultados_dm.append({\n",
    "                    'Tipo_Proceso': tipo_proceso,\n",
    "                    'Modelo': modelo,\n",
    "                    'N_Total_1': ntotal1,\n",
    "                    'N_Total_2': ntotal2,\n",
    "                    'ECRPS_1': round(mean1, 4),\n",
    "                    'ECRPS_2': round(mean2, 4),\n",
    "                    'P_Value': round(p_value, 4) if not np.isnan(p_value) else None,\n",
    "                    'Significativo': 'S√≠' if es_significativo else 'No',\n",
    "                    'Interpretaci√≥n': diferencia\n",
    "                })\n",
    "\n",
    "df_dm = pd.DataFrame(resultados_dm)\n",
    "archivo_dm = output_dir / \"comparaciones_ntotal_diebold_mariano.xlsx\"\n",
    "with pd.ExcelWriter(archivo_dm, engine='openpyxl') as writer:\n",
    "    df_dm.to_excel(writer, sheet_name='Resultados', index=False)\n",
    "\n",
    "# ============================================================================\n",
    "# AN√ÅLISIS 4: RESUMEN ESTAD√çSTICO\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AN√ÅLISIS 4: Resumen Estad√≠stico (ECRPS)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "resumen_stats = []\n",
    "for tipo_proceso in df['Tipo_Proceso'].unique():\n",
    "    for ntotal in sorted(df['N_Total'].unique()):\n",
    "        df_filtrado = df[(df['Tipo_Proceso'] == tipo_proceso) & (df['N_Total'] == ntotal)]\n",
    "        \n",
    "        for modelo in MODELOS:\n",
    "            vals = df_filtrado[modelo] # Asumimos ECRPS directo\n",
    "            resumen_stats.append({\n",
    "                'Tipo_Proceso': tipo_proceso,\n",
    "                'N_Total': ntotal,\n",
    "                'Modelo': modelo,\n",
    "                'Media': round(vals.mean(), 4),\n",
    "                'Mediana': round(vals.median(), 4),\n",
    "                'Desv_Std': round(vals.std(), 4),\n",
    "                'Min': round(vals.min(), 4),\n",
    "                'Max': round(vals.max(), 4)\n",
    "            })\n",
    "\n",
    "df_resumen = pd.DataFrame(resumen_stats)\n",
    "df_resumen.to_excel(output_dir / \"resumen_estadistico_ntotal.xlsx\", index=False)\n",
    "\n",
    "# ============================================================================\n",
    "# AN√ÅLISIS 5: GR√ÅFICO DE L√çNEAS - EVOLUCI√ìN POR TIPO DE PROCESO\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AN√ÅLISIS 5: Evoluci√≥n del ECRPS por Proceso\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for tipo_proceso in df['Tipo_Proceso'].unique():\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    for modelo in MODELOS:\n",
    "        df_filtrado = df[df['Tipo_Proceso'] == tipo_proceso]\n",
    "        promedios = df_filtrado.groupby('N_Total')[modelo].mean()\n",
    "        \n",
    "        ax.plot(promedios.index, promedios.values, marker='o', linewidth=2, label=modelo)\n",
    "    \n",
    "    ax.set_xlabel('N_Total (Tama√±o de Muestra)', fontsize=12)\n",
    "    ax.set_ylabel('ECRPS Promedio', fontsize=12)\n",
    "    ax.set_title(f'Evoluci√≥n del ECRPS por N_Total\\nTipo de Proceso: {tipo_proceso}',\n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='upper right', fontsize=10, bbox_to_anchor=(1.15, 1))\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    archivo_lineas = output_dir / f\"evolucion_ecrps_{tipo_proceso.replace(' ', '_')}.png\"\n",
    "    plt.savefig(archivo_lineas, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# AN√ÅLISIS 5B: TENDENCIA GLOBAL (TODOS LOS MODELOS EN UNA GR√ÅFICA)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AN√ÅLISIS 5B: Tendencia Global de Modelos (ECRPS vs N_Total)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Agrupar por N_Total para todos los procesos juntos (Promedio General)\n",
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(MODELOS)))\n",
    "\n",
    "for i, modelo in enumerate(MODELOS):\n",
    "    # Calcular promedio global por N_Total (ignorando tipo de proceso)\n",
    "    promedios_globales = df.groupby('N_Total')[modelo].mean()\n",
    "    \n",
    "    ax.plot(promedios_globales.index, promedios_globales.values, \n",
    "            marker='o', markersize=6, linewidth=2.5, \n",
    "            color=colors[i], label=modelo)\n",
    "\n",
    "ax.set_xlabel('N_Total (Tama√±o de Muestra)', fontsize=14)\n",
    "ax.set_ylabel('ECRPS Promedio Global', fontsize=14)\n",
    "ax.set_title('Tendencia Global: ECRPS Promedio por Modelo vs N_Total',\n",
    "             fontsize=18, fontweight='bold', pad=20)\n",
    "\n",
    "# Ajustar leyenda y grid\n",
    "ax.legend(title='Modelos', title_fontsize=12, fontsize=11, \n",
    "          loc='upper left', bbox_to_anchor=(1, 1))\n",
    "ax.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "\n",
    "archivo_global = output_dir / \"tendencia_global_modelos.png\"\n",
    "plt.savefig(archivo_global, dpi=300, bbox_inches='tight')\n",
    "print(f\"Gr√°fica de tendencia global guardada: {archivo_global}\")\n",
    "plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# AN√ÅLISIS 6: RANKINGS Y FRECUENCIAS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AN√ÅLISIS 6: Generando Rankings\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "rankings = []\n",
    "for tipo_proceso in df['Tipo_Proceso'].unique():\n",
    "    for ntotal in sorted(df['N_Total'].unique()):\n",
    "        df_filtrado = df[(df['Tipo_Proceso'] == tipo_proceso) & (df['N_Total'] == ntotal)]\n",
    "        \n",
    "        errores_promedio = {}\n",
    "        for modelo in MODELOS:\n",
    "            errores_promedio[modelo] = df_filtrado[modelo].mean()\n",
    "        \n",
    "        ranking_modelos = sorted(errores_promedio.items(), key=lambda x: x[1])\n",
    "        \n",
    "        for rank, (modelo, score) in enumerate(ranking_modelos, 1):\n",
    "            rankings.append({\n",
    "                'Tipo_Proceso': tipo_proceso,\n",
    "                'N_Total': ntotal,\n",
    "                'Rank': rank,\n",
    "                'Modelo': modelo,\n",
    "                'ECRPS_Promedio': score\n",
    "            })\n",
    "\n",
    "df_rankings = pd.DataFrame(rankings)\n",
    "archivo_rankings = output_dir / \"rankings_modelos_por_ntotal.xlsx\"\n",
    "df_rankings.to_excel(archivo_rankings, index=False)\n",
    "\n",
    "# ============================================================================\n",
    "# AN√ÅLISIS 7: VARIABILIDAD (Heatmaps STD)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AN√ÅLISIS 7: Variabilidad (Desviaci√≥n Est√°ndar)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "variabilidad_resultados = []\n",
    "\n",
    "# Calcular variabilidad general\n",
    "for modelo in MODELOS:\n",
    "    for ntotal in sorted(df['N_Total'].unique()):\n",
    "        vals = df[df['N_Total'] == ntotal][modelo]\n",
    "        variabilidad_resultados.append({\n",
    "            'Escenario': 'General',\n",
    "            'Modelo': modelo,\n",
    "            'N_Total': ntotal,\n",
    "            'Desv_Std': vals.std(),\n",
    "            'CV': (vals.std() / vals.mean() * 100) if vals.mean() != 0 else 0\n",
    "        })\n",
    "\n",
    "df_variabilidad = pd.DataFrame(variabilidad_resultados)\n",
    "\n",
    "# Generar Heatmap de Desviaci√≥n Est√°ndar (General)\n",
    "df_esc = df_variabilidad[df_variabilidad['Escenario'] == 'General']\n",
    "pivot_std = df_esc.pivot(index='Modelo', columns='N_Total', values='Desv_Std')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "\n",
    "sns.heatmap(pivot_std, \n",
    "            annot=True, \n",
    "            fmt='.2f',  # <--- CAMBIO: Solo 2 d√≠gitos\n",
    "            cmap='YlOrRd',\n",
    "            cbar_kws={'label': 'Desviaci√≥n Est√°ndar (ECRPS)', 'shrink': 0.6}, # <--- CAMBIO: Barra reducida\n",
    "            linewidths=0.5,\n",
    "            linecolor='gray',\n",
    "            annot_kws={'size': 9},\n",
    "            square=True,\n",
    "            ax=ax)\n",
    "\n",
    "plt.title('Variabilidad (Desviaci√≥n Est√°ndar) del ECRPS\\nEscenario General',\n",
    "          fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "\n",
    "archivo_var = output_dir / \"variabilidad_std_general.png\"\n",
    "plt.savefig(archivo_var, dpi=300, bbox_inches='tight')\n",
    "print(f\"Heatmap de variabilidad (STD) guardado: {archivo_var}\")\n",
    "plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# FINALIZAR\n",
    "# ============================================================================\n",
    "print(\"\\n‚úÖ Proceso completado. Revisa la carpeta de resultados.\")\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

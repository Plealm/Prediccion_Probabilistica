{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7966bbd6",
   "metadata": {},
   "source": [
    "# Analisis Simulacion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86610207",
   "metadata": {},
   "source": [
    "## Analisis General - Simulación Base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc245af6",
   "metadata": {},
   "source": [
    "### Pre-procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "378a602a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tabla Comparativa de Modelos (Basada en MEDIA) ---\n",
      "             Modelo  General     ARMA     ARIMA    SETAR Mejor_Escenario\n",
      "Block Bootstrapping 4.275512 0.947365 11.251901 0.627270           SETAR\n",
      "    Sieve Bootstrap 0.570491 0.547725  0.547481 0.616268           ARIMA\n",
      "               LSPM 0.845497 0.811287  1.064804 0.660398           SETAR\n",
      "              LSPMW 1.572319 0.960743  3.079645 0.676570           SETAR\n",
      "              AREPD 3.880255 0.936671 10.031183 0.672910           SETAR\n",
      "               MCPS 1.562693 0.759453  3.231805 0.696822           SETAR\n",
      "            AV-MCPS 1.588747 0.740911  3.341841 0.683490           SETAR\n",
      "             DeepAR 1.836024 0.568693  4.329124 0.610255            ARMA\n",
      "         EnCQR-LSTM 2.454851 0.843920  5.850490 0.670144           SETAR\n",
      "\n",
      "--- Tabla Comparativa de Modelos (Basada en MEDIANA) ---\n",
      "             Modelo  General     ARMA    ARIMA    SETAR Mejor_Escenario\n",
      "Block Bootstrapping 0.989417 0.653853 5.275960 0.540499           SETAR\n",
      "    Sieve Bootstrap 0.504848 0.483753 0.487997 0.535568            ARMA\n",
      "               LSPM 0.617954 0.617367 0.813400 0.551614           SETAR\n",
      "              LSPMW 0.803709 0.671465 1.666194 0.559561           SETAR\n",
      "              AREPD 0.987714 0.650945 4.398461 0.566293           SETAR\n",
      "               MCPS 0.682918 0.620742 1.251044 0.596578           SETAR\n",
      "            AV-MCPS 0.674426 0.604950 1.243175 0.587368           SETAR\n",
      "             DeepAR 0.579363 0.510069 1.029325 0.531675            ARMA\n",
      "         EnCQR-LSTM 0.932454 0.637626 3.123052 0.559208           SETAR\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Leer los archivos\n",
    "arma_df = pd.read_excel(\"./datos/Simulacion/Base/resultados_140_ARMA_FINAL.xlsx\")\n",
    "arima_df = pd.read_excel(\"./datos/Simulacion/Base/resultados_140_ARIMA_FINAL.xlsx\")\n",
    "setar_df = pd.read_excel(\"./datos/Simulacion/Base/resultados_140_SETAR_FINAL.xlsx\")\n",
    "\n",
    "# 2. Asignar la columna ESCENARIO a cada dataframe\n",
    "arma_df['ESCENARIO'] = \"Lineal Estacionario\"\n",
    "arima_df['ESCENARIO'] = \"Lineal No estacionario\"\n",
    "setar_df['ESCENARIO'] = \"No lineal Estacionario\"\n",
    "\n",
    "# 3. Juntarlos uno bajo el otro (Concatenar)\n",
    "df_total = pd.concat([arma_df, arima_df, setar_df], ignore_index=True)\n",
    "\n",
    "# Seleccionar solo las columnas requeridas\n",
    "columnas_deseadas = [\n",
    "    \"Paso\", \"Config\", \"Dist\", \"Var\", \"Block Bootstrapping\", \n",
    "    \"Sieve Bootstrap\", \"LSPM\", \"LSPMW\", \"AREPD\", \"MCPS\", \n",
    "    \"AV-MCPS\", \"DeepAR\", \"EnCQR-LSTM\", \"ESCENARIO\"\n",
    "]\n",
    "df_total = df_total[columnas_deseadas]\n",
    "\n",
    "# Definimos cuáles son las columnas que representan a los modelos predictivos\n",
    "modelos = [\n",
    "    \"Block Bootstrapping\", \"Sieve Bootstrap\", \"LSPM\", \"LSPMW\", \n",
    "    \"AREPD\", \"MCPS\", \"AV-MCPS\", \"DeepAR\", \"EnCQR-LSTM\"\n",
    "]\n",
    "\n",
    "# 4. Guardar el dataframe consolidado\n",
    "df_total.to_excel(\"./datos/Simulacion/Base/dataframe_consolidado.xlsx\", index=False)\n",
    "\n",
    "# 5. Generar y mostrar las tablas (Media y Mediana)\n",
    "metricas = {'MEDIA': 'mean', 'MEDIANA': 'median'}\n",
    "\n",
    "for nombre_metrica, funcion in metricas.items():\n",
    "    # Calculamos el valor general según la métrica (mean o median)\n",
    "    if funcion == 'mean':\n",
    "        resumen_general = df_total[modelos].mean()\n",
    "        resumen_escenarios = df_total.groupby('ESCENARIO')[modelos].mean().T\n",
    "    else:\n",
    "        resumen_general = df_total[modelos].median()\n",
    "        resumen_escenarios = df_total.groupby('ESCENARIO')[modelos].median().T\n",
    "\n",
    "    # Construimos la tabla final para esta métrica\n",
    "    tabla_resumen = pd.DataFrame(index=modelos)\n",
    "    tabla_resumen['General'] = resumen_general\n",
    "    tabla_resumen['ARMA'] = resumen_escenarios['Lineal Estacionario']\n",
    "    tabla_resumen['ARIMA'] = resumen_escenarios['Lineal No estacionario']\n",
    "    tabla_resumen['SETAR'] = resumen_escenarios['No lineal Estacionario']\n",
    "\n",
    "    # Determinar el Mejor_Escenario (valor mínimo entre los tres escenarios)\n",
    "    escenarios_cols = ['ARMA', 'ARIMA', 'SETAR']\n",
    "    tabla_resumen['Mejor_Escenario'] = tabla_resumen[escenarios_cols].idxmin(axis=1)\n",
    "\n",
    "    # Imprimir resultado\n",
    "    print(f\"\\n--- Tabla Comparativa de Modelos (Basada en {nombre_metrica}) ---\")\n",
    "    print(tabla_resumen.reset_index().rename(columns={'index': 'Modelo'}).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abc9573",
   "metadata": {},
   "source": [
    "### Analisis general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b90efcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuevo orden de modelos (basado en Lineal No Estacionario (ARIMA)):\n",
      "1. Sieve Bootstrap: 0.5475\n",
      "2. LSPMW: 1.0636\n",
      "3. LSPM: 1.0648\n",
      "4. MCPS: 3.2318\n",
      "5. AV-MCPS: 3.3418\n",
      "6. DeepAR: 4.3291\n",
      "7. EnCQR-LSTM: 5.8505\n",
      "8. AREPD: 10.0312\n",
      "9. Block Bootstrapping: 11.2519\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 1: RENDIMIENTO POR ESCENARIOS\n",
      "================================================================================\n",
      "✓ Gráfica 1.1 guardada\n",
      "✓ Gráfica 1.2 guardada\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 2: ANÁLISIS POR CONFIG\n",
      "================================================================================\n",
      "✓ Gráfica 2.1 guardada\n",
      "✓ Gráfica 2.1.a guardada\n",
      "✓ Gráfica 2.1.b guardada\n",
      "✓ Gráfica 2.1.c guardada\n",
      "✓ Gráfica 2.2 guardada\n",
      "✓ Gráfica 2.2.a guardada\n",
      "✓ Gráfica 2.2.b guardada\n",
      "✓ Gráfica 2.2.c guardada\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 3: ANÁLISIS POR DIST\n",
      "================================================================================\n",
      "✓ Gráfica 3.1 guardada\n",
      "✓ Gráfica 3.1.a guardada\n",
      "✓ Gráfica 3.1.b guardada\n",
      "✓ Gráfica 3.1.c guardada\n",
      "✓ Gráfica 3.2 guardada\n",
      "✓ Gráfica 3.2.a guardada\n",
      "✓ Gráfica 3.2.b guardada\n",
      "✓ Gráfica 3.2.c guardada\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 4: ANÁLISIS POR VAR\n",
      "================================================================================\n",
      "✓ Gráfica 4.1 guardada\n",
      "✓ Gráfica 4.1.a guardada\n",
      "✓ Gráfica 4.1.b guardada\n",
      "✓ Gráfica 4.1.c guardada\n",
      "✓ Gráfica 4.2 guardada\n",
      "✓ Gráfica 4.2.a guardada\n",
      "✓ Gráfica 4.2.b guardada\n",
      "✓ Gráfica 4.2.c guardada\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 5: ANÁLISIS POR PASO (HORIZONTE)\n",
      "================================================================================\n",
      "✓ Gráfica 5.1 guardada\n",
      "✓ Gráfica 5.1.a guardada\n",
      "✓ Gráfica 5.1.b guardada\n",
      "✓ Gráfica 5.1.c guardada\n",
      "✓ Gráfica 5.2 guardada\n",
      "✓ Gráfica 5.2.a guardada\n",
      "✓ Gráfica 5.2.b guardada\n",
      "✓ Gráfica 5.2.c guardada\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 5.5: ANÁLISIS DE INTERACCIONES\n",
      "================================================================================\n",
      "✓ Gráfica 8 (5.7)  guardada: Subplots por Modelo\n",
      "✓ Gráfica 9 (5.8)  guardada: Subplots por Modelo\n",
      "✓ Gráfica 10 (5.9)  guardada: Subplots por Modelo\n",
      "✓ Gráfica 11 (5.10)  guardada: Subplots por Modelo\n",
      "✓ Gráfica 8 (5.7) .a guardada: Subplots por Modelo\n",
      "✓ Gráfica 9 (5.8) .a guardada: Subplots por Modelo\n",
      "✓ Gráfica 10 (5.9) .a guardada: Subplots por Modelo\n",
      "✓ Gráfica 11 (5.10) .a guardada: Subplots por Modelo\n",
      "✓ Gráfica 8 (5.7) .b guardada: Subplots por Modelo\n",
      "✓ Gráfica 9 (5.8) .b guardada: Subplots por Modelo\n",
      "✓ Gráfica 10 (5.9) .b guardada: Subplots por Modelo\n",
      "✓ Gráfica 11 (5.10) .b guardada: Subplots por Modelo\n",
      "✓ Gráfica 8 (5.7) .c guardada: Subplots por Modelo\n",
      "✓ Gráfica 9 (5.8) .c guardada: Subplots por Modelo\n",
      "✓ Gráfica 10 (5.9) .c guardada: Subplots por Modelo\n",
      "✓ Gráfica 11 (5.10) .c guardada: Subplots por Modelo\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 6: ROBUSTEZ Y TEST DIEBOLD-MARIANO\n",
      "================================================================================\n",
      "✓ Gráfica 6.1 guardada (ordenada de menor a mayor CV)\n",
      "✓ Gráfica 6.2 guardada (Test HLN-DM con h=6, T=5040, df=5039)\n",
      "✓ Gráfica 6.2.a guardada (Test HLN-DM con h=6, T=1680, df=1679)\n",
      "✓ Gráfica 6.2.b guardada (Test HLN-DM con h=6, T=1680, df=1679)\n",
      "✓ Gráfica 6.2.c guardada (Test HLN-DM con h=6, T=1680, df=1679)\n",
      "\n",
      "================================================================================\n",
      "PROCESO COMPLETADO\n",
      "================================================================================\n",
      "\n",
      "Mejoras implementadas:\n",
      "1. ✓ Orden consistente en gráficas 1.1 y 1.2\n",
      "2. ✓ Formato de 2 decimales en heatmap 2.2 general\n",
      "3. ✓ Solo Coeficiente de Variación en gráfica 6.1 (ordenado menor a mayor)\n",
      "4. ✓ Test Diebold-Mariano con corrección HLN y distribución t-Student\n",
      "5. ✓ Horizonte de pronóstico (h) incorporado en el análisis\n",
      "\n",
      "================================================================================\n",
      "ANÁLISIS DE INTERACCIONES (Carpeta: Interacciones/)\n",
      "================================================================================\n",
      "6. ✓ Config × Var: Heatmaps por modelo (matriz 3×3)\n",
      "7. ✓ Config × Dist: Heatmaps por modelo (matriz 3×3)\n",
      "8. ✓ Dist × Paso: Gráficas de líneas por distribución\n",
      "9. ✓ Dist × Var: Gráficas de líneas por distribución\n",
      "10. ✓ Config × Paso: Gráficas de líneas por configuración\n",
      "11. ✓ Var × Horizonte: Gráficas de líneas por varianza\n",
      "================================================================================\n",
      "\n",
      "Total de gráficas generadas en Interacciones/: 24 archivos\n",
      "(6 tipos de interacción × 4 escenarios: General + 3 específicos)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import normaltest\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración general\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Crear carpeta de resultados\n",
    "output_dir = Path(\"./Resultados_analisis/Simulacion_base\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Crear carpeta de interacciones\n",
    "interactions_dir = output_dir / \"Interacciones\"\n",
    "interactions_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_excel(\"./datos/Simulacion/Base/dataframe_consolidado.xlsx\")\n",
    "\n",
    "# 1) CAMBIO DE NOMBRES DE ESCENARIOS\n",
    "df['ESCENARIO'] = df['ESCENARIO'].replace({\n",
    "    \"Lineal Estacionario\": \"Lineal Estacionario (ARMA)\",\n",
    "    \"Lineal No estacionario\": \"Lineal No Estacionario (ARIMA)\",\n",
    "    \"No lineal Estacionario\": \"No lineal Estacionario (SETAR)\"\n",
    "})\n",
    "\n",
    "# Identificar columnas de modelos\n",
    "var_cols = ['Paso', 'Config', 'Dist', 'Var', 'ESCENARIO']\n",
    "original_model_cols = [col for col in df.columns if col not in var_cols]\n",
    "\n",
    "# 2) ORGANIZAR MODELOS POR RENDIMIENTO EN \"Lineal No Estacionario (ARIMA)\" (Menor a mayor)\n",
    "target_scenario = \"Lineal No Estacionario (ARIMA)\"\n",
    "model_order_scores = df[df['ESCENARIO'] == target_scenario][original_model_cols].mean().sort_values()\n",
    "model_cols = list(model_order_scores.index)\n",
    "\n",
    "print(\"Nuevo orden de modelos (basado en Lineal No Estacionario (ARIMA)):\")\n",
    "for i, m in enumerate(model_cols, 1):\n",
    "    print(f\"{i}. {m}: {model_order_scores[m]:.4f}\")\n",
    "\n",
    "# Mapeo de escenarios\n",
    "escenarios_map = {\n",
    "    'Lineal Estacionario (ARMA)': 'Lineal Estacionario (ARMA)',\n",
    "    'Lineal No Estacionario (ARIMA)': 'Lineal No Estacionario (ARIMA)',\n",
    "    'No lineal Estacionario (SETAR)': 'No lineal Estacionario (SETAR)'\n",
    "}\n",
    "\n",
    "# Definir colores para cada modelo\n",
    "palette = sns.color_palette(\"husl\", len(model_cols))\n",
    "model_colors = {model: palette[i] for i, model in enumerate(model_cols)}\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 1: RENDIMIENTO POR ESCENARIOS\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 1: RENDIMIENTO POR ESCENARIOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_performance_by_scenario():\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    scenarios = [\"Lineal Estacionario (ARMA)\", \"Lineal No Estacionario (ARIMA)\", \"No lineal Estacionario (SETAR)\"]\n",
    "    x = np.arange(len(model_cols))\n",
    "    width = 0.25 \n",
    "    \n",
    "    scenario_colors = {\n",
    "        'Lineal Estacionario (ARMA)': '#5D3FD3',    \n",
    "        'Lineal No Estacionario (ARIMA)': '#808080', \n",
    "        'No lineal Estacionario (SETAR)': '#00A36C'  \n",
    "    }\n",
    "    \n",
    "    for idx, scenario in enumerate(scenarios):\n",
    "        means = [df[df['ESCENARIO'] == scenario][model].mean() for model in model_cols]\n",
    "        position = x + (idx - 1) * width\n",
    "        \n",
    "        bars = ax.bar(position, means, width, label=scenario, \n",
    "                     color=scenario_colors[scenario], alpha=0.85, edgecolor='black', linewidth=0.5)\n",
    "        \n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{height:.2f}', ha='center', va='bottom', fontsize=7, rotation=0)\n",
    "    \n",
    "    ax.set_xlabel('Modelo (Ordenados por desempeño en ARIMA)', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('ECRPS Promedio', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Rendimiento de Modelos por Escenario (ECRPS)', fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(model_cols, rotation=45, ha='right', fontsize=9)\n",
    "    ax.legend(loc='upper left', ncol=1, fontsize=10, framealpha=0.9)\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / '1.1_rendimiento_por_escenario.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Gráfica 1.1 guardada\")\n",
    "\n",
    "plot_performance_by_scenario()\n",
    "\n",
    "def plot_relative_performance():\n",
    "    base_scenario = 'Lineal Estacionario (ARMA)'\n",
    "    scenarios_compare = ['Lineal No Estacionario (ARIMA)', 'No lineal Estacionario (SETAR)']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 10))\n",
    "    \n",
    "    y = np.arange(len(model_cols))\n",
    "    height = 0.35  \n",
    "    \n",
    "    for idx, scenario in enumerate(scenarios_compare):\n",
    "        changes = []\n",
    "        for model in model_cols:\n",
    "            base_value = df[df['ESCENARIO'] == base_scenario][model].mean()\n",
    "            scenario_value = df[df['ESCENARIO'] == scenario][model].mean()\n",
    "            pct_change = ((scenario_value - base_value) / base_value) * 100\n",
    "            changes.append(pct_change)\n",
    "        \n",
    "        position = y + idx * height\n",
    "        bars = ax.barh(position, changes, height, label=scenario, alpha=0.85, edgecolor='black', linewidth=0.5)\n",
    "        \n",
    "        for bar, val in zip(bars, changes):\n",
    "            width = bar.get_width()\n",
    "            ax.text(width + (1 if width > 0 else -1), bar.get_y() + bar.get_height()/2.,\n",
    "                   f'{val:+.1f}%', ha='left' if val > 0 else 'right', \n",
    "                   va='center', fontsize=7)\n",
    "    \n",
    "    ax.set_yticks(y + height / 2)\n",
    "    ax.set_yticklabels(model_cols, fontsize=10)\n",
    "    ax.set_xlabel('Cambio Relativo (%)', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(f'Cambio Relativo en ECRPS vs. {base_scenario}', fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.axvline(x=0, color='black', linestyle='-', linewidth=1.5)\n",
    "    ax.legend(loc='best', fontsize=10, framealpha=0.9)\n",
    "    ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / '1.2_cambio_relativo_escenario_base.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Gráfica 1.2 guardada\")\n",
    "\n",
    "plot_relative_performance()\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 2: ANÁLISIS POR CONFIG\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 2: ANÁLISIS POR CONFIG\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_zscore_heatmap_config(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Z-scores de ECRPS por Configuración ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Z-scores de ECRPS por Configuración (General)'\n",
    "    \n",
    "    pivot_data = data_filtered.groupby('Config')[model_cols].mean()\n",
    "    z_scores = pivot_data.apply(lambda x: (x - x.mean()) / x.std(), axis=0)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    sns.heatmap(z_scores.T, annot=True, fmt='.2f', cmap='RdYlGn_r', \n",
    "                center=0, cbar_kws={'label': 'Z-score'}, ax=ax,\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    ax.set_title(title, fontsize=12, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Configuración', fontsize=11)\n",
    "    ax.set_ylabel('Modelo', fontsize=11)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'2.1{suffix}_zscore_config.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 2.1{suffix} guardada\")\n",
    "\n",
    "plot_zscore_heatmap_config()\n",
    "plot_zscore_heatmap_config('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_zscore_heatmap_config('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_zscore_heatmap_config('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "def plot_variability_config(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Desv. Estándar de ECRPS por Configuración ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Desv. Estándar de ECRPS por Configuración (General)'\n",
    "    \n",
    "    pivot_std = data_filtered.groupby('Config')[model_cols].std()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    fmt = '.2f' if suffix == '' else '.4f'\n",
    "    sns.heatmap(pivot_std.T, annot=True, fmt=fmt, cmap='YlOrRd', \n",
    "                cbar_kws={'label': 'Desv. Estándar'}, ax=ax,\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Configuración', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'2.2{suffix}_variabilidad_config.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 2.2{suffix} guardada\")\n",
    "\n",
    "plot_variability_config()\n",
    "plot_variability_config('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_variability_config('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_variability_config('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 3: ANÁLISIS POR DIST\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 3: ANÁLISIS POR DIST\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_zscore_heatmap_dist(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Z-scores de ECRPS por Distribución ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Z-scores de ECRPS por Distribución (General)'\n",
    "    \n",
    "    pivot_data = data_filtered.groupby('Dist')[model_cols].mean()\n",
    "    z_scores = pivot_data.apply(lambda x: (x - x.mean()) / x.std(), axis=0)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    sns.heatmap(z_scores.T, annot=True, fmt='.2f', cmap='RdYlGn_r', \n",
    "                center=0, cbar_kws={'label': 'Z-score'}, ax=ax,\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    ax.set_title(title, fontsize=12, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Distribución', fontsize=11)\n",
    "    ax.set_ylabel('Modelo', fontsize=11)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'3.1{suffix}_zscore_dist.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 3.1{suffix} guardada\")\n",
    "\n",
    "plot_zscore_heatmap_dist()\n",
    "plot_zscore_heatmap_dist('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_zscore_heatmap_dist('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_zscore_heatmap_dist('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "def plot_variability_dist(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Desv. Estándar de ECRPS por Distribución ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Desv. Estándar de ECRPS por Distribución (General)'\n",
    "    \n",
    "    pivot_std = data_filtered.groupby('Dist')[model_cols].std()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    sns.heatmap(pivot_std.T, annot=True, fmt='.4f', cmap='YlOrRd', \n",
    "                cbar_kws={'label': 'Desv. Estándar'}, ax=ax,\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Distribución', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'3.2{suffix}_variabilidad_dist.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 3.2{suffix} guardada\")\n",
    "\n",
    "plot_variability_dist()\n",
    "plot_variability_dist('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_variability_dist('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_variability_dist('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 4: ANÁLISIS POR VAR\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 4: ANÁLISIS POR VAR\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_evolution_var(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Evolución de ECRPS por Varianza ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Evolución de ECRPS por Varianza (General)'\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    var_values = sorted(data_filtered['Var'].unique())\n",
    "    \n",
    "    for model in model_cols:\n",
    "        means = []\n",
    "        for var in var_values:\n",
    "            mean_val = data_filtered[data_filtered['Var'] == var][model].mean()\n",
    "            means.append(mean_val)\n",
    "        \n",
    "        ax.plot(var_values, means, marker='o', label=model, color=model_colors[model],\n",
    "                linewidth=2.5, markersize=7, alpha=0.85)\n",
    "    \n",
    "    ax.set_xlabel('Varianza', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('ECRPS Promedio', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.legend(loc='best', fontsize=9, ncol=2, framealpha=0.9)\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'4.1{suffix}_evolucion_var.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 4.1{suffix} guardada\")\n",
    "\n",
    "plot_evolution_var()\n",
    "plot_evolution_var('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_evolution_var('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_evolution_var('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "def plot_variability_var(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Desv. Estándar de ECRPS por Varianza ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Desv. Estándar de ECRPS por Varianza (General)'\n",
    "    \n",
    "    pivot_std = data_filtered.groupby('Var')[model_cols].std()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    sns.heatmap(pivot_std.T, annot=True, fmt='.4f', cmap='YlOrRd', \n",
    "                cbar_kws={'label': 'Desv. Estándar'}, ax=ax,\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Varianza', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'4.2{suffix}_variabilidad_var.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 4.2{suffix} guardada\")\n",
    "\n",
    "plot_variability_var()\n",
    "plot_variability_var('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_variability_var('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_variability_var('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 5: ANÁLISIS POR PASO (HORIZONTE)\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 5: ANÁLISIS POR PASO (HORIZONTE)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_evolution_paso(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Evolución de ECRPS por Horizonte de Pronóstico ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Evolución de ECRPS por Horizonte de Pronóstico (General)'\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    pasos = sorted(data_filtered['Paso'].unique())\n",
    "    \n",
    "    for model in model_cols:\n",
    "        means = []\n",
    "        for paso in pasos:\n",
    "            mean_val = data_filtered[data_filtered['Paso'] == paso][model].mean()\n",
    "            means.append(mean_val)\n",
    "        \n",
    "        ax.plot(pasos, means, marker='o', label=model, color=model_colors[model],\n",
    "                linewidth=2.5, markersize=7, alpha=0.85)\n",
    "    \n",
    "    ax.set_xlabel('Horizonte de Pronóstico', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('ECRPS Promedio', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.legend(loc='best', fontsize=9, ncol=2, framealpha=0.9)\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'5.1{suffix}_evolucion_paso.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 5.1{suffix} guardada\")\n",
    "\n",
    "plot_evolution_paso()\n",
    "plot_evolution_paso('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_evolution_paso('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_evolution_paso('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "def plot_variability_paso(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Desv. Estándar de ECRPS por Horizonte ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Desv. Estándar de ECRPS por Horizonte (General)'\n",
    "    \n",
    "    pivot_std = data_filtered.groupby('Paso')[model_cols].std()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    sns.heatmap(pivot_std.T, annot=True, fmt='.4f', cmap='YlOrRd', \n",
    "                cbar_kws={'label': 'Desv. Estándar'}, ax=ax,\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Horizonte de Pronóstico', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'5.2{suffix}_variabilidad_paso.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 5.2{suffix} guardada\")\n",
    "\n",
    "plot_variability_paso()\n",
    "plot_variability_paso('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_variability_paso('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_variability_paso('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 5.5: ANÁLISIS DE INTERACCIONES\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 5.5: ANÁLISIS DE INTERACCIONES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Función auxiliar para configurar el grid de modelos\n",
    "def get_model_grid_axes(n_models):\n",
    "    n_cols = 3\n",
    "    n_rows = (n_models + n_cols - 1) // n_cols\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 5 * n_rows))\n",
    "    return fig, axes.flatten(), n_rows, n_cols\n",
    "\n",
    "# INTERACCIÓN 3 (Lista 8): DIST × PASO - Subplots por Modelo\n",
    "def plot_interaction_dist_paso(scenario=None, suffix=''):\n",
    "    data_filtered = df[df['ESCENARIO'] == scenario].copy() if scenario else df.copy()\n",
    "    title = f'Interacción Dist × Paso por Modelo ({\"General\" if not scenario else scenario})'\n",
    "    \n",
    "    fig, axes, n_rows, n_cols = get_model_grid_axes(len(model_cols))\n",
    "    dists = sorted(data_filtered['Dist'].unique())\n",
    "    pasos = sorted(data_filtered['Paso'].unique())\n",
    "    colors_dist = sns.color_palette(\"viridis\", len(dists))\n",
    "\n",
    "    for idx, model in enumerate(model_cols):\n",
    "        ax = axes[idx]\n",
    "        for d_idx, dist in enumerate(dists):\n",
    "            means = [data_filtered[(data_filtered['Dist'] == dist) & (data_filtered['Paso'] == p)][model].mean() for p in pasos]\n",
    "            ax.plot(pasos, means, marker='o', label=dist, color=colors_dist[d_idx], linewidth=2)\n",
    "        \n",
    "        ax.set_title(f'Modelo: {model}', fontweight='bold')\n",
    "        ax.set_xlabel('Horizonte (Paso)')\n",
    "        ax.set_ylabel('ECRPS Promedio')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        if idx == 0: ax.legend(title=\"Distribución\", fontsize=8)\n",
    "\n",
    "    for i in range(len(model_cols), len(axes)): axes[i].set_visible(False)\n",
    "    plt.suptitle(title, fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(interactions_dir / f'5.7{suffix}_interaccion_dist_paso_modelos.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 8 (5.7) {suffix} guardada: Subplots por Modelo\")\n",
    "\n",
    "# INTERACCIÓN 4 (Lista 9): DIST × VAR - Subplots por Modelo\n",
    "def plot_interaction_dist_var(scenario=None, suffix=''):\n",
    "    data_filtered = df[df['ESCENARIO'] == scenario].copy() if scenario else df.copy()\n",
    "    title = f'Interacción Dist × Var por Modelo ({\"General\" if not scenario else scenario})'\n",
    "    \n",
    "    fig, axes, _, _ = get_model_grid_axes(len(model_cols))\n",
    "    dists = sorted(data_filtered['Dist'].unique())\n",
    "    vars_val = sorted(data_filtered['Var'].unique())\n",
    "    colors_dist = sns.color_palette(\"magma\", len(dists))\n",
    "\n",
    "    for idx, model in enumerate(model_cols):\n",
    "        ax = axes[idx]\n",
    "        for d_idx, dist in enumerate(dists):\n",
    "            means = [data_filtered[(data_filtered['Dist'] == dist) & (data_filtered['Var'] == v)][model].mean() for v in vars_val]\n",
    "            ax.plot(vars_val, means, marker='s', label=dist, color=colors_dist[d_idx], linewidth=2)\n",
    "        \n",
    "        ax.set_title(f'Modelo: {model}', fontweight='bold')\n",
    "        ax.set_xlabel('Varianza')\n",
    "        ax.set_ylabel('ECRPS Promedio')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        if idx == 0: ax.legend(title=\"Distribución\", fontsize=8)\n",
    "\n",
    "    for i in range(len(model_cols), len(axes)): axes[i].set_visible(False)\n",
    "    plt.suptitle(title, fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(interactions_dir / f'5.8{suffix}_interaccion_dist_var_modelos.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 9 (5.8) {suffix} guardada: Subplots por Modelo\")\n",
    "\n",
    "# INTERACCIÓN 5 (Lista 10): CONFIG × PASO - Subplots por Modelo\n",
    "def plot_interaction_config_paso(scenario=None, suffix=''):\n",
    "    data_filtered = df[df['ESCENARIO'] == scenario].copy() if scenario else df.copy()\n",
    "    title = f'Interacción Config × Paso por Modelo ({\"General\" if not scenario else scenario})'\n",
    "    \n",
    "    fig, axes, _, _ = get_model_grid_axes(len(model_cols))\n",
    "    configs = sorted(data_filtered['Config'].unique())\n",
    "    pasos = sorted(data_filtered['Paso'].unique())\n",
    "    colors_conf = sns.color_palette(\"tab10\", len(configs))\n",
    "\n",
    "    for idx, model in enumerate(model_cols):\n",
    "        ax = axes[idx]\n",
    "        for c_idx, config in enumerate(configs):\n",
    "            means = [data_filtered[(data_filtered['Config'] == config) & (data_filtered['Paso'] == p)][model].mean() for p in pasos]\n",
    "            ax.plot(pasos, means, marker='^', label=config, color=colors_conf[c_idx], linewidth=2)\n",
    "        \n",
    "        ax.set_title(f'Modelo: {model}', fontweight='bold')\n",
    "        ax.set_xlabel('Horizonte (Paso)')\n",
    "        ax.set_ylabel('ECRPS Promedio')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        if idx == 0: ax.legend(title=\"Config\", fontsize=8)\n",
    "\n",
    "    for i in range(len(model_cols), len(axes)): axes[i].set_visible(False)\n",
    "    plt.suptitle(title, fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(interactions_dir / f'5.9{suffix}_interaccion_config_paso_modelos.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 10 (5.9) {suffix} guardada: Subplots por Modelo\")\n",
    "\n",
    "# INTERACCIÓN 6 (Lista 11): VAR × HORIZONTE - Subplots por Modelo\n",
    "def plot_interaction_var_horizonte(scenario=None, suffix=''):\n",
    "    data_filtered = df[df['ESCENARIO'] == scenario].copy() if scenario else df.copy()\n",
    "    title = f'Interacción Var × Horizonte por Modelo ({\"General\" if not scenario else scenario})'\n",
    "    \n",
    "    fig, axes, _, _ = get_model_grid_axes(len(model_cols))\n",
    "    vars_val = sorted(data_filtered['Var'].unique())\n",
    "    pasos = sorted(data_filtered['Paso'].unique())\n",
    "    colors_var = sns.color_palette(\"rocket\", len(vars_val))\n",
    "\n",
    "    for idx, model in enumerate(model_cols):\n",
    "        ax = axes[idx]\n",
    "        for v_idx, var in enumerate(vars_val):\n",
    "            means = [data_filtered[(data_filtered['Var'] == var) & (data_filtered['Paso'] == p)][model].mean() for p in pasos]\n",
    "            ax.plot(pasos, means, marker='d', label=f'Var {var}', color=colors_var[v_idx], linewidth=2)\n",
    "        \n",
    "        ax.set_title(f'Modelo: {model}', fontweight='bold')\n",
    "        ax.set_xlabel('Horizonte (Paso)')\n",
    "        ax.set_ylabel('ECRPS Promedio')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        if idx == 0: ax.legend(title=\"Varianza\", fontsize=8)\n",
    "\n",
    "    for i in range(len(model_cols), len(axes)): axes[i].set_visible(False)\n",
    "    plt.suptitle(title, fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(interactions_dir / f'5.10{suffix}_interaccion_var_horizonte_modelos.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 11 (5.10) {suffix} guardada: Subplots por Modelo\")\n",
    "\n",
    "\n",
    "# ====================================================================================\n",
    "# EJECUCIÓN DE LAS NUEVAS FUNCIONES\n",
    "# ====================================================================================\n",
    "\n",
    "for sc_name, sc_suf in [ (None, ''), ('Lineal Estacionario (ARMA)', '.a'), \n",
    "                        ('Lineal No Estacionario (ARIMA)', '.b'), \n",
    "                        ('No lineal Estacionario (SETAR)', '.c') ]:\n",
    "    plot_interaction_dist_paso(sc_name, sc_suf)\n",
    "    plot_interaction_dist_var(sc_name, sc_suf)\n",
    "    plot_interaction_config_paso(sc_name, sc_suf)\n",
    "    plot_interaction_var_horizonte(sc_name, sc_suf)\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 6: ROBUSTEZ Y TEST DIEBOLD-MARIANO\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 6: ROBUSTEZ Y TEST DIEBOLD-MARIANO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_robustness():\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    cv_data = []\n",
    "    for model in model_cols:\n",
    "        cv = df[model].std() / df[model].mean()\n",
    "        cv_data.append((model, cv))\n",
    "    \n",
    "    cv_df = pd.DataFrame(cv_data, columns=['Modelo', 'CV'])\n",
    "    \n",
    "    # CAMBIO 1: Ordenar de menor a mayor CV para coherencia\n",
    "    cv_df = cv_df.sort_values('CV')\n",
    "    \n",
    "    colors_cv = ['#2ecc71' if cv < cv_df['CV'].median() else '#e74c3c' \n",
    "                 for cv in cv_df['CV']]\n",
    "    \n",
    "    bars = ax.barh(cv_df['Modelo'], cv_df['CV'], color=colors_cv, alpha=0.8, edgecolor='black')\n",
    "    \n",
    "    for bar, cv in zip(bars, cv_df['CV']):\n",
    "        width = bar.get_width()\n",
    "        ax.text(width + 0.001, bar.get_y() + bar.get_height()/2.,\n",
    "               f'{cv:.4f}', ha='left', va='center', fontsize=9)\n",
    "    \n",
    "    ax.set_xlabel('Coeficiente de Variación', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Robustez: Coeficiente de Variación\\n(Ordenado de menor a mayor - Menor valor indica mayor estabilidad)', \n",
    "                  fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.axvline(x=cv_df['CV'].median(), color='black', linestyle='--', linewidth=1.5, alpha=0.5, label='Mediana')\n",
    "    ax.legend(loc='best', fontsize=10)\n",
    "    ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / '6.1_robustez_coeficiente_variacion.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Gráfica 6.1 guardada (ordenada de menor a mayor CV)\")\n",
    "\n",
    "plot_robustness()\n",
    "\n",
    "def modified_diebold_mariano_test(errors1, errors2, h=1):\n",
    "    \"\"\"\n",
    "    Test Diebold-Mariano con fixed-smoothing asymptotics (Coroneo & Iacone, 2020)\n",
    "    \n",
    "    Usa Fixed-m asymptotics (kernel Daniell) que es más robusto en muestras pequeñas\n",
    "    y mantiene buen desempeño en muestras grandes.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    errors1, errors2 : array-like\n",
    "        Errores de pronóstico (ECRPS) de los dos modelos\n",
    "    h : int\n",
    "        Horizonte de pronóstico (forecast horizon)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    hln_dm_stat : float\n",
    "        Estadístico con fixed-m asymptotics\n",
    "    p_value : float\n",
    "        P-valor usando distribución t-Student con 2m grados de libertad\n",
    "    dm_stat : float\n",
    "        Estadístico DM original (para referencia)\n",
    "    \"\"\"\n",
    "    # Calcular diferencial de pérdida\n",
    "    d = errors1 - errors2\n",
    "    d_bar = np.mean(d)\n",
    "    T = len(d)\n",
    "    \n",
    "    if T < 2:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    \n",
    "    # Desviaciones de la media\n",
    "    u = d - d_bar\n",
    "    \n",
    "    # Fixed-m: bandwidth recomendado en el paper\n",
    "    m = max(1, int(np.floor(T**(1/3))))\n",
    "    \n",
    "    # Calcular periodograma\n",
    "    from scipy.fft import fft\n",
    "    \n",
    "    # FFT de las desviaciones\n",
    "    fft_u = fft(u)\n",
    "    periodogram = np.abs(fft_u)**2 / (2 * np.pi * T)\n",
    "    \n",
    "    # WPE con kernel de Daniell: promedio de primeros m periodogramas\n",
    "    # (excluyendo frecuencia 0)\n",
    "    if m >= len(periodogram) - 1:\n",
    "        m = len(periodogram) - 2\n",
    "    \n",
    "    sigma_hat_sq = 2 * np.pi * np.mean(periodogram[1:m+1])\n",
    "    \n",
    "    if sigma_hat_sq <= 0:\n",
    "        # Fallback: usar varianza simple\n",
    "        sigma_hat_sq = np.var(d, ddof=1) / T\n",
    "        if sigma_hat_sq <= 0:\n",
    "            return 0, 1.0, 0\n",
    "    \n",
    "    # Estadístico DM\n",
    "    dm_stat = np.sqrt(T) * d_bar / np.sqrt(sigma_hat_sq)\n",
    "    \n",
    "    # Fixed-m asymptotics: límite es t-Student con 2m grados de libertad\n",
    "    df = 2 * m\n",
    "    hln_dm_stat = dm_stat\n",
    "    \n",
    "    # P-valor usando t-Student\n",
    "    p_value = 2 * (1 - stats.t.cdf(abs(hln_dm_stat), df))\n",
    "    \n",
    "    return hln_dm_stat, p_value, dm_stat\n",
    "\n",
    "def plot_dm_test_heatmap(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Test Diebold-Mariano Modificado (HLN-DM)\\ncon Corrección de Bonferroni ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Test Diebold-Mariano Modificado (HLN-DM)\\ncon Corrección de Bonferroni (General)'\n",
    "    \n",
    "    # Determinar el horizonte de pronóstico promedio\n",
    "    h_forecast = int(data_filtered['Paso'].mean())\n",
    "    \n",
    "    n_models = len(model_cols)\n",
    "    n_comparisons = n_models * (n_models - 1) / 2\n",
    "    alpha = 0.05\n",
    "    bonferroni_alpha = alpha / n_comparisons\n",
    "    \n",
    "    results_matrix = np.zeros((n_models, n_models))\n",
    "    p_values = np.zeros((n_models, n_models))\n",
    "    dm_stats = np.zeros((n_models, n_models))\n",
    "    \n",
    "    for i, model1 in enumerate(model_cols):\n",
    "        for j, model2 in enumerate(model_cols):\n",
    "            if i == j:\n",
    "                results_matrix[i, j] = 0  \n",
    "                p_values[i, j] = 1.0\n",
    "                dm_stats[i, j] = 0\n",
    "            elif i < j:\n",
    "                errors1 = data_filtered[model1].values\n",
    "                errors2 = data_filtered[model2].values\n",
    "                hln_dm_stat, p_val, dm_original = modified_diebold_mariano_test(\n",
    "                    errors1, errors2, h=h_forecast\n",
    "                )\n",
    "                \n",
    "                p_values[i, j] = p_val\n",
    "                p_values[j, i] = p_val\n",
    "                dm_stats[i, j] = hln_dm_stat\n",
    "                dm_stats[j, i] = -hln_dm_stat\n",
    "                \n",
    "                if p_val < bonferroni_alpha:\n",
    "                    mean1 = np.mean(errors1)\n",
    "                    mean2 = np.mean(errors2)\n",
    "                    if mean1 < mean2:  \n",
    "                        results_matrix[i, j] = 1  \n",
    "                        results_matrix[j, i] = -1  \n",
    "                    else:\n",
    "                        results_matrix[i, j] = -1\n",
    "                        results_matrix[j, i] = 1\n",
    "                else:\n",
    "                    results_matrix[i, j] = 0\n",
    "                    results_matrix[j, i] = 0\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 11))\n",
    "    cmap = plt.cm.colors.ListedColormap(['#e74c3c', '#fff9c4', '#2ecc71'])\n",
    "    bounds = [-1.5, -0.5, 0.5, 1.5]\n",
    "    norm = plt.cm.colors.BoundaryNorm(bounds, cmap.N)\n",
    "    \n",
    "    im = ax.imshow(results_matrix, cmap=cmap, norm=norm, aspect='auto')\n",
    "    ax.set_xticks(np.arange(n_models))\n",
    "    ax.set_yticks(np.arange(n_models))\n",
    "    ax.set_xticklabels(model_cols, rotation=45, ha='right', fontsize=9)\n",
    "    ax.set_yticklabels(model_cols, fontsize=9)\n",
    "    \n",
    "    for i in range(n_models):\n",
    "        for j in range(n_models):\n",
    "            if i == j:\n",
    "                text = '-'\n",
    "                color = 'black'\n",
    "            else:\n",
    "                val = results_matrix[i, j]\n",
    "                p_val = p_values[i, j]\n",
    "                dm_val = dm_stats[i, j]\n",
    "                if val == 1:\n",
    "                    text = f'✓\\nHLN-DM={dm_val:.2f}\\np={p_val:.4f}'\n",
    "                    color = 'white'\n",
    "                elif val == -1:\n",
    "                    text = f'✗\\nHLN-DM={dm_val:.2f}\\np={p_val:.4f}'\n",
    "                    color = 'white'\n",
    "                else:\n",
    "                    text = f'≈\\nHLN-DM={dm_val:.2f}\\np={p_val:.4f}'\n",
    "                    color = 'black'\n",
    "            ax.text(j, i, text, ha='center', va='center', \n",
    "                   color=color, fontsize=6, fontweight='bold')\n",
    "    \n",
    "    # Obtener T para el título\n",
    "    T = len(data_filtered)\n",
    "    df_test = T - 1\n",
    "    \n",
    "    ax.set_title(title + f'\\n(h={h_forecast}, T={T}, df={df_test}, α ajustado={bonferroni_alpha:.5f})', \n",
    "                 fontsize=11, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Modelo (Columna)', fontsize=11)\n",
    "    ax.set_ylabel('Modelo (Fila)', fontsize=11)\n",
    "    \n",
    "    legend_elements = [\n",
    "        plt.Rectangle((0,0),1,1, facecolor='#2ecc71', label='Fila supera columna (p < α)'),\n",
    "        plt.Rectangle((0,0),1,1, facecolor='#e74c3c', label='Columna supera fila (p < α)'),\n",
    "        plt.Rectangle((0,0),1,1, facecolor='#fff9c4', label='Sin diferencia significativa (p ≥ α)')\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='upper left', bbox_to_anchor=(1.05, 1), fontsize=9)\n",
    "    \n",
    "    # Agregar nota metodológica\n",
    "    note_text = ('Nota: Se utiliza el test HLN-DM con corrección para muestras finitas.\\n'\n",
    "                 'Distribución: t-Student. Ajuste: Bonferroni para comparaciones múltiples.')\n",
    "    plt.figtext(0.5, -0.02, note_text, ha='center', fontsize=8, style='italic', \n",
    "                wrap=True, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'6.2{suffix}_dm_test_hln_bonferroni.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Guardar resultados en Excel\n",
    "    results_df = pd.DataFrame(results_matrix, index=model_cols, columns=model_cols)\n",
    "    pvalues_df = pd.DataFrame(p_values, index=model_cols, columns=model_cols)\n",
    "    dmstats_df = pd.DataFrame(dm_stats, index=model_cols, columns=model_cols)\n",
    "    \n",
    "    summary_data = []\n",
    "    for model in model_cols:\n",
    "        idx = model_cols.index(model)\n",
    "        victorias = int(np.sum(results_matrix[idx, :] == 1))\n",
    "        derrotas = int(np.sum(results_matrix[idx, :] == -1))\n",
    "        empates = int(np.sum(results_matrix[idx, :] == 0)) - 1\n",
    "        mean_ecrps = data_filtered[model].mean()\n",
    "        std_ecrps = data_filtered[model].std()\n",
    "        cv_ecrps = std_ecrps / mean_ecrps\n",
    "        summary_data.append({\n",
    "            'Modelo': model,\n",
    "            'Victorias': victorias,\n",
    "            'Derrotas': derrotas,\n",
    "            'Empates': empates,\n",
    "            'Tasa_Victoria': f\"{(victorias / (n_models - 1)) * 100:.1f}%\",\n",
    "            'ECRPS_Promedio': f\"{mean_ecrps:.4f}\",\n",
    "            'ECRPS_Desv_Std': f\"{std_ecrps:.4f}\",\n",
    "            'Coef_Variacion': f\"{cv_ecrps:.4f}\"\n",
    "        })\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    # Información metodológica\n",
    "    method_info = pd.DataFrame({\n",
    "        'Parámetro': ['Horizonte de pronóstico (h)', 'Tamaño muestra (T)', \n",
    "                      'Grados libertad (df)', 'Alpha nominal', \n",
    "                      'Alpha ajustado (Bonferroni)', 'Número comparaciones',\n",
    "                      'Distribución', 'Corrección aplicada'],\n",
    "        'Valor': [h_forecast, T, df_test, alpha, bonferroni_alpha, \n",
    "                  int(n_comparisons), 't-Student', 'Harvey-Leybourne-Newbold (1997)']\n",
    "    })\n",
    "    \n",
    "    with pd.ExcelWriter(output_dir / f'6.2{suffix}_dm_test_hln_resultados.xlsx') as writer:\n",
    "        method_info.to_excel(writer, sheet_name='Metodologia', index=False)\n",
    "        results_df.to_excel(writer, sheet_name='Matriz_Resultados')\n",
    "        pvalues_df.to_excel(writer, sheet_name='P_valores')\n",
    "        dmstats_df.to_excel(writer, sheet_name='Estadisticos_HLN_DM')\n",
    "        summary_df.to_excel(writer, sheet_name='Resumen_Modelos', index=False)\n",
    "    \n",
    "    print(f\"✓ Gráfica 6.2{suffix} guardada (Test HLN-DM con h={h_forecast}, T={T}, df={df_test})\")\n",
    "\n",
    "plot_dm_test_heatmap()\n",
    "plot_dm_test_heatmap('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_dm_test_heatmap('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_dm_test_heatmap('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PROCESO COMPLETADO\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nMejoras implementadas:\")\n",
    "print(\"1. ✓ Orden consistente en gráficas 1.1 y 1.2\")\n",
    "print(\"2. ✓ Formato de 2 decimales en heatmap 2.2 general\")\n",
    "print(\"3. ✓ Solo Coeficiente de Variación en gráfica 6.1 (ordenado menor a mayor)\")\n",
    "print(\"4. ✓ Test Diebold-Mariano con corrección HLN y distribución t-Student\")\n",
    "print(\"5. ✓ Horizonte de pronóstico (h) incorporado en el análisis\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANÁLISIS DE INTERACCIONES (Carpeta: Interacciones/)\")\n",
    "print(\"=\"*80)\n",
    "print(\"6. ✓ Config × Var: Heatmaps por modelo (matriz 3×3)\")\n",
    "print(\"7. ✓ Config × Dist: Heatmaps por modelo (matriz 3×3)\")\n",
    "print(\"8. ✓ Dist × Paso: Gráficas de líneas por distribución\")\n",
    "print(\"9. ✓ Dist × Var: Gráficas de líneas por distribución\")\n",
    "print(\"10. ✓ Config × Paso: Gráficas de líneas por configuración\")\n",
    "print(\"11. ✓ Var × Horizonte: Gráficas de líneas por varianza\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal de gráficas generadas en Interacciones/: {6 * 4} archivos\")\n",
    "print(\"(6 tipos de interacción × 4 escenarios: General + 3 específicos)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f71c0b0",
   "metadata": {},
   "source": [
    "## Analisis Diferenciado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b88955e",
   "metadata": {},
   "source": [
    "### Pre-procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "249b1e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla Comparativa de Desempeño (Promedios):\n",
      "                         ARIMA  ARIMA_Diff Mejor_Escenario\n",
      "Modelo                                                    \n",
      "AREPD                10.031183    0.704149      ARIMA_Diff\n",
      "AV-MCPS               3.324007    0.654257      ARIMA_Diff\n",
      "Block Bootstrapping  11.251601    0.666133      ARIMA_Diff\n",
      "DeepAR                4.329124    0.561822      ARIMA_Diff\n",
      "EnCQR-LSTM            6.112344    0.880288      ARIMA_Diff\n",
      "LSPM                  1.064804    0.648039      ARIMA_Diff\n",
      "LSPMW                 3.079645    0.767172      ARIMA_Diff\n",
      "MCPS                  3.218168    0.677471      ARIMA_Diff\n",
      "Sieve Bootstrap       0.547481    0.546020      ARIMA_Diff\n",
      "\n",
      "Archivo de unión guardado en: ./datos/Simulacion/Diferenciado/resultados_UNION_ARIMA.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Cargar los archivos\n",
    "path_diff = \"./datos/Simulacion/Diferenciado/resultados_140_ARIMA_CON_DIFERENCIACION.xlsx\"\n",
    "path_no_diff = \"./datos/Simulacion/Diferenciado/resultados_140_ARIMA_FINAL.xlsx\"\n",
    "\n",
    "arima_Diff_df = pd.read_excel(path_diff)\n",
    "arima_df = pd.read_excel(path_no_diff)\n",
    "\n",
    "# 2. Agregar la columna 'Diferenciacion' al dataframe que no la tiene\n",
    "arima_df['Diferenciacion'] = 'No'\n",
    "\n",
    "# 3. Unir los dataframes (uno debajo del otro)\n",
    "# El orden de las columnas se ajustará automáticamente\n",
    "df_unido = pd.concat([arima_Diff_df, arima_df], ignore_index=True)\n",
    "\n",
    "# 4. Guardar la unión en la misma carpeta\n",
    "path_salida = \"./datos/Simulacion/Diferenciado/resultados_UNION_ARIMA.xlsx\"\n",
    "df_unido.to_excel(path_salida, index=False)\n",
    "\n",
    "# 5. Crear la tabla comparativa (Resumen)\n",
    "# Definimos las métricas/modelos a comparar\n",
    "modelos_metricas = [\n",
    "    'AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', \n",
    "    'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap'\n",
    "]\n",
    "\n",
    "# Calculamos el promedio para cada caso\n",
    "resumen_no_diff = arima_df[modelos_metricas].mean()\n",
    "resumen_diff = arima_Diff_df[modelos_metricas].mean()\n",
    "\n",
    "# Construir el DataFrame comparativo\n",
    "tabla_comparativa = pd.DataFrame({\n",
    "    'ARIMA': resumen_no_diff,\n",
    "    'ARIMA_Diff': resumen_diff\n",
    "})\n",
    "\n",
    "# Determinar el mejor escenario (el que tenga el valor menor, asumiendo que son errores)\n",
    "tabla_comparativa['Mejor_Escenario'] = np.where(\n",
    "    tabla_comparativa['ARIMA'] < tabla_comparativa['ARIMA_Diff'], \n",
    "    'ARIMA', \n",
    "    'ARIMA_Diff'\n",
    ")\n",
    "\n",
    "# Formatear la tabla para que se vea limpia\n",
    "tabla_comparativa.index.name = 'Modelo'\n",
    "tabla_comparativa = tabla_comparativa.sort_index()\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Tabla Comparativa de Desempeño (Promedios):\")\n",
    "print(tabla_comparativa.to_string())\n",
    "\n",
    "print(f\"\\nArchivo de unión guardado en: {path_salida}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08864bc2",
   "metadata": {},
   "source": [
    "### Analisis general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba3ee6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Datos cargados: (26880, 19)\n",
      "✓ Columnas: ['Paso', 'Proceso', 'p', 'd', 'q', 'ARMA_base', 'Distribución', 'Varianza', 'Modalidad', 'Valor_Observado', 'AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', 'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
      "✓ Modelos identificados: ['AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', 'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
      "✓ Valores únicos de d: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(10)]\n",
      "\n",
      "================================================================================\n",
      "INICIANDO ANÁLISIS MULTI-D CON DM TEST (FIXED-M ASYMPTOTICS)\n",
      "================================================================================\n",
      "\n",
      "=== Generando gráfico general de mejora ===\n",
      "\n",
      "=== Generando gráficos de barras con valores por d ===\n",
      "\n",
      "=== Generando Heatmap d vs Modelo ===\n",
      "\n",
      "=== Generando Heatmap de Significancia d vs Diferenciación (DM Test) ===\n",
      "\n",
      "=== Generando Interacciones d vs Dist, Config y Varianza ===\n",
      "\n",
      "=== Calculando Tabla DM por valor de d (Fixed-m Asymptotics) ===\n",
      "✓ Tabla DM guardada con 72 comparaciones\n",
      "\n",
      "=== Generando Excel detallado por d (ordenado por mejora) ===\n",
      "\n",
      "================================================================================\n",
      "✓ ANÁLISIS COMPLETADO EXITOSAMENTE\n",
      "✓ Resultados guardados en: Resultados_analisis\\Multi_d\n",
      "✓ Gráficos guardados en: Resultados_analisis\\Multi_d\\Graficos_Analisis\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.fft import fft\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Configuración inicial\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "# ====================================================================================\n",
    "# TEST DIEBOLD-MARIANO CON FIXED-M ASYMPTOTICS\n",
    "# ====================================================================================\n",
    "def modified_diebold_mariano_test(errors1, errors2, h=1):\n",
    "    \"\"\"\n",
    "    Test Diebold-Mariano con fixed-smoothing asymptotics (Coroneo & Iacone, 2020)\n",
    "    \n",
    "    Usa Fixed-m asymptotics (kernel Daniell) que es más robusto en muestras pequeñas\n",
    "    y mantiene buen desempeño en muestras grandes.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    errors1, errors2 : array-like\n",
    "        Errores de pronóstico (ECRPS) de los dos modelos\n",
    "    h : int\n",
    "        Horizonte de pronóstico (forecast horizon)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    hln_dm_stat : float\n",
    "        Estadístico con fixed-m asymptotics\n",
    "    p_value : float\n",
    "        P-valor usando distribución t-Student con 2m grados de libertad\n",
    "    dm_stat : float\n",
    "        Estadístico DM original (para referencia)\n",
    "    \"\"\"\n",
    "    # Calcular diferencial de pérdida\n",
    "    d = errors1 - errors2\n",
    "    d_bar = np.mean(d)\n",
    "    T = len(d)\n",
    "    \n",
    "    if T < 2:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    \n",
    "    # Desviaciones de la media\n",
    "    u = d - d_bar\n",
    "    \n",
    "    # Fixed-m: bandwidth recomendado en el paper\n",
    "    m = max(1, int(np.floor(T**(1/3))))\n",
    "    \n",
    "    # Calcular periodograma\n",
    "    fft_u = fft(u)\n",
    "    periodogram = np.abs(fft_u)**2 / (2 * np.pi * T)\n",
    "    \n",
    "    # WPE con kernel de Daniell: promedio de primeros m periodogramas\n",
    "    # (excluyendo frecuencia 0)\n",
    "    if m >= len(periodogram) - 1:\n",
    "        m = len(periodogram) - 2\n",
    "    \n",
    "    sigma_hat_sq = 2 * np.pi * np.mean(periodogram[1:m+1])\n",
    "    \n",
    "    if sigma_hat_sq <= 0:\n",
    "        # Fallback: usar varianza simple\n",
    "        sigma_hat_sq = np.var(d, ddof=1) / T\n",
    "        if sigma_hat_sq <= 0:\n",
    "            return 0, 1.0, 0\n",
    "    \n",
    "    # Estadístico DM\n",
    "    dm_stat = np.sqrt(T) * d_bar / np.sqrt(sigma_hat_sq)\n",
    "    \n",
    "    # Fixed-m asymptotics: límite es t-Student con 2m grados de libertad\n",
    "    df = 2 * m\n",
    "    hln_dm_stat = dm_stat\n",
    "    \n",
    "    # P-valor usando t-Student\n",
    "    p_value = 2 * (1 - stats.t.cdf(abs(hln_dm_stat), df))\n",
    "    \n",
    "    return hln_dm_stat, p_value, dm_stat\n",
    "\n",
    "# ====================================================================================\n",
    "# 1. PREPARACIÓN DE DIRECTORIOS\n",
    "# ====================================================================================\n",
    "output_dir = Path(\"./Resultados_analisis/Multi_d\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "plots_dir = output_dir / \"Graficos_Analisis\"\n",
    "plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Cargar datos\n",
    "path_excel = \"./datos/Simulacion/Multi_D/resultados_ARIMA_d1_a_d10_DOBLE_MODALIDAD_COMPLETO.xlsx\"\n",
    "try:\n",
    "    df = pd.read_excel(path_excel)\n",
    "    print(f\"✓ Datos cargados: {df.shape}\")\n",
    "    print(f\"✓ Columnas: {df.columns.tolist()}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error crítico: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Identificar columnas\n",
    "var_cols = ['Paso', 'Proceso', 'p', 'd', 'q', 'ARMA_base', 'Distribución', \n",
    "            'Varianza', 'Modalidad', 'Valor_Observado']\n",
    "model_cols = [col for col in df.columns if col not in var_cols]\n",
    "\n",
    "print(f\"✓ Modelos identificados: {model_cols}\")\n",
    "print(f\"✓ Valores únicos de d: {sorted(df['d'].unique())}\")\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 1: COMPARACIÓN INDIVIDUAL POR VALOR DE d\n",
    "# ====================================================================================\n",
    "def plot_individual_comparisons():\n",
    "    print(\"\\n=== Generando gráficos de barras con valores por d ===\")\n",
    "    \n",
    "    # Para cada valor de d\n",
    "    d_values = sorted(df['d'].unique())\n",
    "    \n",
    "    for d_val in d_values:\n",
    "        stats_list = []\n",
    "        subset_d = df[df['d'] == d_val]\n",
    "        \n",
    "        for model in model_cols:\n",
    "            sin = subset_d[subset_d['Modalidad'] == 'SIN_DIFF'][model].mean()\n",
    "            con = subset_d[subset_d['Modalidad'] == 'CON_DIFF'][model].mean()\n",
    "            mejora = ((sin - con) / sin) * 100 if sin != 0 else 0\n",
    "            stats_list.append({'Modelo': model, 'Sin': sin, 'Con': con, 'Mejora': mejora})\n",
    "        \n",
    "        df_stats = pd.DataFrame(stats_list).sort_values(by='Mejora', ascending=False)\n",
    "        \n",
    "        # 1.1 Barras Comparativas por d\n",
    "        fig, ax = plt.subplots(figsize=(14, 6))\n",
    "        x = np.arange(len(df_stats))\n",
    "        width = 0.35\n",
    "        \n",
    "        b1 = ax.bar(x - width/2, df_stats['Sin'], width, label='Sin Dif.', \n",
    "                    color='#e74c3c', edgecolor='black', alpha=0.8)\n",
    "        b2 = ax.bar(x + width/2, df_stats['Con'], width, label='Con Dif.', \n",
    "                    color='#2ecc71', edgecolor='black', alpha=0.8)\n",
    "        \n",
    "        ax.bar_label(b1, padding=3, fmt='%.3f', fontsize=7, rotation=45)\n",
    "        ax.bar_label(b2, padding=3, fmt='%.3f', fontsize=7, rotation=45)\n",
    "        \n",
    "        ax.set_title(f'ECRPS Promedio por Modelo (d={d_val})', fontweight='bold', fontsize=12)\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(df_stats['Modelo'], rotation=45, ha='right')\n",
    "        ax.set_ylabel('ECRPS')\n",
    "        ax.legend()\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(plots_dir / f'1.1_barras_ecrps_d{d_val}.png')\n",
    "        plt.close()\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 2: HEATMAP d vs MODELO\n",
    "# ====================================================================================\n",
    "def plot_heatmap_d_vs_modelo():\n",
    "    print(\"\\n=== Generando Heatmap d vs Modelo ===\")\n",
    "    \n",
    "    results = []\n",
    "    d_values = sorted(df['d'].unique())\n",
    "    \n",
    "    for d_val in d_values:\n",
    "        subset_d = df[df['d'] == d_val]\n",
    "        for model in model_cols:\n",
    "            sin = subset_d[subset_d['Modalidad'] == 'SIN_DIFF'][model].mean()\n",
    "            con = subset_d[subset_d['Modalidad'] == 'CON_DIFF'][model].mean()\n",
    "            mejora = ((sin - con) / sin) * 100 if sin != 0 else 0\n",
    "            results.append({'d': d_val, 'Modelo': model, 'Mejora_%': mejora})\n",
    "    \n",
    "    df_mejora = pd.DataFrame(results)\n",
    "    pivot = df_mejora.pivot(index='Modelo', columns='d', values='Mejora_%')\n",
    "    \n",
    "    plt.figure(figsize=(14, 10))\n",
    "    sns.heatmap(pivot, annot=True, fmt=\".1f\", cmap=\"RdYlGn\", center=0, \n",
    "                cbar_kws={'label': 'Mejora (%)'}, linewidths=0.5)\n",
    "    plt.title(\"Mejora Porcentual (%): Modelo vs Valor de d\", fontweight='bold', fontsize=14)\n",
    "    plt.xlabel(\"Valor de d (Grado de diferenciación)\", fontweight='bold')\n",
    "    plt.ylabel(\"Modelo\", fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plots_dir / '2_heatmap_d_vs_modelo.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Guardar tabla\n",
    "    pivot.to_excel(output_dir / '2_tabla_d_vs_modelo.xlsx')\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 3: HEATMAP SIGNIFICANCIA CON DM TEST (d vs Diferenciación)\n",
    "# ====================================================================================\n",
    "def plot_heatmap_significancia():\n",
    "    print(\"\\n=== Generando Heatmap de Significancia d vs Diferenciación (DM Test) ===\")\n",
    "    \n",
    "    results = []\n",
    "    d_values = sorted(df['d'].unique())\n",
    "    \n",
    "    for d_val in d_values:\n",
    "        subset_d = df[df['d'] == d_val]\n",
    "        for model in model_cols:\n",
    "            sin = subset_d[subset_d['Modalidad'] == 'SIN_DIFF'][model].values\n",
    "            con = subset_d[subset_d['Modalidad'] == 'CON_DIFF'][model].values\n",
    "            \n",
    "            if len(sin) > 1 and len(con) > 1:\n",
    "                # Usar DM test en lugar de t-test\n",
    "                dm_stat, p_valor, _ = modified_diebold_mariano_test(sin, con, h=1)\n",
    "                \n",
    "                # Determinar dirección y significancia\n",
    "                if p_valor < 0.05:\n",
    "                    if sin.mean() > con.mean():\n",
    "                        valor = 1  # Diferenciación es mejor\n",
    "                    else:\n",
    "                        valor = -1  # Sin diferenciación es mejor\n",
    "                else:\n",
    "                    valor = 0  # No significativo\n",
    "            else:\n",
    "                valor = 0\n",
    "            \n",
    "            results.append({'d': d_val, 'Modelo': model, 'Significancia': valor})\n",
    "    \n",
    "    df_sig = pd.DataFrame(results)\n",
    "    pivot_sig = df_sig.pivot(index='Modelo', columns='d', values='Significancia')\n",
    "    \n",
    "    plt.figure(figsize=(14, 10))\n",
    "    sns.heatmap(pivot_sig, annot=True, fmt=\".0f\", cmap=\"RdYlGn\", center=0,\n",
    "                cbar_kws={'label': 'Significancia DM (-1: Sin Dif mejor | 0: No sig. | 1: Con Dif mejor)'},\n",
    "                linewidths=0.5, vmin=-1, vmax=1)\n",
    "    plt.title(\"Significancia Estadística (DM Test): d vs Diferenciación por Modelo\", \n",
    "              fontweight='bold', fontsize=14)\n",
    "    plt.xlabel(\"Valor de d\", fontweight='bold')\n",
    "    plt.ylabel(\"Modelo\", fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plots_dir / '3_heatmap_significancia_d_DM.png')\n",
    "    plt.close()\n",
    "    \n",
    "    pivot_sig.to_excel(output_dir / '3_tabla_significancia_d_DM.xlsx')\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 4: INTERACCIONES d vs Distribución, Config y Varianza\n",
    "# ====================================================================================\n",
    "def plot_interacciones_d():\n",
    "    print(\"\\n=== Generando Interacciones d vs Dist, Config y Varianza ===\")\n",
    "    \n",
    "    # 4.1 d vs Distribución\n",
    "    def get_improvement_d_group(group_col):\n",
    "        results = []\n",
    "        d_values = sorted(df['d'].unique())\n",
    "        for d_val in d_values:\n",
    "            subset_d = df[df['d'] == d_val]\n",
    "            for val in subset_d[group_col].unique():\n",
    "                subset = subset_d[subset_d[group_col] == val]\n",
    "                for model in model_cols:\n",
    "                    sin = subset[subset['Modalidad'] == 'SIN_DIFF'][model].mean()\n",
    "                    con = subset[subset['Modalidad'] == 'CON_DIFF'][model].mean()\n",
    "                    mejora = ((sin - con) / sin) * 100 if sin != 0 else 0\n",
    "                    results.append({'d': d_val, group_col: val, 'Modelo': model, 'Mejora': mejora})\n",
    "        return pd.DataFrame(results)\n",
    "    \n",
    "    # 4.1 Heatmap d vs Distribución (agrupado por modelo)\n",
    "    df_dist = get_improvement_d_group('Distribución')\n",
    "    \n",
    "    for model in model_cols:\n",
    "        subset = df_dist[df_dist['Modelo'] == model]\n",
    "        pivot = subset.pivot(index='d', columns='Distribución', values='Mejora')\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(pivot, annot=True, fmt=\".1f\", cmap=\"RdYlGn\", center=0)\n",
    "        plt.title(f\"Mejora (%) d vs Distribución - {model}\", fontweight='bold')\n",
    "        plt.xlabel(\"Distribución\")\n",
    "        plt.ylabel(\"Valor de d\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(plots_dir / f'4.1_heatmap_d_dist_{model}.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # 4.2 Heatmap d vs Varianza (líneas por modelo)\n",
    "    df_var = get_improvement_d_group('Varianza')\n",
    "    \n",
    "    plt.figure(figsize=(14, 8))\n",
    "    for model in model_cols:\n",
    "        subset = df_var[df_var['Modelo'] == model]\n",
    "        grouped = subset.groupby(['d', 'Varianza'])['Mejora'].mean().reset_index()\n",
    "        for var_val in grouped['Varianza'].unique():\n",
    "            data = grouped[grouped['Varianza'] == var_val]\n",
    "            plt.plot(data['d'], data['Mejora'], marker='o', label=f'{model}-Var{var_val}', alpha=0.7)\n",
    "    \n",
    "    plt.axhline(0, color='black', linestyle='--', alpha=0.5)\n",
    "    plt.title(\"Tendencia Mejora (%): d vs Varianza por Modelo\", fontweight='bold')\n",
    "    plt.xlabel(\"Valor de d\")\n",
    "    plt.ylabel(\"Mejora Porcentual\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plots_dir / '4.2_linea_d_varianza.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # 4.3 Heatmap d vs Config (por modelo)\n",
    "    if 'ARMA_base' in df.columns:\n",
    "        df_config = get_improvement_d_group('ARMA_base')\n",
    "        \n",
    "        for model in model_cols:\n",
    "            subset = df_config[df_config['Modelo'] == model]\n",
    "            pivot = subset.pivot(index='d', columns='ARMA_base', values='Mejora')\n",
    "            \n",
    "            plt.figure(figsize=(12, 8))\n",
    "            sns.heatmap(pivot, annot=True, fmt=\".1f\", cmap=\"RdYlGn\", center=0)\n",
    "            plt.title(f\"Mejora (%) d vs Configuración Base - {model}\", fontweight='bold')\n",
    "            plt.xlabel(\"Configuración ARMA\")\n",
    "            plt.ylabel(\"Valor de d\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(plots_dir / f'4.3_heatmap_d_config_{model}.png')\n",
    "            plt.close()\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 6: TABLA DM POR VALOR DE d (USANDO DM TEST)\n",
    "# ====================================================================================\n",
    "def run_dm_analysis():\n",
    "    print(\"\\n=== Calculando Tabla DM por valor de d (Fixed-m Asymptotics) ===\")\n",
    "    \n",
    "    d_values = sorted(df['d'].unique())\n",
    "    all_results = []\n",
    "    \n",
    "    for d_val in d_values:\n",
    "        subset_d = df[df['d'] == d_val]\n",
    "        \n",
    "        for model in model_cols:\n",
    "            sin = subset_d[subset_d['Modalidad'] == 'SIN_DIFF'][model].values\n",
    "            con = subset_d[subset_d['Modalidad'] == 'CON_DIFF'][model].values\n",
    "            \n",
    "            if len(sin) > 1 and len(con) > 1:\n",
    "                mean_sin, mean_con = sin.mean(), con.mean()\n",
    "                mejora_pct = ((mean_sin - mean_con) / mean_sin) * 100 if mean_sin != 0 else 0\n",
    "                \n",
    "                # Usar DM test con fixed-m\n",
    "                dm_stat, p_valor, dm_stat_original = modified_diebold_mariano_test(sin, con, h=1)\n",
    "                significativo = 'Sí' if p_valor < 0.05 else 'No'\n",
    "                \n",
    "                if p_valor < 0.05:\n",
    "                    conclusion = \"Diferenciación mejora\" if mejora_pct > 0 else \"Sin dif mejor\"\n",
    "                else:\n",
    "                    conclusion = \"Sin diferencia significativa\"\n",
    "                \n",
    "                all_results.append({\n",
    "                    'd': d_val, 'Modelo': model, \n",
    "                    'ECRPS_Sin_Diff': mean_sin, 'ECRPS_Con_Diff': mean_con,\n",
    "                    'Mejora_%': mejora_pct, \n",
    "                    'DM_Stat': dm_stat,\n",
    "                    'p_valor': p_valor, \n",
    "                    'Significativo': significativo, \n",
    "                    'Conclusion': conclusion\n",
    "                })\n",
    "    \n",
    "    dm_df = pd.DataFrame(all_results).sort_values(by=['d', 'Mejora_%'], ascending=[True, False])\n",
    "    dm_df.to_excel(output_dir / '6_tabla_dm_por_d_fixed_m.xlsx', index=False)\n",
    "    \n",
    "    print(f\"✓ Tabla DM guardada con {len(dm_df)} comparaciones\")\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 9: EXCEL DETALLADO POR d (Agrupado, Ordenado)\n",
    "# ====================================================================================\n",
    "def generate_detailed_excel():\n",
    "    print(\"\\n=== Generando Excel detallado por d (ordenado por mejora) ===\")\n",
    "    file_path = output_dir / \"9_Analisis_Detallado_Modelos_por_d.xlsx\"\n",
    "    \n",
    "    with pd.ExcelWriter(file_path, engine='xlsxwriter') as writer:\n",
    "        for model in model_cols:\n",
    "            # Agrupar por d, ARMA_base, Distribución, Varianza (promediando Pasos)\n",
    "            temp = df.groupby(['d', 'ARMA_base', 'Distribución', 'Varianza', 'Modalidad'])[model].mean().reset_index()\n",
    "            \n",
    "            # Pivotar\n",
    "            detailed = temp.pivot_table(\n",
    "                index=['d', 'ARMA_base', 'Distribución', 'Varianza'],\n",
    "                columns='Modalidad',\n",
    "                values=model\n",
    "            ).reset_index()\n",
    "            \n",
    "            detailed.columns.name = None\n",
    "            detailed = detailed.rename(columns={\n",
    "                'SIN_DIFF': 'ECRPS_Sin_Dif', \n",
    "                'CON_DIFF': 'ECRPS_Con_Dif'\n",
    "            })\n",
    "            \n",
    "            detailed['Mejora_Absoluta'] = detailed['ECRPS_Sin_Dif'] - detailed['ECRPS_Con_Dif']\n",
    "            detailed['Mejora_%'] = (detailed['Mejora_Absoluta'] / detailed['ECRPS_Sin_Dif']) * 100\n",
    "            \n",
    "            # Ordenar por d y luego por mejora\n",
    "            detailed = detailed.sort_values(by=['d', 'Mejora_%'], ascending=[True, False])\n",
    "            \n",
    "            sheet_name = model[:31]\n",
    "            detailed.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "            \n",
    "            # Formatos condicionales\n",
    "            workbook = writer.book\n",
    "            worksheet = writer.sheets[sheet_name]\n",
    "            fmt_green = workbook.add_format({'bg_color': '#C6EFCE', 'font_color': '#006100'})\n",
    "            fmt_red = workbook.add_format({'bg_color': '#FFC7CE', 'font_color': '#9C0006'})\n",
    "            \n",
    "            # Aplicar a columna Mejora_%\n",
    "            col_idx = detailed.columns.get_loc('Mejora_%')\n",
    "            worksheet.conditional_format(1, col_idx, len(detailed), col_idx, {\n",
    "                'type': 'cell', 'criteria': '>', 'value': 0, 'format': fmt_green\n",
    "            })\n",
    "            worksheet.conditional_format(1, col_idx, len(detailed), col_idx, {\n",
    "                'type': 'cell', 'criteria': '<', 'value': 0, 'format': fmt_red\n",
    "            })\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN ADICIONAL: GRÁFICOS PREVIOS MANTENIDOS\n",
    "# ====================================================================================\n",
    "def plot_mejora_general():\n",
    "    \"\"\"Gráfico general de mejora promedio por modelo (todos los d)\"\"\"\n",
    "    print(\"\\n=== Generando gráfico general de mejora ===\")\n",
    "    \n",
    "    stats_list = []\n",
    "    for model in model_cols:\n",
    "        sin = df[df['Modalidad'] == 'SIN_DIFF'][model].mean()\n",
    "        con = df[df['Modalidad'] == 'CON_DIFF'][model].mean()\n",
    "        mejora = ((sin - con) / sin) * 100 if sin != 0 else 0\n",
    "        stats_list.append({'Modelo': model, 'Mejora_%': mejora})\n",
    "    \n",
    "    df_stats = pd.DataFrame(stats_list).sort_values(by='Mejora_%', ascending=False)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    colors = ['#2ecc71' if m > 0 else '#e74c3c' for m in df_stats['Mejora_%']]\n",
    "    bars = ax.barh(df_stats['Modelo'], df_stats['Mejora_%'], color=colors, edgecolor='black')\n",
    "    ax.bar_label(bars, padding=5, fmt='%.1f%%', fontweight='bold')\n",
    "    ax.axvline(0, color='black', lw=1)\n",
    "    ax.set_title('Mejora Porcentual Global con Diferenciación (Todos los d)', fontweight='bold')\n",
    "    ax.set_xlabel('Mejora (%)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plots_dir / '0_mejora_global.png')\n",
    "    plt.close()\n",
    "\n",
    "# ====================================================================================\n",
    "# EJECUCIÓN PRINCIPAL\n",
    "# ====================================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"INICIANDO ANÁLISIS MULTI-D CON DM TEST (FIXED-M ASYMPTOTICS)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    plot_mejora_general()\n",
    "    plot_individual_comparisons()\n",
    "    plot_heatmap_d_vs_modelo()\n",
    "    plot_heatmap_significancia()\n",
    "    plot_interacciones_d()\n",
    "    run_dm_analysis()\n",
    "    generate_detailed_excel()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"✓ ANÁLISIS COMPLETADO EXITOSAMENTE\")\n",
    "    print(f\"✓ Resultados guardados en: {output_dir}\")\n",
    "    print(f\"✓ Gráficos guardados en: {plots_dir}\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e6b598",
   "metadata": {},
   "source": [
    "## Aumento d ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b73a5d",
   "metadata": {},
   "source": [
    "### Pre-procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d843823c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "TEST DIEBOLD-MARIANO MODIFICADO (HLN): Comparación SIN_DIFF vs CON_DIFF por valor de d\n",
      "====================================================================================================\n",
      "\n",
      "H0: No hay diferencia significativa entre las modalidades\n",
      "H1: Hay diferencia significativa entre las modalidades\n",
      "\n",
      "Significancia: *** p<0.01, ** p<0.05, * p<0.10, No = no significativo\n",
      "\n",
      "\n",
      " d  N_obs  ECRPS_SIN_DIFF  ECRPS_CON_DIFF    Diferencia  DM_stat  HLN-DM_stat  p_valor Significativo\n",
      " 1   1680    5.495070e-01    5.485800e-01  9.280000e-04   0.5334       0.5334   0.6067            No\n",
      " 2   1680    2.884661e+01    2.883279e+01  1.382000e-02   0.8679       0.8679   0.4022            No\n",
      " 3   1680    2.725984e+01    2.726032e+01 -4.790000e-04  -0.0186      -0.0186   0.9856            No\n",
      " 4   1680    2.704997e+01    2.704544e+01  4.532000e-03   0.1216       0.1216   0.9066            No\n",
      " 5   1680    3.451632e+01    2.821125e+01  6.305071e+00   1.8941       1.8941   0.0676             *\n",
      " 6   1680    1.400979e+03    2.663349e+01  1.374346e+03   4.4940       4.4940   0.0000           ***\n",
      " 7   1680    9.737277e+04    1.570675e+03  9.580209e+04   5.2118       5.2118   0.0000           ***\n",
      "10   1680    1.502699e+09    6.795862e+07  1.434741e+09   6.5190       6.5190   0.0000           ***\n",
      "\n",
      "====================================================================================================\n",
      "RESUMEN\n",
      "====================================================================================================\n",
      "\n",
      "Total de comparaciones: 8\n",
      "Diferencias significativas: 4 (50.0%)\n",
      "No significativas: 4 (50.0%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Cargar datos\n",
    "base = pd.read_excel(\"./datos/Simulacion/Multi_D/resultados_ARIMA_d1_a_d10_DOBLE_MODALIDAD_COMPLETO.xlsx\")\n",
    "\n",
    "# Seleccionar columnas necesarias\n",
    "columnas_seleccionadas = ['Paso', 'Proceso', 'p', 'd', 'q', 'ARMA_base', \n",
    "                          'Distribución', 'Varianza', 'Modalidad', 'Sieve Bootstrap']\n",
    "datos = base[columnas_seleccionadas].copy()\n",
    "\n",
    "# Renombrar columna para claridad\n",
    "datos.rename(columns={'Sieve Bootstrap': 'ECRPS'}, inplace=True)\n",
    "\n",
    "def modified_diebold_mariano_test(errors1, errors2, h=1):\n",
    "    \"\"\"\n",
    "    Test Diebold-Mariano con fixed-smoothing asymptotics (Coroneo & Iacone, 2020)\n",
    "    \n",
    "    Implementa dos enfoques:\n",
    "    1. Fixed-b asymptotics con kernel de Bartlett\n",
    "    2. Fixed-m asymptotics con kernel de Daniell\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    errors1, errors2 : array-like\n",
    "        Errores de pronóstico (ECRPS) de los dos modelos\n",
    "    h : int\n",
    "        Horizonte de pronóstico (forecast horizon)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    hln_dm_stat : float\n",
    "        Estadístico con fixed-smoothing asymptotics\n",
    "    p_value : float\n",
    "        P-valor usando distribución apropiada\n",
    "    dm_stat : float\n",
    "        Estadístico DM original (para referencia)\n",
    "    \"\"\"\n",
    "    # Calcular diferencial de pérdida\n",
    "    d = errors1 - errors2\n",
    "    d_bar = np.mean(d)\n",
    "    T = len(d)\n",
    "    \n",
    "    if T < 2:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    \n",
    "    # Desviaciones de la media\n",
    "    u = d - d_bar\n",
    "    \n",
    "    # Elegir método según tamaño de muestra\n",
    "    if T >= 80:\n",
    "        # Fixed-b con kernel de Bartlett para muestras medianas/grandes\n",
    "        M = int(np.floor(T**(1/2)))  # Bandwidth recomendado\n",
    "        b = M / T\n",
    "        \n",
    "        # Calcular WCE con kernel de Bartlett\n",
    "        gamma_0 = np.mean(u**2)\n",
    "        gamma_sum = gamma_0\n",
    "        \n",
    "        for j in range(1, min(M, T)):\n",
    "            gamma_j = np.mean(u[j:] * u[:-j])\n",
    "            weight = 1 - j/M  # Kernel de Bartlett\n",
    "            gamma_sum += 2 * weight * gamma_j\n",
    "        \n",
    "        sigma_hat_sq = gamma_sum\n",
    "        \n",
    "        if sigma_hat_sq <= 0:\n",
    "            return 0, 1.0, 0\n",
    "        \n",
    "        # Estadístico DM\n",
    "        dm_stat = np.sqrt(T) * d_bar / np.sqrt(sigma_hat_sq)\n",
    "        \n",
    "        # Valor crítico fixed-b para Bartlett kernel (fórmula del paper)\n",
    "        # Para test de dos colas al 5%\n",
    "        alpha_0, alpha_1, alpha_2, alpha_3 = 1.9600, 2.9694, 0.4160, -0.5324\n",
    "        critical_value = alpha_0 + alpha_1*b + alpha_2*b**2 + alpha_3*b**3\n",
    "        \n",
    "        # P-valor aproximado usando la distribución límite\n",
    "        # Nota: esto es una aproximación, idealmente se simularía\n",
    "        p_value = 2 * (1 - stats.norm.cdf(abs(dm_stat) / (critical_value/1.96)))\n",
    "        \n",
    "        hln_dm_stat = dm_stat\n",
    "        \n",
    "    else:\n",
    "        # Fixed-m con kernel de Daniell para muestras pequeñas\n",
    "        m = int(np.floor(T**(1/3)))  # Bandwidth recomendado\n",
    "        \n",
    "        # Calcular periodograma\n",
    "        from scipy.fft import fft\n",
    "        \n",
    "        # FFT de las desviaciones\n",
    "        fft_u = fft(u)\n",
    "        periodogram = np.abs(fft_u)**2 / (2 * np.pi * T)\n",
    "        \n",
    "        # WPE con kernel de Daniell (promedio de primeros m periodogramas)\n",
    "        sigma_hat_sq = 2 * np.pi * np.mean(periodogram[1:m+1])\n",
    "        \n",
    "        if sigma_hat_sq <= 0:\n",
    "            return 0, 1.0, 0\n",
    "        \n",
    "        # Estadístico DM\n",
    "        dm_stat = np.sqrt(T) * d_bar / np.sqrt(sigma_hat_sq)\n",
    "        \n",
    "        # Fixed-m asymptotics: límite es t-Student con 2m grados de libertad\n",
    "        df = 2 * m\n",
    "        hln_dm_stat = dm_stat\n",
    "        \n",
    "        # P-valor usando t-Student\n",
    "        p_value = 2 * (1 - stats.t.cdf(abs(hln_dm_stat), df))\n",
    "    \n",
    "    return hln_dm_stat, p_value, dm_stat\n",
    "\n",
    "# Obtener valores únicos de d\n",
    "valores_d = sorted(datos['d'].unique())\n",
    "\n",
    "# Lista para almacenar resultados\n",
    "resultados = []\n",
    "\n",
    "# Iterar sobre cada valor de d\n",
    "for d_val in valores_d:\n",
    "    # Filtrar datos para el d actual\n",
    "    datos_d = datos[datos['d'] == d_val].copy()\n",
    "    \n",
    "    # Separar por modalidad\n",
    "    sin_diff = datos_d[datos_d['Modalidad'] == 'SIN_DIFF']['ECRPS'].values\n",
    "    con_diff = datos_d[datos_d['Modalidad'] == 'CON_DIFF']['ECRPS'].values\n",
    "    \n",
    "    # Verificar que ambas modalidades tengan datos\n",
    "    if len(sin_diff) == 0 or len(con_diff) == 0:\n",
    "        print(f\"Advertencia: d={d_val} no tiene datos para ambas modalidades\")\n",
    "        continue\n",
    "    \n",
    "    # Verificar que tengan la misma longitud\n",
    "    if len(sin_diff) != len(con_diff):\n",
    "        print(f\"Advertencia: d={d_val} tiene diferente número de observaciones entre modalidades\")\n",
    "        min_len = min(len(sin_diff), len(con_diff))\n",
    "        sin_diff = sin_diff[:min_len]\n",
    "        con_diff = con_diff[:min_len]\n",
    "    \n",
    "    # Calcular estadísticas descriptivas\n",
    "    ecrps_sin_diff_mean = np.mean(sin_diff)\n",
    "    ecrps_con_diff_mean = np.mean(con_diff)\n",
    "    diferencia = ecrps_sin_diff_mean - ecrps_con_diff_mean\n",
    "    \n",
    "    # Realizar test Diebold-Mariano modificado\n",
    "    hln_dm_stat, p_value, dm_stat = modified_diebold_mariano_test(sin_diff, con_diff, h=1)\n",
    "    \n",
    "    # Determinar significancia (niveles comunes: 0.01, 0.05, 0.10)\n",
    "    if p_value < 0.01:\n",
    "        significativo = \"***\"\n",
    "    elif p_value < 0.05:\n",
    "        significativo = \"**\"\n",
    "    elif p_value < 0.10:\n",
    "        significativo = \"*\"\n",
    "    else:\n",
    "        significativo = \"No\"\n",
    "    \n",
    "    # Agregar a resultados\n",
    "    resultados.append({\n",
    "        'd': d_val,\n",
    "        'N_obs': len(sin_diff),\n",
    "        'ECRPS_SIN_DIFF': ecrps_sin_diff_mean,\n",
    "        'ECRPS_CON_DIFF': ecrps_con_diff_mean,\n",
    "        'Diferencia': diferencia,\n",
    "        'DM_stat': dm_stat,\n",
    "        'HLN-DM_stat': hln_dm_stat,\n",
    "        'p_valor': p_value,\n",
    "        'Significativo': significativo\n",
    "    })\n",
    "\n",
    "# Crear DataFrame con resultados\n",
    "resultados_df = pd.DataFrame(resultados)\n",
    "\n",
    "# Formatear para mejor visualización\n",
    "resultados_df['ECRPS_SIN_DIFF'] = resultados_df['ECRPS_SIN_DIFF'].round(6)\n",
    "resultados_df['ECRPS_CON_DIFF'] = resultados_df['ECRPS_CON_DIFF'].round(6)\n",
    "resultados_df['Diferencia'] = resultados_df['Diferencia'].round(6)\n",
    "resultados_df['DM_stat'] = resultados_df['DM_stat'].round(4)\n",
    "resultados_df['HLN-DM_stat'] = resultados_df['HLN-DM_stat'].round(4)\n",
    "resultados_df['p_valor'] = resultados_df['p_valor'].round(4)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"TEST DIEBOLD-MARIANO MODIFICADO (HLN): Comparación SIN_DIFF vs CON_DIFF por valor de d\")\n",
    "print(\"=\"*100)\n",
    "print(\"\\nH0: No hay diferencia significativa entre las modalidades\")\n",
    "print(\"H1: Hay diferencia significativa entre las modalidades\")\n",
    "print(\"\\nSignificancia: *** p<0.01, ** p<0.05, * p<0.10, No = no significativo\")\n",
    "print(\"\\n\")\n",
    "print(resultados_df.to_string(index=False))\n",
    "\n",
    "# Resumen de resultados\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"RESUMEN\")\n",
    "print(\"=\"*100)\n",
    "n_significativos = len(resultados_df[resultados_df['Significativo'] != 'No'])\n",
    "n_total = len(resultados_df)\n",
    "print(f\"\\nTotal de comparaciones: {n_total}\")\n",
    "print(f\"Diferencias significativas: {n_significativos} ({100*n_significativos/n_total:.1f}%)\")\n",
    "print(f\"No significativas: {n_total - n_significativos} ({100*(n_total-n_significativos)/n_total:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6425b70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================================================================\n",
      "TEST DIEBOLD-MARIANO MODIFICADO (HLN): Comparación Sin Diferenciación (No) vs Con Diferenciación (Si)\n",
      "========================================================================================================================\n",
      "\n",
      "H0: No hay diferencia significativa entre aplicar o no diferenciación\n",
      "H1: Hay diferencia significativa entre aplicar o no diferenciación\n",
      "\n",
      "Significancia: *** p<0.01, ** p<0.05, * p<0.10, No = no significativo\n",
      "========================================================================================================================\n",
      "\n",
      "\n",
      "             Método  N_obs  ECRPS_Sin_Diff  ECRPS_Con_Diff  Diferencia  DM_stat  HLN-DM_stat  p_valor Significativo\n",
      "Block Bootstrapping   1680       11.251601        0.666133   10.585468   5.9736       5.9736   0.0000           ***\n",
      "    Sieve Bootstrap   1680        0.547481        0.546020    0.001461   1.1882       1.1882   0.2515            No\n",
      "               LSPM   1680        1.064804        0.648039    0.416766  14.2307      14.2307   0.0000           ***\n",
      "              LSPMW   1680        3.079645        0.767172    2.312473  10.3870      10.3870   0.0000           ***\n",
      "              AREPD   1680       10.031183        0.704149    9.327035   5.7364       5.7364   0.0000           ***\n",
      "               MCPS   1680        3.218168        0.677471    2.540697   5.1990       5.1990   0.0000           ***\n",
      "            AV-MCPS   1680        3.324007        0.654257    2.669750   5.8485       5.8485   0.0000           ***\n",
      "             DeepAR   1680        4.329124        0.561822    3.767302   3.4823       3.4823   0.0008           ***\n",
      "         EnCQR-LSTM   1680        6.112344        0.880288    5.232056   6.5596       6.5596   0.0000           ***\n",
      "\n",
      "========================================================================================================================\n",
      "RESUMEN\n",
      "========================================================================================================================\n",
      "\n",
      "Total de métodos comparados: 9\n",
      "Diferencias significativas: 8 (88.9%)\n",
      "No significativas: 1 (11.1%)\n",
      "\n",
      "Métodos con diferencias significativas:\n",
      "             Método Significativo  p_valor\n",
      "Block Bootstrapping           ***   0.0000\n",
      "               LSPM           ***   0.0000\n",
      "              LSPMW           ***   0.0000\n",
      "              AREPD           ***   0.0000\n",
      "               MCPS           ***   0.0000\n",
      "            AV-MCPS           ***   0.0000\n",
      "             DeepAR           ***   0.0008\n",
      "         EnCQR-LSTM           ***   0.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Cargar datos\n",
    "base = pd.read_excel(\"./datos/Simulacion/Diferenciado/resultados_UNION_ARIMA.xlsx\")\n",
    "\n",
    "def modified_diebold_mariano_test(errors1, errors2, h=1):\n",
    "    \"\"\"\n",
    "    Test Diebold-Mariano con fixed-smoothing asymptotics (Coroneo & Iacone, 2020)\n",
    "    \n",
    "    Implementa dos enfoques:\n",
    "    1. Fixed-b asymptotics con kernel de Bartlett\n",
    "    2. Fixed-m asymptotics con kernel de Daniell\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    errors1, errors2 : array-like\n",
    "        Errores de pronóstico (ECRPS) de los dos modelos\n",
    "    h : int\n",
    "        Horizonte de pronóstico (forecast horizon)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    hln_dm_stat : float\n",
    "        Estadístico con fixed-smoothing asymptotics\n",
    "    p_value : float\n",
    "        P-valor usando distribución apropiada\n",
    "    dm_stat : float\n",
    "        Estadístico DM original (para referencia)\n",
    "    \"\"\"\n",
    "    # Calcular diferencial de pérdida\n",
    "    d = errors1 - errors2\n",
    "    d_bar = np.mean(d)\n",
    "    T = len(d)\n",
    "    \n",
    "    if T < 2:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    \n",
    "    # Desviaciones de la media\n",
    "    u = d - d_bar\n",
    "    \n",
    "    # Elegir método según tamaño de muestra\n",
    "    if T >= 80:\n",
    "        # Fixed-b con kernel de Bartlett para muestras medianas/grandes\n",
    "        M = int(np.floor(T**(1/2)))  # Bandwidth recomendado\n",
    "        b = M / T\n",
    "        \n",
    "        # Calcular WCE con kernel de Bartlett\n",
    "        gamma_0 = np.mean(u**2)\n",
    "        gamma_sum = gamma_0\n",
    "        \n",
    "        for j in range(1, min(M, T)):\n",
    "            gamma_j = np.mean(u[j:] * u[:-j])\n",
    "            weight = 1 - j/M  # Kernel de Bartlett\n",
    "            gamma_sum += 2 * weight * gamma_j\n",
    "        \n",
    "        sigma_hat_sq = gamma_sum\n",
    "        \n",
    "        if sigma_hat_sq <= 0:\n",
    "            return 0, 1.0, 0\n",
    "        \n",
    "        # Estadístico DM\n",
    "        dm_stat = np.sqrt(T) * d_bar / np.sqrt(sigma_hat_sq)\n",
    "        \n",
    "        # Valor crítico fixed-b para Bartlett kernel (fórmula del paper)\n",
    "        # Para test de dos colas al 5%\n",
    "        alpha_0, alpha_1, alpha_2, alpha_3 = 1.9600, 2.9694, 0.4160, -0.5324\n",
    "        critical_value = alpha_0 + alpha_1*b + alpha_2*b**2 + alpha_3*b**3\n",
    "        \n",
    "        # P-valor aproximado usando la distribución límite\n",
    "        # Nota: esto es una aproximación, idealmente se simularía\n",
    "        p_value = 2 * (1 - stats.norm.cdf(abs(dm_stat) / (critical_value/1.96)))\n",
    "        \n",
    "        hln_dm_stat = dm_stat\n",
    "        \n",
    "    else:\n",
    "        # Fixed-m con kernel de Daniell para muestras pequeñas\n",
    "        m = int(np.floor(T**(1/3)))  # Bandwidth recomendado\n",
    "        \n",
    "        # Calcular periodograma\n",
    "        from scipy.fft import fft\n",
    "        \n",
    "        # FFT de las desviaciones\n",
    "        fft_u = fft(u)\n",
    "        periodogram = np.abs(fft_u)**2 / (2 * np.pi * T)\n",
    "        \n",
    "        # WPE con kernel de Daniell (promedio de primeros m periodogramas)\n",
    "        sigma_hat_sq = 2 * np.pi * np.mean(periodogram[1:m+1])\n",
    "        \n",
    "        if sigma_hat_sq <= 0:\n",
    "            return 0, 1.0, 0\n",
    "        \n",
    "        # Estadístico DM\n",
    "        dm_stat = np.sqrt(T) * d_bar / np.sqrt(sigma_hat_sq)\n",
    "        \n",
    "        # Fixed-m asymptotics: límite es t-Student con 2m grados de libertad\n",
    "        df = 2 * m\n",
    "        hln_dm_stat = dm_stat\n",
    "        \n",
    "        # P-valor usando t-Student\n",
    "        p_value = 2 * (1 - stats.t.cdf(abs(hln_dm_stat), df))\n",
    "    \n",
    "    return hln_dm_stat, p_value, dm_stat\n",
    "\n",
    "\n",
    "# Separar por diferenciación\n",
    "sin_diff = base[base['Diferenciacion'] == 'No'].copy()\n",
    "con_diff = base[base['Diferenciacion'] == 'Si'].copy()\n",
    "\n",
    "# Métodos a comparar (todos excepto las columnas de configuración)\n",
    "metodos = ['Block Bootstrapping', 'Sieve Bootstrap', 'LSPM', 'LSPMW', \n",
    "           'AREPD', 'MCPS', 'AV-MCPS', 'DeepAR', 'EnCQR-LSTM']\n",
    "\n",
    "# Lista para almacenar resultados\n",
    "resultados = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"TEST DIEBOLD-MARIANO MODIFICADO (HLN): Comparación Sin Diferenciación (No) vs Con Diferenciación (Si)\")\n",
    "print(\"=\"*120)\n",
    "print(\"\\nH0: No hay diferencia significativa entre aplicar o no diferenciación\")\n",
    "print(\"H1: Hay diferencia significativa entre aplicar o no diferenciación\")\n",
    "print(\"\\nSignificancia: *** p<0.01, ** p<0.05, * p<0.10, No = no significativo\")\n",
    "print(\"=\"*120)\n",
    "\n",
    "# Iterar sobre cada método\n",
    "for metodo in metodos:\n",
    "    # Obtener valores de ECRPS para cada modalidad\n",
    "    ecrps_sin = sin_diff[metodo].values\n",
    "    ecrps_con = con_diff[metodo].values\n",
    "    \n",
    "    # Verificar que ambas modalidades tengan datos\n",
    "    if len(ecrps_sin) == 0 or len(ecrps_con) == 0:\n",
    "        print(f\"\\nAdvertencia: {metodo} no tiene datos para ambas modalidades\")\n",
    "        continue\n",
    "    \n",
    "    # Verificar que tengan la misma longitud\n",
    "    if len(ecrps_sin) != len(ecrps_con):\n",
    "        print(f\"\\nAdvertencia: {metodo} tiene diferente número de observaciones\")\n",
    "        min_len = min(len(ecrps_sin), len(ecrps_con))\n",
    "        ecrps_sin = ecrps_sin[:min_len]\n",
    "        ecrps_con = ecrps_con[:min_len]\n",
    "    \n",
    "    # Calcular estadísticas descriptivas\n",
    "    ecrps_sin_mean = np.mean(ecrps_sin)\n",
    "    ecrps_con_mean = np.mean(ecrps_con)\n",
    "    diferencia = ecrps_sin_mean - ecrps_con_mean\n",
    "    \n",
    "    # Realizar test Diebold-Mariano modificado\n",
    "    hln_dm_stat, p_value, dm_stat = modified_diebold_mariano_test(ecrps_sin, ecrps_con, h=1)\n",
    "    \n",
    "    # Determinar significancia\n",
    "    if p_value < 0.01:\n",
    "        significativo = \"***\"\n",
    "    elif p_value < 0.05:\n",
    "        significativo = \"**\"\n",
    "    elif p_value < 0.10:\n",
    "        significativo = \"*\"\n",
    "    else:\n",
    "        significativo = \"No\"\n",
    "    \n",
    "    # Agregar a resultados\n",
    "    resultados.append({\n",
    "        'Método': metodo,\n",
    "        'N_obs': len(ecrps_sin),\n",
    "        'ECRPS_Sin_Diff': ecrps_sin_mean,\n",
    "        'ECRPS_Con_Diff': ecrps_con_mean,\n",
    "        'Diferencia': diferencia,\n",
    "        'DM_stat': dm_stat,\n",
    "        'HLN-DM_stat': hln_dm_stat,\n",
    "        'p_valor': p_value,\n",
    "        'Significativo': significativo\n",
    "    })\n",
    "\n",
    "# Crear DataFrame con resultados\n",
    "resultados_df = pd.DataFrame(resultados)\n",
    "\n",
    "# Formatear para mejor visualización\n",
    "resultados_df['ECRPS_Sin_Diff'] = resultados_df['ECRPS_Sin_Diff'].round(6)\n",
    "resultados_df['ECRPS_Con_Diff'] = resultados_df['ECRPS_Con_Diff'].round(6)\n",
    "resultados_df['Diferencia'] = resultados_df['Diferencia'].round(6)\n",
    "resultados_df['DM_stat'] = resultados_df['DM_stat'].round(4)\n",
    "resultados_df['HLN-DM_stat'] = resultados_df['HLN-DM_stat'].round(4)\n",
    "resultados_df['p_valor'] = resultados_df['p_valor'].round(4)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"\\n\")\n",
    "print(resultados_df.to_string(index=False))\n",
    "\n",
    "# Resumen de resultados\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"RESUMEN\")\n",
    "print(\"=\"*120)\n",
    "n_significativos = len(resultados_df[resultados_df['Significativo'] != 'No'])\n",
    "n_total = len(resultados_df)\n",
    "print(f\"\\nTotal de métodos comparados: {n_total}\")\n",
    "print(f\"Diferencias significativas: {n_significativos} ({100*n_significativos/n_total:.1f}%)\")\n",
    "print(f\"No significativas: {n_total - n_significativos} ({100*(n_total-n_significativos)/n_total:.1f}%)\")\n",
    "\n",
    "# Mostrar cuáles métodos tienen diferencias significativas\n",
    "if n_significativos > 0:\n",
    "    print(\"\\nMétodos con diferencias significativas:\")\n",
    "    metodos_sig = resultados_df[resultados_df['Significativo'] != 'No'][['Método', 'Significativo', 'p_valor']]\n",
    "    print(metodos_sig.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbb8245",
   "metadata": {},
   "source": [
    "### Analisis general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3b604c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Datos cargados: (26880, 19)\n",
      "✓ Columnas: ['Paso', 'Proceso', 'p', 'd', 'q', 'ARMA_base', 'Distribución', 'Varianza', 'Modalidad', 'Valor_Observado', 'AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', 'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
      "✓ Modelos identificados: ['AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', 'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
      "✓ Valores únicos de d: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(10)]\n",
      "\n",
      "================================================================================\n",
      "INICIANDO ANÁLISIS MULTI-D COMPLETO\n",
      "================================================================================\n",
      "\n",
      "=== NUEVO 1: Heatmaps ECRPS por Modalidad ===\n",
      "\n",
      "=== NUEVO 2: Sensibilidad al Incremento de d ===\n",
      "\n",
      "=== NUEVO 3: Test Diebold-Mariano ===\n",
      "\n",
      "=== MODIFICADO 1.2: Heatmaps por d ===\n",
      "\n",
      "=== MODIFICADO 3: Heatmaps por Proceso ===\n",
      "\n",
      "=== MODIFICADO 4: Heatmaps por Distribución ===\n",
      "\n",
      "=== MODIFICADO 5: Matrices Varianza ===\n",
      "\n",
      "=== MODIFICADO 9: Excel con d ===\n",
      "\n",
      "=== Heatmap d vs Modelo ===\n",
      "\n",
      "================================================================================\n",
      "✓ ANÁLISIS COMPLETADO\n",
      "✓ Resultados: Resultados_analisis\\Multi_d\n",
      "✓ Gráficos: Resultados_analisis\\Multi_d\\Graficos_Analisis\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Configuración inicial\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "# ====================================================================================\n",
    "# 1. PREPARACIÓN DE DIRECTORIOS\n",
    "# ====================================================================================\n",
    "output_dir = Path(\"./Resultados_analisis/Multi_d\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "plots_dir = output_dir / \"Graficos_Analisis\"\n",
    "plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Cargar datos\n",
    "path_excel = \"./datos/Simulacion/Multi_D/resultados_ARIMA_d1_a_d10_DOBLE_MODALIDAD_COMPLETO.xlsx\"\n",
    "try:\n",
    "    df = pd.read_excel(path_excel)\n",
    "    print(f\"✓ Datos cargados: {df.shape}\")\n",
    "    print(f\"✓ Columnas: {df.columns.tolist()}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error crítico: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Identificar columnas\n",
    "var_cols = ['Paso', 'Proceso', 'p', 'd', 'q', 'ARMA_base', 'Distribución', \n",
    "            'Varianza', 'Modalidad', 'Valor_Observado']\n",
    "model_cols = [col for col in df.columns if col not in var_cols]\n",
    "print(f\"✓ Modelos identificados: {model_cols}\")\n",
    "print(f\"✓ Valores únicos de d: {sorted(df['d'].unique())}\")\n",
    "\n",
    "# ====================================================================================\n",
    "# TEST DE DIEBOLD-MARIANO CON CORRECCIÓN\n",
    "# ====================================================================================\n",
    "def modified_diebold_mariano_test(errors1, errors2, h=1):\n",
    "    \"\"\"\n",
    "    Test Diebold-Mariano con fixed-smoothing asymptotics (Coroneo & Iacone, 2020)\n",
    "    \n",
    "    Usa Fixed-m asymptotics (kernel Daniell) que es más robusto en muestras pequeñas\n",
    "    y mantiene buen desempeño en muestras grandes.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    errors1, errors2 : array-like\n",
    "        Errores de pronóstico (ECRPS) de los dos modelos\n",
    "    h : int\n",
    "        Horizonte de pronóstico (forecast horizon)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    hln_dm_stat : float\n",
    "        Estadístico con fixed-m asymptotics\n",
    "    p_value : float\n",
    "        P-valor usando distribución t-Student con 2m grados de libertad\n",
    "    dm_stat : float\n",
    "        Estadístico DM original (para referencia)\n",
    "    \"\"\"\n",
    "    # Calcular diferencial de pérdida\n",
    "    d = errors1 - errors2\n",
    "    d_bar = np.mean(d)\n",
    "    T = len(d)\n",
    "    \n",
    "    if T < 2:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    \n",
    "    # Desviaciones de la media\n",
    "    u = d - d_bar\n",
    "    \n",
    "    # Fixed-m: bandwidth recomendado en el paper\n",
    "    m = max(1, int(np.floor(T**(1/3))))\n",
    "    \n",
    "    # Calcular periodograma\n",
    "    from scipy.fft import fft\n",
    "    \n",
    "    # FFT de las desviaciones\n",
    "    fft_u = fft(u)\n",
    "    periodogram = np.abs(fft_u)**2 / (2 * np.pi * T)\n",
    "    \n",
    "    # WPE con kernel de Daniell: promedio de primeros m periodogramas\n",
    "    # (excluyendo frecuencia 0)\n",
    "    if m >= len(periodogram) - 1:\n",
    "        m = len(periodogram) - 2\n",
    "    \n",
    "    sigma_hat_sq = 2 * np.pi * np.mean(periodogram[1:m+1])\n",
    "    \n",
    "    if sigma_hat_sq <= 0:\n",
    "        # Fallback: usar varianza simple\n",
    "        sigma_hat_sq = np.var(d, ddof=1) / T\n",
    "        if sigma_hat_sq <= 0:\n",
    "            return 0, 1.0, 0\n",
    "    \n",
    "    # Estadístico DM\n",
    "    dm_stat = np.sqrt(T) * d_bar / np.sqrt(sigma_hat_sq)\n",
    "    \n",
    "    # Fixed-m asymptotics: límite es t-Student con 2m grados de libertad\n",
    "    df = 2 * m\n",
    "    hln_dm_stat = dm_stat\n",
    "    \n",
    "    # P-valor usando t-Student\n",
    "    p_value = 2 * (1 - stats.t.cdf(abs(hln_dm_stat), df))\n",
    "    \n",
    "    return hln_dm_stat, p_value, dm_stat\n",
    "\n",
    "# ====================================================================================\n",
    "# NUEVO 1: HEATMAPS ECRPS POR MODALIDAD\n",
    "# ====================================================================================\n",
    "def plot_heatmaps_ecrps_por_modalidad():\n",
    "    print(\"\\n=== NUEVO 1: Heatmaps ECRPS por Modalidad ===\")\n",
    "    d_values = sorted(df['d'].unique())\n",
    "    \n",
    "    for modalidad in ['SIN_DIFF', 'CON_DIFF']:\n",
    "        matrix_data = []\n",
    "        for model in model_cols:\n",
    "            row = []\n",
    "            for d_val in d_values:\n",
    "                subset = df[(df['d'] == d_val) & (df['Modalidad'] == modalidad)]\n",
    "                avg_ecrps = subset[model].mean()\n",
    "                row.append(avg_ecrps)\n",
    "            matrix_data.append(row)\n",
    "        \n",
    "        df_heatmap = pd.DataFrame(matrix_data, index=model_cols, columns=[f'd={d}' for d in d_values])\n",
    "        \n",
    "        plt.figure(figsize=(14, 10))\n",
    "        annot_matrix = df_heatmap.applymap(lambda x: f'{x:.2e}' if abs(x) >= 1000 else f'{x:.2f}')\n",
    "        sns.heatmap(df_heatmap, annot=annot_matrix, fmt='', cmap='RdYlGn_r', \n",
    "                   cbar_kws={'label': 'ECRPS'}, linewidths=0.5, center=df_heatmap.mean().mean())\n",
    "        plt.title(f'Heatmap ECRPS - Modalidad: {modalidad}', fontweight='bold', fontsize=14)\n",
    "        plt.xlabel('Orden de Diferenciación (d)', fontweight='bold')\n",
    "        plt.ylabel('Modelo', fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(plots_dir / f'NUEVO_1_heatmap_ecrps_{modalidad}.png')\n",
    "        plt.close()\n",
    "        df_heatmap.to_excel(output_dir / f'NUEVO_1_tabla_ecrps_{modalidad}.xlsx')\n",
    "\n",
    "# ====================================================================================\n",
    "# NUEVO 2: SENSIBILIDAD AL INCREMENTO DE d\n",
    "# ====================================================================================\n",
    "def plot_sensibilidad_incremento_d():\n",
    "    print(\"\\n=== NUEVO 2: Sensibilidad al Incremento de d ===\")\n",
    "    d_values = sorted(df['d'].unique())\n",
    "    sensibilidad = []\n",
    "    \n",
    "    for model in model_cols:\n",
    "        cambios = []\n",
    "        for i in range(len(d_values) - 1):\n",
    "            avg_d1 = df[df['d'] == d_values[i]][model].mean()\n",
    "            avg_d2 = df[df['d'] == d_values[i+1]][model].mean()\n",
    "            cambios.append(abs(avg_d2 - avg_d1))\n",
    "        \n",
    "        sensibilidad_modelo = np.mean(cambios)\n",
    "        std_entre_d = np.std([df[df['d'] == d][model].mean() for d in d_values])\n",
    "        sensibilidad.append({'Modelo': model, 'Sensibilidad_Media': sensibilidad_modelo, \n",
    "                           'Std_entre_d': std_entre_d})\n",
    "    \n",
    "    df_sens = pd.DataFrame(sensibilidad).sort_values('Sensibilidad_Media', ascending=False)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    colors = plt.cm.RdYlGn_r(np.linspace(0.3, 0.9, len(df_sens)))\n",
    "    \n",
    "    bars1 = ax1.barh(df_sens['Modelo'], df_sens['Sensibilidad_Media'], color=colors, edgecolor='black')\n",
    "    ax1.bar_label(bars1, fmt='%.3f', padding=5, fontsize=8)\n",
    "    ax1.set_xlabel('Sensibilidad Media', fontweight='bold')\n",
    "    ax1.set_title('Sensibilidad por Cambio Promedio', fontweight='bold')\n",
    "    ax1.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    bars2 = ax2.barh(df_sens['Modelo'], df_sens['Std_entre_d'], color=colors, edgecolor='black')\n",
    "    ax2.bar_label(bars2, fmt='%.3f', padding=5, fontsize=8)\n",
    "    ax2.set_xlabel('Desviación Estándar', fontweight='bold')\n",
    "    ax2.set_title('Sensibilidad por Variabilidad', fontweight='bold')\n",
    "    ax2.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plots_dir / 'NUEVO_2_sensibilidad_incremento_d.png')\n",
    "    plt.close()\n",
    "    df_sens.to_excel(output_dir / 'NUEVO_2_tabla_sensibilidad.xlsx', index=False)\n",
    "    \n",
    "    # Trayectorias\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    for model in model_cols:\n",
    "        trayectoria = [df[df['d'] == d][model].mean() for d in d_values]\n",
    "        plt.plot(d_values, trayectoria, marker='o', label=model, linewidth=2, alpha=0.7)\n",
    "    plt.xlabel('Orden de Diferenciación (d)', fontweight='bold', fontsize=12)\n",
    "    plt.ylabel('ECRPS Promedio', fontweight='bold', fontsize=12)\n",
    "    plt.title('Trayectorias de ECRPS según d', fontweight='bold', fontsize=14)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plots_dir / 'NUEVO_2_trayectorias_d.png')\n",
    "    plt.close()\n",
    "\n",
    "# ====================================================================================\n",
    "# NUEVO 3: TEST DIEBOLD-MARIANO\n",
    "# ====================================================================================\n",
    "def plot_heatmap_diebold_mariano():\n",
    "    print(\"\\n=== NUEVO 3: Test Diebold-Mariano ===\")\n",
    "    d_values = sorted(df['d'].unique())\n",
    "    results = []\n",
    "    \n",
    "    for model in model_cols:\n",
    "        for d_val in d_values:\n",
    "            sin_diff = df[(df['d'] == d_val) & (df['Modalidad'] == 'SIN_DIFF')][model].values\n",
    "            con_diff = df[(df['d'] == d_val) & (df['Modalidad'] == 'CON_DIFF')][model].values\n",
    "            \n",
    "            if len(sin_diff) > 5 and len(con_diff) > 5:\n",
    "                dm_stat, p_value, _ = modified_diebold_mariano_test(sin_diff, con_diff)\n",
    "                results.append({'Modelo': model, 'd': d_val, 'DM_stat': dm_stat, \n",
    "                              'p_valor': p_value, 'Significativo': 'Sí' if p_value < 0.05 else 'No'})\n",
    "    \n",
    "    df_dm = pd.DataFrame(results)\n",
    "    pivot_pvalor = df_dm.pivot(index='Modelo', columns='d', values='p_valor')\n",
    "    pivot_dm_stat = df_dm.pivot(index='Modelo', columns='d', values='DM_stat')\n",
    "    \n",
    "    # Heatmap p-valores\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    sns.heatmap(pivot_pvalor, annot=True, fmt='.3f', cmap='RdYlGn', \n",
    "               cbar_kws={'label': 'p-valor'}, linewidths=0.5, vmin=0, vmax=0.1, center=0.05)\n",
    "    plt.title('Test DM: P-valores (SIN_DIFF vs CON_DIFF)', fontweight='bold', fontsize=14)\n",
    "    plt.xlabel('Orden de Diferenciación (d)', fontweight='bold')\n",
    "    plt.ylabel('Modelo', fontweight='bold')\n",
    "    plt.figtext(0.5, -0.02, 'Valores < 0.05: diferencias significativas', \n",
    "               ha='center', fontsize=10, style='italic')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plots_dir / 'NUEVO_3_heatmap_dm_pvalor.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Heatmap estadísticos\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    sns.heatmap(pivot_dm_stat, annot=True, fmt='.2f', cmap='RdBu_r', \n",
    "               cbar_kws={'label': 'Estadístico DM'}, linewidths=0.5, center=0)\n",
    "    plt.title('Test DM: Estadísticos', fontweight='bold', fontsize=14)\n",
    "    plt.xlabel('Orden de Diferenciación (d)', fontweight='bold')\n",
    "    plt.ylabel('Modelo', fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plots_dir / 'NUEVO_3_heatmap_dm_stat.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    df_dm.to_excel(output_dir / 'NUEVO_3_tabla_diebold_mariano.xlsx', index=False)\n",
    "    pivot_pvalor.to_excel(output_dir / 'NUEVO_3_matriz_pvalores.xlsx')\n",
    "\n",
    "# ====================================================================================\n",
    "# MODIFICADO 1.2: HEATMAPS POR d\n",
    "# ====================================================================================\n",
    "def plot_heatmaps_mejora_por_d():\n",
    "    print(\"\\n=== MODIFICADO 1.2: Heatmaps por d ===\")\n",
    "    d_values = sorted(df['d'].unique())\n",
    "    \n",
    "    for d_val in d_values:\n",
    "        subset_d = df[df['d'] == d_val]\n",
    "        mejoras = []\n",
    "        for model in model_cols:\n",
    "            sin = subset_d[subset_d['Modalidad'] == 'SIN_DIFF'][model].mean()\n",
    "            con = subset_d[subset_d['Modalidad'] == 'CON_DIFF'][model].mean()\n",
    "            mejora_pct = ((sin - con) / sin) * 100 if sin != 0 else 0\n",
    "            mejoras.append(mejora_pct)\n",
    "        \n",
    "        df_mejora = pd.DataFrame([mejoras], columns=model_cols, index=[f'd={d_val}'])\n",
    "        \n",
    "        plt.figure(figsize=(16, 3))\n",
    "        sns.heatmap(df_mejora, annot=True, fmt='.2f', cmap='RdYlGn', center=0,\n",
    "                   cbar_kws={'label': 'Mejora (%)'}, linewidths=1)\n",
    "        plt.title(f'Mejora (CON_DIFF vs SIN_DIFF) - d={d_val}', fontweight='bold')\n",
    "        plt.xlabel('Modelo', fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(plots_dir / f'MOD_1.2_mejora_d{d_val}.png')\n",
    "        plt.close()\n",
    "\n",
    "# ====================================================================================\n",
    "# MODIFICADO 3: HEATMAPS POR PROCESO\n",
    "# ====================================================================================\n",
    "def plot_heatmaps_mejora_por_proceso():\n",
    "    print(\"\\n=== MODIFICADO 3: Heatmaps por Proceso ===\")\n",
    "    d_values = sorted(df['d'].unique())\n",
    "    \n",
    "    for model in model_cols:\n",
    "        mejoras_proceso = []\n",
    "        procesos = sorted(df['Proceso'].unique())\n",
    "        \n",
    "        for proceso in procesos:\n",
    "            mejoras_d = []\n",
    "            for d_val in d_values:\n",
    "                subset = df[(df['d'] == d_val) & (df['Proceso'] == proceso)]\n",
    "                sin = subset[subset['Modalidad'] == 'SIN_DIFF'][model].mean()\n",
    "                con = subset[subset['Modalidad'] == 'CON_DIFF'][model].mean()\n",
    "                mejora_pct = ((sin - con) / sin) * 100 if sin != 0 else 0\n",
    "                mejoras_d.append(mejora_pct)\n",
    "            mejoras_proceso.append(mejoras_d)\n",
    "        \n",
    "        df_mejora = pd.DataFrame(mejoras_proceso, index=procesos, \n",
    "                                columns=[f'd={d}' for d in d_values])\n",
    "        \n",
    "        plt.figure(figsize=(14, max(8, len(procesos) * 0.5)))\n",
    "        sns.heatmap(df_mejora, annot=True, fmt='.1f', cmap='RdYlGn', center=0,\n",
    "                   cbar_kws={'label': 'Mejora (%)'}, linewidths=0.5)\n",
    "        plt.title(f'Mejora por Proceso - {model}', fontweight='bold')\n",
    "        plt.xlabel('Orden de Diferenciación (d)', fontweight='bold')\n",
    "        plt.ylabel('Proceso ARMA', fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        safe_name = model.replace(' ', '_').replace('/', '_')\n",
    "        plt.savefig(plots_dir / f'MOD_3_proceso_{safe_name}.png')\n",
    "        plt.close()\n",
    "        df_mejora.to_excel(output_dir / f'MOD_3_proceso_{safe_name}.xlsx')\n",
    "\n",
    "# ====================================================================================\n",
    "# MODIFICADO 4: HEATMAPS POR DISTRIBUCIÓN\n",
    "# ====================================================================================\n",
    "def plot_heatmaps_mejora_por_distribucion():\n",
    "    print(\"\\n=== MODIFICADO 4: Heatmaps por Distribución ===\")\n",
    "    d_values = sorted(df['d'].unique())\n",
    "    \n",
    "    for model in model_cols:\n",
    "        mejoras_dist = []\n",
    "        distribuciones = sorted(df['Distribución'].unique())\n",
    "        \n",
    "        for dist in distribuciones:\n",
    "            mejoras_d = []\n",
    "            for d_val in d_values:\n",
    "                subset = df[(df['d'] == d_val) & (df['Distribución'] == dist)]\n",
    "                sin = subset[subset['Modalidad'] == 'SIN_DIFF'][model].mean()\n",
    "                con = subset[subset['Modalidad'] == 'CON_DIFF'][model].mean()\n",
    "                mejora_pct = ((sin - con) / sin) * 100 if sin != 0 else 0\n",
    "                mejoras_d.append(mejora_pct)\n",
    "            mejoras_dist.append(mejoras_d)\n",
    "        \n",
    "        df_mejora = pd.DataFrame(mejoras_dist, index=distribuciones, \n",
    "                                columns=[f'd={d}' for d in d_values])\n",
    "        \n",
    "        plt.figure(figsize=(14, max(6, len(distribuciones) * 1.5)))\n",
    "        sns.heatmap(df_mejora, annot=True, fmt='.1f', cmap='RdYlGn', center=0,\n",
    "                   cbar_kws={'label': 'Mejora (%)'}, linewidths=0.5)\n",
    "        plt.title(f'Mejora por Distribución - {model}', fontweight='bold')\n",
    "        plt.xlabel('d', fontweight='bold')\n",
    "        plt.ylabel('Distribución', fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        safe_name = model.replace(' ', '_').replace('/', '_')\n",
    "        plt.savefig(plots_dir / f'MOD_4_dist_{safe_name}.png')\n",
    "        plt.close()\n",
    "        df_mejora.to_excel(output_dir / f'MOD_4_dist_{safe_name}.xlsx')\n",
    "\n",
    "# ====================================================================================\n",
    "# MODIFICADO 5: MATRICES VARIANZA\n",
    "# ====================================================================================\n",
    "def plot_matrices_mejora_por_varianza():\n",
    "    print(\"\\n=== MODIFICADO 5: Matrices Varianza ===\")\n",
    "    d_values = sorted(df['d'].unique())\n",
    "    varianzas = sorted(df['Varianza'].unique())\n",
    "    \n",
    "    for model in model_cols:\n",
    "        mejoras_var = []\n",
    "        for d_val in d_values:\n",
    "            mejoras_por_var = []\n",
    "            for var in varianzas:\n",
    "                subset = df[(df['d'] == d_val) & (df['Varianza'] == var)]\n",
    "                sin = subset[subset['Modalidad'] == 'SIN_DIFF'][model].mean()\n",
    "                con = subset[subset['Modalidad'] == 'CON_DIFF'][model].mean()\n",
    "                mejora_pct = ((sin - con) / sin) * 100 if sin != 0 else 0\n",
    "                mejoras_por_var.append(mejora_pct)\n",
    "            mejoras_var.append(mejoras_por_var)\n",
    "        \n",
    "        df_mejora = pd.DataFrame(mejoras_var, index=[f'd={d}' for d in d_values], \n",
    "                                columns=[f'Var={v}' for v in varianzas])\n",
    "        \n",
    "        plt.figure(figsize=(max(10, len(varianzas) * 2), 10))\n",
    "        sns.heatmap(df_mejora, annot=True, fmt='.1f', cmap='RdYlGn', center=0,\n",
    "                   cbar_kws={'label': 'Mejora (%)'}, linewidths=0.5)\n",
    "        plt.title(f'Mejora por Varianza - {model}', fontweight='bold')\n",
    "        plt.xlabel('Varianza', fontweight='bold')\n",
    "        plt.ylabel('d', fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        safe_name = model.replace(' ', '_').replace('/', '_')\n",
    "        plt.savefig(plots_dir / f'MOD_5_var_{safe_name}.png')\n",
    "        plt.close()\n",
    "        df_mejora.to_excel(output_dir / f'MOD_5_var_{safe_name}.xlsx')\n",
    "\n",
    "# ====================================================================================\n",
    "# MODIFICADO 9: EXCEL DETALLADO CON d\n",
    "# ====================================================================================\n",
    "def generate_detailed_excel_with_d():\n",
    "    print(\"\\n=== MODIFICADO 9: Excel con d ===\")\n",
    "    file_path = output_dir / \"MOD_9_Detallado_Con_d.xlsx\"\n",
    "    \n",
    "    with pd.ExcelWriter(file_path, engine='xlsxwriter') as writer:\n",
    "        for model in model_cols:\n",
    "            temp = df.groupby(['d', 'Proceso', 'ARMA_base', 'Distribución', \n",
    "                              'Varianza', 'Modalidad'])[model].mean().reset_index()\n",
    "            \n",
    "            detailed = temp.pivot_table(\n",
    "                index=['d', 'Proceso', 'ARMA_base', 'Distribución', 'Varianza'],\n",
    "                columns='Modalidad', values=model).reset_index()\n",
    "            \n",
    "            detailed.columns.name = None\n",
    "            detailed = detailed.rename(columns={'SIN_DIFF': 'ECRPS_Sin_Dif', \n",
    "                                               'CON_DIFF': 'ECRPS_Con_Dif'})\n",
    "            \n",
    "            detailed['Mejora_Absoluta'] = detailed['ECRPS_Sin_Dif'] - detailed['ECRPS_Con_Dif']\n",
    "            detailed['Mejora_%'] = (detailed['Mejora_Absoluta'] / detailed['ECRPS_Sin_Dif']) * 100\n",
    "            detailed = detailed.sort_values(by=['d', 'Mejora_%'], ascending=[True, False])\n",
    "            \n",
    "            sheet_name = model.replace(' ', '_').replace('/', '_')[:31]\n",
    "            detailed.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "            \n",
    "            workbook = writer.book\n",
    "            worksheet = writer.sheets[sheet_name]\n",
    "            fmt_green = workbook.add_format({'bg_color': '#C6EFCE', 'font_color': '#006100'})\n",
    "            fmt_red = workbook.add_format({'bg_color': '#FFC7CE', 'font_color': '#9C0006'})\n",
    "            \n",
    "            col_idx = detailed.columns.get_loc('Mejora_%')\n",
    "            worksheet.conditional_format(1, col_idx, len(detailed), col_idx, \n",
    "                                       {'type': 'cell', 'criteria': '>', 'value': 0, 'format': fmt_green})\n",
    "            worksheet.conditional_format(1, col_idx, len(detailed), col_idx,\n",
    "                                       {'type': 'cell', 'criteria': '<', 'value': 0, 'format': fmt_red})\n",
    "\n",
    "# ====================================================================================\n",
    "# FUNCIONES ORIGINALES\n",
    "# ====================================================================================\n",
    "def plot_heatmap_d_vs_modelo():\n",
    "    print(\"\\n=== Heatmap d vs Modelo ===\")\n",
    "    results = []\n",
    "    d_values = sorted(df['d'].unique())\n",
    "    \n",
    "    for d_val in d_values:\n",
    "        subset_d = df[df['d'] == d_val]\n",
    "        for model in model_cols:\n",
    "            sin = subset_d[subset_d['Modalidad'] == 'SIN_DIFF'][model].mean()\n",
    "            con = subset_d[subset_d['Modalidad'] == 'CON_DIFF'][model].mean()\n",
    "            mejora = ((sin - con) / sin) * 100 if sin != 0 else 0\n",
    "            results.append({'d': d_val, 'Modelo': model, 'Mejora_%': mejora})\n",
    "    \n",
    "    df_mejora = pd.DataFrame(results)\n",
    "    pivot = df_mejora.pivot(index='Modelo', columns='d', values='Mejora_%')\n",
    "    \n",
    "    plt.figure(figsize=(14, 10))\n",
    "    sns.heatmap(pivot, annot=True, fmt=\".1f\", cmap=\"RdYlGn\", center=0, \n",
    "                cbar_kws={'label': 'Mejora (%)'}, linewidths=0.5)\n",
    "    plt.title(\"Mejora: Modelo vs d\", fontweight='bold', fontsize=14)\n",
    "    plt.xlabel(\"Valor de d\", fontweight='bold')\n",
    "    plt.ylabel(\"Modelo\", fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plots_dir / '2_heatmap_d_vs_modelo.png')\n",
    "    plt.close()\n",
    "    pivot.to_excel(output_dir / '2_tabla_d_vs_modelo.xlsx')\n",
    "\n",
    "# ====================================================================================\n",
    "# EJECUCIÓN PRINCIPAL\n",
    "# ====================================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"INICIANDO ANÁLISIS MULTI-D COMPLETO\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Nuevas funciones\n",
    "    plot_heatmaps_ecrps_por_modalidad()\n",
    "    plot_sensibilidad_incremento_d()\n",
    "    plot_heatmap_diebold_mariano()\n",
    "    \n",
    "    # Modificadas\n",
    "    plot_heatmaps_mejora_por_d()\n",
    "    plot_heatmaps_mejora_por_proceso()\n",
    "    plot_heatmaps_mejora_por_distribucion()\n",
    "    plot_matrices_mejora_por_varianza()\n",
    "    generate_detailed_excel_with_d()\n",
    "    \n",
    "    # Originales\n",
    "    plot_heatmap_d_vs_modelo()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"✓ ANÁLISIS COMPLETADO\")\n",
    "    print(f\"✓ Resultados: {output_dir}\")\n",
    "    print(f\"✓ Gráficos: {plots_dir}\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b8a52b",
   "metadata": {},
   "source": [
    "## Analisis Tamaño"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0169f259",
   "metadata": {},
   "source": [
    "### Pre-procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfd6fb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TABLA COMPARATIVA DE MODELOS POR ESCENARIO\n",
      "(Promedio de amplitud de intervalos de predicción)\n",
      "================================================================================\n",
      "             Modelo   ARMA   ARIMA  SETAR Mejor_Escenario\n",
      "              AREPD 0.9264 12.3986 0.8148           SETAR\n",
      "            AV-MCPS 0.6780  3.0524 0.6585           SETAR\n",
      "Block Bootstrapping 0.9036 14.2503 0.7915           SETAR\n",
      "             DeepAR 0.5745  2.8056 0.5736           SETAR\n",
      "         EnCQR-LSTM 0.7947  6.1857 0.7544           SETAR\n",
      "               LSPM 0.7721  1.0854 0.6490           SETAR\n",
      "              LSPMW 0.7839  1.0846 0.6610           SETAR\n",
      "               MCPS 0.6613  2.8912 0.6488           SETAR\n",
      "    Sieve Bootstrap 0.5444  0.5473 0.5544            ARMA\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Archivo 'Base_Tamaño_3_escenarios.xlsx' creado exitosamente!\n",
      "Columna 'Block Bootstrapping' verificada en el archivo final.\n",
      "Total de filas: 25200\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Leer los tres archivos\n",
    "arma_df = pd.read_excel(\"./datos/Simulacion/Tamaño/resultados_TAMANOS_CRECIENTES_ARMA.xlsx\")\n",
    "arima_df = pd.read_excel(\"./datos/Simulacion/Tamaño/resultados_TAMANOS_CRECIENTES_ARIMA.xlsx\")\n",
    "setar_df = pd.read_excel(\"./datos/Simulacion/Tamaño/resultados_TAMANOS_CRECIENTES_SETAR.xlsx\")\n",
    "\n",
    "# 2. ESTANDARIZAR NOMBRES DE COLUMNAS\n",
    "# Renombramos 'Block Bootstrap' a 'Block Bootstrapping' en ARIMA y SETAR para que coincidan con ARMA\n",
    "arima_df = arima_df.rename(columns={'Block Bootstrap': 'Block Bootstrapping'})\n",
    "setar_df = setar_df.rename(columns={'Block Bootstrap': 'Block Bootstrapping'})\n",
    "\n",
    "# 3. Asignar escenarios\n",
    "arma_df['ESCENARIO'] = \"Lineal Estacionario\"\n",
    "arima_df['ESCENARIO'] = \"Lineal No estacionario\"\n",
    "setar_df['ESCENARIO'] = \"No lineal Estacionario\"\n",
    "\n",
    "# 4. Filtrar los que no tienen \"Promedio\" en la columna \"Paso\"\n",
    "arma_df = arma_df[arma_df['Paso'] != 'Promedio']\n",
    "arima_df = arima_df[arima_df['Paso'] != 'Promedio']\n",
    "setar_df = setar_df[setar_df['Paso'] != 'Promedio']\n",
    "\n",
    "# 5. Lista de modelos (ahora el nombre es uniforme)\n",
    "modelos = ['AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR',\n",
    "           'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
    "\n",
    "# 6. Crear tabla comparativa\n",
    "comparacion = []\n",
    "\n",
    "for modelo in modelos:\n",
    "    fila = {'Modelo': modelo}\n",
    "    \n",
    "    # Calcular promedio para cada escenario\n",
    "    arma_promedio = arma_df[modelo].mean() if modelo in arma_df.columns else np.nan\n",
    "    arima_promedio = arima_df[modelo].mean() if modelo in arima_df.columns else np.nan\n",
    "    setar_promedio = setar_df[modelo].mean() if modelo in setar_df.columns else np.nan\n",
    "    \n",
    "    fila['ARMA'] = arma_promedio\n",
    "    fila['ARIMA'] = arima_promedio\n",
    "    fila['SETAR'] = setar_promedio\n",
    "    \n",
    "    # Determinar mejor escenario (menor promedio)\n",
    "    promedios = {\n",
    "        'ARMA': arma_promedio,\n",
    "        'ARIMA': arima_promedio,\n",
    "        'SETAR': setar_promedio\n",
    "    }\n",
    "    \n",
    "    promedios_validos = {k: v for k, v in promedios.items() if not pd.isna(v)}\n",
    "    \n",
    "    if promedios_validos:\n",
    "        mejor_escenario = min(promedios_validos, key=promedios_validos.get)\n",
    "        fila['Mejor_Escenario'] = mejor_escenario\n",
    "    else:\n",
    "        fila['Mejor_Escenario'] = 'N/A'\n",
    "    \n",
    "    comparacion.append(fila)\n",
    "\n",
    "# Crear DataFrame con la tabla comparativa\n",
    "tabla_comparativa = pd.DataFrame(comparacion)\n",
    "columnas_numericas = ['ARMA', 'ARIMA', 'SETAR']\n",
    "tabla_comparativa[columnas_numericas] = tabla_comparativa[columnas_numericas].round(4)\n",
    "\n",
    "# Mostrar tabla comparativa\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TABLA COMPARATIVA DE MODELOS POR ESCENARIO\")\n",
    "print(\"(Promedio de amplitud de intervalos de predicción)\")\n",
    "print(\"=\"*80)\n",
    "print(tabla_comparativa.to_string(index=False))\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# 7. Procesamiento final y exportación\n",
    "if 'Descripción' in setar_df.columns:\n",
    "    setar_df = setar_df.drop('Descripción', axis=1)\n",
    "\n",
    "# Concatenar los tres dataframes (ahora las columnas se alinearán perfectamente)\n",
    "base_consolidada = pd.concat([arma_df, arima_df, setar_df], ignore_index=True)\n",
    "\n",
    "# Guardar en un archivo Excel\n",
    "base_consolidada.to_excel(\"./datos/Simulacion/Tamaño/Base_Tamaño_3_escenarios.xlsx\", index=False)\n",
    "\n",
    "print(\"\\nArchivo 'Base_Tamaño_3_escenarios.xlsx' creado exitosamente!\")\n",
    "print(f\"Columna 'Block Bootstrapping' verificada en el archivo final.\")\n",
    "print(f\"Total de filas: {len(base_consolidada)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6a6937",
   "metadata": {},
   "source": [
    "### Analisis general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "518faae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PALETA DE COLORES GENERADA PARA 9 MODELOS\n",
      "================================================================================\n",
      " 1. Block Bootstrapping            -> RGB: (0.122, 0.467, 0.706)\n",
      " 2. Sieve Bootstrap                -> RGB: (1.000, 0.498, 0.055)\n",
      " 3. LSPM                           -> RGB: (0.173, 0.627, 0.173)\n",
      " 4. LSPMW                          -> RGB: (0.839, 0.153, 0.157)\n",
      " 5. AREPD                          -> RGB: (0.580, 0.404, 0.741)\n",
      " 6. MCPS                           -> RGB: (0.549, 0.337, 0.294)\n",
      " 7. AV-MCPS                        -> RGB: (0.890, 0.467, 0.761)\n",
      " 8. DeepAR                         -> RGB: (0.498, 0.498, 0.498)\n",
      " 9. EnCQR-LSTM                     -> RGB: (0.737, 0.741, 0.133)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "SIMULACIÓN 3: EFECTOS DEL TAMAÑO MUESTRAL ABSOLUTO\n",
      "CON TEST DIEBOLD-MARIANO MODIFICADO Y CORRECCIÓN DE BONFERRONI\n",
      "================================================================================\n",
      "\n",
      "Modelos evaluados: 9\n",
      "Tamaños muestrales: [np.int64(120), np.int64(240), np.int64(360), np.int64(600), np.int64(1200)]\n",
      "Escenarios: ['Lineal Estacionario (ARMA)', 'Lineal No Estacionario (ARIMA)', 'No lineal Estacionario (SETAR)']\n",
      "\n",
      "================================================================================\n",
      "1. GENERANDO HEATMAPS: Z-scores por Modelo\n",
      "================================================================================\n",
      "✓ Heatmap Z-scores generado: General\n",
      "✓ Heatmap Z-scores generado: Lineal_Estacionario_ARMA\n",
      "✓ Heatmap Z-scores generado: Lineal_No_Estacionario_ARIMA\n",
      "✓ Heatmap Z-scores generado: No_lineal_Estacionario_SETAR\n",
      "\n",
      "================================================================================\n",
      "2. TEST DM CON CORRECCIÓN DE BONFERRONI\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "CORRECCIÓN DE BONFERRONI - General\n",
      "================================================================================\n",
      "Número total de comparaciones: 90\n",
      "α nominal: 0.05\n",
      "α corregido (Bonferroni): 0.000556\n",
      "================================================================================\n",
      "\n",
      "✓ Test DM con Bonferroni (Excel) generado: General\n",
      "  - 90 comparaciones totales\n",
      "  - 37 significativas sin corrección (p<0.05)\n",
      "  - 8 significativas con Bonferroni\n",
      "\n",
      "\n",
      "================================================================================\n",
      "CORRECCIÓN DE BONFERRONI - Lineal_Estacionario_ARMA\n",
      "================================================================================\n",
      "Número total de comparaciones: 90\n",
      "α nominal: 0.05\n",
      "α corregido (Bonferroni): 0.000556\n",
      "================================================================================\n",
      "\n",
      "✓ Test DM con Bonferroni (Excel) generado: Lineal_Estacionario_ARMA\n",
      "  - 90 comparaciones totales\n",
      "  - 37 significativas sin corrección (p<0.05)\n",
      "  - 25 significativas con Bonferroni\n",
      "\n",
      "\n",
      "================================================================================\n",
      "CORRECCIÓN DE BONFERRONI - Lineal_No_Estacionario_ARIMA\n",
      "================================================================================\n",
      "Número total de comparaciones: 90\n",
      "α nominal: 0.05\n",
      "α corregido (Bonferroni): 0.000556\n",
      "================================================================================\n",
      "\n",
      "✓ Test DM con Bonferroni (Excel) generado: Lineal_No_Estacionario_ARIMA\n",
      "  - 90 comparaciones totales\n",
      "  - 39 significativas sin corrección (p<0.05)\n",
      "  - 21 significativas con Bonferroni\n",
      "\n",
      "\n",
      "================================================================================\n",
      "CORRECCIÓN DE BONFERRONI - No_lineal_Estacionario_SETAR\n",
      "================================================================================\n",
      "Número total de comparaciones: 90\n",
      "α nominal: 0.05\n",
      "α corregido (Bonferroni): 0.000556\n",
      "================================================================================\n",
      "\n",
      "✓ Test DM con Bonferroni (Excel) generado: No_lineal_Estacionario_SETAR\n",
      "  - 90 comparaciones totales\n",
      "  - 44 significativas sin corrección (p<0.05)\n",
      "  - 27 significativas con Bonferroni\n",
      "\n",
      "\n",
      "================================================================================\n",
      "3. GRÁFICAS DE MEJORA RELATIVA\n",
      "================================================================================\n",
      "✓ Mejora relativa generada: General\n",
      "✓ Mejora relativa generada: Lineal_Estacionario_ARMA\n",
      "✓ Mejora relativa generada: Lineal_No_Estacionario_ARIMA\n",
      "✓ Mejora relativa generada: No_lineal_Estacionario_SETAR\n",
      "\n",
      "================================================================================\n",
      "RESUMEN EJECUTIVO\n",
      "================================================================================\n",
      "\n",
      "Mejor modelo por tamaño muestral (menor ECRPS promedio):\n",
      "------------------------------------------------------------\n",
      "  N= 120: Sieve Bootstrap                (ECRPS = 0.5663)\n",
      "  N= 240: Sieve Bootstrap                (ECRPS = 0.5492)\n",
      "  N= 360: Sieve Bootstrap                (ECRPS = 0.5467)\n",
      "  N= 600: Sieve Bootstrap                (ECRPS = 0.5436)\n",
      "  N=1200: Sieve Bootstrap                (ECRPS = 0.5378)\n",
      "\n",
      "Comparaciones N=120 vs N=1200 (CON BONFERRONI):\n",
      "------------------------------------------------------------\n",
      "\n",
      "Modelos con mejoras significativas (post-Bonferroni): 1\n",
      "Top 5 mejoras significativas (Bonferroni):\n",
      "  Sieve Bootstrap               :   5.03% - Sí (p<0.000556)\n",
      "\n",
      "Top 5 mayores mejoras (sin considerar Bonferroni):\n",
      "  Sieve Bootstrap               :   5.03% - Sin corr: Sí (p<0.01) | Bonf: Sí (p<0.000556)\n",
      "  LSPMW                         :  -0.27% - Sin corr: No | Bonf: No\n",
      "  LSPM                          :  -0.34% - Sin corr: No | Bonf: No\n",
      "  DeepAR                        :  -3.46% - Sin corr: No | Bonf: No\n",
      "  MCPS                          : -25.79% - Sin corr: Marginal (p<0.1) | Bonf: No\n",
      "\n",
      "Menores mejoras o empeoramientos:\n",
      "  MCPS                          : -25.79% - Sin corr: Marginal (p<0.1) | Bonf: No\n",
      "  AV-MCPS                       : -26.66% - Sin corr: Marginal (p<0.1) | Bonf: No\n",
      "  EnCQR-LSTM                    : -104.65% - Sin corr: Sí (p<0.01) | Bonf: No\n",
      "  AREPD                         : -221.72% - Sin corr: Sí (p<0.01) | Bonf: No\n",
      "  Block Bootstrapping           : -251.30% - Sin corr: Sí (p<0.01) | Bonf: No\n",
      "\n",
      "================================================================================\n",
      "ANÁLISIS COMPLETADO EXITOSAMENTE\n",
      "================================================================================\n",
      "Resultados guardados en: Resultados_analisis\\Tamaño\n",
      "\n",
      "Archivos generados:\n",
      "  - 4 Heatmaps con Z-scores (1 general + 3 por escenario)\n",
      "  - 4 Archivos Excel con Test DM y Bonferroni (1 general + 3 por escenario)\n",
      "  - 4 Gráficas de mejora relativa (1 general + 3 por escenario)\n",
      "  - Cada Excel incluye hoja de resumen con estadísticas de Bonferroni\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# ====================================================================================\n",
    "# 1. CONFIGURACIÓN Y PREPARACIÓN DE DATOS\n",
    "# ====================================================================================\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración de gráficas\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "# Rutas\n",
    "output_dir = Path(\"./Resultados_analisis/Tamaño\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Cargar datos\n",
    "try:\n",
    "    df = pd.read_excel(\"./datos/Simulacion/Tamaño/Base_Tamaño_3_escenarios.xlsx\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: No se encontró el archivo Excel. Verifica la ruta.\")\n",
    "    exit()\n",
    "\n",
    "# Renombrar escenarios\n",
    "df['ESCENARIO'] = df['ESCENARIO'].replace({\n",
    "    \"Lineal Estacionario\": \"Lineal Estacionario (ARMA)\",\n",
    "    \"Lineal No estacionario\": \"Lineal No Estacionario (ARIMA)\",\n",
    "    \"No lineal Estacionario\": \"No lineal Estacionario (SETAR)\"\n",
    "})\n",
    "\n",
    "# Identificación de variables y modelos\n",
    "var_cols = ['Paso', 'Proceso', 'Tipo_Proceso', 'Distribución', 'Varianza', \n",
    "            'N_Train', 'N_Calib', 'N_Total', 'Valor_Observado', 'ESCENARIO', 'Size']\n",
    "\n",
    "model_cols = [col for col in df.columns \n",
    "              if col not in var_cols and pd.api.types.is_numeric_dtype(df[col])]\n",
    "\n",
    "n_total_values = sorted(df['N_Total'].unique())\n",
    "escenarios = df['ESCENARIO'].unique()\n",
    "\n",
    "# ====================================================================================\n",
    "# PALETA DE COLORES ÚNICA Y DISTINTIVA PARA MODELOS\n",
    "# ====================================================================================\n",
    "def generate_maximally_distinct_colors(n):\n",
    "    \"\"\"\n",
    "    Genera n colores MAXIMAMENTE distintivos usando diferentes estrategias\n",
    "    combinadas para evitar colores similares\n",
    "    \"\"\"\n",
    "    if n <= 10:\n",
    "        base_colors = plt.cm.tab10(np.linspace(0, 1, 10))\n",
    "        return base_colors[:n]\n",
    "    elif n <= 20:\n",
    "        base_colors = plt.cm.tab20(np.linspace(0, 1, 20))\n",
    "        return base_colors[:n]\n",
    "    else:\n",
    "        colors = []\n",
    "        \n",
    "        # Estrategia 1: Colores base de tab20\n",
    "        tab20 = plt.cm.tab20(np.linspace(0, 1, 20))\n",
    "        colors.extend(tab20)\n",
    "        \n",
    "        # Estrategia 2: Colores de Set3 (pasteles)\n",
    "        if n > 20:\n",
    "            set3 = plt.cm.Set3(np.linspace(0, 1, 12))\n",
    "            colors.extend(set3)\n",
    "        \n",
    "        # Estrategia 3: Colores de Paired\n",
    "        if n > 32:\n",
    "            paired = plt.cm.Paired(np.linspace(0, 1, 12))\n",
    "            colors.extend(paired)\n",
    "        \n",
    "        # Estrategia 4: Generar colores en HSV con máxima separación\n",
    "        if n > 44:\n",
    "            remaining = n - len(colors)\n",
    "            hsv_colors = []\n",
    "            for i in range(remaining):\n",
    "                hue = (i * 0.618033988749895) % 1.0  # Golden ratio\n",
    "                saturation = 0.6 + (i % 3) * 0.15\n",
    "                value = 0.7 + (i % 2) * 0.2\n",
    "                rgb = plt.cm.hsv(hue)\n",
    "                hsv_colors.append(rgb)\n",
    "            colors.extend(hsv_colors)\n",
    "        \n",
    "        return np.array(colors[:n])\n",
    "\n",
    "MODEL_COLORS = dict(zip(model_cols, generate_maximally_distinct_colors(len(model_cols))))\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"PALETA DE COLORES GENERADA PARA {len(model_cols)} MODELOS\")\n",
    "print(f\"{'='*80}\")\n",
    "for i, (model, color) in enumerate(MODEL_COLORS.items(), 1):\n",
    "    print(f\"{i:2d}. {model:30s} -> RGB: ({color[0]:.3f}, {color[1]:.3f}, {color[2]:.3f})\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# ====================================================================================\n",
    "# 2. TEST DIEBOLD-MARIANO MODIFICADO\n",
    "# ====================================================================================\n",
    "\n",
    "def modified_diebold_mariano_test(errors1, errors2, h=1):\n",
    "    \"\"\"Test Diebold-Mariano con fixed-smoothing asymptotics.\"\"\"\n",
    "    d = errors1 - errors2\n",
    "    d_bar = np.mean(d)\n",
    "    T = len(d)\n",
    "    if T < 2: \n",
    "        return np.nan, np.nan, np.nan\n",
    "    \n",
    "    u = d - d_bar\n",
    "    m = max(1, int(np.floor(T**(1/3))))\n",
    "    \n",
    "    from scipy.fft import fft\n",
    "    fft_u = fft(u)\n",
    "    periodogram = np.abs(fft_u)**2 / (2 * np.pi * T)\n",
    "    \n",
    "    if m >= len(periodogram) - 1: \n",
    "        m = len(periodogram) - 2\n",
    "    \n",
    "    sigma_hat_sq = 2 * np.pi * np.mean(periodogram[1:m+1])\n",
    "    if sigma_hat_sq <= 0: \n",
    "        sigma_hat_sq = np.var(d, ddof=1) / T\n",
    "    \n",
    "    dm_stat = np.sqrt(T) * d_bar / np.sqrt(sigma_hat_sq)\n",
    "    df_t = 2 * m\n",
    "    p_value = 2 * (1 - stats.t.cdf(abs(dm_stat), df_t))\n",
    "    \n",
    "    return dm_stat, p_value, d_bar\n",
    "\n",
    "# ====================================================================================\n",
    "# 2B. CORRECCIÓN DE BONFERRONI\n",
    "# ====================================================================================\n",
    "\n",
    "def bonferroni_correction(p_values, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Aplica corrección de Bonferroni a una lista de p-values.\n",
    "    \n",
    "    Parámetros:\n",
    "    -----------\n",
    "    p_values : array-like\n",
    "        Lista de p-values a corregir\n",
    "    alpha : float\n",
    "        Nivel de significancia nominal (default: 0.05)\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    corrected_alpha : float\n",
    "        Nivel de significancia ajustado (alpha / número de tests)\n",
    "    significant_bonferroni : array-like\n",
    "        Array booleano indicando si cada test es significativo tras corrección\n",
    "    \"\"\"\n",
    "    n_comparisons = len(p_values)\n",
    "    corrected_alpha = alpha / n_comparisons\n",
    "    significant_bonferroni = np.array(p_values) < corrected_alpha\n",
    "    \n",
    "    return corrected_alpha, significant_bonferroni\n",
    "\n",
    "def classify_significance(p_value, p_bonf, alpha=0.05, alpha_bonf=None):\n",
    "    \"\"\"\n",
    "    Clasifica la significancia de un test considerando tanto el p-value original\n",
    "    como la corrección de Bonferroni.\n",
    "    \n",
    "    Parámetros:\n",
    "    -----------\n",
    "    p_value : float\n",
    "        P-value sin corregir\n",
    "    p_bonf : float\n",
    "        P-value con corrección de Bonferroni\n",
    "    alpha : float\n",
    "        Nivel de significancia nominal\n",
    "    alpha_bonf : float\n",
    "        Nivel de significancia corregido por Bonferroni\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    tuple : (clasificacion_sin_correccion, clasificacion_con_bonferroni)\n",
    "    \"\"\"\n",
    "    # Sin corrección\n",
    "    if p_value < 0.01:\n",
    "        sin_corr = 'Sí (p<0.01)'\n",
    "    elif p_value < 0.05:\n",
    "        sin_corr = 'Sí (p<0.05)'\n",
    "    elif p_value < 0.1:\n",
    "        sin_corr = 'Marginal (p<0.1)'\n",
    "    else:\n",
    "        sin_corr = 'No'\n",
    "    \n",
    "    # Con corrección de Bonferroni\n",
    "    if alpha_bonf is None:\n",
    "        alpha_bonf = 0.05  # valor por defecto\n",
    "    \n",
    "    if p_bonf:  # Si pasó la corrección de Bonferroni\n",
    "        if p_value < alpha_bonf:\n",
    "            con_bonf = f'Sí (Bonferroni α={alpha_bonf:.6f})'\n",
    "        else:\n",
    "            con_bonf = 'No (post-Bonferroni)'\n",
    "    else:\n",
    "        con_bonf = 'No (post-Bonferroni)'\n",
    "    \n",
    "    return sin_corr, con_bonf\n",
    "\n",
    "# ====================================================================================\n",
    "# 3. HEATMAP: MODELOS VS N_TOTAL (Z-SCORES POR MODELO)\n",
    "# ====================================================================================\n",
    "\n",
    "def plot_heatmap_zscores_models_vs_ntotal(data, scenario_name=None):\n",
    "    \"\"\"\n",
    "    Heatmap de Modelos (filas) vs N_Total (columnas) con Z-scores\n",
    "    Z-score calculado POR MODELO (estandarización por fila)\n",
    "    \"\"\"\n",
    "    if scenario_name:\n",
    "        data = data[data['ESCENARIO'] == scenario_name]\n",
    "        suffix = scenario_name.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        title = f'Z-scores de ECRPS: Modelos vs N_Total\\n{scenario_name}'\n",
    "    else:\n",
    "        suffix = \"General\"\n",
    "        title = 'Z-scores de ECRPS: Modelos vs N_Total\\nTodos los Escenarios'\n",
    "    \n",
    "    # Crear matriz de ECRPS promedio\n",
    "    ecrps_data = []\n",
    "    for model in model_cols:\n",
    "        row = []\n",
    "        for nt in n_total_values:\n",
    "            ecrps_mean = data[data['N_Total'] == nt][model].mean()\n",
    "            row.append(ecrps_mean)\n",
    "        ecrps_data.append(row)\n",
    "    \n",
    "    ecrps_df = pd.DataFrame(ecrps_data, \n",
    "                             index=model_cols, \n",
    "                             columns=[f'N={nt}' for nt in n_total_values])\n",
    "    \n",
    "    # Calcular Z-scores POR MODELO (por fila)\n",
    "    zscore_df = ecrps_df.apply(lambda row: (row - row.mean()) / row.std() if row.std() > 0 else 0, axis=1)\n",
    "    \n",
    "    # Guardar datos\n",
    "    ecrps_df.to_excel(output_dir / f'heatmap_ecrps_{suffix}.xlsx')\n",
    "    zscore_df.to_excel(output_dir / f'heatmap_zscores_{suffix}.xlsx')\n",
    "    \n",
    "    # Graficar\n",
    "    plt.figure(figsize=(10, max(8, len(model_cols) * 0.4)))\n",
    "    sns.heatmap(zscore_df, annot=True, fmt='.2f', cmap='RdYlGn_r', \n",
    "                center=0, vmin=-2, vmax=2,\n",
    "                cbar_kws={'label': 'Z-score'},\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    plt.title(title, fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Tamaño Muestral Total', fontsize=12)\n",
    "    plt.ylabel('Modelo', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / f'heatmap_zscore_{suffix}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"✓ Heatmap Z-scores generado: {suffix}\")\n",
    "\n",
    "# ====================================================================================\n",
    "# 4. TEST DM CON BONFERRONI: COMPARACIÓN ENTRE TODOS LOS TAMAÑOS (FORMATO EXCEL)\n",
    "# ====================================================================================\n",
    "\n",
    "def dm_test_all_sizes_excel(data, scenario_name=None, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Test DM comparando TODOS los pares de tamaños para cada modelo\n",
    "    CON CORRECCIÓN DE BONFERRONI\n",
    "    \n",
    "    Formato: Modelo | Tamaño1 | Tamaño2 | ECRPS1 | ECRPS2 | Mejora% | \n",
    "             DM_Stat | p_value | Significativo | Significativo_Bonferroni\n",
    "    \"\"\"\n",
    "    if scenario_name:\n",
    "        data = data[data['ESCENARIO'] == scenario_name]\n",
    "        suffix = scenario_name.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "    else:\n",
    "        suffix = \"General\"\n",
    "    \n",
    "    results = []\n",
    "    p_values_list = []\n",
    "    \n",
    "    # PASO 1: Realizar todos los tests y recopilar p-values\n",
    "    for model in model_cols:\n",
    "        for i, n1 in enumerate(n_total_values):\n",
    "            for n2 in n_total_values[i+1:]:\n",
    "                \n",
    "                errors1 = data[data['N_Total'] == n1][model].values\n",
    "                errors2 = data[data['N_Total'] == n2][model].values\n",
    "                \n",
    "                min_len = min(len(errors1), len(errors2))\n",
    "                errors1 = errors1[:min_len]\n",
    "                errors2 = errors2[:min_len]\n",
    "                \n",
    "                ecrps1 = errors1.mean()\n",
    "                ecrps2 = errors2.mean()\n",
    "                \n",
    "                mejora_absoluta = ecrps1 - ecrps2\n",
    "                mejora_relativa = (mejora_absoluta / ecrps1) * 100 if ecrps1 != 0 else 0\n",
    "                \n",
    "                dm_stat, p_value, _ = modified_diebold_mariano_test(errors1, errors2)\n",
    "                \n",
    "                results.append({\n",
    "                    'Modelo': model,\n",
    "                    'Tamaño_1': n1,\n",
    "                    'Tamaño_2': n2,\n",
    "                    'ECRPS_Promedio_1': ecrps1,\n",
    "                    'ECRPS_Promedio_2': ecrps2,\n",
    "                    'Mejora_%': mejora_relativa,\n",
    "                    'DM_Statistic': dm_stat,\n",
    "                    'p_value': p_value\n",
    "                })\n",
    "                \n",
    "                p_values_list.append(p_value)\n",
    "    \n",
    "    # PASO 2: Aplicar corrección de Bonferroni\n",
    "    n_comparisons = len(p_values_list)\n",
    "    alpha_bonferroni = alpha / n_comparisons\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"CORRECCIÓN DE BONFERRONI - {suffix}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Número total de comparaciones: {n_comparisons}\")\n",
    "    print(f\"α nominal: {alpha}\")\n",
    "    print(f\"α corregido (Bonferroni): {alpha_bonferroni:.6f}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # PASO 3: Clasificar significancia con y sin corrección\n",
    "    for i, result in enumerate(results):\n",
    "        p_val = result['p_value']\n",
    "        \n",
    "        # Significancia sin corrección\n",
    "        if p_val < 0.01:\n",
    "            sig_sin_corr = 'Sí (p<0.01)'\n",
    "        elif p_val < 0.05:\n",
    "            sig_sin_corr = 'Sí (p<0.05)'\n",
    "        elif p_val < 0.1:\n",
    "            sig_sin_corr = 'Marginal (p<0.1)'\n",
    "        else:\n",
    "            sig_sin_corr = 'No'\n",
    "        \n",
    "        # Significancia con Bonferroni\n",
    "        if p_val < alpha_bonferroni:\n",
    "            sig_bonf = f'Sí (p<{alpha_bonferroni:.6f})'\n",
    "        else:\n",
    "            sig_bonf = 'No'\n",
    "        \n",
    "        result['Significativo_Sin_Corrección'] = sig_sin_corr\n",
    "        result['Significativo_Bonferroni'] = sig_bonf\n",
    "        result['Alpha_Bonferroni'] = alpha_bonferroni\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df.sort_values(['Modelo', 'Tamaño_1', 'Tamaño_2'])\n",
    "    \n",
    "    # PASO 4: Guardar en Excel con formato mejorado\n",
    "    excel_path = output_dir / f'dm_bonferroni_comparacion_{suffix}.xlsx'\n",
    "    with pd.ExcelWriter(excel_path, engine='xlsxwriter') as writer:\n",
    "        results_df.to_excel(writer, sheet_name='Comparaciones_DM_Bonferroni', index=False)\n",
    "        \n",
    "        workbook = writer.book\n",
    "        worksheet = writer.sheets['Comparaciones_DM_Bonferroni']\n",
    "        \n",
    "        # Formatos\n",
    "        format_header = workbook.add_format({\n",
    "            'bold': True,\n",
    "            'bg_color': '#4CAF50',\n",
    "            'font_color': 'white',\n",
    "            'align': 'center',\n",
    "            'valign': 'vcenter',\n",
    "            'border': 1\n",
    "        })\n",
    "        \n",
    "        format_number = workbook.add_format({'num_format': '0.0000', 'align': 'center'})\n",
    "        format_percent = workbook.add_format({'num_format': '0.00%', 'align': 'center'})\n",
    "        format_pvalue = workbook.add_format({'num_format': '0.000000', 'align': 'center'})\n",
    "        format_sig_yes = workbook.add_format({\n",
    "            'bg_color': '#90EE90',\n",
    "            'align': 'center',\n",
    "            'border': 1\n",
    "        })\n",
    "        format_sig_no = workbook.add_format({\n",
    "            'bg_color': '#FFB6C1',\n",
    "            'align': 'center',\n",
    "            'border': 1\n",
    "        })\n",
    "        \n",
    "        # Aplicar formato a encabezados\n",
    "        for col_num, value in enumerate(results_df.columns.values):\n",
    "            worksheet.write(0, col_num, value, format_header)\n",
    "        \n",
    "        # Ajustar anchos de columna\n",
    "        worksheet.set_column('A:A', 30)  # Modelo\n",
    "        worksheet.set_column('B:C', 12)  # Tamaños\n",
    "        worksheet.set_column('D:E', 15)  # ECRPS\n",
    "        worksheet.set_column('F:F', 12)  # Mejora%\n",
    "        worksheet.set_column('G:G', 13)  # DM Stat\n",
    "        worksheet.set_column('H:H', 12)  # p-value\n",
    "        worksheet.set_column('I:I', 22)  # Sig sin corrección\n",
    "        worksheet.set_column('J:J', 22)  # Sig con Bonferroni\n",
    "        worksheet.set_column('K:K', 18)  # Alpha Bonferroni\n",
    "        \n",
    "        # Aplicar formatos\n",
    "        for row_num in range(1, len(results_df) + 1):\n",
    "            worksheet.write_number(row_num, 3, results_df.iloc[row_num-1]['ECRPS_Promedio_1'], format_number)\n",
    "            worksheet.write_number(row_num, 4, results_df.iloc[row_num-1]['ECRPS_Promedio_2'], format_number)\n",
    "            worksheet.write_number(row_num, 5, results_df.iloc[row_num-1]['Mejora_%'] / 100, format_percent)\n",
    "            worksheet.write_number(row_num, 6, results_df.iloc[row_num-1]['DM_Statistic'], format_number)\n",
    "            worksheet.write_number(row_num, 7, results_df.iloc[row_num-1]['p_value'], format_pvalue)\n",
    "            worksheet.write_number(row_num, 10, alpha_bonferroni, format_pvalue)\n",
    "            \n",
    "            # Formato condicional para significancia Bonferroni\n",
    "            sig_bonf = results_df.iloc[row_num-1]['Significativo_Bonferroni']\n",
    "            if sig_bonf.startswith('Sí'):\n",
    "                worksheet.write(row_num, 9, sig_bonf, format_sig_yes)\n",
    "            else:\n",
    "                worksheet.write(row_num, 9, sig_bonf, format_sig_no)\n",
    "        \n",
    "        # Agregar hoja de resumen\n",
    "        summary_data = {\n",
    "            'Métrica': [\n",
    "                'Total de comparaciones',\n",
    "                'α nominal',\n",
    "                'α corregido (Bonferroni)',\n",
    "                'Significativas sin corrección (p<0.05)',\n",
    "                'Significativas con Bonferroni',\n",
    "                '% Supervivencia post-Bonferroni'\n",
    "            ],\n",
    "            'Valor': [\n",
    "                n_comparisons,\n",
    "                alpha,\n",
    "                alpha_bonferroni,\n",
    "                len(results_df[results_df['p_value'] < 0.05]),\n",
    "                len(results_df[results_df['p_value'] < alpha_bonferroni]),\n",
    "                f\"{(len(results_df[results_df['p_value'] < alpha_bonferroni]) / len(results_df[results_df['p_value'] < 0.05]) * 100) if len(results_df[results_df['p_value'] < 0.05]) > 0 else 0:.2f}%\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "        summary_df.to_excel(writer, sheet_name='Resumen_Bonferroni', index=False)\n",
    "        \n",
    "        worksheet_summary = writer.sheets['Resumen_Bonferroni']\n",
    "        for col_num, value in enumerate(summary_df.columns.values):\n",
    "            worksheet_summary.write(0, col_num, value, format_header)\n",
    "        worksheet_summary.set_column('A:A', 40)\n",
    "        worksheet_summary.set_column('B:B', 25)\n",
    "    \n",
    "    print(f\"✓ Test DM con Bonferroni (Excel) generado: {suffix}\")\n",
    "    print(f\"  - {n_comparisons} comparaciones totales\")\n",
    "    print(f\"  - {len(results_df[results_df['p_value'] < 0.05])} significativas sin corrección (p<0.05)\")\n",
    "    print(f\"  - {len(results_df[results_df['p_value'] < alpha_bonferroni])} significativas con Bonferroni\\n\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# ====================================================================================\n",
    "# 5. GRÁFICA DE MEJORA RELATIVA\n",
    "# ====================================================================================\n",
    "\n",
    "def plot_relative_improvement(data, scenario_name=None):\n",
    "    \"\"\"\n",
    "    Mejora relativa (%) respecto al tamaño base (primer N_Total)\n",
    "    \"\"\"\n",
    "    if scenario_name:\n",
    "        data = data[data['ESCENARIO'] == scenario_name]\n",
    "        suffix = scenario_name.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        title = f'Mejora Relativa vs N={n_total_values[0]} - {scenario_name}'\n",
    "    else:\n",
    "        suffix = \"General\"\n",
    "        title = f'Mejora Relativa vs N={n_total_values[0]} - Todos los Escenarios'\n",
    "    \n",
    "    baseline = n_total_values[0]\n",
    "    improvements = {}\n",
    "    \n",
    "    for model in model_cols:\n",
    "        base_perf = data[data['N_Total'] == baseline][model].mean()\n",
    "        model_impr = []\n",
    "        for nt in n_total_values:\n",
    "            current = data[data['N_Total'] == nt][model].mean()\n",
    "            improvement = ((base_perf - current) / base_perf) * 100 if base_perf != 0 else 0\n",
    "            model_impr.append(improvement)\n",
    "        improvements[model] = model_impr\n",
    "    \n",
    "    # Guardar datos\n",
    "    improvements_df = pd.DataFrame(improvements, index=n_total_values)\n",
    "    improvements_df.index.name = 'N_Total'\n",
    "    improvements_df.to_excel(output_dir / f'mejora_relativa_{suffix}.xlsx')\n",
    "    \n",
    "    # Graficar\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    for model, values in improvements.items():\n",
    "        plt.plot(n_total_values, values, marker='o', label=model, \n",
    "                color=MODEL_COLORS[model], linewidth=2.5, markersize=8)\n",
    "    \n",
    "    plt.axhline(y=0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "    plt.title(title, fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('N_Total', fontsize=12)\n",
    "    plt.ylabel('Mejora Relativa (%)', fontsize=12)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)\n",
    "    plt.grid(True, alpha=0.3, linestyle=':', linewidth=0.8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / f'mejora_relativa_{suffix}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"✓ Mejora relativa generada: {suffix}\")\n",
    "\n",
    "# ====================================================================================\n",
    "# 6. EJECUCIÓN PRINCIPAL\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SIMULACIÓN 3: EFECTOS DEL TAMAÑO MUESTRAL ABSOLUTO\")\n",
    "print(\"CON TEST DIEBOLD-MARIANO MODIFICADO Y CORRECCIÓN DE BONFERRONI\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "print(f\"Modelos evaluados: {len(model_cols)}\")\n",
    "print(f\"Tamaños muestrales: {n_total_values}\")\n",
    "print(f\"Escenarios: {list(escenarios)}\\n\")\n",
    "\n",
    "# 1. HEATMAPS\n",
    "print(\"=\"*80)\n",
    "print(\"1. GENERANDO HEATMAPS: Z-scores por Modelo\")\n",
    "print(\"=\"*80)\n",
    "plot_heatmap_zscores_models_vs_ntotal(df)\n",
    "for scen in escenarios:\n",
    "    plot_heatmap_zscores_models_vs_ntotal(df, scen)\n",
    "print()\n",
    "\n",
    "# 2. TEST DM CON BONFERRONI\n",
    "print(\"=\"*80)\n",
    "print(\"2. TEST DM CON CORRECCIÓN DE BONFERRONI\")\n",
    "print(\"=\"*80)\n",
    "dm_results_general = dm_test_all_sizes_excel(df)\n",
    "for scen in escenarios:\n",
    "    dm_test_all_sizes_excel(df, scen)\n",
    "print()\n",
    "\n",
    "# 3. MEJORA RELATIVA\n",
    "print(\"=\"*80)\n",
    "print(\"3. GRÁFICAS DE MEJORA RELATIVA\")\n",
    "print(\"=\"*80)\n",
    "plot_relative_improvement(df)\n",
    "for scen in escenarios:\n",
    "    plot_relative_improvement(df, scen)\n",
    "print()\n",
    "\n",
    "# ====================================================================================\n",
    "# 7. RESUMEN EJECUTIVO CON BONFERRONI\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"RESUMEN EJECUTIVO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Mejor modelo por tamaño\n",
    "print(\"\\nMejor modelo por tamaño muestral (menor ECRPS promedio):\")\n",
    "print(\"-\" * 60)\n",
    "for nt in n_total_values:\n",
    "    data_nt = df[df['N_Total'] == nt]\n",
    "    best_model = None\n",
    "    best_ecrps = float('inf')\n",
    "    for model in model_cols:\n",
    "        ecrps = data_nt[model].mean()\n",
    "        if ecrps < best_ecrps:\n",
    "            best_ecrps = ecrps\n",
    "            best_model = model\n",
    "    print(f\"  N={nt:4d}: {best_model:30s} (ECRPS = {best_ecrps:.4f})\")\n",
    "\n",
    "# Análisis de mejoras significativas con Bonferroni\n",
    "print(f\"\\nComparaciones N={n_total_values[0]} vs N={n_total_values[-1]} (CON BONFERRONI):\")\n",
    "print(\"-\" * 60)\n",
    "comparacion_extremos = dm_results_general[\n",
    "    (dm_results_general['Tamaño_1'] == n_total_values[0]) & \n",
    "    (dm_results_general['Tamaño_2'] == n_total_values[-1])\n",
    "]\n",
    "comparacion_extremos = comparacion_extremos.sort_values('Mejora_%', ascending=False)\n",
    "\n",
    "# Significativas con Bonferroni\n",
    "sig_bonf = comparacion_extremos[comparacion_extremos['Significativo_Bonferroni'].str.startswith('Sí')]\n",
    "print(f\"\\nModelos con mejoras significativas (post-Bonferroni): {len(sig_bonf)}\")\n",
    "if len(sig_bonf) > 0:\n",
    "    print(\"Top 5 mejoras significativas (Bonferroni):\")\n",
    "    for _, row in sig_bonf.head(5).iterrows():\n",
    "        print(f\"  {row['Modelo']:30s}: {row['Mejora_%']:6.2f}% - {row['Significativo_Bonferroni']}\")\n",
    "else:\n",
    "    print(\"  No hay mejoras significativas tras corrección de Bonferroni\")\n",
    "\n",
    "print(\"\\nTop 5 mayores mejoras (sin considerar Bonferroni):\")\n",
    "for _, row in comparacion_extremos.head(5).iterrows():\n",
    "    print(f\"  {row['Modelo']:30s}: {row['Mejora_%']:6.2f}% - Sin corr: {row['Significativo_Sin_Corrección']} | Bonf: {row['Significativo_Bonferroni']}\")\n",
    "\n",
    "print(\"\\nMenores mejoras o empeoramientos:\")\n",
    "for _, row in comparacion_extremos.tail(5).iterrows():\n",
    "    print(f\"  {row['Modelo']:30s}: {row['Mejora_%']:6.2f}% - Sin corr: {row['Significativo_Sin_Corrección']} | Bonf: {row['Significativo_Bonferroni']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANÁLISIS COMPLETADO EXITOSAMENTE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Resultados guardados en: {output_dir}\")\n",
    "print(f\"\\nArchivos generados:\")\n",
    "print(f\"  - 4 Heatmaps con Z-scores (1 general + 3 por escenario)\")\n",
    "print(f\"  - 4 Archivos Excel con Test DM y Bonferroni (1 general + 3 por escenario)\")\n",
    "print(f\"  - 4 Gráficas de mejora relativa (1 general + 3 por escenario)\")\n",
    "print(f\"  - Cada Excel incluye hoja de resumen con estadísticas de Bonferroni\")\n",
    "print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0a2b92",
   "metadata": {},
   "source": [
    "## Analisis proporciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52209586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SIMULACIÓN 4: PROPORCIONES DE CALIBRACIÓN (N=240 FIJO)\n",
      "CON TEST DIEBOLD-MARIANO MODIFICADO Y CORRECCIÓN DE BONFERRONI\n",
      "================================================================================\n",
      "\n",
      "Modelos evaluados: 9\n",
      "Proporciones: [np.int64(10), np.int64(20), np.int64(30), np.int64(40), np.int64(50)]\n",
      "Escenarios: ['Lineal Estacionario (ARMA)', 'Lineal No Estacionario (ARIMA)', 'No Lineal Estacionario (SETAR)']\n",
      "\n",
      "================================================================================\n",
      "1. GENERANDO HEATMAPS: Z-scores por Modelo\n",
      "================================================================================\n",
      "✓ Heatmap Z-scores generado: General\n",
      "✓ Heatmap Z-scores generado: Lineal_Estacionario_ARMA\n",
      "✓ Heatmap Z-scores generado: Lineal_No_Estacionario_ARIMA\n",
      "✓ Heatmap Z-scores generado: No_Lineal_Estacionario_SETAR\n",
      "\n",
      "================================================================================\n",
      "2. TEST DM CON CORRECCIÓN DE BONFERRONI\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "CORRECCIÓN DE BONFERRONI - General\n",
      "================================================================================\n",
      "Número de modelos: 9\n",
      "Comparaciones por modelo: 10\n",
      "Total de comparaciones: 90\n",
      "α nominal: 0.05\n",
      "α corregido (Bonferroni): 0.00055556\n",
      "================================================================================\n",
      "\n",
      "✓ Test DM con Bonferroni (Excel) generado: General\n",
      "  - 90 comparaciones totales\n",
      "  - 2 significativas sin corrección (p<0.05)\n",
      "  - 0 significativas con Bonferroni\n",
      "  - 0.00% tasa de supervivencia\n",
      "\n",
      "\n",
      "================================================================================\n",
      "CORRECCIÓN DE BONFERRONI - Lineal_Estacionario_ARMA\n",
      "================================================================================\n",
      "Número de modelos: 9\n",
      "Comparaciones por modelo: 10\n",
      "Total de comparaciones: 90\n",
      "α nominal: 0.05\n",
      "α corregido (Bonferroni): 0.00055556\n",
      "================================================================================\n",
      "\n",
      "✓ Test DM con Bonferroni (Excel) generado: Lineal_Estacionario_ARMA\n",
      "  - 90 comparaciones totales\n",
      "  - 0 significativas sin corrección (p<0.05)\n",
      "  - 0 significativas con Bonferroni\n",
      "  - 0.00% tasa de supervivencia\n",
      "\n",
      "\n",
      "================================================================================\n",
      "CORRECCIÓN DE BONFERRONI - Lineal_No_Estacionario_ARIMA\n",
      "================================================================================\n",
      "Número de modelos: 9\n",
      "Comparaciones por modelo: 10\n",
      "Total de comparaciones: 90\n",
      "α nominal: 0.05\n",
      "α corregido (Bonferroni): 0.00055556\n",
      "================================================================================\n",
      "\n",
      "✓ Test DM con Bonferroni (Excel) generado: Lineal_No_Estacionario_ARIMA\n",
      "  - 90 comparaciones totales\n",
      "  - 6 significativas sin corrección (p<0.05)\n",
      "  - 0 significativas con Bonferroni\n",
      "  - 0.00% tasa de supervivencia\n",
      "\n",
      "\n",
      "================================================================================\n",
      "CORRECCIÓN DE BONFERRONI - No_Lineal_Estacionario_SETAR\n",
      "================================================================================\n",
      "Número de modelos: 9\n",
      "Comparaciones por modelo: 10\n",
      "Total de comparaciones: 90\n",
      "α nominal: 0.05\n",
      "α corregido (Bonferroni): 0.00055556\n",
      "================================================================================\n",
      "\n",
      "✓ Test DM con Bonferroni (Excel) generado: No_Lineal_Estacionario_SETAR\n",
      "  - 90 comparaciones totales\n",
      "  - 3 significativas sin corrección (p<0.05)\n",
      "  - 0 significativas con Bonferroni\n",
      "  - 0.00% tasa de supervivencia\n",
      "\n",
      "\n",
      "================================================================================\n",
      "3. GRÁFICAS DE EVOLUCIÓN POR PROPORCIÓN\n",
      "================================================================================\n",
      "✓ Evolución por proporción generada: General\n",
      "✓ Evolución por proporción generada: Lineal_Estacionario_ARMA\n",
      "✓ Evolución por proporción generada: Lineal_No_Estacionario_ARIMA\n",
      "✓ Evolución por proporción generada: No_Lineal_Estacionario_SETAR\n",
      "\n",
      "================================================================================\n",
      "4. ANÁLISIS DE PROPORCIÓN ÓPTIMA\n",
      "================================================================================\n",
      "✓ Análisis proporción óptima generado: General\n",
      "✓ Análisis proporción óptima generado: Lineal_Estacionario_ARMA\n",
      "✓ Análisis proporción óptima generado: Lineal_No_Estacionario_ARIMA\n",
      "✓ Análisis proporción óptima generado: No_Lineal_Estacionario_SETAR\n",
      "\n",
      "================================================================================\n",
      "5. ANÁLISIS DE SENSIBILIDAD\n",
      "================================================================================\n",
      "✓ Análisis de sensibilidad generado: General\n",
      "✓ Análisis de sensibilidad generado: Lineal_Estacionario_ARMA\n",
      "✓ Análisis de sensibilidad generado: Lineal_No_Estacionario_ARIMA\n",
      "✓ Análisis de sensibilidad generado: No_Lineal_Estacionario_SETAR\n",
      "\n",
      "================================================================================\n",
      "RESUMEN EJECUTIVO\n",
      "================================================================================\n",
      "\n",
      "Proporción óptima más frecuente:\n",
      "------------------------------------------------------------\n",
      "  50%: 5 modelos\n",
      "  20%: 3 modelos\n",
      "  30%: 1 modelos\n",
      "\n",
      "Top 5 modelos con menor sensibilidad (más robustos):\n",
      "------------------------------------------------------------\n",
      "  Sieve Bootstrap               :   0.96% variación\n",
      "  LSPMW                         :   2.08% variación\n",
      "  LSPM                          :   2.11% variación\n",
      "  Block Bootstrapping           :  15.33% variación\n",
      "  AREPD                         :  15.51% variación\n",
      "\n",
      "Top 5 modelos con mayor sensibilidad:\n",
      "------------------------------------------------------------\n",
      "  DeepAR                        :  39.95% variación\n",
      "  MCPS                          :  28.02% variación\n",
      "  AV-MCPS                       :  26.77% variación\n",
      "  EnCQR-LSTM                    :  17.41% variación\n",
      "  AREPD                         :  15.51% variación\n",
      "\n",
      "Análisis de Significancia Estadística (Bonferroni):\n",
      "------------------------------------------------------------\n",
      "\n",
      "Comparación 10% vs 50%:\n",
      "  α corregido (Bonferroni): 0.00055556\n",
      "\n",
      "  Modelos con diferencias significativas (post-Bonferroni): 0/9\n",
      "    No hay diferencias significativas tras corrección de Bonferroni\n",
      "\n",
      "  Comparación de tasas de significancia:\n",
      "    Sin corrección (p<0.05): 0/9 (0.0%)\n",
      "    Con Bonferroni: 0/9 (0.0%)\n",
      "\n",
      "  Resumen completo de comparaciones 10% vs 50%:\n",
      "  Modelo                          Mejora%      p-value Sin Corr.          Bonferroni          \n",
      "  ------------------------------------------------------------------------------------------\n",
      "  MCPS                              28.02     0.102602 No                 No                  \n",
      "  AV-MCPS                           26.77     0.166308 No                 No                  \n",
      "  DeepAR                            19.19     0.241714 No                 No                  \n",
      "  Block Bootstrapping               13.70     0.298616 No                 No                  \n",
      "  AREPD                             13.29     0.330861 No                 No                  \n",
      "  Sieve Bootstrap                    0.56     0.244366 No                 No                  \n",
      "  LSPM                              -0.77     0.462433 No                 No                  \n",
      "  LSPMW                             -1.41     0.191352 No                 No                  \n",
      "  EnCQR-LSTM                        -5.66     0.578160 No                 No                  \n",
      "\n",
      "================================================================================\n",
      "ANÁLISIS COMPLETADO EXITOSAMENTE\n",
      "================================================================================\n",
      "Resultados guardados en: Resultados_analisis\\Proporciones\n",
      "\n",
      "Archivos generados:\n",
      "  - 4 Heatmaps con Z-scores (1 general + 3 por escenario)\n",
      "  - 4 Archivos Excel con Test DM y Bonferroni (1 general + 3 por escenario)\n",
      "    * Cada Excel incluye hoja de resumen con estadísticas de Bonferroni\n",
      "  - 4 Gráficas de evolución (1 general + 3 por escenario)\n",
      "  - 4 Análisis de proporción óptima (1 general + 3 por escenario)\n",
      "  - 4 Análisis de sensibilidad (1 general + 3 por escenario)\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# ====================================================================================\n",
    "# 1. CONFIGURACIÓN Y PREPARACIÓN DE DATOS\n",
    "# ====================================================================================\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración de gráficas\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "# Rutas\n",
    "output_dir = Path(\"./Resultados_analisis/Proporciones\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Cargar datos\n",
    "try:\n",
    "    df = pd.read_excel(\"./datos/Simulacion/proporciones/resultados_PROPORCIONES_240_TODOS.xlsx\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: No se encontró el archivo Excel. Verifica la ruta.\")\n",
    "    exit()\n",
    "\n",
    "# Renombrar escenarios\n",
    "df['Tipo_Proceso'] = df['Tipo_Proceso'].replace({\n",
    "    \"ARMA\": \"Lineal Estacionario (ARMA)\",\n",
    "    \"ARIMA\": \"Lineal No Estacionario (ARIMA)\",\n",
    "    \"SETAR\": \"No Lineal Estacionario (SETAR)\"\n",
    "})\n",
    "\n",
    "# Limpiar Prop_Calib\n",
    "def clean_prop_calib(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    value_str = str(value).strip()\n",
    "    if '%' in value_str:\n",
    "        value_str = value_str.split('%')[0]\n",
    "    try:\n",
    "        value_num = float(value_str)\n",
    "        if value_num < 1:\n",
    "            return int(value_num * 100)\n",
    "        else:\n",
    "            return int(value_num)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "df['Prop_Calib_Pct'] = df['Prop_Calib'].apply(clean_prop_calib)\n",
    "df['Prop_Calib'] = df['Prop_Calib_Pct'] / 100\n",
    "\n",
    "# Limpiar Paso\n",
    "def clean_paso(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    value_str = str(value).strip()\n",
    "    import re\n",
    "    numbers = re.findall(r'\\d+', value_str)\n",
    "    if numbers:\n",
    "        return int(numbers[0])\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df['Paso'] = df['Paso'].apply(clean_paso)\n",
    "\n",
    "# Identificación de variables y modelos\n",
    "var_cols = ['Paso', 'Proceso', 'Distribución', 'Varianza', \n",
    "            'N_Train', 'N_Calib', 'Prop_Calib', 'Prop_Calib_Pct', 'Tipo_Proceso']\n",
    "model_cols = [col for col in df.columns if col not in var_cols and pd.api.types.is_numeric_dtype(df[col])]\n",
    "\n",
    "# Limpiar datos numéricos\n",
    "for col in ['N_Train', 'N_Calib', 'Varianza', 'Paso']:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "for model in model_cols:\n",
    "    df[model] = pd.to_numeric(df[model], errors='coerce')\n",
    "\n",
    "# Eliminar NaN\n",
    "critical_cols = ['Paso', 'Prop_Calib_Pct', 'N_Train', 'N_Calib'] + model_cols\n",
    "df = df.dropna(subset=critical_cols)\n",
    "\n",
    "prop_values = sorted(df['Prop_Calib_Pct'].unique())\n",
    "escenarios = df['Tipo_Proceso'].unique()\n",
    "\n",
    "# ====================================================================================\n",
    "# PALETA DE COLORES ÚNICA PARA MODELOS\n",
    "# ====================================================================================\n",
    "def generate_maximally_distinct_colors(n):\n",
    "    if n <= 10:\n",
    "        base_colors = plt.cm.tab10(np.linspace(0, 1, 10))\n",
    "        return base_colors[:n]\n",
    "    elif n <= 20:\n",
    "        base_colors = plt.cm.tab20(np.linspace(0, 1, 20))\n",
    "        return base_colors[:n]\n",
    "    else:\n",
    "        colors = []\n",
    "        tab20 = plt.cm.tab20(np.linspace(0, 1, 20))\n",
    "        colors.extend(tab20)\n",
    "        \n",
    "        if n > 20:\n",
    "            set3 = plt.cm.Set3(np.linspace(0, 1, 12))\n",
    "            colors.extend(set3)\n",
    "        \n",
    "        if n > 32:\n",
    "            paired = plt.cm.Paired(np.linspace(0, 1, 12))\n",
    "            colors.extend(paired)\n",
    "        \n",
    "        if n > 44:\n",
    "            remaining = n - len(colors)\n",
    "            hsv_colors = []\n",
    "            for i in range(remaining):\n",
    "                hue = (i * 0.618033988749895) % 1.0\n",
    "                saturation = 0.6 + (i % 3) * 0.15\n",
    "                value = 0.7 + (i % 2) * 0.2\n",
    "                rgb = plt.cm.hsv(hue)\n",
    "                hsv_colors.append(rgb)\n",
    "            colors.extend(hsv_colors)\n",
    "        \n",
    "        return np.array(colors[:n])\n",
    "\n",
    "MODEL_COLORS = dict(zip(model_cols, generate_maximally_distinct_colors(len(model_cols))))\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"SIMULACIÓN 4: PROPORCIONES DE CALIBRACIÓN (N=240 FIJO)\")\n",
    "print(f\"CON TEST DIEBOLD-MARIANO MODIFICADO Y CORRECCIÓN DE BONFERRONI\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nModelos evaluados: {len(model_cols)}\")\n",
    "print(f\"Proporciones: {prop_values}\")\n",
    "print(f\"Escenarios: {list(escenarios)}\\n\")\n",
    "\n",
    "# ====================================================================================\n",
    "# 2. TEST DIEBOLD-MARIANO MODIFICADO\n",
    "# ====================================================================================\n",
    "\n",
    "def modified_diebold_mariano_test(errors1, errors2, h=1):\n",
    "    \"\"\"Test Diebold-Mariano con fixed-smoothing asymptotics.\"\"\"\n",
    "    d = errors1 - errors2\n",
    "    d_bar = np.mean(d)\n",
    "    T = len(d)\n",
    "    if T < 2: \n",
    "        return np.nan, np.nan, np.nan\n",
    "    \n",
    "    u = d - d_bar\n",
    "    m = max(1, int(np.floor(T**(1/3))))\n",
    "    \n",
    "    from scipy.fft import fft\n",
    "    fft_u = fft(u)\n",
    "    periodogram = np.abs(fft_u)**2 / (2 * np.pi * T)\n",
    "    \n",
    "    if m >= len(periodogram) - 1: \n",
    "        m = len(periodogram) - 2\n",
    "    \n",
    "    sigma_hat_sq = 2 * np.pi * np.mean(periodogram[1:m+1])\n",
    "    if sigma_hat_sq <= 0: \n",
    "        sigma_hat_sq = np.var(d, ddof=1) / T\n",
    "    \n",
    "    dm_stat = np.sqrt(T) * d_bar / np.sqrt(sigma_hat_sq)\n",
    "    df_t = 2 * m\n",
    "    p_value = 2 * (1 - stats.t.cdf(abs(dm_stat), df_t))\n",
    "    \n",
    "    return dm_stat, p_value, d_bar\n",
    "\n",
    "# ====================================================================================\n",
    "# 3. HEATMAP: MODELOS VS PROPORCIONES (Z-SCORES)\n",
    "# ====================================================================================\n",
    "\n",
    "def plot_heatmap_zscores_models_vs_props(data, scenario_name=None):\n",
    "    \"\"\"Heatmap de Modelos vs Proporciones con Z-scores por modelo\"\"\"\n",
    "    if scenario_name:\n",
    "        data = data[data['Tipo_Proceso'] == scenario_name]\n",
    "        suffix = scenario_name.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        title = f'Z-scores de ECRPS: Modelos vs Proporción\\n{scenario_name}'\n",
    "    else:\n",
    "        suffix = \"General\"\n",
    "        title = 'Z-scores de ECRPS: Modelos vs Proporción\\nTodos los Escenarios'\n",
    "    \n",
    "    # Crear matriz de ECRPS promedio\n",
    "    ecrps_data = []\n",
    "    for model in model_cols:\n",
    "        row = []\n",
    "        for prop in prop_values:\n",
    "            ecrps_mean = data[data['Prop_Calib_Pct'] == prop][model].mean()\n",
    "            row.append(ecrps_mean)\n",
    "        ecrps_data.append(row)\n",
    "    \n",
    "    ecrps_df = pd.DataFrame(ecrps_data, \n",
    "                             index=model_cols, \n",
    "                             columns=[f'{p}%' for p in prop_values])\n",
    "    \n",
    "    # Calcular Z-scores POR MODELO (por fila)\n",
    "    zscore_df = ecrps_df.apply(lambda row: (row - row.mean()) / row.std() if row.std() > 0 else 0, axis=1)\n",
    "    \n",
    "    # Guardar datos\n",
    "    ecrps_df.to_excel(output_dir / f'heatmap_ecrps_{suffix}.xlsx')\n",
    "    zscore_df.to_excel(output_dir / f'heatmap_zscores_{suffix}.xlsx')\n",
    "    \n",
    "    # Graficar\n",
    "    plt.figure(figsize=(10, max(8, len(model_cols) * 0.4)))\n",
    "    sns.heatmap(zscore_df, annot=True, fmt='.2f', cmap='RdYlGn_r', \n",
    "                center=0, vmin=-2, vmax=2,\n",
    "                cbar_kws={'label': 'Z-score'},\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    plt.title(title, fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Proporción de Calibración', fontsize=12)\n",
    "    plt.ylabel('Modelo', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / f'heatmap_zscore_{suffix}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"✓ Heatmap Z-scores generado: {suffix}\")\n",
    "\n",
    "# ====================================================================================\n",
    "# 4. TEST DM CON BONFERRONI: COMPARACIÓN ENTRE PROPORCIONES (FORMATO EXCEL)\n",
    "# ====================================================================================\n",
    "\n",
    "def dm_test_all_props_excel(data, scenario_name=None, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Test DM comparando todos los pares de proporciones para cada modelo\n",
    "    CON CORRECCIÓN DE BONFERRONI\n",
    "    \"\"\"\n",
    "    if scenario_name:\n",
    "        data = data[data['Tipo_Proceso'] == scenario_name]\n",
    "        suffix = scenario_name.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "    else:\n",
    "        suffix = \"General\"\n",
    "    \n",
    "    results = []\n",
    "    p_values_list = []\n",
    "    \n",
    "    # Calcular número de comparaciones\n",
    "    n_props = len(prop_values)\n",
    "    n_comparisons_per_model = (n_props * (n_props - 1)) // 2\n",
    "    n_total_comparisons = len(model_cols) * n_comparisons_per_model\n",
    "    \n",
    "    # PASO 1: Realizar todos los tests y recopilar p-values\n",
    "    for model in model_cols:\n",
    "        for i, prop1 in enumerate(prop_values):\n",
    "            for prop2 in prop_values[i+1:]:\n",
    "                \n",
    "                errors1 = data[data['Prop_Calib_Pct'] == prop1][model].values\n",
    "                errors2 = data[data['Prop_Calib_Pct'] == prop2][model].values\n",
    "                \n",
    "                min_len = min(len(errors1), len(errors2))\n",
    "                errors1 = errors1[:min_len]\n",
    "                errors2 = errors2[:min_len]\n",
    "                \n",
    "                ecrps1 = errors1.mean()\n",
    "                ecrps2 = errors2.mean()\n",
    "                \n",
    "                mejora_absoluta = ecrps1 - ecrps2\n",
    "                mejora_relativa = (mejora_absoluta / ecrps1) * 100 if ecrps1 != 0 else 0\n",
    "                \n",
    "                dm_stat, p_value, _ = modified_diebold_mariano_test(errors1, errors2)\n",
    "                \n",
    "                results.append({\n",
    "                    'Modelo': model,\n",
    "                    'Proporcion_1_%': prop1,\n",
    "                    'Proporcion_2_%': prop2,\n",
    "                    'ECRPS_Promedio_1': ecrps1,\n",
    "                    'ECRPS_Promedio_2': ecrps2,\n",
    "                    'Mejora_%': mejora_relativa,\n",
    "                    'DM_Statistic': dm_stat,\n",
    "                    'p_value': p_value\n",
    "                })\n",
    "                \n",
    "                p_values_list.append(p_value)\n",
    "    \n",
    "    # PASO 2: Aplicar corrección de Bonferroni\n",
    "    alpha_bonferroni = alpha / n_total_comparisons\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"CORRECCIÓN DE BONFERRONI - {suffix}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Número de modelos: {len(model_cols)}\")\n",
    "    print(f\"Comparaciones por modelo: {n_comparisons_per_model}\")\n",
    "    print(f\"Total de comparaciones: {n_total_comparisons}\")\n",
    "    print(f\"α nominal: {alpha}\")\n",
    "    print(f\"α corregido (Bonferroni): {alpha_bonferroni:.8f}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # PASO 3: Clasificar significancia con y sin corrección\n",
    "    for i, result in enumerate(results):\n",
    "        p_val = result['p_value']\n",
    "        \n",
    "        # Significancia sin corrección\n",
    "        if p_val < 0.01:\n",
    "            sig_sin_corr = 'Sí (p<0.01)'\n",
    "        elif p_val < 0.05:\n",
    "            sig_sin_corr = 'Sí (p<0.05)'\n",
    "        elif p_val < 0.1:\n",
    "            sig_sin_corr = 'Marginal (p<0.1)'\n",
    "        else:\n",
    "            sig_sin_corr = 'No'\n",
    "        \n",
    "        # Significancia con Bonferroni\n",
    "        if p_val < alpha_bonferroni:\n",
    "            sig_bonf = f'Sí (p<{alpha_bonferroni:.8f})'\n",
    "        else:\n",
    "            sig_bonf = 'No'\n",
    "        \n",
    "        result['Significativo_Sin_Corrección'] = sig_sin_corr\n",
    "        result['Significativo_Bonferroni'] = sig_bonf\n",
    "        result['Alpha_Bonferroni'] = alpha_bonferroni\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df.sort_values(['Modelo', 'Proporcion_1_%', 'Proporcion_2_%'])\n",
    "    \n",
    "    # PASO 4: Guardar en Excel con formato mejorado\n",
    "    excel_path = output_dir / f'dm_bonferroni_proporciones_{suffix}.xlsx'\n",
    "    with pd.ExcelWriter(excel_path, engine='xlsxwriter') as writer:\n",
    "        results_df.to_excel(writer, sheet_name='Comparaciones_DM_Bonferroni', index=False)\n",
    "        \n",
    "        workbook = writer.book\n",
    "        worksheet = writer.sheets['Comparaciones_DM_Bonferroni']\n",
    "        \n",
    "        # Formatos\n",
    "        format_header = workbook.add_format({\n",
    "            'bold': True,\n",
    "            'bg_color': '#4CAF50',\n",
    "            'font_color': 'white',\n",
    "            'align': 'center',\n",
    "            'valign': 'vcenter',\n",
    "            'border': 1\n",
    "        })\n",
    "        \n",
    "        format_number = workbook.add_format({'num_format': '0.0000', 'align': 'center'})\n",
    "        format_percent = workbook.add_format({'num_format': '0.00%', 'align': 'center'})\n",
    "        format_pvalue = workbook.add_format({'num_format': '0.00000000', 'align': 'center'})\n",
    "        format_sig_yes = workbook.add_format({\n",
    "            'bg_color': '#90EE90',\n",
    "            'align': 'center',\n",
    "            'border': 1\n",
    "        })\n",
    "        format_sig_no = workbook.add_format({\n",
    "            'bg_color': '#FFB6C1',\n",
    "            'align': 'center',\n",
    "            'border': 1\n",
    "        })\n",
    "        \n",
    "        # Aplicar formato a encabezados\n",
    "        for col_num, value in enumerate(results_df.columns.values):\n",
    "            worksheet.write(0, col_num, value, format_header)\n",
    "        \n",
    "        # Ajustar anchos de columna\n",
    "        worksheet.set_column('A:A', 30)  # Modelo\n",
    "        worksheet.set_column('B:C', 15)  # Proporciones\n",
    "        worksheet.set_column('D:E', 18)  # ECRPS\n",
    "        worksheet.set_column('F:F', 12)  # Mejora%\n",
    "        worksheet.set_column('G:G', 13)  # DM Stat\n",
    "        worksheet.set_column('H:H', 14)  # p-value\n",
    "        worksheet.set_column('I:I', 22)  # Sig sin corrección\n",
    "        worksheet.set_column('J:J', 28)  # Sig con Bonferroni\n",
    "        worksheet.set_column('K:K', 18)  # Alpha Bonferroni\n",
    "        \n",
    "        # Aplicar formatos\n",
    "        for row_num in range(1, len(results_df) + 1):\n",
    "            worksheet.write_number(row_num, 3, results_df.iloc[row_num-1]['ECRPS_Promedio_1'], format_number)\n",
    "            worksheet.write_number(row_num, 4, results_df.iloc[row_num-1]['ECRPS_Promedio_2'], format_number)\n",
    "            worksheet.write_number(row_num, 5, results_df.iloc[row_num-1]['Mejora_%'] / 100, format_percent)\n",
    "            worksheet.write_number(row_num, 6, results_df.iloc[row_num-1]['DM_Statistic'], format_number)\n",
    "            worksheet.write_number(row_num, 7, results_df.iloc[row_num-1]['p_value'], format_pvalue)\n",
    "            worksheet.write_number(row_num, 10, alpha_bonferroni, format_pvalue)\n",
    "            \n",
    "            # Formato condicional para significancia Bonferroni\n",
    "            sig_bonf = results_df.iloc[row_num-1]['Significativo_Bonferroni']\n",
    "            if sig_bonf.startswith('Sí'):\n",
    "                worksheet.write(row_num, 9, sig_bonf, format_sig_yes)\n",
    "            else:\n",
    "                worksheet.write(row_num, 9, sig_bonf, format_sig_no)\n",
    "        \n",
    "        # Agregar hoja de resumen\n",
    "        sig_sin_corr = len(results_df[results_df['p_value'] < 0.05])\n",
    "        sig_con_bonf = len(results_df[results_df['p_value'] < alpha_bonferroni])\n",
    "        tasa_supervivencia = (sig_con_bonf / sig_sin_corr * 100) if sig_sin_corr > 0 else 0\n",
    "        \n",
    "        summary_data = {\n",
    "            'Métrica': [\n",
    "                'Número de modelos',\n",
    "                'Comparaciones por modelo',\n",
    "                'Total de comparaciones',\n",
    "                'α nominal',\n",
    "                'α corregido (Bonferroni)',\n",
    "                'Significativas sin corrección (p<0.05)',\n",
    "                'Significativas con Bonferroni',\n",
    "                '% Supervivencia post-Bonferroni'\n",
    "            ],\n",
    "            'Valor': [\n",
    "                len(model_cols),\n",
    "                n_comparisons_per_model,\n",
    "                n_total_comparisons,\n",
    "                alpha,\n",
    "                alpha_bonferroni,\n",
    "                sig_sin_corr,\n",
    "                sig_con_bonf,\n",
    "                f\"{tasa_supervivencia:.2f}%\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "        summary_df.to_excel(writer, sheet_name='Resumen_Bonferroni', index=False)\n",
    "        \n",
    "        worksheet_summary = writer.sheets['Resumen_Bonferroni']\n",
    "        for col_num, value in enumerate(summary_df.columns.values):\n",
    "            worksheet_summary.write(0, col_num, value, format_header)\n",
    "        worksheet_summary.set_column('A:A', 45)\n",
    "        worksheet_summary.set_column('B:B', 25)\n",
    "    \n",
    "    print(f\"✓ Test DM con Bonferroni (Excel) generado: {suffix}\")\n",
    "    print(f\"  - {n_total_comparisons} comparaciones totales\")\n",
    "    print(f\"  - {sig_sin_corr} significativas sin corrección (p<0.05)\")\n",
    "    print(f\"  - {sig_con_bonf} significativas con Bonferroni\")\n",
    "    print(f\"  - {tasa_supervivencia:.2f}% tasa de supervivencia\\n\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# ====================================================================================\n",
    "# 5. GRÁFICA DE EVOLUCIÓN POR PROPORCIÓN\n",
    "# ====================================================================================\n",
    "\n",
    "def plot_evolution_by_proportion(data, scenario_name=None):\n",
    "    \"\"\"Evolución del ECRPS de cada modelo a través de proporciones\"\"\"\n",
    "    if scenario_name:\n",
    "        data = data[data['Tipo_Proceso'] == scenario_name]\n",
    "        suffix = scenario_name.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        title = f'Evolución del ECRPS por Proporción\\n{scenario_name}'\n",
    "    else:\n",
    "        suffix = \"General\"\n",
    "        title = 'Evolución del ECRPS por Proporción\\nTodos los Escenarios'\n",
    "    \n",
    "    plt.figure(figsize=(12, 7))\n",
    "    for model in model_cols:\n",
    "        means = [data[data['Prop_Calib_Pct'] == p][model].mean() for p in prop_values]\n",
    "        plt.plot(prop_values, means, marker='o', label=model, \n",
    "                color=MODEL_COLORS[model], linewidth=2.5, markersize=8)\n",
    "    \n",
    "    plt.xlabel('Proporción de Calibración (%)', fontsize=12)\n",
    "    plt.ylabel('ECRPS Promedio', fontsize=12)\n",
    "    plt.title(title, fontsize=14, fontweight='bold')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)\n",
    "    plt.grid(True, alpha=0.3, linestyle=':', linewidth=0.8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / f'evolucion_proporciones_{suffix}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"✓ Evolución por proporción generada: {suffix}\")\n",
    "\n",
    "# ====================================================================================\n",
    "# 6. PROPORCIÓN ÓPTIMA POR MODELO\n",
    "# ====================================================================================\n",
    "\n",
    "def analyze_optimal_proportion(data, scenario_name=None):\n",
    "    \"\"\"Identifica la proporción óptima para cada modelo\"\"\"\n",
    "    if scenario_name:\n",
    "        data = data[data['Tipo_Proceso'] == scenario_name]\n",
    "        suffix = scenario_name.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        title = f'Proporción Óptima por Modelo\\n{scenario_name}'\n",
    "    else:\n",
    "        suffix = \"General\"\n",
    "        title = 'Proporción Óptima por Modelo\\nTodos los Escenarios'\n",
    "    \n",
    "    optimal_results = []\n",
    "    \n",
    "    for model in model_cols:\n",
    "        prop_means = {}\n",
    "        for prop in prop_values:\n",
    "            prop_means[prop] = data[data['Prop_Calib_Pct'] == prop][model].mean()\n",
    "        \n",
    "        optimal_prop = min(prop_means, key=prop_means.get)\n",
    "        worst_prop = max(prop_means, key=prop_means.get)\n",
    "        \n",
    "        optimal_results.append({\n",
    "            'Modelo': model,\n",
    "            'Proporcion_Optima_%': optimal_prop,\n",
    "            'ECRPS_Optimo': prop_means[optimal_prop],\n",
    "            'Proporcion_Peor_%': worst_prop,\n",
    "            'ECRPS_Peor': prop_means[worst_prop],\n",
    "            'Diferencia_%': ((prop_means[worst_prop] - prop_means[optimal_prop]) / prop_means[optimal_prop]) * 100\n",
    "        })\n",
    "    \n",
    "    optimal_df = pd.DataFrame(optimal_results).sort_values('ECRPS_Optimo')\n",
    "    \n",
    "    # Gráfica\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    y_pos = np.arange(len(optimal_df))\n",
    "    colors = [MODEL_COLORS[m] for m in optimal_df['Modelo']]\n",
    "    \n",
    "    bars = ax.barh(y_pos, optimal_df['ECRPS_Optimo'], \n",
    "                   color=colors, alpha=0.85, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(optimal_df['Modelo'])\n",
    "    ax.set_xlabel('ECRPS en Proporción Óptima', fontsize=11, fontweight='bold')\n",
    "    ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Anotar proporción óptima\n",
    "    for i, (bar, (_, row)) in enumerate(zip(bars, optimal_df.iterrows())):\n",
    "        width = bar.get_width()\n",
    "        ax.text(width + width*0.01, bar.get_y() + bar.get_height()/2.,\n",
    "               f\"{row['Proporcion_Optima_%']}%\",\n",
    "               ha='left', va='center', fontsize=9, fontweight='bold',\n",
    "               bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / f'proporcion_optima_{suffix}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Guardar tabla\n",
    "    optimal_df.to_excel(output_dir / f'proporcion_optima_{suffix}.xlsx', index=False)\n",
    "    \n",
    "    print(f\"✓ Análisis proporción óptima generado: {suffix}\")\n",
    "    \n",
    "    return optimal_df\n",
    "\n",
    "# ====================================================================================\n",
    "# 7. ANÁLISIS DE SENSIBILIDAD A LA PROPORCIÓN\n",
    "# ====================================================================================\n",
    "\n",
    "def analyze_sensitivity_to_proportion(data, scenario_name=None):\n",
    "    \"\"\"Identifica qué modelos son más sensibles a cambios en la proporción\"\"\"\n",
    "    if scenario_name:\n",
    "        data = data[data['Tipo_Proceso'] == scenario_name]\n",
    "        suffix = scenario_name.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        title = f'Sensibilidad a Proporción de Calibración\\n{scenario_name}'\n",
    "    else:\n",
    "        suffix = \"General\"\n",
    "        title = 'Sensibilidad a Proporción de Calibración\\nTodos los Escenarios'\n",
    "    \n",
    "    sensitivity_results = []\n",
    "    \n",
    "    for model in model_cols:\n",
    "        means_by_prop = []\n",
    "        for prop in prop_values:\n",
    "            means_by_prop.append(data[data['Prop_Calib_Pct'] == prop][model].mean())\n",
    "        \n",
    "        means_array = np.array(means_by_prop)\n",
    "        \n",
    "        # Métricas de sensibilidad\n",
    "        rango_absoluto = means_array.max() - means_array.min()\n",
    "        rango_relativo = (rango_absoluto / means_array[0]) * 100\n",
    "        volatilidad = np.std(means_array)\n",
    "        cv = volatilidad / np.mean(means_array)\n",
    "        \n",
    "        # Correlación con proporción\n",
    "        from scipy.stats import spearmanr\n",
    "        corr, p_val = spearmanr(prop_values, means_array)\n",
    "        \n",
    "        sensitivity_results.append({\n",
    "            'Modelo': model,\n",
    "            'Rango_Absoluto': rango_absoluto,\n",
    "            'Rango_Relativo_%': rango_relativo,\n",
    "            'Volatilidad': volatilidad,\n",
    "            'CV': cv,\n",
    "            'Correlacion_Spearman': corr,\n",
    "            'P_value': p_val,\n",
    "            'ECRPS_Medio': means_array.mean()\n",
    "        })\n",
    "    \n",
    "    sensitivity_df = pd.DataFrame(sensitivity_results).sort_values('Rango_Relativo_%', ascending=False)\n",
    "    \n",
    "    # Gráfica\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    colors = plt.cm.RdYlGn_r(sensitivity_df['Rango_Relativo_%'] / sensitivity_df['Rango_Relativo_%'].max())\n",
    "    bars = ax.barh(sensitivity_df['Modelo'], sensitivity_df['Rango_Relativo_%'],\n",
    "                  color=colors, alpha=0.85, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    ax.set_xlabel('Variación Relativa Máxima (%)', fontsize=11, fontweight='bold')\n",
    "    ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    for bar, (_, row) in zip(bars, sensitivity_df.iterrows()):\n",
    "        width = bar.get_width()\n",
    "        ax.text(width + 0.5, bar.get_y() + bar.get_height()/2.,\n",
    "               f\"{row['Rango_Relativo_%']:.2f}%\",\n",
    "               ha='left', va='center', fontsize=8, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / f'sensibilidad_proporcion_{suffix}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    sensitivity_df.to_excel(output_dir / f'sensibilidad_proporcion_{suffix}.xlsx', index=False)\n",
    "    \n",
    "    print(f\"✓ Análisis de sensibilidad generado: {suffix}\")\n",
    "    \n",
    "    return sensitivity_df\n",
    "\n",
    "# ====================================================================================\n",
    "# 8. EJECUCIÓN PRINCIPAL\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"1. GENERANDO HEATMAPS: Z-scores por Modelo\")\n",
    "print(\"=\"*80)\n",
    "plot_heatmap_zscores_models_vs_props(df)\n",
    "for scen in escenarios:\n",
    "    plot_heatmap_zscores_models_vs_props(df, scen)\n",
    "print()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"2. TEST DM CON CORRECCIÓN DE BONFERRONI\")\n",
    "print(\"=\"*80)\n",
    "dm_results_general = dm_test_all_props_excel(df)\n",
    "for scen in escenarios:\n",
    "    dm_test_all_props_excel(df, scen)\n",
    "print()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"3. GRÁFICAS DE EVOLUCIÓN POR PROPORCIÓN\")\n",
    "print(\"=\"*80)\n",
    "plot_evolution_by_proportion(df)\n",
    "for scen in escenarios:\n",
    "    plot_evolution_by_proportion(df, scen)\n",
    "print()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"4. ANÁLISIS DE PROPORCIÓN ÓPTIMA\")\n",
    "print(\"=\"*80)\n",
    "optimal_general = analyze_optimal_proportion(df)\n",
    "for scen in escenarios:\n",
    "    analyze_optimal_proportion(df, scen)\n",
    "print()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"5. ANÁLISIS DE SENSIBILIDAD\")\n",
    "print(\"=\"*80)\n",
    "sensitivity_general = analyze_sensitivity_to_proportion(df)\n",
    "for scen in escenarios:\n",
    "    analyze_sensitivity_to_proportion(df, scen)\n",
    "print()\n",
    "\n",
    "# ====================================================================================\n",
    "# 9. RESUMEN EJECUTIVO CON BONFERRONI\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"RESUMEN EJECUTIVO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nProporción óptima más frecuente:\")\n",
    "print(\"-\" * 60)\n",
    "optimal_counts = optimal_general['Proporcion_Optima_%'].value_counts()\n",
    "for prop, count in optimal_counts.items():\n",
    "    print(f\"  {prop}%: {count} modelos\")\n",
    "\n",
    "print(f\"\\nTop 5 modelos con menor sensibilidad (más robustos):\")\n",
    "print(\"-\" * 60)\n",
    "top_5_robust = sensitivity_general.nsmallest(5, 'Rango_Relativo_%')\n",
    "for _, row in top_5_robust.iterrows():\n",
    "    print(f\"  {row['Modelo']:30s}: {row['Rango_Relativo_%']:6.2f}% variación\")\n",
    "\n",
    "print(f\"\\nTop 5 modelos con mayor sensibilidad:\")\n",
    "print(\"-\" * 60)\n",
    "top_5_sensitive = sensitivity_general.nlargest(5, 'Rango_Relativo_%')\n",
    "for _, row in top_5_sensitive.iterrows():\n",
    "    print(f\"  {row['Modelo']:30s}: {row['Rango_Relativo_%']:6.2f}% variación\")\n",
    "\n",
    "# Análisis de significancia con Bonferroni\n",
    "print(f\"\\nAnálisis de Significancia Estadística (Bonferroni):\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Calcular proporciones extremas\n",
    "prop_min = min(prop_values)\n",
    "prop_max = max(prop_values)\n",
    "\n",
    "# Filtrar comparaciones extremas\n",
    "comparaciones_extremas = dm_results_general[\n",
    "    (dm_results_general['Proporcion_1_%'] == prop_min) & \n",
    "    (dm_results_general['Proporcion_2_%'] == prop_max)\n",
    "]\n",
    "\n",
    "if len(comparaciones_extremas) > 0:\n",
    "    # Calcular alpha bonferroni\n",
    "    n_comparisons = len(dm_results_general)\n",
    "    alpha_bonf = 0.05 / n_comparisons\n",
    "    \n",
    "    print(f\"\\nComparación {prop_min}% vs {prop_max}%:\")\n",
    "    print(f\"  α corregido (Bonferroni): {alpha_bonf:.8f}\")\n",
    "    \n",
    "    # Significativas con Bonferroni\n",
    "    sig_bonf = comparaciones_extremas[\n",
    "        comparaciones_extremas['Significativo_Bonferroni'].str.startswith('Sí')\n",
    "    ].sort_values('Mejora_%', ascending=False)\n",
    "    \n",
    "    print(f\"\\n  Modelos con diferencias significativas (post-Bonferroni): {len(sig_bonf)}/{len(comparaciones_extremas)}\")\n",
    "    \n",
    "    if len(sig_bonf) > 0:\n",
    "        print(f\"\\n  Top 5 mayores mejoras significativas (Bonferroni):\")\n",
    "        for _, row in sig_bonf.head(5).iterrows():\n",
    "            print(f\"    {row['Modelo']:30s}: {row['Mejora_%']:6.2f}% - {row['Significativo_Bonferroni']}\")\n",
    "    else:\n",
    "        print(\"    No hay diferencias significativas tras corrección de Bonferroni\")\n",
    "    \n",
    "    # Comparación sin corrección vs con corrección\n",
    "    sig_sin_corr = comparaciones_extremas[\n",
    "        comparaciones_extremas['p_value'] < 0.05\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\n  Comparación de tasas de significancia:\")\n",
    "    print(f\"    Sin corrección (p<0.05): {len(sig_sin_corr)}/{len(comparaciones_extremas)} ({len(sig_sin_corr)/len(comparaciones_extremas)*100:.1f}%)\")\n",
    "    print(f\"    Con Bonferroni: {len(sig_bonf)}/{len(comparaciones_extremas)} ({len(sig_bonf)/len(comparaciones_extremas)*100:.1f}%)\")\n",
    "    \n",
    "    if len(sig_sin_corr) > 0:\n",
    "        tasa_supervivencia = len(sig_bonf) / len(sig_sin_corr) * 100\n",
    "        print(f\"    Tasa de supervivencia: {tasa_supervivencia:.1f}%\")\n",
    "    \n",
    "    # Mostrar todos los resultados con ambas clasificaciones\n",
    "    print(f\"\\n  Resumen completo de comparaciones {prop_min}% vs {prop_max}%:\")\n",
    "    print(f\"  {'Modelo':<30} {'Mejora%':>8} {'p-value':>12} {'Sin Corr.':<18} {'Bonferroni':<20}\")\n",
    "    print(\"  \" + \"-\" * 90)\n",
    "    \n",
    "    for _, row in comparaciones_extremas.sort_values('Mejora_%', ascending=False).iterrows():\n",
    "        print(f\"  {row['Modelo']:<30} {row['Mejora_%']:>8.2f} {row['p_value']:>12.6f} \"\n",
    "              f\"{row['Significativo_Sin_Corrección']:<18} {row['Significativo_Bonferroni']:<20}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANÁLISIS COMPLETADO EXITOSAMENTE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Resultados guardados en: {output_dir}\")\n",
    "print(f\"\\nArchivos generados:\")\n",
    "print(f\"  - 4 Heatmaps con Z-scores (1 general + 3 por escenario)\")\n",
    "print(f\"  - 4 Archivos Excel con Test DM y Bonferroni (1 general + 3 por escenario)\")\n",
    "print(f\"    * Cada Excel incluye hoja de resumen con estadísticas de Bonferroni\")\n",
    "print(f\"  - 4 Gráficas de evolución (1 general + 3 por escenario)\")\n",
    "print(f\"  - 4 Análisis de proporción óptima (1 general + 3 por escenario)\")\n",
    "print(f\"  - 4 Análisis de sensibilidad (1 general + 3 por escenario)\")\n",
    "print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e77a51",
   "metadata": {},
   "source": [
    "# Analisis Simulacion h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fb751e",
   "metadata": {},
   "source": [
    "### Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b7c750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tabla Comparativa de Modelos (Basada en MEDIA) ---\n",
      "         Modelo  General     ARMA    ARIMA    SETAR Mejor_Escenario\n",
      "Sieve Bootstrap 1.261013 0.793567 2.405825 0.583647           SETAR\n",
      "           LSPM 1.423114 0.863196 2.811590 0.594555           SETAR\n",
      "           MCPS 2.104899 0.881556 4.823525 0.609616           SETAR\n",
      "         DeepAR 3.126949 0.833898 7.970984 0.575966           SETAR\n",
      "\n",
      "--- Tabla Comparativa de Modelos (Basada en MEDIANA) ---\n",
      "         Modelo  General     ARMA    ARIMA    SETAR Mejor_Escenario\n",
      "Sieve Bootstrap 0.722924 0.622694 1.688908 0.497262           SETAR\n",
      "           LSPM 0.786162 0.661725 1.946193 0.502726           SETAR\n",
      "           MCPS 0.847082 0.659495 2.883693 0.522937           SETAR\n",
      "         DeepAR 0.821647 0.635593 3.456565 0.473015           SETAR\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Leer los archivos\n",
    "arma_df = pd.read_excel(\"./datos/Simulacion_h/resultados_140_trayectorias_ARMA_FINAL.xlsx\")\n",
    "arima_df = pd.read_excel(\"./datos/Simulacion_h/resultados_140_trayectorias_ARIMA_FINAL.xlsx\")\n",
    "setar_df = pd.read_excel(\"./datos/Simulacion_h/resultados_140_trayectorias_SETAR_FINAL.xlsx\")\n",
    "LSPMW_df = pd.read_excel(\"./datos/Simulacion_h/resultados_LSPMW_todos_procesos.xlsx\")\n",
    "\n",
    "\n",
    "# 2. Asignar la columna ESCENARIO a cada dataframe\n",
    "arma_df['ESCENARIO'] = \"Lineal Estacionario\"\n",
    "arima_df['ESCENARIO'] = \"Lineal No estacionario\"\n",
    "setar_df['ESCENARIO'] = \"No lineal Estacionario\"\n",
    "\n",
    "# 3. Juntarlos uno bajo el otro (Concatenar)\n",
    "df_total = pd.concat([arma_df, arima_df, setar_df], ignore_index=True)\n",
    "\n",
    "# Seleccionar solo las columnas requeridas\n",
    "columnas_deseadas = [\n",
    "    \"Paso\", \"Config\", \"Dist\", \"Var\",  \n",
    "    \"Sieve Bootstrap\", \"LSPM\",  \"MCPS\", \n",
    "    \"DeepAR\", \"ESCENARIO\"\n",
    "]\n",
    "df_total = df_total[columnas_deseadas]\n",
    "\n",
    "# Definimos cuáles son las columnas que representan a los modelos predictivos\n",
    "modelos = [\n",
    "    \"Sieve Bootstrap\", \"LSPM\",  \"MCPS\", \n",
    "    \"DeepAR\"\n",
    "]\n",
    "\n",
    "# 4. Guardar el dataframe consolidado\n",
    "df_total.to_excel(\"./datos/Simulacion_h/dataframe_consolidado.xlsx\", index=False)\n",
    "\n",
    "# 5. Generar y mostrar las tablas (Media y Mediana)\n",
    "metricas = {'MEDIA': 'mean', 'MEDIANA': 'median'}\n",
    "\n",
    "for nombre_metrica, funcion in metricas.items():\n",
    "    # Calculamos el valor general según la métrica (mean o median)\n",
    "    if funcion == 'mean':\n",
    "        resumen_general = df_total[modelos].mean()\n",
    "        resumen_escenarios = df_total.groupby('ESCENARIO')[modelos].mean().T\n",
    "    else:\n",
    "        resumen_general = df_total[modelos].median()\n",
    "        resumen_escenarios = df_total.groupby('ESCENARIO')[modelos].median().T\n",
    "\n",
    "    # Construimos la tabla final para esta métrica\n",
    "    tabla_resumen = pd.DataFrame(index=modelos)\n",
    "    tabla_resumen['General'] = resumen_general\n",
    "    tabla_resumen['ARMA'] = resumen_escenarios['Lineal Estacionario']\n",
    "    tabla_resumen['ARIMA'] = resumen_escenarios['Lineal No estacionario']\n",
    "    tabla_resumen['SETAR'] = resumen_escenarios['No lineal Estacionario']\n",
    "\n",
    "    # Determinar el Mejor_Escenario (valor mínimo entre los tres escenarios)\n",
    "    escenarios_cols = ['ARMA', 'ARIMA', 'SETAR']\n",
    "    tabla_resumen['Mejor_Escenario'] = tabla_resumen[escenarios_cols].idxmin(axis=1)\n",
    "\n",
    "    # Imprimir resultado\n",
    "    print(f\"\\n--- Tabla Comparativa de Modelos (Basada en {nombre_metrica}) ---\")\n",
    "    print(tabla_resumen.reset_index().rename(columns={'index': 'Modelo'}).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f053082f",
   "metadata": {},
   "source": [
    "### Analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cbb14cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuevo orden de modelos (basado en Lineal No Estacionario (ARIMA)):\n",
      "1. Sieve Bootstrap: 2.4058\n",
      "2. LSPM: 2.8116\n",
      "3. MCPS: 4.8235\n",
      "4. DeepAR: 7.9710\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 1: RENDIMIENTO POR ESCENARIOS\n",
      "================================================================================\n",
      "✓ Gráfica 1.1 guardada\n",
      "✓ Gráfica 1.2 guardada\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 2: ANÁLISIS POR CONFIG\n",
      "================================================================================\n",
      "✓ Gráfica 2.1 guardada\n",
      "✓ Gráfica 2.1.a guardada\n",
      "✓ Gráfica 2.1.b guardada\n",
      "✓ Gráfica 2.1.c guardada\n",
      "✓ Gráfica 2.2 guardada\n",
      "✓ Gráfica 2.2.a guardada\n",
      "✓ Gráfica 2.2.b guardada\n",
      "✓ Gráfica 2.2.c guardada\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 3: ANÁLISIS POR DIST\n",
      "================================================================================\n",
      "✓ Gráfica 3.1 guardada\n",
      "✓ Gráfica 3.1.a guardada\n",
      "✓ Gráfica 3.1.b guardada\n",
      "✓ Gráfica 3.1.c guardada\n",
      "✓ Gráfica 3.2 guardada\n",
      "✓ Gráfica 3.2.a guardada\n",
      "✓ Gráfica 3.2.b guardada\n",
      "✓ Gráfica 3.2.c guardada\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 4: ANÁLISIS POR VAR\n",
      "================================================================================\n",
      "✓ Gráfica 4.1 guardada\n",
      "✓ Gráfica 4.1.a guardada\n",
      "✓ Gráfica 4.1.b guardada\n",
      "✓ Gráfica 4.1.c guardada\n",
      "✓ Gráfica 4.2 guardada\n",
      "✓ Gráfica 4.2.a guardada\n",
      "✓ Gráfica 4.2.b guardada\n",
      "✓ Gráfica 4.2.c guardada\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 5: ANÁLISIS POR PASO (HORIZONTE)\n",
      "================================================================================\n",
      "✓ Gráfica 5.1 guardada\n",
      "✓ Gráfica 5.1.a guardada\n",
      "✓ Gráfica 5.1.b guardada\n",
      "✓ Gráfica 5.1.c guardada\n",
      "✓ Gráfica 5.2 guardada\n",
      "✓ Gráfica 5.2.a guardada\n",
      "✓ Gráfica 5.2.b guardada\n",
      "✓ Gráfica 5.2.c guardada\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 5.5: ANÁLISIS DE INTERACCIONES\n",
      "================================================================================\n",
      "✓ Gráfica 8 (5.7)  guardada: Subplots por Modelo\n",
      "✓ Gráfica 9 (5.8)  guardada: Subplots por Modelo\n",
      "✓ Gráfica 10 (5.9)  guardada: Subplots por Modelo\n",
      "✓ Gráfica 11 (5.10)  guardada: Subplots por Modelo\n",
      "✓ Gráfica 8 (5.7) .a guardada: Subplots por Modelo\n",
      "✓ Gráfica 9 (5.8) .a guardada: Subplots por Modelo\n",
      "✓ Gráfica 10 (5.9) .a guardada: Subplots por Modelo\n",
      "✓ Gráfica 11 (5.10) .a guardada: Subplots por Modelo\n",
      "✓ Gráfica 8 (5.7) .b guardada: Subplots por Modelo\n",
      "✓ Gráfica 9 (5.8) .b guardada: Subplots por Modelo\n",
      "✓ Gráfica 10 (5.9) .b guardada: Subplots por Modelo\n",
      "✓ Gráfica 11 (5.10) .b guardada: Subplots por Modelo\n",
      "✓ Gráfica 8 (5.7) .c guardada: Subplots por Modelo\n",
      "✓ Gráfica 9 (5.8) .c guardada: Subplots por Modelo\n",
      "✓ Gráfica 10 (5.9) .c guardada: Subplots por Modelo\n",
      "✓ Gráfica 11 (5.10) .c guardada: Subplots por Modelo\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 6: ROBUSTEZ Y TEST DIEBOLD-MARIANO\n",
      "================================================================================\n",
      "✓ Gráfica 6.1 guardada (ordenada de menor a mayor CV)\n",
      "✓ Gráfica 6.2 guardada (Test HLN-DM con h=6, T=5040, df=5039)\n",
      "✓ Gráfica 6.2.a guardada (Test HLN-DM con h=6, T=1680, df=1679)\n",
      "✓ Gráfica 6.2.b guardada (Test HLN-DM con h=6, T=1680, df=1679)\n",
      "✓ Gráfica 6.2.c guardada (Test HLN-DM con h=6, T=1680, df=1679)\n",
      "\n",
      "================================================================================\n",
      "PROCESO COMPLETADO\n",
      "================================================================================\n",
      "\n",
      "Mejoras implementadas:\n",
      "1. ✓ Orden consistente en gráficas 1.1 y 1.2\n",
      "2. ✓ Formato de 2 decimales en heatmap 2.2 general\n",
      "3. ✓ Solo Coeficiente de Variación en gráfica 6.1 (ordenado menor a mayor)\n",
      "4. ✓ Test Diebold-Mariano con corrección HLN y distribución t-Student\n",
      "5. ✓ Horizonte de pronóstico (h) incorporado en el análisis\n",
      "\n",
      "================================================================================\n",
      "ANÁLISIS DE INTERACCIONES (Carpeta: Interacciones/)\n",
      "================================================================================\n",
      "6. ✓ Config × Var: Heatmaps por modelo (matriz 3×3)\n",
      "7. ✓ Config × Dist: Heatmaps por modelo (matriz 3×3)\n",
      "8. ✓ Dist × Paso: Gráficas de líneas por distribución\n",
      "9. ✓ Dist × Var: Gráficas de líneas por distribución\n",
      "10. ✓ Config × Paso: Gráficas de líneas por configuración\n",
      "11. ✓ Var × Horizonte: Gráficas de líneas por varianza\n",
      "================================================================================\n",
      "\n",
      "Total de gráficas generadas en Interacciones/: 24 archivos\n",
      "(6 tipos de interacción × 4 escenarios: General + 3 específicos)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import normaltest\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración general\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Crear carpeta de resultados\n",
    "output_dir = Path(\"./Resultados_analisis/Simulacion_h\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Crear carpeta de interacciones\n",
    "interactions_dir = output_dir / \"Interacciones\"\n",
    "interactions_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_excel(\"./datos/Simulacion_h/dataframe_consolidado.xlsx\")\n",
    "\n",
    "# 1) CAMBIO DE NOMBRES DE ESCENARIOS\n",
    "df['ESCENARIO'] = df['ESCENARIO'].replace({\n",
    "    \"Lineal Estacionario\": \"Lineal Estacionario (ARMA)\",\n",
    "    \"Lineal No estacionario\": \"Lineal No Estacionario (ARIMA)\",\n",
    "    \"No lineal Estacionario\": \"No lineal Estacionario (SETAR)\"\n",
    "})\n",
    "\n",
    "# Identificar columnas de modelos\n",
    "var_cols = ['Paso', 'Config', 'Dist', 'Var', 'ESCENARIO']\n",
    "original_model_cols = [col for col in df.columns if col not in var_cols]\n",
    "\n",
    "# 2) ORGANIZAR MODELOS POR RENDIMIENTO EN \"Lineal No Estacionario (ARIMA)\" (Menor a mayor)\n",
    "target_scenario = \"Lineal No Estacionario (ARIMA)\"\n",
    "model_order_scores = df[df['ESCENARIO'] == target_scenario][original_model_cols].mean().sort_values()\n",
    "model_cols = list(model_order_scores.index)\n",
    "\n",
    "print(\"Nuevo orden de modelos (basado en Lineal No Estacionario (ARIMA)):\")\n",
    "for i, m in enumerate(model_cols, 1):\n",
    "    print(f\"{i}. {m}: {model_order_scores[m]:.4f}\")\n",
    "\n",
    "# Mapeo de escenarios\n",
    "escenarios_map = {\n",
    "    'Lineal Estacionario (ARMA)': 'Lineal Estacionario (ARMA)',\n",
    "    'Lineal No Estacionario (ARIMA)': 'Lineal No Estacionario (ARIMA)',\n",
    "    'No lineal Estacionario (SETAR)': 'No lineal Estacionario (SETAR)'\n",
    "}\n",
    "\n",
    "# Definir colores para cada modelo\n",
    "palette = sns.color_palette(\"husl\", len(model_cols))\n",
    "model_colors = {model: palette[i] for i, model in enumerate(model_cols)}\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 1: RENDIMIENTO POR ESCENARIOS\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 1: RENDIMIENTO POR ESCENARIOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_performance_by_scenario():\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    scenarios = [\"Lineal Estacionario (ARMA)\", \"Lineal No Estacionario (ARIMA)\", \"No lineal Estacionario (SETAR)\"]\n",
    "    x = np.arange(len(model_cols))\n",
    "    width = 0.25 \n",
    "    \n",
    "    scenario_colors = {\n",
    "        'Lineal Estacionario (ARMA)': '#5D3FD3',    \n",
    "        'Lineal No Estacionario (ARIMA)': '#808080', \n",
    "        'No lineal Estacionario (SETAR)': '#00A36C'  \n",
    "    }\n",
    "    \n",
    "    for idx, scenario in enumerate(scenarios):\n",
    "        means = [df[df['ESCENARIO'] == scenario][model].mean() for model in model_cols]\n",
    "        position = x + (idx - 1) * width\n",
    "        \n",
    "        bars = ax.bar(position, means, width, label=scenario, \n",
    "                     color=scenario_colors[scenario], alpha=0.85, edgecolor='black', linewidth=0.5)\n",
    "        \n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{height:.2f}', ha='center', va='bottom', fontsize=7, rotation=0)\n",
    "    \n",
    "    ax.set_xlabel('Modelo (Ordenados por desempeño en ARIMA)', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('ECRPS Promedio', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Rendimiento de Modelos por Escenario (ECRPS)', fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(model_cols, rotation=45, ha='right', fontsize=9)\n",
    "    ax.legend(loc='upper left', ncol=1, fontsize=10, framealpha=0.9)\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / '1.1_rendimiento_por_escenario.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Gráfica 1.1 guardada\")\n",
    "\n",
    "plot_performance_by_scenario()\n",
    "\n",
    "def plot_relative_performance():\n",
    "    base_scenario = 'Lineal Estacionario (ARMA)'\n",
    "    scenarios_compare = ['Lineal No Estacionario (ARIMA)', 'No lineal Estacionario (SETAR)']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 10))\n",
    "    \n",
    "    y = np.arange(len(model_cols))\n",
    "    height = 0.35  \n",
    "    \n",
    "    for idx, scenario in enumerate(scenarios_compare):\n",
    "        changes = []\n",
    "        for model in model_cols:\n",
    "            base_value = df[df['ESCENARIO'] == base_scenario][model].mean()\n",
    "            scenario_value = df[df['ESCENARIO'] == scenario][model].mean()\n",
    "            pct_change = ((scenario_value - base_value) / base_value) * 100\n",
    "            changes.append(pct_change)\n",
    "        \n",
    "        position = y + idx * height\n",
    "        bars = ax.barh(position, changes, height, label=scenario, alpha=0.85, edgecolor='black', linewidth=0.5)\n",
    "        \n",
    "        for bar, val in zip(bars, changes):\n",
    "            width = bar.get_width()\n",
    "            ax.text(width + (1 if width > 0 else -1), bar.get_y() + bar.get_height()/2.,\n",
    "                   f'{val:+.1f}%', ha='left' if val > 0 else 'right', \n",
    "                   va='center', fontsize=7)\n",
    "    \n",
    "    ax.set_yticks(y + height / 2)\n",
    "    ax.set_yticklabels(model_cols, fontsize=10)\n",
    "    ax.set_xlabel('Cambio Relativo (%)', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(f'Cambio Relativo en ECRPS vs. {base_scenario}', fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.axvline(x=0, color='black', linestyle='-', linewidth=1.5)\n",
    "    ax.legend(loc='best', fontsize=10, framealpha=0.9)\n",
    "    ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / '1.2_cambio_relativo_escenario_base.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Gráfica 1.2 guardada\")\n",
    "\n",
    "plot_relative_performance()\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 2: ANÁLISIS POR CONFIG\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 2: ANÁLISIS POR CONFIG\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_zscore_heatmap_config(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Z-scores de ECRPS por Configuración ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Z-scores de ECRPS por Configuración (General)'\n",
    "    \n",
    "    pivot_data = data_filtered.groupby('Config')[model_cols].mean()\n",
    "    z_scores = pivot_data.apply(lambda x: (x - x.mean()) / x.std(), axis=0)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    sns.heatmap(z_scores.T, annot=True, fmt='.2f', cmap='RdYlGn_r', \n",
    "                center=0, cbar_kws={'label': 'Z-score'}, ax=ax,\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    ax.set_title(title, fontsize=12, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Configuración', fontsize=11)\n",
    "    ax.set_ylabel('Modelo', fontsize=11)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'2.1{suffix}_zscore_config.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 2.1{suffix} guardada\")\n",
    "\n",
    "plot_zscore_heatmap_config()\n",
    "plot_zscore_heatmap_config('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_zscore_heatmap_config('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_zscore_heatmap_config('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "def plot_variability_config(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Desv. Estándar de ECRPS por Configuración ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Desv. Estándar de ECRPS por Configuración (General)'\n",
    "    \n",
    "    pivot_std = data_filtered.groupby('Config')[model_cols].std()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    fmt = '.2f' if suffix == '' else '.4f'\n",
    "    sns.heatmap(pivot_std.T, annot=True, fmt=fmt, cmap='YlOrRd', \n",
    "                cbar_kws={'label': 'Desv. Estándar'}, ax=ax,\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Configuración', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'2.2{suffix}_variabilidad_config.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 2.2{suffix} guardada\")\n",
    "\n",
    "plot_variability_config()\n",
    "plot_variability_config('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_variability_config('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_variability_config('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 3: ANÁLISIS POR DIST\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 3: ANÁLISIS POR DIST\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_zscore_heatmap_dist(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Z-scores de ECRPS por Distribución ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Z-scores de ECRPS por Distribución (General)'\n",
    "    \n",
    "    pivot_data = data_filtered.groupby('Dist')[model_cols].mean()\n",
    "    z_scores = pivot_data.apply(lambda x: (x - x.mean()) / x.std(), axis=0)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    sns.heatmap(z_scores.T, annot=True, fmt='.2f', cmap='RdYlGn_r', \n",
    "                center=0, cbar_kws={'label': 'Z-score'}, ax=ax,\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    ax.set_title(title, fontsize=12, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Distribución', fontsize=11)\n",
    "    ax.set_ylabel('Modelo', fontsize=11)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'3.1{suffix}_zscore_dist.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 3.1{suffix} guardada\")\n",
    "\n",
    "plot_zscore_heatmap_dist()\n",
    "plot_zscore_heatmap_dist('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_zscore_heatmap_dist('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_zscore_heatmap_dist('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "def plot_variability_dist(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Desv. Estándar de ECRPS por Distribución ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Desv. Estándar de ECRPS por Distribución (General)'\n",
    "    \n",
    "    pivot_std = data_filtered.groupby('Dist')[model_cols].std()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    sns.heatmap(pivot_std.T, annot=True, fmt='.4f', cmap='YlOrRd', \n",
    "                cbar_kws={'label': 'Desv. Estándar'}, ax=ax,\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Distribución', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'3.2{suffix}_variabilidad_dist.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 3.2{suffix} guardada\")\n",
    "\n",
    "plot_variability_dist()\n",
    "plot_variability_dist('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_variability_dist('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_variability_dist('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 4: ANÁLISIS POR VAR\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 4: ANÁLISIS POR VAR\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_evolution_var(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Evolución de ECRPS por Varianza ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Evolución de ECRPS por Varianza (General)'\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    var_values = sorted(data_filtered['Var'].unique())\n",
    "    \n",
    "    for model in model_cols:\n",
    "        means = []\n",
    "        for var in var_values:\n",
    "            mean_val = data_filtered[data_filtered['Var'] == var][model].mean()\n",
    "            means.append(mean_val)\n",
    "        \n",
    "        ax.plot(var_values, means, marker='o', label=model, color=model_colors[model],\n",
    "                linewidth=2.5, markersize=7, alpha=0.85)\n",
    "    \n",
    "    ax.set_xlabel('Varianza', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('ECRPS Promedio', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.legend(loc='best', fontsize=9, ncol=2, framealpha=0.9)\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'4.1{suffix}_evolucion_var.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 4.1{suffix} guardada\")\n",
    "\n",
    "plot_evolution_var()\n",
    "plot_evolution_var('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_evolution_var('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_evolution_var('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "def plot_variability_var(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Desv. Estándar de ECRPS por Varianza ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Desv. Estándar de ECRPS por Varianza (General)'\n",
    "    \n",
    "    pivot_std = data_filtered.groupby('Var')[model_cols].std()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    sns.heatmap(pivot_std.T, annot=True, fmt='.4f', cmap='YlOrRd', \n",
    "                cbar_kws={'label': 'Desv. Estándar'}, ax=ax,\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Varianza', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'4.2{suffix}_variabilidad_var.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 4.2{suffix} guardada\")\n",
    "\n",
    "plot_variability_var()\n",
    "plot_variability_var('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_variability_var('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_variability_var('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 5: ANÁLISIS POR PASO (HORIZONTE)\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 5: ANÁLISIS POR PASO (HORIZONTE)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_evolution_paso(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Evolución de ECRPS por Horizonte de Pronóstico ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Evolución de ECRPS por Horizonte de Pronóstico (General)'\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    pasos = sorted(data_filtered['Paso'].unique())\n",
    "    \n",
    "    for model in model_cols:\n",
    "        means = []\n",
    "        for paso in pasos:\n",
    "            mean_val = data_filtered[data_filtered['Paso'] == paso][model].mean()\n",
    "            means.append(mean_val)\n",
    "        \n",
    "        ax.plot(pasos, means, marker='o', label=model, color=model_colors[model],\n",
    "                linewidth=2.5, markersize=7, alpha=0.85)\n",
    "    \n",
    "    ax.set_xlabel('Horizonte de Pronóstico', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('ECRPS Promedio', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.legend(loc='best', fontsize=9, ncol=2, framealpha=0.9)\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'5.1{suffix}_evolucion_paso.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 5.1{suffix} guardada\")\n",
    "\n",
    "plot_evolution_paso()\n",
    "plot_evolution_paso('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_evolution_paso('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_evolution_paso('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "def plot_variability_paso(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Desv. Estándar de ECRPS por Horizonte ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Desv. Estándar de ECRPS por Horizonte (General)'\n",
    "    \n",
    "    pivot_std = data_filtered.groupby('Paso')[model_cols].std()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    sns.heatmap(pivot_std.T, annot=True, fmt='.4f', cmap='YlOrRd', \n",
    "                cbar_kws={'label': 'Desv. Estándar'}, ax=ax,\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Horizonte de Pronóstico', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'5.2{suffix}_variabilidad_paso.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 5.2{suffix} guardada\")\n",
    "\n",
    "plot_variability_paso()\n",
    "plot_variability_paso('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_variability_paso('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_variability_paso('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 5.5: ANÁLISIS DE INTERACCIONES\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 5.5: ANÁLISIS DE INTERACCIONES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Función auxiliar para configurar el grid de modelos\n",
    "def get_model_grid_axes(n_models):\n",
    "    n_cols = 3\n",
    "    n_rows = (n_models + n_cols - 1) // n_cols\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 5 * n_rows))\n",
    "    return fig, axes.flatten(), n_rows, n_cols\n",
    "\n",
    "# INTERACCIÓN 3 (Lista 8): DIST × PASO - Subplots por Modelo\n",
    "def plot_interaction_dist_paso(scenario=None, suffix=''):\n",
    "    data_filtered = df[df['ESCENARIO'] == scenario].copy() if scenario else df.copy()\n",
    "    title = f'Interacción Dist × Paso por Modelo ({\"General\" if not scenario else scenario})'\n",
    "    \n",
    "    fig, axes, n_rows, n_cols = get_model_grid_axes(len(model_cols))\n",
    "    dists = sorted(data_filtered['Dist'].unique())\n",
    "    pasos = sorted(data_filtered['Paso'].unique())\n",
    "    colors_dist = sns.color_palette(\"viridis\", len(dists))\n",
    "\n",
    "    for idx, model in enumerate(model_cols):\n",
    "        ax = axes[idx]\n",
    "        for d_idx, dist in enumerate(dists):\n",
    "            means = [data_filtered[(data_filtered['Dist'] == dist) & (data_filtered['Paso'] == p)][model].mean() for p in pasos]\n",
    "            ax.plot(pasos, means, marker='o', label=dist, color=colors_dist[d_idx], linewidth=2)\n",
    "        \n",
    "        ax.set_title(f'Modelo: {model}', fontweight='bold')\n",
    "        ax.set_xlabel('Horizonte (Paso)')\n",
    "        ax.set_ylabel('ECRPS Promedio')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        if idx == 0: ax.legend(title=\"Distribución\", fontsize=8)\n",
    "\n",
    "    for i in range(len(model_cols), len(axes)): axes[i].set_visible(False)\n",
    "    plt.suptitle(title, fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(interactions_dir / f'5.7{suffix}_interaccion_dist_paso_modelos.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 8 (5.7) {suffix} guardada: Subplots por Modelo\")\n",
    "\n",
    "# INTERACCIÓN 4 (Lista 9): DIST × VAR - Subplots por Modelo\n",
    "def plot_interaction_dist_var(scenario=None, suffix=''):\n",
    "    data_filtered = df[df['ESCENARIO'] == scenario].copy() if scenario else df.copy()\n",
    "    title = f'Interacción Dist × Var por Modelo ({\"General\" if not scenario else scenario})'\n",
    "    \n",
    "    fig, axes, _, _ = get_model_grid_axes(len(model_cols))\n",
    "    dists = sorted(data_filtered['Dist'].unique())\n",
    "    vars_val = sorted(data_filtered['Var'].unique())\n",
    "    colors_dist = sns.color_palette(\"magma\", len(dists))\n",
    "\n",
    "    for idx, model in enumerate(model_cols):\n",
    "        ax = axes[idx]\n",
    "        for d_idx, dist in enumerate(dists):\n",
    "            means = [data_filtered[(data_filtered['Dist'] == dist) & (data_filtered['Var'] == v)][model].mean() for v in vars_val]\n",
    "            ax.plot(vars_val, means, marker='s', label=dist, color=colors_dist[d_idx], linewidth=2)\n",
    "        \n",
    "        ax.set_title(f'Modelo: {model}', fontweight='bold')\n",
    "        ax.set_xlabel('Varianza')\n",
    "        ax.set_ylabel('ECRPS Promedio')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        if idx == 0: ax.legend(title=\"Distribución\", fontsize=8)\n",
    "\n",
    "    for i in range(len(model_cols), len(axes)): axes[i].set_visible(False)\n",
    "    plt.suptitle(title, fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(interactions_dir / f'5.8{suffix}_interaccion_dist_var_modelos.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 9 (5.8) {suffix} guardada: Subplots por Modelo\")\n",
    "\n",
    "# INTERACCIÓN 5 (Lista 10): CONFIG × PASO - Subplots por Modelo\n",
    "def plot_interaction_config_paso(scenario=None, suffix=''):\n",
    "    data_filtered = df[df['ESCENARIO'] == scenario].copy() if scenario else df.copy()\n",
    "    title = f'Interacción Config × Paso por Modelo ({\"General\" if not scenario else scenario})'\n",
    "    \n",
    "    fig, axes, _, _ = get_model_grid_axes(len(model_cols))\n",
    "    configs = sorted(data_filtered['Config'].unique())\n",
    "    pasos = sorted(data_filtered['Paso'].unique())\n",
    "    colors_conf = sns.color_palette(\"tab10\", len(configs))\n",
    "\n",
    "    for idx, model in enumerate(model_cols):\n",
    "        ax = axes[idx]\n",
    "        for c_idx, config in enumerate(configs):\n",
    "            means = [data_filtered[(data_filtered['Config'] == config) & (data_filtered['Paso'] == p)][model].mean() for p in pasos]\n",
    "            ax.plot(pasos, means, marker='^', label=config, color=colors_conf[c_idx], linewidth=2)\n",
    "        \n",
    "        ax.set_title(f'Modelo: {model}', fontweight='bold')\n",
    "        ax.set_xlabel('Horizonte (Paso)')\n",
    "        ax.set_ylabel('ECRPS Promedio')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        if idx == 0: ax.legend(title=\"Config\", fontsize=8)\n",
    "\n",
    "    for i in range(len(model_cols), len(axes)): axes[i].set_visible(False)\n",
    "    plt.suptitle(title, fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(interactions_dir / f'5.9{suffix}_interaccion_config_paso_modelos.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 10 (5.9) {suffix} guardada: Subplots por Modelo\")\n",
    "\n",
    "# INTERACCIÓN 6 (Lista 11): VAR × HORIZONTE - Subplots por Modelo\n",
    "def plot_interaction_var_horizonte(scenario=None, suffix=''):\n",
    "    data_filtered = df[df['ESCENARIO'] == scenario].copy() if scenario else df.copy()\n",
    "    title = f'Interacción Var × Horizonte por Modelo ({\"General\" if not scenario else scenario})'\n",
    "    \n",
    "    fig, axes, _, _ = get_model_grid_axes(len(model_cols))\n",
    "    vars_val = sorted(data_filtered['Var'].unique())\n",
    "    pasos = sorted(data_filtered['Paso'].unique())\n",
    "    colors_var = sns.color_palette(\"rocket\", len(vars_val))\n",
    "\n",
    "    for idx, model in enumerate(model_cols):\n",
    "        ax = axes[idx]\n",
    "        for v_idx, var in enumerate(vars_val):\n",
    "            means = [data_filtered[(data_filtered['Var'] == var) & (data_filtered['Paso'] == p)][model].mean() for p in pasos]\n",
    "            ax.plot(pasos, means, marker='d', label=f'Var {var}', color=colors_var[v_idx], linewidth=2)\n",
    "        \n",
    "        ax.set_title(f'Modelo: {model}', fontweight='bold')\n",
    "        ax.set_xlabel('Horizonte (Paso)')\n",
    "        ax.set_ylabel('ECRPS Promedio')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        if idx == 0: ax.legend(title=\"Varianza\", fontsize=8)\n",
    "\n",
    "    for i in range(len(model_cols), len(axes)): axes[i].set_visible(False)\n",
    "    plt.suptitle(title, fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(interactions_dir / f'5.10{suffix}_interaccion_var_horizonte_modelos.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 11 (5.10) {suffix} guardada: Subplots por Modelo\")\n",
    "\n",
    "\n",
    "# ====================================================================================\n",
    "# EJECUCIÓN DE LAS NUEVAS FUNCIONES\n",
    "# ====================================================================================\n",
    "\n",
    "for sc_name, sc_suf in [ (None, ''), ('Lineal Estacionario (ARMA)', '.a'), \n",
    "                        ('Lineal No Estacionario (ARIMA)', '.b'), \n",
    "                        ('No lineal Estacionario (SETAR)', '.c') ]:\n",
    "    plot_interaction_dist_paso(sc_name, sc_suf)\n",
    "    plot_interaction_dist_var(sc_name, sc_suf)\n",
    "    plot_interaction_config_paso(sc_name, sc_suf)\n",
    "    plot_interaction_var_horizonte(sc_name, sc_suf)\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 6: ROBUSTEZ Y TEST DIEBOLD-MARIANO\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 6: ROBUSTEZ Y TEST DIEBOLD-MARIANO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_robustness():\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    cv_data = []\n",
    "    for model in model_cols:\n",
    "        cv = df[model].std() / df[model].mean()\n",
    "        cv_data.append((model, cv))\n",
    "    \n",
    "    cv_df = pd.DataFrame(cv_data, columns=['Modelo', 'CV'])\n",
    "    \n",
    "    # CAMBIO 1: Ordenar de menor a mayor CV para coherencia\n",
    "    cv_df = cv_df.sort_values('CV')\n",
    "    \n",
    "    colors_cv = ['#2ecc71' if cv < cv_df['CV'].median() else '#e74c3c' \n",
    "                 for cv in cv_df['CV']]\n",
    "    \n",
    "    bars = ax.barh(cv_df['Modelo'], cv_df['CV'], color=colors_cv, alpha=0.8, edgecolor='black')\n",
    "    \n",
    "    for bar, cv in zip(bars, cv_df['CV']):\n",
    "        width = bar.get_width()\n",
    "        ax.text(width + 0.001, bar.get_y() + bar.get_height()/2.,\n",
    "               f'{cv:.4f}', ha='left', va='center', fontsize=9)\n",
    "    \n",
    "    ax.set_xlabel('Coeficiente de Variación', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Robustez: Coeficiente de Variación\\n(Ordenado de menor a mayor - Menor valor indica mayor estabilidad)', \n",
    "                  fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.axvline(x=cv_df['CV'].median(), color='black', linestyle='--', linewidth=1.5, alpha=0.5, label='Mediana')\n",
    "    ax.legend(loc='best', fontsize=10)\n",
    "    ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / '6.1_robustez_coeficiente_variacion.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Gráfica 6.1 guardada (ordenada de menor a mayor CV)\")\n",
    "\n",
    "plot_robustness()\n",
    "\n",
    "def modified_diebold_mariano_test(errors1, errors2, h=1):\n",
    "    \"\"\"\n",
    "    Test Diebold-Mariano con fixed-smoothing asymptotics (Coroneo & Iacone, 2020)\n",
    "    \n",
    "    Usa Fixed-m asymptotics (kernel Daniell) que es más robusto en muestras pequeñas\n",
    "    y mantiene buen desempeño en muestras grandes.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    errors1, errors2 : array-like\n",
    "        Errores de pronóstico (ECRPS) de los dos modelos\n",
    "    h : int\n",
    "        Horizonte de pronóstico (forecast horizon)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    hln_dm_stat : float\n",
    "        Estadístico con fixed-m asymptotics\n",
    "    p_value : float\n",
    "        P-valor usando distribución t-Student con 2m grados de libertad\n",
    "    dm_stat : float\n",
    "        Estadístico DM original (para referencia)\n",
    "    \"\"\"\n",
    "    # Calcular diferencial de pérdida\n",
    "    d = errors1 - errors2\n",
    "    d_bar = np.mean(d)\n",
    "    T = len(d)\n",
    "    \n",
    "    if T < 2:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    \n",
    "    # Desviaciones de la media\n",
    "    u = d - d_bar\n",
    "    \n",
    "    # Fixed-m: bandwidth recomendado en el paper\n",
    "    m = max(1, int(np.floor(T**(1/3))))\n",
    "    \n",
    "    # Calcular periodograma\n",
    "    from scipy.fft import fft\n",
    "    \n",
    "    # FFT de las desviaciones\n",
    "    fft_u = fft(u)\n",
    "    periodogram = np.abs(fft_u)**2 / (2 * np.pi * T)\n",
    "    \n",
    "    # WPE con kernel de Daniell: promedio de primeros m periodogramas\n",
    "    # (excluyendo frecuencia 0)\n",
    "    if m >= len(periodogram) - 1:\n",
    "        m = len(periodogram) - 2\n",
    "    \n",
    "    sigma_hat_sq = 2 * np.pi * np.mean(periodogram[1:m+1])\n",
    "    \n",
    "    if sigma_hat_sq <= 0:\n",
    "        # Fallback: usar varianza simple\n",
    "        sigma_hat_sq = np.var(d, ddof=1) / T\n",
    "        if sigma_hat_sq <= 0:\n",
    "            return 0, 1.0, 0\n",
    "    \n",
    "    # Estadístico DM\n",
    "    dm_stat = np.sqrt(T) * d_bar / np.sqrt(sigma_hat_sq)\n",
    "    \n",
    "    # Fixed-m asymptotics: límite es t-Student con 2m grados de libertad\n",
    "    df = 2 * m\n",
    "    hln_dm_stat = dm_stat\n",
    "    \n",
    "    # P-valor usando t-Student\n",
    "    p_value = 2 * (1 - stats.t.cdf(abs(hln_dm_stat), df))\n",
    "    \n",
    "    return hln_dm_stat, p_value, dm_stat\n",
    "\n",
    "def plot_dm_test_heatmap(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Test Diebold-Mariano Modificado (HLN-DM)\\ncon Corrección de Bonferroni ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Test Diebold-Mariano Modificado (HLN-DM)\\ncon Corrección de Bonferroni (General)'\n",
    "    \n",
    "    # Determinar el horizonte de pronóstico promedio\n",
    "    h_forecast = int(data_filtered['Paso'].mean())\n",
    "    \n",
    "    n_models = len(model_cols)\n",
    "    n_comparisons = n_models * (n_models - 1) / 2\n",
    "    alpha = 0.05\n",
    "    bonferroni_alpha = alpha / n_comparisons\n",
    "    \n",
    "    results_matrix = np.zeros((n_models, n_models))\n",
    "    p_values = np.zeros((n_models, n_models))\n",
    "    dm_stats = np.zeros((n_models, n_models))\n",
    "    \n",
    "    for i, model1 in enumerate(model_cols):\n",
    "        for j, model2 in enumerate(model_cols):\n",
    "            if i == j:\n",
    "                results_matrix[i, j] = 0  \n",
    "                p_values[i, j] = 1.0\n",
    "                dm_stats[i, j] = 0\n",
    "            elif i < j:\n",
    "                errors1 = data_filtered[model1].values\n",
    "                errors2 = data_filtered[model2].values\n",
    "                hln_dm_stat, p_val, dm_original = modified_diebold_mariano_test(\n",
    "                    errors1, errors2, h=h_forecast\n",
    "                )\n",
    "                \n",
    "                p_values[i, j] = p_val\n",
    "                p_values[j, i] = p_val\n",
    "                dm_stats[i, j] = hln_dm_stat\n",
    "                dm_stats[j, i] = -hln_dm_stat\n",
    "                \n",
    "                if p_val < bonferroni_alpha:\n",
    "                    mean1 = np.mean(errors1)\n",
    "                    mean2 = np.mean(errors2)\n",
    "                    if mean1 < mean2:  \n",
    "                        results_matrix[i, j] = 1  \n",
    "                        results_matrix[j, i] = -1  \n",
    "                    else:\n",
    "                        results_matrix[i, j] = -1\n",
    "                        results_matrix[j, i] = 1\n",
    "                else:\n",
    "                    results_matrix[i, j] = 0\n",
    "                    results_matrix[j, i] = 0\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 11))\n",
    "    cmap = plt.cm.colors.ListedColormap(['#e74c3c', '#fff9c4', '#2ecc71'])\n",
    "    bounds = [-1.5, -0.5, 0.5, 1.5]\n",
    "    norm = plt.cm.colors.BoundaryNorm(bounds, cmap.N)\n",
    "    \n",
    "    im = ax.imshow(results_matrix, cmap=cmap, norm=norm, aspect='auto')\n",
    "    ax.set_xticks(np.arange(n_models))\n",
    "    ax.set_yticks(np.arange(n_models))\n",
    "    ax.set_xticklabels(model_cols, rotation=45, ha='right', fontsize=9)\n",
    "    ax.set_yticklabels(model_cols, fontsize=9)\n",
    "    \n",
    "    for i in range(n_models):\n",
    "        for j in range(n_models):\n",
    "            if i == j:\n",
    "                text = '-'\n",
    "                color = 'black'\n",
    "            else:\n",
    "                val = results_matrix[i, j]\n",
    "                p_val = p_values[i, j]\n",
    "                dm_val = dm_stats[i, j]\n",
    "                if val == 1:\n",
    "                    text = f'✓\\nHLN-DM={dm_val:.2f}\\np={p_val:.4f}'\n",
    "                    color = 'white'\n",
    "                elif val == -1:\n",
    "                    text = f'✗\\nHLN-DM={dm_val:.2f}\\np={p_val:.4f}'\n",
    "                    color = 'white'\n",
    "                else:\n",
    "                    text = f'≈\\nHLN-DM={dm_val:.2f}\\np={p_val:.4f}'\n",
    "                    color = 'black'\n",
    "            ax.text(j, i, text, ha='center', va='center', \n",
    "                   color=color, fontsize=6, fontweight='bold')\n",
    "    \n",
    "    # Obtener T para el título\n",
    "    T = len(data_filtered)\n",
    "    df_test = T - 1\n",
    "    \n",
    "    ax.set_title(title + f'\\n(h={h_forecast}, T={T}, df={df_test}, α ajustado={bonferroni_alpha:.5f})', \n",
    "                 fontsize=11, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Modelo (Columna)', fontsize=11)\n",
    "    ax.set_ylabel('Modelo (Fila)', fontsize=11)\n",
    "    \n",
    "    legend_elements = [\n",
    "        plt.Rectangle((0,0),1,1, facecolor='#2ecc71', label='Fila supera columna (p < α)'),\n",
    "        plt.Rectangle((0,0),1,1, facecolor='#e74c3c', label='Columna supera fila (p < α)'),\n",
    "        plt.Rectangle((0,0),1,1, facecolor='#fff9c4', label='Sin diferencia significativa (p ≥ α)')\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='upper left', bbox_to_anchor=(1.05, 1), fontsize=9)\n",
    "    \n",
    "    # Agregar nota metodológica\n",
    "    note_text = ('Nota: Se utiliza el test HLN-DM con corrección para muestras finitas.\\n'\n",
    "                 'Distribución: t-Student. Ajuste: Bonferroni para comparaciones múltiples.')\n",
    "    plt.figtext(0.5, -0.02, note_text, ha='center', fontsize=8, style='italic', \n",
    "                wrap=True, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'6.2{suffix}_dm_test_hln_bonferroni.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Guardar resultados en Excel\n",
    "    results_df = pd.DataFrame(results_matrix, index=model_cols, columns=model_cols)\n",
    "    pvalues_df = pd.DataFrame(p_values, index=model_cols, columns=model_cols)\n",
    "    dmstats_df = pd.DataFrame(dm_stats, index=model_cols, columns=model_cols)\n",
    "    \n",
    "    summary_data = []\n",
    "    for model in model_cols:\n",
    "        idx = model_cols.index(model)\n",
    "        victorias = int(np.sum(results_matrix[idx, :] == 1))\n",
    "        derrotas = int(np.sum(results_matrix[idx, :] == -1))\n",
    "        empates = int(np.sum(results_matrix[idx, :] == 0)) - 1\n",
    "        mean_ecrps = data_filtered[model].mean()\n",
    "        std_ecrps = data_filtered[model].std()\n",
    "        cv_ecrps = std_ecrps / mean_ecrps\n",
    "        summary_data.append({\n",
    "            'Modelo': model,\n",
    "            'Victorias': victorias,\n",
    "            'Derrotas': derrotas,\n",
    "            'Empates': empates,\n",
    "            'Tasa_Victoria': f\"{(victorias / (n_models - 1)) * 100:.1f}%\",\n",
    "            'ECRPS_Promedio': f\"{mean_ecrps:.4f}\",\n",
    "            'ECRPS_Desv_Std': f\"{std_ecrps:.4f}\",\n",
    "            'Coef_Variacion': f\"{cv_ecrps:.4f}\"\n",
    "        })\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    # Información metodológica\n",
    "    method_info = pd.DataFrame({\n",
    "        'Parámetro': ['Horizonte de pronóstico (h)', 'Tamaño muestra (T)', \n",
    "                      'Grados libertad (df)', 'Alpha nominal', \n",
    "                      'Alpha ajustado (Bonferroni)', 'Número comparaciones',\n",
    "                      'Distribución', 'Corrección aplicada'],\n",
    "        'Valor': [h_forecast, T, df_test, alpha, bonferroni_alpha, \n",
    "                  int(n_comparisons), 't-Student', 'Harvey-Leybourne-Newbold (1997)']\n",
    "    })\n",
    "    \n",
    "    with pd.ExcelWriter(output_dir / f'6.2{suffix}_dm_test_hln_resultados.xlsx') as writer:\n",
    "        method_info.to_excel(writer, sheet_name='Metodologia', index=False)\n",
    "        results_df.to_excel(writer, sheet_name='Matriz_Resultados')\n",
    "        pvalues_df.to_excel(writer, sheet_name='P_valores')\n",
    "        dmstats_df.to_excel(writer, sheet_name='Estadisticos_HLN_DM')\n",
    "        summary_df.to_excel(writer, sheet_name='Resumen_Modelos', index=False)\n",
    "    \n",
    "    print(f\"✓ Gráfica 6.2{suffix} guardada (Test HLN-DM con h={h_forecast}, T={T}, df={df_test})\")\n",
    "\n",
    "plot_dm_test_heatmap()\n",
    "plot_dm_test_heatmap('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_dm_test_heatmap('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_dm_test_heatmap('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PROCESO COMPLETADO\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nMejoras implementadas:\")\n",
    "print(\"1. ✓ Orden consistente en gráficas 1.1 y 1.2\")\n",
    "print(\"2. ✓ Formato de 2 decimales en heatmap 2.2 general\")\n",
    "print(\"3. ✓ Solo Coeficiente de Variación en gráfica 6.1 (ordenado menor a mayor)\")\n",
    "print(\"4. ✓ Test Diebold-Mariano con corrección HLN y distribución t-Student\")\n",
    "print(\"5. ✓ Horizonte de pronóstico (h) incorporado en el análisis\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANÁLISIS DE INTERACCIONES (Carpeta: Interacciones/)\")\n",
    "print(\"=\"*80)\n",
    "print(\"6. ✓ Config × Var: Heatmaps por modelo (matriz 3×3)\")\n",
    "print(\"7. ✓ Config × Dist: Heatmaps por modelo (matriz 3×3)\")\n",
    "print(\"8. ✓ Dist × Paso: Gráficas de líneas por distribución\")\n",
    "print(\"9. ✓ Dist × Var: Gráficas de líneas por distribución\")\n",
    "print(\"10. ✓ Config × Paso: Gráficas de líneas por configuración\")\n",
    "print(\"11. ✓ Var × Horizonte: Gráficas de líneas por varianza\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal de gráficas generadas en Interacciones/: {6 * 4} archivos\")\n",
    "print(\"(6 tipos de interacción × 4 escenarios: General + 3 específicos)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891694e2",
   "metadata": {},
   "source": [
    "# Revisión uso DM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e06b6b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATOS SIMULADOS (primeras 12 filas)\n",
      "================================================================================\n",
      "    Config       Dist  Var  Paso  Modelo_A  Modelo_B\n",
      "0        1     Normal  0.5     1  0.424836  0.493087\n",
      "1        1     Normal  0.5     2  0.432384  0.576151\n",
      "2        1     Normal  0.5     3  0.388292  0.488293\n",
      "3        1     Normal  1.0     1  0.478961  0.538372\n",
      "4        1     Normal  1.0     2  0.376526  0.527128\n",
      "5        1     Normal  1.0     3  0.376829  0.476714\n",
      "6        1  T-Student  0.5     1  0.412098  0.404336\n",
      "7        1  T-Student  0.5     2  0.313754  0.471886\n",
      "8        1  T-Student  0.5     3  0.349358  0.515712\n",
      "9        1  T-Student  1.0     1  0.354599  0.429385\n",
      "10       1  T-Student  1.0     2  0.473282  0.488711\n",
      "11       1  T-Student  1.0     3  0.403376  0.428763\n",
      "\n",
      "Total observaciones: 24\n",
      "\n",
      "================================================================================\n",
      "ENFOQUE 1: TEST D-M GLOBAL (COMO ESTÁ EN TU CÓDIGO)\n",
      "================================================================================\n",
      "\n",
      "Diferencias individuales (primeras 12):\n",
      "[-0.06825108 -0.14376707 -0.10000082 -0.0594111  -0.15060172 -0.0998844\n",
      "  0.00776213 -0.15813152 -0.16635392 -0.07478602 -0.01542875 -0.02538618]\n",
      "\n",
      "Media de diferencias: -0.0035\n",
      "Desv. Std de diferencias: 0.1792\n",
      "\n",
      "Estadístico D-M: -0.0951\n",
      "P-valor: 0.9242\n",
      "Conclusión: No hay diferencia significativa\n",
      "\n",
      "================================================================================\n",
      "ENFOQUE 2: TESTS D-M ESTRATIFICADOS POR CONDICIÓN\n",
      "================================================================================\n",
      "\n",
      "Tests por Config:\n",
      "  Config 1: media_dif=-0.0879, DM=-5.1703, p=0.0000\n",
      "  Config 2: media_dif=0.0809, DM=1.2773, p=0.2015\n",
      "\n",
      "Tests por Varianza:\n",
      "  Var 0.5: media_dif=-0.1077, DM=-5.7022, p=0.0000\n",
      "  Var 1.0: media_dif=0.1008, DM=1.7646, p=0.0776\n",
      "\n",
      "Tests por Config × Var (combinación crítica):\n",
      "  Config=1, Var=0.5: media_dif=-0.1048, DM=-3.8539, p=0.0001\n",
      "  Config=1, Var=1.0: media_dif=-0.0709, DM=-3.4758, p=0.0005\n",
      "  Config=2, Var=0.5: media_dif=-0.1107, DM=-3.8467, p=0.0001\n",
      "  Config=2, Var=1.0: media_dif=0.2725, DM=5.8855, p=0.0000\n",
      "\n",
      "================================================================================\n",
      "ENFOQUE 3: ANOVA MULTIFACTORIAL SOBRE DIFERENCIAS\n",
      "================================================================================\n",
      "\n",
      "Efecto de Config:\n",
      "  F=6.6223, p=0.0173\n",
      "\n",
      "Efecto de Var:\n",
      "  F=12.0147, p=0.0022\n",
      "\n",
      "Efecto de Dist:\n",
      "  F=0.0195, p=0.8902\n",
      "\n",
      "Efecto de interacción Config × Var:\n",
      "  F=33.1020, p=0.0000\n",
      "\n",
      "================================================================================\n",
      "RESUMEN: MEDIAS DE DIFERENCIAS POR CONDICIÓN\n",
      "================================================================================\n",
      "\n",
      "Tabla: Diferencia promedio (Modelo_A - Modelo_B)\n",
      "Dist        Normal  T-Student\n",
      "Config Var                   \n",
      "1      0.5 -0.1040    -0.1056\n",
      "       1.0 -0.1033    -0.0385\n",
      "2      0.5 -0.1415    -0.0798\n",
      "       1.0  0.3140     0.2309\n",
      "\n",
      "Interpretación:\n",
      "  - Valores negativos: Modelo A mejor (menor ECRPS)\n",
      "  - Valores positivos: Modelo B mejor\n",
      "  - Nota: Config=2 + Var=1.0 tiene diferencias positivas (A peor que B)\n",
      "\n",
      "================================================================================\n",
      "CONCLUSIONES COMPARATIVAS\n",
      "================================================================================\n",
      "\n",
      "1. TEST D-M GLOBAL (tu código actual):\n",
      "   → Conclusión: Modelo A peor que B en promedio\n",
      "   → Problema: NO detecta que en Config=2+Var=1.0 la situación se invierte\n",
      "\n",
      "2. TESTS D-M ESTRATIFICADOS:\n",
      "   → Conclusión: La superioridad de A depende de las condiciones\n",
      "   → Ventaja: Identifica dónde cada modelo es mejor\n",
      "   → Problema: Múltiples tests, ajuste de Bonferroni muy conservador\n",
      "\n",
      "3. ANOVA SOBRE DIFERENCIAS:\n",
      "   → Conclusión: Hay efectos significativos de Config, Var, y su interacción\n",
      "   → Ventaja: Cuantifica qué factores afectan las diferencias\n",
      "   → Limitación: No hace comparación pairwise directa entre modelos\n",
      "\n",
      "================================================================================\n",
      "RECOMENDACIÓN PARA TU ANÁLISIS\n",
      "================================================================================\n",
      "\n",
      "Deberías combinar los tres enfoques:\n",
      "\n",
      "1. Test D-M global → Responde: \"¿Quién es mejor en general?\"\n",
      "2. Tests D-M por escenario → Responde: \"¿Esa conclusión se mantiene en todos los escenarios?\"\n",
      "3. ANOVA sobre diferencias → Responde: \"¿Qué factores explican las diferencias?\"\n",
      "\n",
      "Esto te da una historia completa:\n",
      "- Modelo A es mejor en promedio (D-M global)\n",
      "- PERO esa ventaja desaparece cuando Config=2 y Var=1.0 (D-M estratificado)\n",
      "- Los factores Config y Var tienen efectos significativos (ANOVA)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# ============================================================================\n",
    "# SIMULACIÓN DE DATOS SIMPLIFICADA\n",
    "# ============================================================================\n",
    "# Supongamos solo 2 modelos, 2 configs, 2 distribuciones, 2 varianzas, 3 pasos\n",
    "# Total: 2×2×2×3 = 24 observaciones por modelo\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "configs = [1, 2]\n",
    "dists = ['Normal', 'T-Student']\n",
    "vars_val = [0.5, 1.0]\n",
    "pasos = [1, 2, 3]\n",
    "\n",
    "data = []\n",
    "for config in configs:\n",
    "    for dist in dists:\n",
    "        for var in vars_val:\n",
    "            for paso in pasos:\n",
    "                # Modelo A: mejor en general, pero peor con Config=2 + Var=1.0\n",
    "                if config == 2 and var == 1.0:\n",
    "                    ecrps_A = np.random.normal(0.8, 0.1)  # Peor\n",
    "                else:\n",
    "                    ecrps_A = np.random.normal(0.4, 0.05)  # Mejor\n",
    "                \n",
    "                # Modelo B: más estable, rendimiento medio\n",
    "                ecrps_B = np.random.normal(0.5, 0.05)\n",
    "                \n",
    "                data.append({\n",
    "                    'Config': config,\n",
    "                    'Dist': dist,\n",
    "                    'Var': var,\n",
    "                    'Paso': paso,\n",
    "                    'Modelo_A': ecrps_A,\n",
    "                    'Modelo_B': ecrps_B\n",
    "                })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"=\"*80)\n",
    "print(\"DATOS SIMULADOS (primeras 12 filas)\")\n",
    "print(\"=\"*80)\n",
    "print(df.head(12))\n",
    "print(f\"\\nTotal observaciones: {len(df)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# ENFOQUE ACTUAL: UN SOLO TEST D-M CON TODAS LAS OBSERVACIONES\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ENFOQUE 1: TEST D-M GLOBAL (COMO ESTÁ EN TU CÓDIGO)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "errors_A = df['Modelo_A'].values\n",
    "errors_B = df['Modelo_B'].values\n",
    "diferencias = errors_A - errors_B\n",
    "\n",
    "print(f\"\\nDiferencias individuales (primeras 12):\")\n",
    "print(diferencias[:12])\n",
    "print(f\"\\nMedia de diferencias: {np.mean(diferencias):.4f}\")\n",
    "print(f\"Desv. Std de diferencias: {np.std(diferencias, ddof=1):.4f}\")\n",
    "\n",
    "# Test D-M simple\n",
    "d_bar = np.mean(diferencias)\n",
    "T = len(diferencias)\n",
    "se = np.std(diferencias, ddof=1) / np.sqrt(T)\n",
    "dm_stat = d_bar / se\n",
    "p_value_dm = 2 * (1 - stats.norm.cdf(abs(dm_stat)))\n",
    "\n",
    "print(f\"\\nEstadístico D-M: {dm_stat:.4f}\")\n",
    "print(f\"P-valor: {p_value_dm:.4f}\")\n",
    "print(f\"Conclusión: {'Modelo A significativamente diferente de B' if p_value_dm < 0.05 else 'No hay diferencia significativa'}\")\n",
    "\n",
    "# ============================================================================\n",
    "# ENFOQUE ALTERNATIVO 1: TESTS D-M ESTRATIFICADOS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ENFOQUE 2: TESTS D-M ESTRATIFICADOS POR CONDICIÓN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nTests por Config:\")\n",
    "for config in configs:\n",
    "    subset = df[df['Config'] == config]\n",
    "    dif = subset['Modelo_A'].values - subset['Modelo_B'].values\n",
    "    d_bar = np.mean(dif)\n",
    "    se = np.std(dif, ddof=1) / np.sqrt(len(dif))\n",
    "    dm_stat = d_bar / se\n",
    "    p_val = 2 * (1 - stats.norm.cdf(abs(dm_stat)))\n",
    "    print(f\"  Config {config}: media_dif={d_bar:.4f}, DM={dm_stat:.4f}, p={p_val:.4f}\")\n",
    "\n",
    "print(\"\\nTests por Varianza:\")\n",
    "for var in vars_val:\n",
    "    subset = df[df['Var'] == var]\n",
    "    dif = subset['Modelo_A'].values - subset['Modelo_B'].values\n",
    "    d_bar = np.mean(dif)\n",
    "    se = np.std(dif, ddof=1) / np.sqrt(len(dif))\n",
    "    dm_stat = d_bar / se\n",
    "    p_val = 2 * (1 - stats.norm.cdf(abs(dm_stat)))\n",
    "    print(f\"  Var {var}: media_dif={d_bar:.4f}, DM={dm_stat:.4f}, p={p_val:.4f}\")\n",
    "\n",
    "print(\"\\nTests por Config × Var (combinación crítica):\")\n",
    "for config in configs:\n",
    "    for var in vars_val:\n",
    "        subset = df[(df['Config'] == config) & (df['Var'] == var)]\n",
    "        dif = subset['Modelo_A'].values - subset['Modelo_B'].values\n",
    "        d_bar = np.mean(dif)\n",
    "        se = np.std(dif, ddof=1) / np.sqrt(len(dif))\n",
    "        dm_stat = d_bar / se if se > 0 else 0\n",
    "        p_val = 2 * (1 - stats.norm.cdf(abs(dm_stat))) if se > 0 else 1.0\n",
    "        print(f\"  Config={config}, Var={var}: media_dif={d_bar:.4f}, DM={dm_stat:.4f}, p={p_val:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# ENFOQUE ALTERNATIVO 2: ANOVA SOBRE LAS DIFERENCIAS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ENFOQUE 3: ANOVA MULTIFACTORIAL SOBRE DIFERENCIAS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df['Diferencia'] = df['Modelo_A'] - df['Modelo_B']\n",
    "\n",
    "# ANOVA de efectos principales\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "print(\"\\nEfecto de Config:\")\n",
    "grupos_config = [df[df['Config'] == c]['Diferencia'].values for c in configs]\n",
    "F_stat, p_val = f_oneway(*grupos_config)\n",
    "print(f\"  F={F_stat:.4f}, p={p_val:.4f}\")\n",
    "\n",
    "print(\"\\nEfecto de Var:\")\n",
    "grupos_var = [df[df['Var'] == v]['Diferencia'].values for v in vars_val]\n",
    "F_stat, p_val = f_oneway(*grupos_var)\n",
    "print(f\"  F={F_stat:.4f}, p={p_val:.4f}\")\n",
    "\n",
    "print(\"\\nEfecto de Dist:\")\n",
    "grupos_dist = [df[df['Dist'] == d]['Diferencia'].values for d in dists]\n",
    "F_stat, p_val = f_oneway(*grupos_dist)\n",
    "print(f\"  F={F_stat:.4f}, p={p_val:.4f}\")\n",
    "\n",
    "# Interacción Config × Var\n",
    "print(\"\\nEfecto de interacción Config × Var:\")\n",
    "grupos_interaccion = []\n",
    "for config in configs:\n",
    "    for var in vars_val:\n",
    "        subset = df[(df['Config'] == config) & (df['Var'] == var)]\n",
    "        grupos_interaccion.append(subset['Diferencia'].values)\n",
    "F_stat, p_val = f_oneway(*grupos_interaccion)\n",
    "print(f\"  F={F_stat:.4f}, p={p_val:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# RESUMEN VISUAL\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMEN: MEDIAS DE DIFERENCIAS POR CONDICIÓN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "pivot = df.pivot_table(values='Diferencia', \n",
    "                       index=['Config', 'Var'], \n",
    "                       columns='Dist', \n",
    "                       aggfunc='mean')\n",
    "print(\"\\nTabla: Diferencia promedio (Modelo_A - Modelo_B)\")\n",
    "print(pivot.round(4))\n",
    "print(\"\\nInterpretación:\")\n",
    "print(\"  - Valores negativos: Modelo A mejor (menor ECRPS)\")\n",
    "print(\"  - Valores positivos: Modelo B mejor\")\n",
    "print(\"  - Nota: Config=2 + Var=1.0 tiene diferencias positivas (A peor que B)\")\n",
    "\n",
    "# ============================================================================\n",
    "# CONCLUSIÓN COMPARATIVA\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONCLUSIONES COMPARATIVAS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. TEST D-M GLOBAL (tu código actual):\")\n",
    "print(f\"   → Conclusión: Modelo A {'mejor' if d_bar < 0 else 'peor'} que B en promedio\")\n",
    "print(f\"   → Problema: NO detecta que en Config=2+Var=1.0 la situación se invierte\")\n",
    "\n",
    "print(\"\\n2. TESTS D-M ESTRATIFICADOS:\")\n",
    "print(\"   → Conclusión: La superioridad de A depende de las condiciones\")\n",
    "print(\"   → Ventaja: Identifica dónde cada modelo es mejor\")\n",
    "print(\"   → Problema: Múltiples tests, ajuste de Bonferroni muy conservador\")\n",
    "\n",
    "print(\"\\n3. ANOVA SOBRE DIFERENCIAS:\")\n",
    "print(\"   → Conclusión: Hay efectos significativos de Config, Var, y su interacción\")\n",
    "print(\"   → Ventaja: Cuantifica qué factores afectan las diferencias\")\n",
    "print(\"   → Limitación: No hace comparación pairwise directa entre modelos\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RECOMENDACIÓN PARA TU ANÁLISIS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "Deberías combinar los tres enfoques:\n",
    "\n",
    "1. Test D-M global → Responde: \"¿Quién es mejor en general?\"\n",
    "2. Tests D-M por escenario → Responde: \"¿Esa conclusión se mantiene en todos los escenarios?\"\n",
    "3. ANOVA sobre diferencias → Responde: \"¿Qué factores explican las diferencias?\"\n",
    "\n",
    "Esto te da una historia completa:\n",
    "- Modelo A es mejor en promedio (D-M global)\n",
    "- PERO esa ventaja desaparece cuando Config=2 y Var=1.0 (D-M estratificado)\n",
    "- Los factores Config y Var tienen efectos significativos (ANOVA)\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86610207",
   "metadata": {},
   "source": [
    "# Analisis General - Simulación Base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc245af6",
   "metadata": {},
   "source": [
    "## Pre-procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "378a602a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tabla Comparativa de Modelos (Basada en MEDIA) ---\n",
      "             Modelo  General     ARMA     ARIMA    SETAR Mejor_Escenario\n",
      "Block Bootstrapping 4.275365 0.946781 11.251601 0.627714           SETAR\n",
      "    Sieve Bootstrap 0.570491 0.547725  0.547481 0.616268           ARIMA\n",
      "               LSPM 0.845497 0.811287  1.064804 0.660398           SETAR\n",
      "              LSPMW 1.572319 0.960743  3.079645 0.676570           SETAR\n",
      "              AREPD 3.880255 0.936671 10.031183 0.672910           SETAR\n",
      "               MCPS 1.553139 0.752295  3.218168 0.688955           SETAR\n",
      "            AV-MCPS 1.578091 0.733188  3.324007 0.677078           SETAR\n",
      "             DeepAR 1.836024 0.568693  4.329124 0.610255            ARMA\n",
      "         EnCQR-LSTM 2.675191 1.071557  6.112344 0.841671           SETAR\n",
      "\n",
      "--- Tabla Comparativa de Modelos (Basada en MEDIANA) ---\n",
      "             Modelo  General     ARMA    ARIMA    SETAR Mejor_Escenario\n",
      "Block Bootstrapping 0.989415 0.654169 5.283530 0.540627           SETAR\n",
      "    Sieve Bootstrap 0.504848 0.483753 0.487997 0.535568            ARMA\n",
      "               LSPM 0.617954 0.617367 0.813400 0.551614           SETAR\n",
      "              LSPMW 0.803709 0.671465 1.666194 0.559561           SETAR\n",
      "              AREPD 0.987714 0.650945 4.398461 0.566293           SETAR\n",
      "               MCPS 0.676059 0.612732 1.237445 0.590001           SETAR\n",
      "            AV-MCPS 0.668131 0.597699 1.229916 0.581804           SETAR\n",
      "             DeepAR 0.579363 0.510069 1.029325 0.531675            ARMA\n",
      "         EnCQR-LSTM 1.250342 0.889849 3.776379 0.735301           SETAR\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Leer los archivos\n",
    "arma_df = pd.read_excel(\"./datos/Simulacion/Base/resultados_140_ARMA_FINAL.xlsx\")\n",
    "arima_df = pd.read_excel(\"./datos/Simulacion/Base/resultados_140_ARIMA_FINAL.xlsx\")\n",
    "setar_df = pd.read_excel(\"./datos/Simulacion/Base/resultados_140_SETAR_FINAL.xlsx\")\n",
    "\n",
    "# 2. Asignar la columna ESCENARIO a cada dataframe\n",
    "arma_df['ESCENARIO'] = \"Lineal Estacionario\"\n",
    "arima_df['ESCENARIO'] = \"Lineal No estacionario\"\n",
    "setar_df['ESCENARIO'] = \"No lineal Estacionario\"\n",
    "\n",
    "# 3. Juntarlos uno bajo el otro (Concatenar)\n",
    "df_total = pd.concat([arma_df, arima_df, setar_df], ignore_index=True)\n",
    "\n",
    "# Seleccionar solo las columnas requeridas\n",
    "columnas_deseadas = [\n",
    "    \"Paso\", \"Config\", \"Dist\", \"Var\", \"Block Bootstrapping\", \n",
    "    \"Sieve Bootstrap\", \"LSPM\", \"LSPMW\", \"AREPD\", \"MCPS\", \n",
    "    \"AV-MCPS\", \"DeepAR\", \"EnCQR-LSTM\", \"ESCENARIO\"\n",
    "]\n",
    "df_total = df_total[columnas_deseadas]\n",
    "\n",
    "# Definimos cuáles son las columnas que representan a los modelos predictivos\n",
    "modelos = [\n",
    "    \"Block Bootstrapping\", \"Sieve Bootstrap\", \"LSPM\", \"LSPMW\", \n",
    "    \"AREPD\", \"MCPS\", \"AV-MCPS\", \"DeepAR\", \"EnCQR-LSTM\"\n",
    "]\n",
    "\n",
    "# 4. Guardar el dataframe consolidado\n",
    "df_total.to_excel(\"./datos/Simulacion/Base/dataframe_consolidado.xlsx\", index=False)\n",
    "\n",
    "# 5. Generar y mostrar las tablas (Media y Mediana)\n",
    "metricas = {'MEDIA': 'mean', 'MEDIANA': 'median'}\n",
    "\n",
    "for nombre_metrica, funcion in metricas.items():\n",
    "    # Calculamos el valor general según la métrica (mean o median)\n",
    "    if funcion == 'mean':\n",
    "        resumen_general = df_total[modelos].mean()\n",
    "        resumen_escenarios = df_total.groupby('ESCENARIO')[modelos].mean().T\n",
    "    else:\n",
    "        resumen_general = df_total[modelos].median()\n",
    "        resumen_escenarios = df_total.groupby('ESCENARIO')[modelos].median().T\n",
    "\n",
    "    # Construimos la tabla final para esta métrica\n",
    "    tabla_resumen = pd.DataFrame(index=modelos)\n",
    "    tabla_resumen['General'] = resumen_general\n",
    "    tabla_resumen['ARMA'] = resumen_escenarios['Lineal Estacionario']\n",
    "    tabla_resumen['ARIMA'] = resumen_escenarios['Lineal No estacionario']\n",
    "    tabla_resumen['SETAR'] = resumen_escenarios['No lineal Estacionario']\n",
    "\n",
    "    # Determinar el Mejor_Escenario (valor mínimo entre los tres escenarios)\n",
    "    escenarios_cols = ['ARMA', 'ARIMA', 'SETAR']\n",
    "    tabla_resumen['Mejor_Escenario'] = tabla_resumen[escenarios_cols].idxmin(axis=1)\n",
    "\n",
    "    # Imprimir resultado\n",
    "    print(f\"\\n--- Tabla Comparativa de Modelos (Basada en {nombre_metrica}) ---\")\n",
    "    print(tabla_resumen.reset_index().rename(columns={'index': 'Modelo'}).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abc9573",
   "metadata": {},
   "source": [
    "## Analisis general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b90efcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuevo orden de modelos (basado en Lineal No Estacionario (ARIMA)):\n",
      "1. Sieve Bootstrap: 0.5475\n",
      "2. LSPM: 1.0648\n",
      "3. LSPMW: 3.0796\n",
      "4. MCPS: 3.2182\n",
      "5. AV-MCPS: 3.3240\n",
      "6. DeepAR: 4.3291\n",
      "7. EnCQR-LSTM: 6.1123\n",
      "8. AREPD: 10.0312\n",
      "9. Block Bootstrapping: 11.2516\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 1: RENDIMIENTO POR ESCENARIOS\n",
      "================================================================================\n",
      "✓ Gráfica 1.1 guardada\n",
      "✓ Gráfica 1.2 guardada\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 2: ANÁLISIS POR CONFIG\n",
      "================================================================================\n",
      "✓ Gráfica 2.1 guardada\n",
      "✓ Gráfica 2.1.a guardada\n",
      "✓ Gráfica 2.1.b guardada\n",
      "✓ Gráfica 2.1.c guardada\n",
      "✓ Gráfica 2.2 guardada\n",
      "✓ Gráfica 2.2.a guardada\n",
      "✓ Gráfica 2.2.b guardada\n",
      "✓ Gráfica 2.2.c guardada\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 3: ANÁLISIS POR DIST\n",
      "================================================================================\n",
      "✓ Gráfica 3.1 guardada\n",
      "✓ Gráfica 3.1.a guardada\n",
      "✓ Gráfica 3.1.b guardada\n",
      "✓ Gráfica 3.1.c guardada\n",
      "✓ Gráfica 3.2 guardada\n",
      "✓ Gráfica 3.2.a guardada\n",
      "✓ Gráfica 3.2.b guardada\n",
      "✓ Gráfica 3.2.c guardada\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 4: ANÁLISIS POR VAR\n",
      "================================================================================\n",
      "✓ Gráfica 4.1 guardada\n",
      "✓ Gráfica 4.1.a guardada\n",
      "✓ Gráfica 4.1.b guardada\n",
      "✓ Gráfica 4.1.c guardada\n",
      "✓ Gráfica 4.2 guardada\n",
      "✓ Gráfica 4.2.a guardada\n",
      "✓ Gráfica 4.2.b guardada\n",
      "✓ Gráfica 4.2.c guardada\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 5: ANÁLISIS POR PASO (HORIZONTE)\n",
      "================================================================================\n",
      "✓ Gráfica 5.1 guardada\n",
      "✓ Gráfica 5.1.a guardada\n",
      "✓ Gráfica 5.1.b guardada\n",
      "✓ Gráfica 5.1.c guardada\n",
      "✓ Gráfica 5.2 guardada\n",
      "✓ Gráfica 5.2.a guardada\n",
      "✓ Gráfica 5.2.b guardada\n",
      "✓ Gráfica 5.2.c guardada\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 5.5: ANÁLISIS DE INTERACCIONES\n",
      "================================================================================\n",
      "✓ Gráfica 8 (5.7)  guardada: Subplots por Modelo\n",
      "✓ Gráfica 9 (5.8)  guardada: Subplots por Modelo\n",
      "✓ Gráfica 10 (5.9)  guardada: Subplots por Modelo\n",
      "✓ Gráfica 11 (5.10)  guardada: Subplots por Modelo\n",
      "✓ Gráfica 8 (5.7) .a guardada: Subplots por Modelo\n",
      "✓ Gráfica 9 (5.8) .a guardada: Subplots por Modelo\n",
      "✓ Gráfica 10 (5.9) .a guardada: Subplots por Modelo\n",
      "✓ Gráfica 11 (5.10) .a guardada: Subplots por Modelo\n",
      "✓ Gráfica 8 (5.7) .b guardada: Subplots por Modelo\n",
      "✓ Gráfica 9 (5.8) .b guardada: Subplots por Modelo\n",
      "✓ Gráfica 10 (5.9) .b guardada: Subplots por Modelo\n",
      "✓ Gráfica 11 (5.10) .b guardada: Subplots por Modelo\n",
      "✓ Gráfica 8 (5.7) .c guardada: Subplots por Modelo\n",
      "✓ Gráfica 9 (5.8) .c guardada: Subplots por Modelo\n",
      "✓ Gráfica 10 (5.9) .c guardada: Subplots por Modelo\n",
      "✓ Gráfica 11 (5.10) .c guardada: Subplots por Modelo\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 6: ROBUSTEZ Y TEST DIEBOLD-MARIANO\n",
      "================================================================================\n",
      "✓ Gráfica 6.1 guardada (ordenada de menor a mayor CV)\n",
      "✓ Gráfica 6.2 guardada (Test HLN-DM con h=6, T=5040, df=5039)\n",
      "✓ Gráfica 6.2.a guardada (Test HLN-DM con h=6, T=1680, df=1679)\n",
      "✓ Gráfica 6.2.b guardada (Test HLN-DM con h=6, T=1680, df=1679)\n",
      "✓ Gráfica 6.2.c guardada (Test HLN-DM con h=6, T=1680, df=1679)\n",
      "\n",
      "================================================================================\n",
      "PROCESO COMPLETADO\n",
      "================================================================================\n",
      "\n",
      "Mejoras implementadas:\n",
      "1. ✓ Orden consistente en gráficas 1.1 y 1.2\n",
      "2. ✓ Formato de 2 decimales en heatmap 2.2 general\n",
      "3. ✓ Solo Coeficiente de Variación en gráfica 6.1 (ordenado menor a mayor)\n",
      "4. ✓ Test Diebold-Mariano con corrección HLN y distribución t-Student\n",
      "5. ✓ Horizonte de pronóstico (h) incorporado en el análisis\n",
      "\n",
      "================================================================================\n",
      "ANÁLISIS DE INTERACCIONES (Carpeta: Interacciones/)\n",
      "================================================================================\n",
      "6. ✓ Config × Var: Heatmaps por modelo (matriz 3×3)\n",
      "7. ✓ Config × Dist: Heatmaps por modelo (matriz 3×3)\n",
      "8. ✓ Dist × Paso: Gráficas de líneas por distribución\n",
      "9. ✓ Dist × Var: Gráficas de líneas por distribución\n",
      "10. ✓ Config × Paso: Gráficas de líneas por configuración\n",
      "11. ✓ Var × Horizonte: Gráficas de líneas por varianza\n",
      "================================================================================\n",
      "\n",
      "Total de gráficas generadas en Interacciones/: 24 archivos\n",
      "(6 tipos de interacción × 4 escenarios: General + 3 específicos)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import normaltest\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración general\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Crear carpeta de resultados\n",
    "output_dir = Path(\"./Resultados_analisis/Simulacion_base\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Crear carpeta de interacciones\n",
    "interactions_dir = output_dir / \"Interacciones\"\n",
    "interactions_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_excel(\"./datos/Simulacion/Base/dataframe_consolidado.xlsx\")\n",
    "\n",
    "# 1) CAMBIO DE NOMBRES DE ESCENARIOS\n",
    "df['ESCENARIO'] = df['ESCENARIO'].replace({\n",
    "    \"Lineal Estacionario\": \"Lineal Estacionario (ARMA)\",\n",
    "    \"Lineal No estacionario\": \"Lineal No Estacionario (ARIMA)\",\n",
    "    \"No lineal Estacionario\": \"No lineal Estacionario (SETAR)\"\n",
    "})\n",
    "\n",
    "# Identificar columnas de modelos\n",
    "var_cols = ['Paso', 'Config', 'Dist', 'Var', 'ESCENARIO']\n",
    "original_model_cols = [col for col in df.columns if col not in var_cols]\n",
    "\n",
    "# 2) ORGANIZAR MODELOS POR RENDIMIENTO EN \"Lineal No Estacionario (ARIMA)\" (Menor a mayor)\n",
    "target_scenario = \"Lineal No Estacionario (ARIMA)\"\n",
    "model_order_scores = df[df['ESCENARIO'] == target_scenario][original_model_cols].mean().sort_values()\n",
    "model_cols = list(model_order_scores.index)\n",
    "\n",
    "print(\"Nuevo orden de modelos (basado en Lineal No Estacionario (ARIMA)):\")\n",
    "for i, m in enumerate(model_cols, 1):\n",
    "    print(f\"{i}. {m}: {model_order_scores[m]:.4f}\")\n",
    "\n",
    "# Mapeo de escenarios\n",
    "escenarios_map = {\n",
    "    'Lineal Estacionario (ARMA)': 'Lineal Estacionario (ARMA)',\n",
    "    'Lineal No Estacionario (ARIMA)': 'Lineal No Estacionario (ARIMA)',\n",
    "    'No lineal Estacionario (SETAR)': 'No lineal Estacionario (SETAR)'\n",
    "}\n",
    "\n",
    "# Definir colores para cada modelo\n",
    "palette = sns.color_palette(\"husl\", len(model_cols))\n",
    "model_colors = {model: palette[i] for i, model in enumerate(model_cols)}\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 1: RENDIMIENTO POR ESCENARIOS\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 1: RENDIMIENTO POR ESCENARIOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_performance_by_scenario():\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    scenarios = [\"Lineal Estacionario (ARMA)\", \"Lineal No Estacionario (ARIMA)\", \"No lineal Estacionario (SETAR)\"]\n",
    "    x = np.arange(len(model_cols))\n",
    "    width = 0.25 \n",
    "    \n",
    "    scenario_colors = {\n",
    "        'Lineal Estacionario (ARMA)': '#5D3FD3',    \n",
    "        'Lineal No Estacionario (ARIMA)': '#808080', \n",
    "        'No lineal Estacionario (SETAR)': '#00A36C'  \n",
    "    }\n",
    "    \n",
    "    for idx, scenario in enumerate(scenarios):\n",
    "        means = [df[df['ESCENARIO'] == scenario][model].mean() for model in model_cols]\n",
    "        position = x + (idx - 1) * width\n",
    "        \n",
    "        bars = ax.bar(position, means, width, label=scenario, \n",
    "                     color=scenario_colors[scenario], alpha=0.85, edgecolor='black', linewidth=0.5)\n",
    "        \n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{height:.2f}', ha='center', va='bottom', fontsize=7, rotation=0)\n",
    "    \n",
    "    ax.set_xlabel('Modelo (Ordenados por desempeño en ARIMA)', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('ECRPS Promedio', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Rendimiento de Modelos por Escenario (ECRPS)', fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(model_cols, rotation=45, ha='right', fontsize=9)\n",
    "    ax.legend(loc='upper left', ncol=1, fontsize=10, framealpha=0.9)\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / '1.1_rendimiento_por_escenario.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Gráfica 1.1 guardada\")\n",
    "\n",
    "plot_performance_by_scenario()\n",
    "\n",
    "def plot_relative_performance():\n",
    "    base_scenario = 'Lineal Estacionario (ARMA)'\n",
    "    scenarios_compare = ['Lineal No Estacionario (ARIMA)', 'No lineal Estacionario (SETAR)']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 10))\n",
    "    \n",
    "    y = np.arange(len(model_cols))\n",
    "    height = 0.35  \n",
    "    \n",
    "    for idx, scenario in enumerate(scenarios_compare):\n",
    "        changes = []\n",
    "        for model in model_cols:\n",
    "            base_value = df[df['ESCENARIO'] == base_scenario][model].mean()\n",
    "            scenario_value = df[df['ESCENARIO'] == scenario][model].mean()\n",
    "            pct_change = ((scenario_value - base_value) / base_value) * 100\n",
    "            changes.append(pct_change)\n",
    "        \n",
    "        position = y + idx * height\n",
    "        bars = ax.barh(position, changes, height, label=scenario, alpha=0.85, edgecolor='black', linewidth=0.5)\n",
    "        \n",
    "        for bar, val in zip(bars, changes):\n",
    "            width = bar.get_width()\n",
    "            ax.text(width + (1 if width > 0 else -1), bar.get_y() + bar.get_height()/2.,\n",
    "                   f'{val:+.1f}%', ha='left' if val > 0 else 'right', \n",
    "                   va='center', fontsize=7)\n",
    "    \n",
    "    ax.set_yticks(y + height / 2)\n",
    "    ax.set_yticklabels(model_cols, fontsize=10)\n",
    "    ax.set_xlabel('Cambio Relativo (%)', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(f'Cambio Relativo en ECRPS vs. {base_scenario}', fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.axvline(x=0, color='black', linestyle='-', linewidth=1.5)\n",
    "    ax.legend(loc='best', fontsize=10, framealpha=0.9)\n",
    "    ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / '1.2_cambio_relativo_escenario_base.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Gráfica 1.2 guardada\")\n",
    "\n",
    "plot_relative_performance()\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 2: ANÁLISIS POR CONFIG\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 2: ANÁLISIS POR CONFIG\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_zscore_heatmap_config(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Z-scores de ECRPS por Configuración ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Z-scores de ECRPS por Configuración (General)'\n",
    "    \n",
    "    pivot_data = data_filtered.groupby('Config')[model_cols].mean()\n",
    "    z_scores = pivot_data.apply(lambda x: (x - x.mean()) / x.std(), axis=0)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    sns.heatmap(z_scores.T, annot=True, fmt='.2f', cmap='RdYlGn_r', \n",
    "                center=0, cbar_kws={'label': 'Z-score'}, ax=ax,\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    ax.set_title(title, fontsize=12, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Configuración', fontsize=11)\n",
    "    ax.set_ylabel('Modelo', fontsize=11)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'2.1{suffix}_zscore_config.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 2.1{suffix} guardada\")\n",
    "\n",
    "plot_zscore_heatmap_config()\n",
    "plot_zscore_heatmap_config('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_zscore_heatmap_config('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_zscore_heatmap_config('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "def plot_variability_config(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Desv. Estándar de ECRPS por Configuración ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Desv. Estándar de ECRPS por Configuración (General)'\n",
    "    \n",
    "    pivot_std = data_filtered.groupby('Config')[model_cols].std()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    fmt = '.2f' if suffix == '' else '.4f'\n",
    "    sns.heatmap(pivot_std.T, annot=True, fmt=fmt, cmap='YlOrRd', \n",
    "                cbar_kws={'label': 'Desv. Estándar'}, ax=ax,\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Configuración', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'2.2{suffix}_variabilidad_config.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 2.2{suffix} guardada\")\n",
    "\n",
    "plot_variability_config()\n",
    "plot_variability_config('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_variability_config('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_variability_config('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 3: ANÁLISIS POR DIST\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 3: ANÁLISIS POR DIST\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_zscore_heatmap_dist(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Z-scores de ECRPS por Distribución ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Z-scores de ECRPS por Distribución (General)'\n",
    "    \n",
    "    pivot_data = data_filtered.groupby('Dist')[model_cols].mean()\n",
    "    z_scores = pivot_data.apply(lambda x: (x - x.mean()) / x.std(), axis=0)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    sns.heatmap(z_scores.T, annot=True, fmt='.2f', cmap='RdYlGn_r', \n",
    "                center=0, cbar_kws={'label': 'Z-score'}, ax=ax,\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    ax.set_title(title, fontsize=12, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Distribución', fontsize=11)\n",
    "    ax.set_ylabel('Modelo', fontsize=11)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'3.1{suffix}_zscore_dist.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 3.1{suffix} guardada\")\n",
    "\n",
    "plot_zscore_heatmap_dist()\n",
    "plot_zscore_heatmap_dist('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_zscore_heatmap_dist('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_zscore_heatmap_dist('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "def plot_variability_dist(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Desv. Estándar de ECRPS por Distribución ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Desv. Estándar de ECRPS por Distribución (General)'\n",
    "    \n",
    "    pivot_std = data_filtered.groupby('Dist')[model_cols].std()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    sns.heatmap(pivot_std.T, annot=True, fmt='.4f', cmap='YlOrRd', \n",
    "                cbar_kws={'label': 'Desv. Estándar'}, ax=ax,\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Distribución', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'3.2{suffix}_variabilidad_dist.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 3.2{suffix} guardada\")\n",
    "\n",
    "plot_variability_dist()\n",
    "plot_variability_dist('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_variability_dist('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_variability_dist('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 4: ANÁLISIS POR VAR\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 4: ANÁLISIS POR VAR\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_evolution_var(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Evolución de ECRPS por Varianza ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Evolución de ECRPS por Varianza (General)'\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    var_values = sorted(data_filtered['Var'].unique())\n",
    "    \n",
    "    for model in model_cols:\n",
    "        means = []\n",
    "        for var in var_values:\n",
    "            mean_val = data_filtered[data_filtered['Var'] == var][model].mean()\n",
    "            means.append(mean_val)\n",
    "        \n",
    "        ax.plot(var_values, means, marker='o', label=model, color=model_colors[model],\n",
    "                linewidth=2.5, markersize=7, alpha=0.85)\n",
    "    \n",
    "    ax.set_xlabel('Varianza', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('ECRPS Promedio', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.legend(loc='best', fontsize=9, ncol=2, framealpha=0.9)\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'4.1{suffix}_evolucion_var.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 4.1{suffix} guardada\")\n",
    "\n",
    "plot_evolution_var()\n",
    "plot_evolution_var('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_evolution_var('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_evolution_var('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "def plot_variability_var(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Desv. Estándar de ECRPS por Varianza ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Desv. Estándar de ECRPS por Varianza (General)'\n",
    "    \n",
    "    pivot_std = data_filtered.groupby('Var')[model_cols].std()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    sns.heatmap(pivot_std.T, annot=True, fmt='.4f', cmap='YlOrRd', \n",
    "                cbar_kws={'label': 'Desv. Estándar'}, ax=ax,\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Varianza', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'4.2{suffix}_variabilidad_var.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 4.2{suffix} guardada\")\n",
    "\n",
    "plot_variability_var()\n",
    "plot_variability_var('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_variability_var('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_variability_var('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 5: ANÁLISIS POR PASO (HORIZONTE)\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 5: ANÁLISIS POR PASO (HORIZONTE)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_evolution_paso(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Evolución de ECRPS por Horizonte de Pronóstico ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Evolución de ECRPS por Horizonte de Pronóstico (General)'\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    pasos = sorted(data_filtered['Paso'].unique())\n",
    "    \n",
    "    for model in model_cols:\n",
    "        means = []\n",
    "        for paso in pasos:\n",
    "            mean_val = data_filtered[data_filtered['Paso'] == paso][model].mean()\n",
    "            means.append(mean_val)\n",
    "        \n",
    "        ax.plot(pasos, means, marker='o', label=model, color=model_colors[model],\n",
    "                linewidth=2.5, markersize=7, alpha=0.85)\n",
    "    \n",
    "    ax.set_xlabel('Horizonte de Pronóstico', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('ECRPS Promedio', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.legend(loc='best', fontsize=9, ncol=2, framealpha=0.9)\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'5.1{suffix}_evolucion_paso.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 5.1{suffix} guardada\")\n",
    "\n",
    "plot_evolution_paso()\n",
    "plot_evolution_paso('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_evolution_paso('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_evolution_paso('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "def plot_variability_paso(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Desv. Estándar de ECRPS por Horizonte ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Desv. Estándar de ECRPS por Horizonte (General)'\n",
    "    \n",
    "    pivot_std = data_filtered.groupby('Paso')[model_cols].std()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    sns.heatmap(pivot_std.T, annot=True, fmt='.4f', cmap='YlOrRd', \n",
    "                cbar_kws={'label': 'Desv. Estándar'}, ax=ax,\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Horizonte de Pronóstico', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'5.2{suffix}_variabilidad_paso.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 5.2{suffix} guardada\")\n",
    "\n",
    "plot_variability_paso()\n",
    "plot_variability_paso('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_variability_paso('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_variability_paso('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 5.5: ANÁLISIS DE INTERACCIONES\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 5.5: ANÁLISIS DE INTERACCIONES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Función auxiliar para configurar el grid de modelos\n",
    "def get_model_grid_axes(n_models):\n",
    "    n_cols = 3\n",
    "    n_rows = (n_models + n_cols - 1) // n_cols\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 5 * n_rows))\n",
    "    return fig, axes.flatten(), n_rows, n_cols\n",
    "\n",
    "# INTERACCIÓN 3 (Lista 8): DIST × PASO - Subplots por Modelo\n",
    "def plot_interaction_dist_paso(scenario=None, suffix=''):\n",
    "    data_filtered = df[df['ESCENARIO'] == scenario].copy() if scenario else df.copy()\n",
    "    title = f'Interacción Dist × Paso por Modelo ({\"General\" if not scenario else scenario})'\n",
    "    \n",
    "    fig, axes, n_rows, n_cols = get_model_grid_axes(len(model_cols))\n",
    "    dists = sorted(data_filtered['Dist'].unique())\n",
    "    pasos = sorted(data_filtered['Paso'].unique())\n",
    "    colors_dist = sns.color_palette(\"viridis\", len(dists))\n",
    "\n",
    "    for idx, model in enumerate(model_cols):\n",
    "        ax = axes[idx]\n",
    "        for d_idx, dist in enumerate(dists):\n",
    "            means = [data_filtered[(data_filtered['Dist'] == dist) & (data_filtered['Paso'] == p)][model].mean() for p in pasos]\n",
    "            ax.plot(pasos, means, marker='o', label=dist, color=colors_dist[d_idx], linewidth=2)\n",
    "        \n",
    "        ax.set_title(f'Modelo: {model}', fontweight='bold')\n",
    "        ax.set_xlabel('Horizonte (Paso)')\n",
    "        ax.set_ylabel('ECRPS Promedio')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        if idx == 0: ax.legend(title=\"Distribución\", fontsize=8)\n",
    "\n",
    "    for i in range(len(model_cols), len(axes)): axes[i].set_visible(False)\n",
    "    plt.suptitle(title, fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(interactions_dir / f'5.7{suffix}_interaccion_dist_paso_modelos.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 8 (5.7) {suffix} guardada: Subplots por Modelo\")\n",
    "\n",
    "# INTERACCIÓN 4 (Lista 9): DIST × VAR - Subplots por Modelo\n",
    "def plot_interaction_dist_var(scenario=None, suffix=''):\n",
    "    data_filtered = df[df['ESCENARIO'] == scenario].copy() if scenario else df.copy()\n",
    "    title = f'Interacción Dist × Var por Modelo ({\"General\" if not scenario else scenario})'\n",
    "    \n",
    "    fig, axes, _, _ = get_model_grid_axes(len(model_cols))\n",
    "    dists = sorted(data_filtered['Dist'].unique())\n",
    "    vars_val = sorted(data_filtered['Var'].unique())\n",
    "    colors_dist = sns.color_palette(\"magma\", len(dists))\n",
    "\n",
    "    for idx, model in enumerate(model_cols):\n",
    "        ax = axes[idx]\n",
    "        for d_idx, dist in enumerate(dists):\n",
    "            means = [data_filtered[(data_filtered['Dist'] == dist) & (data_filtered['Var'] == v)][model].mean() for v in vars_val]\n",
    "            ax.plot(vars_val, means, marker='s', label=dist, color=colors_dist[d_idx], linewidth=2)\n",
    "        \n",
    "        ax.set_title(f'Modelo: {model}', fontweight='bold')\n",
    "        ax.set_xlabel('Varianza')\n",
    "        ax.set_ylabel('ECRPS Promedio')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        if idx == 0: ax.legend(title=\"Distribución\", fontsize=8)\n",
    "\n",
    "    for i in range(len(model_cols), len(axes)): axes[i].set_visible(False)\n",
    "    plt.suptitle(title, fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(interactions_dir / f'5.8{suffix}_interaccion_dist_var_modelos.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 9 (5.8) {suffix} guardada: Subplots por Modelo\")\n",
    "\n",
    "# INTERACCIÓN 5 (Lista 10): CONFIG × PASO - Subplots por Modelo\n",
    "def plot_interaction_config_paso(scenario=None, suffix=''):\n",
    "    data_filtered = df[df['ESCENARIO'] == scenario].copy() if scenario else df.copy()\n",
    "    title = f'Interacción Config × Paso por Modelo ({\"General\" if not scenario else scenario})'\n",
    "    \n",
    "    fig, axes, _, _ = get_model_grid_axes(len(model_cols))\n",
    "    configs = sorted(data_filtered['Config'].unique())\n",
    "    pasos = sorted(data_filtered['Paso'].unique())\n",
    "    colors_conf = sns.color_palette(\"tab10\", len(configs))\n",
    "\n",
    "    for idx, model in enumerate(model_cols):\n",
    "        ax = axes[idx]\n",
    "        for c_idx, config in enumerate(configs):\n",
    "            means = [data_filtered[(data_filtered['Config'] == config) & (data_filtered['Paso'] == p)][model].mean() for p in pasos]\n",
    "            ax.plot(pasos, means, marker='^', label=config, color=colors_conf[c_idx], linewidth=2)\n",
    "        \n",
    "        ax.set_title(f'Modelo: {model}', fontweight='bold')\n",
    "        ax.set_xlabel('Horizonte (Paso)')\n",
    "        ax.set_ylabel('ECRPS Promedio')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        if idx == 0: ax.legend(title=\"Config\", fontsize=8)\n",
    "\n",
    "    for i in range(len(model_cols), len(axes)): axes[i].set_visible(False)\n",
    "    plt.suptitle(title, fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(interactions_dir / f'5.9{suffix}_interaccion_config_paso_modelos.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 10 (5.9) {suffix} guardada: Subplots por Modelo\")\n",
    "\n",
    "# INTERACCIÓN 6 (Lista 11): VAR × HORIZONTE - Subplots por Modelo\n",
    "def plot_interaction_var_horizonte(scenario=None, suffix=''):\n",
    "    data_filtered = df[df['ESCENARIO'] == scenario].copy() if scenario else df.copy()\n",
    "    title = f'Interacción Var × Horizonte por Modelo ({\"General\" if not scenario else scenario})'\n",
    "    \n",
    "    fig, axes, _, _ = get_model_grid_axes(len(model_cols))\n",
    "    vars_val = sorted(data_filtered['Var'].unique())\n",
    "    pasos = sorted(data_filtered['Paso'].unique())\n",
    "    colors_var = sns.color_palette(\"rocket\", len(vars_val))\n",
    "\n",
    "    for idx, model in enumerate(model_cols):\n",
    "        ax = axes[idx]\n",
    "        for v_idx, var in enumerate(vars_val):\n",
    "            means = [data_filtered[(data_filtered['Var'] == var) & (data_filtered['Paso'] == p)][model].mean() for p in pasos]\n",
    "            ax.plot(pasos, means, marker='d', label=f'Var {var}', color=colors_var[v_idx], linewidth=2)\n",
    "        \n",
    "        ax.set_title(f'Modelo: {model}', fontweight='bold')\n",
    "        ax.set_xlabel('Horizonte (Paso)')\n",
    "        ax.set_ylabel('ECRPS Promedio')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        if idx == 0: ax.legend(title=\"Varianza\", fontsize=8)\n",
    "\n",
    "    for i in range(len(model_cols), len(axes)): axes[i].set_visible(False)\n",
    "    plt.suptitle(title, fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(interactions_dir / f'5.10{suffix}_interaccion_var_horizonte_modelos.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 11 (5.10) {suffix} guardada: Subplots por Modelo\")\n",
    "\n",
    "\n",
    "# ====================================================================================\n",
    "# EJECUCIÓN DE LAS NUEVAS FUNCIONES\n",
    "# ====================================================================================\n",
    "\n",
    "for sc_name, sc_suf in [ (None, ''), ('Lineal Estacionario (ARMA)', '.a'), \n",
    "                        ('Lineal No Estacionario (ARIMA)', '.b'), \n",
    "                        ('No lineal Estacionario (SETAR)', '.c') ]:\n",
    "    plot_interaction_dist_paso(sc_name, sc_suf)\n",
    "    plot_interaction_dist_var(sc_name, sc_suf)\n",
    "    plot_interaction_config_paso(sc_name, sc_suf)\n",
    "    plot_interaction_var_horizonte(sc_name, sc_suf)\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 6: ROBUSTEZ Y TEST DIEBOLD-MARIANO\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 6: ROBUSTEZ Y TEST DIEBOLD-MARIANO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_robustness():\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    cv_data = []\n",
    "    for model in model_cols:\n",
    "        cv = df[model].std() / df[model].mean()\n",
    "        cv_data.append((model, cv))\n",
    "    \n",
    "    cv_df = pd.DataFrame(cv_data, columns=['Modelo', 'CV'])\n",
    "    \n",
    "    # CAMBIO 1: Ordenar de menor a mayor CV para coherencia\n",
    "    cv_df = cv_df.sort_values('CV')\n",
    "    \n",
    "    colors_cv = ['#2ecc71' if cv < cv_df['CV'].median() else '#e74c3c' \n",
    "                 for cv in cv_df['CV']]\n",
    "    \n",
    "    bars = ax.barh(cv_df['Modelo'], cv_df['CV'], color=colors_cv, alpha=0.8, edgecolor='black')\n",
    "    \n",
    "    for bar, cv in zip(bars, cv_df['CV']):\n",
    "        width = bar.get_width()\n",
    "        ax.text(width + 0.001, bar.get_y() + bar.get_height()/2.,\n",
    "               f'{cv:.4f}', ha='left', va='center', fontsize=9)\n",
    "    \n",
    "    ax.set_xlabel('Coeficiente de Variación', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Robustez: Coeficiente de Variación\\n(Ordenado de menor a mayor - Menor valor indica mayor estabilidad)', \n",
    "                  fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.axvline(x=cv_df['CV'].median(), color='black', linestyle='--', linewidth=1.5, alpha=0.5, label='Mediana')\n",
    "    ax.legend(loc='best', fontsize=10)\n",
    "    ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / '6.1_robustez_coeficiente_variacion.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Gráfica 6.1 guardada (ordenada de menor a mayor CV)\")\n",
    "\n",
    "plot_robustness()\n",
    "\n",
    "def modified_diebold_mariano_test(errors1, errors2, h=1):\n",
    "    \"\"\"\n",
    "    Test Diebold-Mariano modificado con corrección Harvey-Leybourne-Newbold (1997)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    errors1, errors2 : array-like\n",
    "        Errores de pronóstico (ECRPS) de los dos modelos\n",
    "    h : int\n",
    "        Horizonte de pronóstico (forecast horizon)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    hlm_dm_stat : float\n",
    "        Estadístico DM corregido (HLN-DM)\n",
    "    p_value : float\n",
    "        P-valor usando distribución t-Student con T-1 grados de libertad\n",
    "    dm_stat : float\n",
    "        Estadístico DM original (sin corrección)\n",
    "    \"\"\"\n",
    "    # Calcular diferencial de pérdida\n",
    "    d = errors1 - errors2\n",
    "    d_bar = np.mean(d)\n",
    "    T = len(d)\n",
    "    \n",
    "    # Calcular autocovarianzas\n",
    "    def gamma_d(k):\n",
    "        if k == 0:\n",
    "            return np.var(d, ddof=1)\n",
    "        else:\n",
    "            return np.mean((d[k:] - d_bar) * (d[:-k] - d_bar))\n",
    "    \n",
    "    # Estimar la varianza de largo plazo usando Newey-West\n",
    "    # Para h-step-ahead forecasts, incluimos hasta h-1 lags\n",
    "    gamma_0 = gamma_d(0)\n",
    "    gamma_sum = gamma_0\n",
    "    \n",
    "    if h > 1:\n",
    "        for k in range(1, h):\n",
    "            gamma_k = gamma_d(k)\n",
    "            gamma_sum += 2 * gamma_k\n",
    "    \n",
    "    var_d = gamma_sum / T\n",
    "    \n",
    "    if var_d <= 0:\n",
    "        return 0, 1.0, 0\n",
    "    \n",
    "    # Estadístico DM original\n",
    "    dm_stat = d_bar / np.sqrt(var_d)\n",
    "    \n",
    "    # Corrección Harvey-Leybourne-Newbold (1997)\n",
    "    correction_factor = np.sqrt((T + 1 - 2*h + h*(h-1)) / T)\n",
    "    hln_dm_stat = correction_factor * dm_stat\n",
    "    \n",
    "    # P-valor usando t-Student con T-1 grados de libertad\n",
    "    df = T - 1\n",
    "    p_value = 2 * (1 - stats.t.cdf(abs(hln_dm_stat), df))\n",
    "    \n",
    "    return hln_dm_stat, p_value, dm_stat\n",
    "\n",
    "def plot_dm_test_heatmap(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Test Diebold-Mariano Modificado (HLN-DM)\\ncon Corrección de Bonferroni ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Test Diebold-Mariano Modificado (HLN-DM)\\ncon Corrección de Bonferroni (General)'\n",
    "    \n",
    "    # Determinar el horizonte de pronóstico promedio\n",
    "    h_forecast = int(data_filtered['Paso'].mean())\n",
    "    \n",
    "    n_models = len(model_cols)\n",
    "    n_comparisons = n_models * (n_models - 1) / 2\n",
    "    alpha = 0.05\n",
    "    bonferroni_alpha = alpha / n_comparisons\n",
    "    \n",
    "    results_matrix = np.zeros((n_models, n_models))\n",
    "    p_values = np.zeros((n_models, n_models))\n",
    "    dm_stats = np.zeros((n_models, n_models))\n",
    "    \n",
    "    for i, model1 in enumerate(model_cols):\n",
    "        for j, model2 in enumerate(model_cols):\n",
    "            if i == j:\n",
    "                results_matrix[i, j] = 0  \n",
    "                p_values[i, j] = 1.0\n",
    "                dm_stats[i, j] = 0\n",
    "            elif i < j:\n",
    "                errors1 = data_filtered[model1].values\n",
    "                errors2 = data_filtered[model2].values\n",
    "                hln_dm_stat, p_val, dm_original = modified_diebold_mariano_test(\n",
    "                    errors1, errors2, h=h_forecast\n",
    "                )\n",
    "                \n",
    "                p_values[i, j] = p_val\n",
    "                p_values[j, i] = p_val\n",
    "                dm_stats[i, j] = hln_dm_stat\n",
    "                dm_stats[j, i] = -hln_dm_stat\n",
    "                \n",
    "                if p_val < bonferroni_alpha:\n",
    "                    mean1 = np.mean(errors1)\n",
    "                    mean2 = np.mean(errors2)\n",
    "                    if mean1 < mean2:  \n",
    "                        results_matrix[i, j] = 1  \n",
    "                        results_matrix[j, i] = -1  \n",
    "                    else:\n",
    "                        results_matrix[i, j] = -1\n",
    "                        results_matrix[j, i] = 1\n",
    "                else:\n",
    "                    results_matrix[i, j] = 0\n",
    "                    results_matrix[j, i] = 0\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 11))\n",
    "    cmap = plt.cm.colors.ListedColormap(['#e74c3c', '#fff9c4', '#2ecc71'])\n",
    "    bounds = [-1.5, -0.5, 0.5, 1.5]\n",
    "    norm = plt.cm.colors.BoundaryNorm(bounds, cmap.N)\n",
    "    \n",
    "    im = ax.imshow(results_matrix, cmap=cmap, norm=norm, aspect='auto')\n",
    "    ax.set_xticks(np.arange(n_models))\n",
    "    ax.set_yticks(np.arange(n_models))\n",
    "    ax.set_xticklabels(model_cols, rotation=45, ha='right', fontsize=9)\n",
    "    ax.set_yticklabels(model_cols, fontsize=9)\n",
    "    \n",
    "    for i in range(n_models):\n",
    "        for j in range(n_models):\n",
    "            if i == j:\n",
    "                text = '-'\n",
    "                color = 'black'\n",
    "            else:\n",
    "                val = results_matrix[i, j]\n",
    "                p_val = p_values[i, j]\n",
    "                dm_val = dm_stats[i, j]\n",
    "                if val == 1:\n",
    "                    text = f'✓\\nHLN-DM={dm_val:.2f}\\np={p_val:.4f}'\n",
    "                    color = 'white'\n",
    "                elif val == -1:\n",
    "                    text = f'✗\\nHLN-DM={dm_val:.2f}\\np={p_val:.4f}'\n",
    "                    color = 'white'\n",
    "                else:\n",
    "                    text = f'≈\\nHLN-DM={dm_val:.2f}\\np={p_val:.4f}'\n",
    "                    color = 'black'\n",
    "            ax.text(j, i, text, ha='center', va='center', \n",
    "                   color=color, fontsize=6, fontweight='bold')\n",
    "    \n",
    "    # Obtener T para el título\n",
    "    T = len(data_filtered)\n",
    "    df_test = T - 1\n",
    "    \n",
    "    ax.set_title(title + f'\\n(h={h_forecast}, T={T}, df={df_test}, α ajustado={bonferroni_alpha:.5f})', \n",
    "                 fontsize=11, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Modelo (Columna)', fontsize=11)\n",
    "    ax.set_ylabel('Modelo (Fila)', fontsize=11)\n",
    "    \n",
    "    legend_elements = [\n",
    "        plt.Rectangle((0,0),1,1, facecolor='#2ecc71', label='Fila supera columna (p < α)'),\n",
    "        plt.Rectangle((0,0),1,1, facecolor='#e74c3c', label='Columna supera fila (p < α)'),\n",
    "        plt.Rectangle((0,0),1,1, facecolor='#fff9c4', label='Sin diferencia significativa (p ≥ α)')\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='upper left', bbox_to_anchor=(1.05, 1), fontsize=9)\n",
    "    \n",
    "    # Agregar nota metodológica\n",
    "    note_text = ('Nota: Se utiliza el test HLN-DM con corrección para muestras finitas.\\n'\n",
    "                 'Distribución: t-Student. Ajuste: Bonferroni para comparaciones múltiples.')\n",
    "    plt.figtext(0.5, -0.02, note_text, ha='center', fontsize=8, style='italic', \n",
    "                wrap=True, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'6.2{suffix}_dm_test_hln_bonferroni.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Guardar resultados en Excel\n",
    "    results_df = pd.DataFrame(results_matrix, index=model_cols, columns=model_cols)\n",
    "    pvalues_df = pd.DataFrame(p_values, index=model_cols, columns=model_cols)\n",
    "    dmstats_df = pd.DataFrame(dm_stats, index=model_cols, columns=model_cols)\n",
    "    \n",
    "    summary_data = []\n",
    "    for model in model_cols:\n",
    "        idx = model_cols.index(model)\n",
    "        victorias = int(np.sum(results_matrix[idx, :] == 1))\n",
    "        derrotas = int(np.sum(results_matrix[idx, :] == -1))\n",
    "        empates = int(np.sum(results_matrix[idx, :] == 0)) - 1\n",
    "        mean_ecrps = data_filtered[model].mean()\n",
    "        std_ecrps = data_filtered[model].std()\n",
    "        cv_ecrps = std_ecrps / mean_ecrps\n",
    "        summary_data.append({\n",
    "            'Modelo': model,\n",
    "            'Victorias': victorias,\n",
    "            'Derrotas': derrotas,\n",
    "            'Empates': empates,\n",
    "            'Tasa_Victoria': f\"{(victorias / (n_models - 1)) * 100:.1f}%\",\n",
    "            'ECRPS_Promedio': f\"{mean_ecrps:.4f}\",\n",
    "            'ECRPS_Desv_Std': f\"{std_ecrps:.4f}\",\n",
    "            'Coef_Variacion': f\"{cv_ecrps:.4f}\"\n",
    "        })\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    # Información metodológica\n",
    "    method_info = pd.DataFrame({\n",
    "        'Parámetro': ['Horizonte de pronóstico (h)', 'Tamaño muestra (T)', \n",
    "                      'Grados libertad (df)', 'Alpha nominal', \n",
    "                      'Alpha ajustado (Bonferroni)', 'Número comparaciones',\n",
    "                      'Distribución', 'Corrección aplicada'],\n",
    "        'Valor': [h_forecast, T, df_test, alpha, bonferroni_alpha, \n",
    "                  int(n_comparisons), 't-Student', 'Harvey-Leybourne-Newbold (1997)']\n",
    "    })\n",
    "    \n",
    "    with pd.ExcelWriter(output_dir / f'6.2{suffix}_dm_test_hln_resultados.xlsx') as writer:\n",
    "        method_info.to_excel(writer, sheet_name='Metodologia', index=False)\n",
    "        results_df.to_excel(writer, sheet_name='Matriz_Resultados')\n",
    "        pvalues_df.to_excel(writer, sheet_name='P_valores')\n",
    "        dmstats_df.to_excel(writer, sheet_name='Estadisticos_HLN_DM')\n",
    "        summary_df.to_excel(writer, sheet_name='Resumen_Modelos', index=False)\n",
    "    \n",
    "    print(f\"✓ Gráfica 6.2{suffix} guardada (Test HLN-DM con h={h_forecast}, T={T}, df={df_test})\")\n",
    "\n",
    "plot_dm_test_heatmap()\n",
    "plot_dm_test_heatmap('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_dm_test_heatmap('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_dm_test_heatmap('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PROCESO COMPLETADO\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nMejoras implementadas:\")\n",
    "print(\"1. ✓ Orden consistente en gráficas 1.1 y 1.2\")\n",
    "print(\"2. ✓ Formato de 2 decimales en heatmap 2.2 general\")\n",
    "print(\"3. ✓ Solo Coeficiente de Variación en gráfica 6.1 (ordenado menor a mayor)\")\n",
    "print(\"4. ✓ Test Diebold-Mariano con corrección HLN y distribución t-Student\")\n",
    "print(\"5. ✓ Horizonte de pronóstico (h) incorporado en el análisis\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANÁLISIS DE INTERACCIONES (Carpeta: Interacciones/)\")\n",
    "print(\"=\"*80)\n",
    "print(\"6. ✓ Config × Var: Heatmaps por modelo (matriz 3×3)\")\n",
    "print(\"7. ✓ Config × Dist: Heatmaps por modelo (matriz 3×3)\")\n",
    "print(\"8. ✓ Dist × Paso: Gráficas de líneas por distribución\")\n",
    "print(\"9. ✓ Dist × Var: Gráficas de líneas por distribución\")\n",
    "print(\"10. ✓ Config × Paso: Gráficas de líneas por configuración\")\n",
    "print(\"11. ✓ Var × Horizonte: Gráficas de líneas por varianza\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal de gráficas generadas en Interacciones/: {6 * 4} archivos\")\n",
    "print(\"(6 tipos de interacción × 4 escenarios: General + 3 específicos)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f71c0b0",
   "metadata": {},
   "source": [
    "# Analisis Diferenciado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b88955e",
   "metadata": {},
   "source": [
    "## Pre-procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "249b1e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TABLA COMPARATIVA DE MODELOS POR ESCENARIO\n",
      "(Promedio de amplitud de intervalos de predicción)\n",
      "================================================================================\n",
      "             Modelo   ARIMA  ARIMA_Diff Mejor_Escenario\n",
      "              AREPD  9.7604      0.7485      ARIMA_Diff\n",
      "            AV-MCPS  3.0618      0.6493      ARIMA_Diff\n",
      "Block Bootstrapping 10.9690      0.6844      ARIMA_Diff\n",
      "             DeepAR  3.1462      0.5704      ARIMA_Diff\n",
      "         EnCQR-LSTM  5.8306      0.8656      ARIMA_Diff\n",
      "               LSPM  1.1140      0.6481      ARIMA_Diff\n",
      "              LSPMW  3.5094      0.8032      ARIMA_Diff\n",
      "               MCPS  2.8994      0.6581      ARIMA_Diff\n",
      "    Sieve Bootstrap  0.5479      0.5454      ARIMA_Diff\n",
      "================================================================================\n",
      "\n",
      "Tabla comparativa guardada en 'Tabla_Comparativa_Modelos_Diff.xlsx'\n",
      "\n",
      "Archivo 'Base_140_diff_escenarios.xlsx' creado exitosamente!\n",
      "\n",
      "Total de filas: 3360\n",
      "- ARIMA: 1680 filas\n",
      "- ARIMA_Diff: 1680 filas\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Leer los tres archivos\n",
    "arima_df = pd.read_excel(\"./datos/resultados_140_ARIMA_FINAL.xlsx\")\n",
    "arima_Diff_df = pd.read_excel(\"./datos/resultados_140_ARIMA_CON_DIFERENCIACION.xlsx\")\n",
    "\n",
    "# Filtrar los que no tienen \"Promedio\" en la columna \"Paso\"\n",
    "arima_df = arima_df[arima_df['Paso'] != 'Promedio']\n",
    "arima_Diff_df = arima_Diff_df[arima_Diff_df['Paso'] != 'Promedio']\n",
    "\n",
    "# Lista de modelos (columnas a promediar)\n",
    "modelos = ['AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR',\n",
    "           'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
    "\n",
    "# Crear tabla comparativa\n",
    "comparacion = []\n",
    "\n",
    "for modelo in modelos:\n",
    "    fila = {'Modelo': modelo}\n",
    "    \n",
    "    # Calcular promedio para cada escenario (de la columna del modelo)\n",
    "    arima_promedio = arima_df[modelo].mean() if modelo in arima_df.columns else np.nan\n",
    "    arima_Diff_promedio = arima_Diff_df[modelo].mean() if modelo in arima_Diff_df.columns else np.nan\n",
    "    \n",
    "    fila['ARIMA'] = arima_promedio\n",
    "    fila['ARIMA_Diff'] = arima_Diff_promedio\n",
    "    \n",
    "    # Determinar mejor escenario (menor promedio)\n",
    "    promedios = {\n",
    "        'ARIMA': arima_promedio,\n",
    "        'ARIMA_Diff': arima_Diff_promedio\n",
    "    }\n",
    "    \n",
    "    # Filtrar NaN si existen\n",
    "    promedios_validos = {k: v for k, v in promedios.items() if not pd.isna(v)}\n",
    "    \n",
    "    if promedios_validos:\n",
    "        mejor_escenario = min(promedios_validos, key=promedios_validos.get)\n",
    "        fila['Mejor_Escenario'] = mejor_escenario\n",
    "    else:\n",
    "        fila['Mejor_Escenario'] = 'N/A'\n",
    "    \n",
    "    comparacion.append(fila)\n",
    "\n",
    "# Crear DataFrame con la tabla comparativa\n",
    "tabla_comparativa = pd.DataFrame(comparacion)\n",
    "\n",
    "# Redondear valores para mejor visualización\n",
    "columnas_numericas = ['ARIMA', 'ARIMA_Diff']\n",
    "tabla_comparativa[columnas_numericas] = tabla_comparativa[columnas_numericas].round(4)\n",
    "\n",
    "# Mostrar tabla comparativa\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TABLA COMPARATIVA DE MODELOS POR ESCENARIO\")\n",
    "print(\"(Promedio de amplitud de intervalos de predicción)\")\n",
    "print(\"=\"*80)\n",
    "print(tabla_comparativa.to_string(index=False))\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Guardar tabla comparativa en Excel\n",
    "tabla_comparativa.to_excel(\"Tabla_Comparativa_Modelos_Diff.xlsx\", index=False)\n",
    "print(\"Tabla comparativa guardada en 'Tabla_Comparativa_Modelos_Diff.xlsx'\")\n",
    "\n",
    "# Agregar columna ESCENARIO a cada DataFrame antes de concatenar\n",
    "arima_df['ESCENARIO'] = 'Sin diferenciación'\n",
    "arima_Diff_df['ESCENARIO'] = 'Diferenciado'\n",
    "\n",
    "# Concatenar los tres dataframes\n",
    "base_consolidada = pd.concat([arima_df, arima_Diff_df], ignore_index=True)\n",
    "# Guardar en un archivo Excel\n",
    "base_consolidada.to_excel(\"Base_140_diff_escenarios.xlsx\", index=False)\n",
    "\n",
    "print(\"\\nArchivo 'Base_140_diff_escenarios.xlsx' creado exitosamente!\")\n",
    "print(f\"\\nTotal de filas: {len(base_consolidada)}\")\n",
    "print(f\"- ARIMA: {len(arima_df)} filas\")\n",
    "print(f\"- ARIMA_Diff: {len(arima_Diff_df)} filas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08864bc2",
   "metadata": {},
   "source": [
    "## Analisis general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba3ee6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "INICIANDO ANÁLISIS COMPARATIVO (AJUSTADO - BARRAS HORIZONTALES)\n",
      "================================================================================\n",
      "\n",
      "Base: Sin diferenciación | Comparado: Diferenciado\n",
      "1️⃣  Comparativa Global...\n",
      "2️⃣  Modelo Generador...\n",
      "3️⃣  Variabilidad IQR (Por Tipo)...\n",
      "4️⃣  Distribución...\n",
      "5️⃣  Varianza...\n",
      "6️⃣  Sensibilidad Ruido...\n",
      "7️⃣  Robustez (QCD)...\n",
      "8️⃣  Excel DM...\n",
      "   ✅ Excel: resultados_escenarios_comparativos\\Comparacion_DM_Por_Modelo.xlsx\n",
      "\n",
      "✅ HECHO.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "import warnings\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración de estilo\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURACIÓN GLOBAL\n",
    "# ============================================================================\n",
    "\n",
    "RUTA_DATOS = \"./Base_140_diff_escenarios.xlsx\"\n",
    "DIR_SALIDA = \"./resultados_escenarios_comparativos\"\n",
    "\n",
    "MODELOS = ['AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR',\n",
    "           'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
    "\n",
    "# Colores fijos para barras comparativas\n",
    "COLOR_SIN_DIFF = '#7f7f7f'  # Gris\n",
    "COLOR_CON_DIFF = '#1f77b4'  # Azul\n",
    "\n",
    "# Paleta UNIFICADA para todos los Heatmaps\n",
    "# RdYlGn_r: Rojo (Valores altos/malos) -> Verde (Valores bajos/buenos)\n",
    "CMAP_HEATMAP = 'RdYlGn_r' \n",
    "\n",
    "# ============================================================================\n",
    "# FUNCIONES AUXILIARES\n",
    "# ============================================================================\n",
    "\n",
    "def diebold_mariano_test(errores1, errores2, h=1, alternative='two-sided', loss_function='none'):\n",
    "    \"\"\"Test DM Robusto (HAC)\"\"\"\n",
    "    e1 = np.asarray(errores1)\n",
    "    e2 = np.asarray(errores2)\n",
    "    n = len(e1)\n",
    "    \n",
    "    if loss_function == 'none':\n",
    "        d = e1 - e2\n",
    "    elif loss_function == 'squared':\n",
    "        d = e1**2 - e2**2\n",
    "    else: # absolute\n",
    "        d = np.abs(e1) - np.abs(e2)\n",
    "        \n",
    "    d_mean = np.mean(d)\n",
    "    \n",
    "    if h == 1:\n",
    "        var_d = np.var(d, ddof=1) / n\n",
    "    else:\n",
    "        gamma_0 = np.var(d, ddof=1)\n",
    "        gamma_sum = 0\n",
    "        max_lags = min(h-1, n-1)\n",
    "        for k in range(1, max_lags + 1):\n",
    "            if k < n:\n",
    "                gamma_k = np.cov(d[:-k], d[k:], ddof=1)[0,1] if len(d) > k else 0\n",
    "                gamma_sum += (1 - k/(max_lags+1)) * gamma_k\n",
    "        var_d = (gamma_0 + 2 * gamma_sum) / n\n",
    "    \n",
    "    hlnc = np.sqrt((n + 1 - 2 * h + h * (h - 1) / n) / n) if h > 1 else 1.0\n",
    "    \n",
    "    dm_stat = (d_mean / np.sqrt(var_d)) * hlnc if var_d > 0 else 0\n",
    "    p_value = 2 * (1 - stats.norm.cdf(abs(dm_stat)))\n",
    "    \n",
    "    return {'p_value': p_value, 'mean_diff': d_mean, 'dm_statistic': dm_stat}\n",
    "\n",
    "def comparar_modelo_entre_escenarios(df, modelo, esc_base, esc_diff, alpha=0.05):\n",
    "    data_base = df[df['ESCENARIO'] == esc_base][modelo].dropna()\n",
    "    data_diff = df[df['ESCENARIO'] == esc_diff][modelo].dropna()\n",
    "    \n",
    "    if len(data_base) < 10 or len(data_diff) < 10:\n",
    "        return {'Modelo': modelo, 'Conclusión': 'Datos insuficientes', 'p_value': np.nan}\n",
    "    \n",
    "    med_base = data_base.median()\n",
    "    med_diff = data_diff.median()\n",
    "    mejora_pct = ((med_base - med_diff) / med_base) * 100 if med_base != 0 else 0\n",
    "    \n",
    "    try:\n",
    "        res = diebold_mariano_test(data_base.values, data_diff.values, h=1, loss_function='none')\n",
    "        sig = res['p_value'] < alpha\n",
    "        \n",
    "        if sig:\n",
    "            conclusion = 'Diferenciación mejora' if res['mean_diff'] > 0 else 'Sin diferenciación es mejor'\n",
    "        else:\n",
    "            conclusion = 'Sin diferencia significativa'\n",
    "            \n",
    "        return {\n",
    "            'Modelo': modelo,\n",
    "            'ECRPS_Sin_Dif': round(med_base, 3),\n",
    "            'ECRPS_Con_Dif': round(med_diff, 3),\n",
    "            'Mejora_%': round(mejora_pct, 2),\n",
    "            'dm_statistic': round(res['dm_statistic'], 4),\n",
    "            'p_value': res['p_value'],\n",
    "            'Significativo': 'Sí' if sig else 'No',\n",
    "            'Conclusión': conclusion\n",
    "        }\n",
    "    except:\n",
    "        return {'Modelo': modelo, 'Conclusión': 'Error'}\n",
    "\n",
    "# ============================================================================\n",
    "# CLASE PRINCIPAL\n",
    "# ============================================================================\n",
    "\n",
    "class AnalizadorBaseCompleta:\n",
    "\n",
    "    def __init__(self, ruta_datos):\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"INICIANDO ANÁLISIS COMPARATIVO (AJUSTADO - BARRAS HORIZONTALES)\")\n",
    "        print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "        self.df = pd.read_excel(ruta_datos)\n",
    "        \n",
    "        # Limpieza básica\n",
    "        self.df['ESCENARIO'] = self.df['ESCENARIO'].astype(str).str.strip()\n",
    "        self.escenarios_unicos = sorted(self.df['ESCENARIO'].unique())\n",
    "        \n",
    "        if 'proces_simulacion' in self.df.columns:\n",
    "            self.df['Tipo de Modelo'] = self.df['proces_simulacion']\n",
    "        \n",
    "        self.modelos = [m for m in MODELOS if m in self.df.columns]\n",
    "        self.dir_salida = Path(DIR_SALIDA)\n",
    "        self.dir_salida.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Determinar base vs diff\n",
    "        if len(self.escenarios_unicos) == 2:\n",
    "            e1, e2 = self.escenarios_unicos\n",
    "            if ('sin' in e1.lower() or 'no' in e1.lower()) and not ('sin' in e2.lower()):\n",
    "                self.esc_base, self.esc_diff = e1, e2\n",
    "            elif ('sin' in e2.lower() or 'no' in e2.lower()):\n",
    "                self.esc_base, self.esc_diff = e2, e1\n",
    "            else:\n",
    "                self.esc_base, self.esc_diff = e1, e2\n",
    "        else:\n",
    "            self.esc_base = self.escenarios_unicos[0]\n",
    "            self.esc_diff = self.escenarios_unicos[-1]\n",
    "\n",
    "        print(f\"Base: {self.esc_base} | Comparado: {self.esc_diff}\")\n",
    "\n",
    "    def ejecutar_analisis_completo(self):\n",
    "        print(\"1️⃣  Comparativa Global...\")\n",
    "        self._1_comparativo_global()\n",
    "        print(\"2️⃣  Modelo Generador...\")\n",
    "        self._2_modelo_generador()\n",
    "        print(\"3️⃣  Variabilidad IQR (Por Tipo)...\")\n",
    "        self._3_variabilidad_iqr()\n",
    "        print(\"4️⃣  Distribución...\")\n",
    "        self._4_distribucion()\n",
    "        print(\"5️⃣  Varianza...\")\n",
    "        self._5_varianza_tendencias()\n",
    "        print(\"6️⃣  Sensibilidad Ruido...\")\n",
    "        self._6_sensibilidad_ruido()\n",
    "        print(\"7️⃣  Robustez (QCD)...\")\n",
    "        self._7_analisis_robustez()\n",
    "        print(\"8️⃣  Excel DM...\")\n",
    "        self._analisis_dm_excel()\n",
    "        print(\"\\n✅ HECHO.\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # 1. COMPARATIVAS GLOBALES\n",
    "    # ========================================================================\n",
    "    def _1_comparativo_global(self):\n",
    "        datos_agg = self.df.groupby(['ESCENARIO'])[self.modelos].median().T\n",
    "        \n",
    "        # 1.1 Barras HORIZONTALES (Izquierda a Derecha)\n",
    "        fig, ax = plt.subplots(figsize=(15, 10))\n",
    "        y = np.arange(len(self.modelos))\n",
    "        height = 0.35 # Altura de la barra en horizontal\n",
    "        \n",
    "        # Note: En barh, el primer argumento es Y, el segundo es width (valor X)\n",
    "        ax.barh(y - height/2, datos_agg[self.esc_base], height, label=self.esc_base, color=COLOR_SIN_DIFF)\n",
    "        ax.barh(y + height/2, datos_agg[self.esc_diff], height, label=self.esc_diff, color=COLOR_CON_DIFF)\n",
    "\n",
    "        ax.set_xlabel('Mediana ECRPS', fontweight='bold')\n",
    "        ax.set_title(f'1.1 Rendimiento: {self.esc_base} vs {self.esc_diff}', fontweight='bold')\n",
    "        ax.set_yticks(y)\n",
    "        ax.set_yticklabels(self.modelos)\n",
    "        ax.invert_yaxis() # Para que el primer modelo esté arriba\n",
    "        ax.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '1_1_Comparacion_Barras_Horizontales.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        # 1.2 Cambio Porcentual (Ya era Horizontal)\n",
    "        cambio_pct = ((datos_agg[self.esc_diff] - datos_agg[self.esc_base]) / datos_agg[self.esc_base]) * 100\n",
    "        cambio_pct = cambio_pct.sort_values()\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        norm = plt.Normalize(cambio_pct.min(), cambio_pct.max())\n",
    "        cmap = plt.get_cmap(CMAP_HEATMAP)\n",
    "        colores = [cmap(norm(v)) for v in cambio_pct.values]\n",
    "        \n",
    "        bars = ax.barh(cambio_pct.index, cambio_pct.values, color=colores, edgecolor='k')\n",
    "        \n",
    "        ax.axvline(0, color='k', linestyle='--')\n",
    "        ax.set_xlabel('Cambio Porcentual del Error (%)', fontweight='bold')\n",
    "        ax.set_title('1.2 Impacto de la Diferenciación (Verde = Mejora)', fontweight='bold')\n",
    "        \n",
    "        for bar in bars:\n",
    "            w = bar.get_width()\n",
    "            align = 'left' if w > 0 else 'right'\n",
    "            ax.text(w, bar.get_y() + bar.get_height()/2, f'{w:.1f}%', va='center', ha=align)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '1_2_Cambio_Porcentual.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    # ========================================================================\n",
    "    # 2. MODELO GENERADOR\n",
    "    # ========================================================================\n",
    "    def _2_modelo_generador(self):\n",
    "        if 'Tipo de Modelo' not in self.df.columns: return\n",
    "\n",
    "        df_diff = self.df[self.df['ESCENARIO'] == self.esc_diff]\n",
    "        df_base = self.df[self.df['ESCENARIO'] == self.esc_base]\n",
    "        \n",
    "        piv_diff = df_diff.groupby('Tipo de Modelo')[self.modelos].median()\n",
    "        piv_base = df_base.groupby('Tipo de Modelo')[self.modelos].median()\n",
    "\n",
    "        # 2.1 Heatmap Normalizado\n",
    "        fig, ax = plt.subplots(figsize=(16, 9))\n",
    "        row_stats = piv_diff.T.agg(['median', 'std'], axis=1)\n",
    "        zscore = piv_diff.T.sub(row_stats['median'], axis=0).div(row_stats['std'].replace(0,1), axis=0)\n",
    "        \n",
    "        sns.heatmap(zscore, annot=True, fmt='.2f', cmap=CMAP_HEATMAP, center=0, ax=ax)\n",
    "        ax.set_title(f'2.1 Z-Score Rendimiento - {self.esc_diff}', fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '2_1_MG_ZScore_Diferenciado.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        # 2.2 Cambio Absoluto\n",
    "        delta = piv_diff - piv_base\n",
    "        fig, ax = plt.subplots(figsize=(16, 9))\n",
    "        sns.heatmap(delta.T, annot=True, fmt='.3f', cmap=CMAP_HEATMAP, center=0, ax=ax)\n",
    "        ax.set_title(f'2.2 Cambio en ECRPS (Diff - Base)', fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '2_2_MG_Cambios.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    # ========================================================================\n",
    "    # 3. VARIABILIDAD IQR (AGRUPADO POR TIPO)\n",
    "    # ========================================================================\n",
    "    def _3_variabilidad_iqr(self):\n",
    "        if 'Tipo de Modelo' not in self.df.columns: return\n",
    "        \n",
    "        # --- PREPARACIÓN DE DATOS PARA 3.1 y 3.2 ---\n",
    "        # Queremos métricas agregadas por TIPO DE MODELO\n",
    "        \n",
    "        tipos_modelo = self.df['Tipo de Modelo'].dropna().unique()\n",
    "        data_resumen = []\n",
    "\n",
    "        for tipo in tipos_modelo:\n",
    "            # Función interna para calcular promedio de IQRs de los modelos en ese tipo\n",
    "            def calcular_iqr_promedio_tipo(escenario):\n",
    "                subset = self.df[(self.df['ESCENARIO'] == escenario) & \n",
    "                                 (self.df['Tipo de Modelo'] == tipo)]\n",
    "                if subset.empty: return np.nan\n",
    "                \n",
    "                iqrs_individuales = []\n",
    "                for mod in self.modelos:\n",
    "                    vals = subset[mod].dropna()\n",
    "                    if len(vals) > 0:\n",
    "                        q75, q25 = np.percentile(vals, [75, 25])\n",
    "                        iqrs_individuales.append(q75 - q25)\n",
    "                \n",
    "                return np.mean(iqrs_individuales) if iqrs_individuales else np.nan\n",
    "\n",
    "            iqr_base = calcular_iqr_promedio_tipo(self.esc_base)\n",
    "            iqr_diff = calcular_iqr_promedio_tipo(self.esc_diff)\n",
    "            \n",
    "            if not np.isnan(iqr_diff):\n",
    "                delta = iqr_diff - iqr_base if not np.isnan(iqr_base) else np.nan\n",
    "                data_resumen.append({\n",
    "                    'Tipo': tipo, \n",
    "                    'IQR_Diff': iqr_diff,\n",
    "                    'Delta_IQR': delta\n",
    "                })\n",
    "        \n",
    "        df_resumen = pd.DataFrame(data_resumen)\n",
    "        if df_resumen.empty: return\n",
    "\n",
    "        # 3.1 Gráfico por TIPO DE MODELO - Nivel absoluto (Diff)\n",
    "        df_31 = df_resumen.sort_values('IQR_Diff')\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        ax.barh(df_31['Tipo'], df_31['IQR_Diff'], color=COLOR_CON_DIFF, alpha=0.8)\n",
    "        ax.set_title(f'3.1 Variabilidad Promedio (IQR) por TIPO DE MODELO - {self.esc_diff}', fontweight='bold')\n",
    "        ax.set_xlabel('IQR Promedio del Tipo')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '3_1_IQR_Diferenciado_PorTipo.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        # 3.2 Cambio IQR por TIPO DE MODELO (Delta)\n",
    "        # Aquí cumplimos el requerimiento: 3.2 ahora es sobre Tipos, no modelos individuales\n",
    "        df_32 = df_resumen.dropna(subset=['Delta_IQR']).sort_values('Delta_IQR')\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        colors = ['green' if x < 0 else 'red' for x in df_32['Delta_IQR']]\n",
    "        bars = ax.barh(df_32['Tipo'], df_32['Delta_IQR'], color=colors, alpha=0.7, edgecolor='k')\n",
    "        \n",
    "        ax.set_title('3.2 Cambio en Variabilidad (Delta IQR) por TIPO DE MODELO\\n(Verde = Menos variabilidad con diferenciación)', fontweight='bold')\n",
    "        ax.axvline(0, color='k', linestyle='--')\n",
    "        \n",
    "        for bar in bars:\n",
    "            w = bar.get_width()\n",
    "            align = 'left' if w > 0 else 'right'\n",
    "            ax.text(w, bar.get_y() + bar.get_height()/2, f'{w:.3f}', va='center', ha=align)\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '3_2_Cambios_IQR_PorTipo.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    # ========================================================================\n",
    "    # 4. DISTRIBUCIÓN\n",
    "    # ========================================================================\n",
    "    def _4_distribucion(self):\n",
    "        if 'Distribución' not in self.df.columns: return\n",
    "\n",
    "        piv_diff = self.df[self.df['ESCENARIO'] == self.esc_diff].groupby('Distribución')[self.modelos].median()\n",
    "        piv_base = self.df[self.df['ESCENARIO'] == self.esc_base].groupby('Distribución')[self.modelos].median()\n",
    "        \n",
    "        # 4.1 Heatmap (Diff)\n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        sns.heatmap(piv_diff.T, annot=True, fmt='.3f', cmap=CMAP_HEATMAP, ax=ax)\n",
    "        ax.set_title(f'4.1 Rendimiento por Distribución - {self.esc_diff}', fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '4_1_Dist_Heatmap_Diferenciado.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        # 4.2 Heatmap (Delta)\n",
    "        delta = piv_diff - piv_base\n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        sns.heatmap(delta.T, annot=True, fmt='.3f', cmap=CMAP_HEATMAP, center=0, ax=ax)\n",
    "        ax.set_title(f'4.2 Diferencial (Diff - Base)', fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '4_2_Dist_Heatmap_Diferencial.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    # ========================================================================\n",
    "    # 5. VARIANZA\n",
    "    # ========================================================================\n",
    "    def _5_varianza_tendencias(self):\n",
    "        if 'Varianza error' not in self.df.columns: return\n",
    "        \n",
    "        df_diff = self.df[self.df['ESCENARIO'] == self.esc_diff]\n",
    "        df_base = self.df[self.df['ESCENARIO'] == self.esc_base]\n",
    "\n",
    "        # 5.1 Tendencias Diferenciado\n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        for mod in self.modelos:\n",
    "            c = df_diff.groupby('Varianza error')[mod].median()\n",
    "            ax.plot(c.index, c.values, marker='o', label=mod)\n",
    "        ax.set_title(f'5.1 Sensibilidad a Varianza - {self.esc_diff}', fontweight='bold')\n",
    "        ax.legend(bbox_to_anchor=(1.01, 1))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '5_1_Varianza_Tendencias_Diferenciado.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        # 5.2 Cambio\n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        for mod in self.modelos:\n",
    "            c1 = df_diff.groupby('Varianza error')[mod].median()\n",
    "            c2 = df_base.groupby('Varianza error')[mod].median()\n",
    "            if not c1.empty and not c2.empty:\n",
    "                delta = c1 - c2\n",
    "                ax.plot(delta.index, delta.values, marker='o', label=mod)\n",
    "        ax.axhline(0, color='k', linestyle='--')\n",
    "        ax.set_title('5.2 Cambio de Comportamiento (Negativo = Mejora)', fontweight='bold')\n",
    "        ax.legend(bbox_to_anchor=(1.01, 1))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '5_2_Varianza_Cambio_Comportamiento.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    # ========================================================================\n",
    "    # 6. SENSIBILIDAD RUIDO\n",
    "    # ========================================================================\n",
    "    def _6_sensibilidad_ruido(self):\n",
    "        if 'Varianza error' not in self.df.columns: return\n",
    "\n",
    "        slopes = []\n",
    "        for esc in [self.esc_base, self.esc_diff]:\n",
    "            df_c = self.df[self.df['ESCENARIO'] == esc]\n",
    "            for mod in self.modelos:\n",
    "                dat = df_c[['Varianza error', mod]].dropna()\n",
    "                if len(dat) > 2:\n",
    "                    res = stats.theilslopes(dat[mod], dat['Varianza error'])\n",
    "                    slopes.append({'Modelo': mod, 'Esc': esc, 'Slope': res[0]})\n",
    "        \n",
    "        df_slopes = pd.DataFrame(slopes)\n",
    "        if df_slopes.empty: return\n",
    "\n",
    "        # 6.1 Sensibilidad Diff (Ya era Horizontal)\n",
    "        sub = df_slopes[df_slopes['Esc'] == self.esc_diff].sort_values('Slope')\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        ax.barh(sub['Modelo'], sub['Slope'], color=COLOR_CON_DIFF)\n",
    "        ax.set_title(f'6.1 Sensibilidad Ruido (Pendiente) - {self.esc_diff}', fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '6_1_Sensibilidad_Ruido_Diferenciado.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        # 6.2 Cambio Sensibilidad (Ya era Horizontal)\n",
    "        piv = df_slopes.pivot(index='Modelo', columns='Esc', values='Slope')\n",
    "        piv['Delta'] = piv[self.esc_diff] - piv[self.esc_base]\n",
    "        piv = piv.sort_values('Delta')\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        colors = ['green' if x < 0 else 'red' for x in piv['Delta']]\n",
    "        bars = ax.barh(piv.index, piv['Delta'], color=colors, edgecolor='k')\n",
    "        ax.axvline(0, color='k')\n",
    "        ax.set_title('6.2 Cambio en Sensibilidad (Verde = Menos sensible)', fontweight='bold')\n",
    "        \n",
    "        for bar in bars:\n",
    "            w = bar.get_width()\n",
    "            align = 'left' if w > 0 else 'right'\n",
    "            ax.text(w, bar.get_y() + bar.get_height()/2, f'{w:.4f}', va='center', ha=align)\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '6_2_Sensibilidad_Cambio.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    # ========================================================================\n",
    "    # 7. ROBUSTEZ (QCD) - CON COMPARACIÓN\n",
    "    # ========================================================================\n",
    "    def _7_analisis_robustez(self):\n",
    "        # Calcular QCD para ambos escenarios\n",
    "        metricas = []\n",
    "        for esc in [self.esc_base, self.esc_diff]:\n",
    "            df_c = self.df[self.df['ESCENARIO'] == esc]\n",
    "            for mod in self.modelos:\n",
    "                dat = df_c[mod].dropna()\n",
    "                if len(dat) > 0:\n",
    "                    q75, q25 = np.percentile(dat, [75, 25])\n",
    "                    if (q75 + q25) > 0:\n",
    "                        qcd = (q75 - q25) / (q75 + q25)\n",
    "                        metricas.append({'Modelo': mod, 'Esc': esc, 'QCD': qcd})\n",
    "        \n",
    "        df_qcd = pd.DataFrame(metricas)\n",
    "        if df_qcd.empty: return\n",
    "\n",
    "        # 7.1 QCD Diferenciado (Ya era Horizontal)\n",
    "        sub_diff = df_qcd[df_qcd['Esc'] == self.esc_diff].sort_values('QCD')\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        norm = plt.Normalize(sub_diff['QCD'].min(), sub_diff['QCD'].max())\n",
    "        cmap = plt.get_cmap(CMAP_HEATMAP)\n",
    "        colors = [cmap(1 - norm(v)) for v in sub_diff['QCD']]\n",
    "\n",
    "        bars = ax.barh(sub_diff['Modelo'], sub_diff['QCD'], color=colors, edgecolor='k')\n",
    "        ax.set_title(f'7.1 Robustez (QCD) - {self.esc_diff} (Menor es mejor)', fontweight='bold')\n",
    "        \n",
    "        for bar in bars:\n",
    "            w = bar.get_width()\n",
    "            ax.text(w, bar.get_y() + bar.get_height()/2, f'{w:.3f}', va='center', ha='left')\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '7_1_Robustez_Diferenciado.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        # 7.2 COMPARACIÓN DE ROBUSTEZ (Ya era Horizontal)\n",
    "        piv = df_qcd.pivot(index='Modelo', columns='Esc', values='QCD')\n",
    "        piv['Delta'] = piv[self.esc_diff] - piv[self.esc_base]\n",
    "        piv = piv.sort_values('Delta')\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        colors = ['green' if x < 0 else 'red' for x in piv['Delta']]\n",
    "        bars = ax.barh(piv.index, piv['Delta'], color=colors, edgecolor='k', alpha=0.8)\n",
    "        \n",
    "        ax.set_title('7.2 Cambio en Robustez (QCD)\\n(Valores negativos indican mayor robustez en diferenciado)', fontweight='bold')\n",
    "        ax.axvline(0, color='k', linestyle='--')\n",
    "        \n",
    "        for bar in bars:\n",
    "            w = bar.get_width()\n",
    "            align = 'left' if w > 0 else 'right'\n",
    "            ax.text(w, bar.get_y() + bar.get_height()/2, f'{w:.3f}', va='center', ha=align)\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '7_2_Robustez_Cambio.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    # ========================================================================\n",
    "    # 8. EXCEL\n",
    "    # ========================================================================\n",
    "    def _analisis_dm_excel(self):\n",
    "        res = [comparar_modelo_entre_escenarios(self.df, m, self.esc_base, self.esc_diff) for m in self.modelos]\n",
    "        df_res = pd.DataFrame(res)\n",
    "        nombre = self.dir_salida / \"Comparacion_DM_Por_Modelo.xlsx\"\n",
    "        df_res.to_excel(nombre, index=False)\n",
    "        print(f\"   ✅ Excel: {nombre}\")\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN\n",
    "# ============================================================================\n",
    "def main():\n",
    "    try:\n",
    "        AnalizadorBaseCompleta(RUTA_DATOS).ejecutar_analisis_completo()\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e6b598",
   "metadata": {},
   "source": [
    "# Aumento d ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3b604c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ANÁLISIS DE SENSIBILIDAD AL PARÁMETRO D (ORDEN DE DIFERENCIACIÓN)\n",
      "================================================================================\n",
      "\n",
      "📊 Valores de d: [np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(7), np.int64(10)]\n",
      "🎭 Modalidades: ['CON_DIFF', 'SIN_DIFF']\n",
      "📈 Modelos analizados: 9\n",
      "\n",
      "📊 Generando Heatmaps Generales de Rendimiento...\n",
      "   ✅ Gráfico guardado: 0_General_Heatmaps_ECRPS_Medio.png\n",
      "\n",
      "================================================================================\n",
      "PREGUNTA 1: ¿Qué modelo es más sensible a los cambios en d?\n",
      "================================================================================\n",
      "   ✅ Excel guardado: P1_Sensibilidad_Modelos.xlsx\n",
      "\n",
      "🔥 TOP 3 MODELOS MÁS SENSIBLES A d:\n",
      "   Block Bootstrapping (SIN_DIFF): Score=8.23e+10\n",
      "   AREPD (SIN_DIFF): Score=8.04e+10\n",
      "   DeepAR (SIN_DIFF): Score=7.69e+10\n",
      "\n",
      "================================================================================\n",
      "PREGUNTA 2: ¿Existe un punto de inflexión en d?\n",
      "================================================================================\n",
      "   ✅ Excel guardado: P2_Puntos_Inflexion.xlsx\n",
      "\n",
      "================================================================================\n",
      "PREGUNTA 3: ¿Cómo impacta d en la variabilidad?\n",
      "================================================================================\n",
      "   ✅ Excel guardado: P3_Variabilidad_por_d.xlsx\n",
      "\n",
      "================================================================================\n",
      "PREGUNTA 4: ¿La diferenciación previa amplifica el efecto de d?\n",
      "================================================================================\n",
      "   ✅ Excel guardado: P4_Interaccion_Modalidad.xlsx\n",
      "\n",
      "================================================================================\n",
      "PREGUNTA 5: ¿Cuándo es significativa la diferenciación? (Foco: Sieve Bootstrap)\n",
      "================================================================================\n",
      "\n",
      "🔎 Analizando significancia estadística (Mann-Whitney U)...\n",
      "   ✅ Excel guardado: P5_Significancia_Diferenciacion.xlsx\n",
      "\n",
      "🧐 ANÁLISIS ESPECÍFICO: Sieve Bootstrap\n",
      "   👉 Para Sieve Bootstrap, la diferenciación es estadísticamente significativa (p < 0.05)\n",
      "      a partir de d = 4\n",
      "\n",
      "✅ ANÁLISIS COMPLETO FINALIZADO\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURACIÓN GLOBAL\n",
    "# ============================================================================\n",
    "\n",
    "RUTA_DATOS = \"./datos/resultados_ARIMA_d1_a_d10_DOBLE_MODALIDAD_COMPLETO.xlsx\"\n",
    "DIR_SALIDA = \"./resultados_diff_d\"\n",
    "\n",
    "MODELOS = ['AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR',\n",
    "           'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
    "\n",
    "# Paleta de colores para modelos\n",
    "COLORES_MODELOS = plt.cm.tab10(np.linspace(0, 1, len(MODELOS)))\n",
    "COLOR_MAP_MODELOS = {mod: COLORES_MODELOS[i] for i, mod in enumerate(MODELOS)}\n",
    "\n",
    "# Colores para modalidades\n",
    "COLOR_SIN_DIFF = '#e74c3c'  # Rojo\n",
    "COLOR_CON_DIFF = '#3498db'  # Azul\n",
    "\n",
    "CMAP_HEATMAP = 'RdYlGn_r' # Rojo = Malo (Alto Error), Verde = Bueno (Bajo Error)\n",
    "\n",
    "# ============================================================================\n",
    "# CLASE PRINCIPAL\n",
    "# ============================================================================\n",
    "\n",
    "class AnalizadorSensibilidadD:\n",
    "    \n",
    "    def __init__(self, ruta_datos):\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"ANÁLISIS DE SENSIBILIDAD AL PARÁMETRO D (ORDEN DE DIFERENCIACIÓN)\")\n",
    "        print(\"=\" * 80 + \"\\n\")\n",
    "        \n",
    "        self.df = pd.read_excel(ruta_datos)\n",
    "        \n",
    "        # Limpieza\n",
    "        self.df['Modalidad'] = self.df['Modalidad'].astype(str).str.strip().str.upper()\n",
    "        self.df['d'] = pd.to_numeric(self.df['d'], errors='coerce')\n",
    "        \n",
    "        # Filtrar datos válidos\n",
    "        self.df = self.df[self.df['d'].notna()].copy()\n",
    "        self.valores_d = sorted(self.df['d'].unique())\n",
    "        \n",
    "        self.modelos = [m for m in MODELOS if m in self.df.columns]\n",
    "        self.modalidades = sorted(self.df['Modalidad'].unique())\n",
    "        \n",
    "        self.dir_salida = Path(DIR_SALIDA)\n",
    "        self.dir_salida.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        print(f\"📊 Valores de d: {self.valores_d}\")\n",
    "        print(f\"🎭 Modalidades: {self.modalidades}\")\n",
    "        print(f\"📈 Modelos analizados: {len(self.modelos)}\\n\")\n",
    "\n",
    "    def _fmt(self, x):\n",
    "        \"\"\"\n",
    "        Formatea números: \n",
    "        - Usa notación científica si abs(x) >= 10,000 (5 dígitos) o x < 0.001\n",
    "        - Usa decimales estándar en caso contrario.\n",
    "        \"\"\"\n",
    "        if pd.isna(x):\n",
    "            return \"\"\n",
    "        if x == 0:\n",
    "            return \"0\"\n",
    "        # Umbral: 5 dígitos enteros (10,000) o muy pequeños\n",
    "        if abs(x) >= 10000 or (0 < abs(x) < 0.001):\n",
    "            return f\"{x:.2e}\"\n",
    "        return f\"{x:.3f}\"\n",
    "\n",
    "    def ejecutar_analisis_completo(self):\n",
    "        \"\"\"Ejecuta todas las preguntas de investigación\"\"\"\n",
    "        \n",
    "        # --- VISUALIZACIÓN GENERAL ---\n",
    "        self._visualizar_heatmaps_ecrps_absolutos()\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"PREGUNTA 1: ¿Qué modelo es más sensible a los cambios en d?\")\n",
    "        print(\"=\" * 80)\n",
    "        self._pregunta1_sensibilidad_modelos()\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"PREGUNTA 2: ¿Existe un punto de inflexión en d?\")\n",
    "        print(\"=\" * 80)\n",
    "        self._pregunta2_punto_inflexion()\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"PREGUNTA 3: ¿Cómo impacta d en la variabilidad?\")\n",
    "        print(\"=\" * 80)\n",
    "        self._pregunta3_variabilidad()\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"PREGUNTA 4: ¿La diferenciación previa amplifica el efecto de d?\")\n",
    "        print(\"=\" * 80)\n",
    "        self._pregunta4_interaccion_modalidad()\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"PREGUNTA 5: ¿Cuándo es significativa la diferenciación? (Foco: Sieve Bootstrap)\")\n",
    "        print(\"=\" * 80)\n",
    "        self._pregunta5_consistencia()\n",
    "        \n",
    "        print(\"\\n✅ ANÁLISIS COMPLETO FINALIZADO\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # VISUALIZACIÓN EXTRA: HEATMAPS DE ECRPS MEDIO (Modelo vs d)\n",
    "    # ========================================================================\n",
    "    def _visualizar_heatmaps_ecrps_absolutos(self):\n",
    "        print(\"📊 Generando Heatmaps Generales de Rendimiento...\")\n",
    "\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(24, 10))\n",
    "        \n",
    "        vmin = self.df[self.modelos].min().min()\n",
    "        vmax_robust = np.percentile(self.df[self.modelos].values, 95)\n",
    "\n",
    "        for idx, modalidad in enumerate(self.modalidades):\n",
    "            if idx >= 2: break \n",
    "            \n",
    "            ax = axes[idx]\n",
    "            df_mod = self.df[self.df['Modalidad'] == modalidad]\n",
    "            \n",
    "            heatmap_data = df_mod.groupby('d')[self.modelos].mean().T\n",
    "            \n",
    "            # Crear matriz de anotaciones formateadas\n",
    "            annot_data = heatmap_data.applymap(self._fmt)\n",
    "            \n",
    "            sns.heatmap(heatmap_data, ax=ax, cmap=CMAP_HEATMAP, \n",
    "                        annot=annot_data.values, fmt='', # fmt='' es necesario cuando pasamos strings\n",
    "                        vmin=vmin, vmax=vmax_robust, \n",
    "                        linewidths=.5, cbar_kws={'label': 'ECRPS Medio'})\n",
    "            \n",
    "            ax.set_title(f'Rendimiento Medio (ECRPS) - {modalidad}', fontweight='bold', fontsize=14)\n",
    "            ax.set_xlabel('Orden de Diferenciación (d)', fontsize=12, fontweight='bold')\n",
    "            ax.set_ylabel('Modelo', fontsize=12, fontweight='bold')\n",
    "            ax.tick_params(axis='y', rotation=0)\n",
    "\n",
    "        plt.suptitle('Comparación de ECRPS Medio: Modelos vs. Orden de Diferenciación (d)', \n",
    "                     fontsize=16, fontweight='bold', y=0.98)\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        \n",
    "        nombre_archivo = \"0_General_Heatmaps_ECRPS_Medio.png\"\n",
    "        plt.savefig(self.dir_salida / nombre_archivo, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"   ✅ Gráfico guardado: {nombre_archivo}\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # PREGUNTA 1: SENSIBILIDAD DE MODELOS A d\n",
    "    # ========================================================================\n",
    "    def _pregunta1_sensibilidad_modelos(self):\n",
    "        resultados = []\n",
    "        for modalidad in self.modalidades:\n",
    "            df_mod = self.df[self.df['Modalidad'] == modalidad]\n",
    "            for modelo in self.modelos:\n",
    "                serie = df_mod.groupby('d')[modelo].median()\n",
    "                if len(serie) > 3:\n",
    "                    slope, intercept, _, _ = stats.theilslopes(serie.values, serie.index)\n",
    "                    corr, p_value = stats.spearmanr(serie.index, serie.values)\n",
    "                    rango = serie.max() - serie.min()\n",
    "                    variacion_pct = (rango / serie.mean()) * 100 if serie.mean() != 0 else 0\n",
    "                    \n",
    "                    resultados.append({\n",
    "                        'Modelo': modelo, 'Modalidad': modalidad, 'Pendiente': slope,\n",
    "                        'Correlación': corr, 'p_value': p_value, 'Rango': rango,\n",
    "                        'Variación_%': variacion_pct, 'Sensibilidad_Score': abs(slope) * abs(corr)\n",
    "                    })\n",
    "        \n",
    "        df_resultados = pd.DataFrame(resultados)\n",
    "        df_resultados.to_excel(self.dir_salida / \"P1_Sensibilidad_Modelos.xlsx\", index=False)\n",
    "        print(f\"   ✅ Excel guardado: P1_Sensibilidad_Modelos.xlsx\")\n",
    "        \n",
    "        self._visualizar_pregunta1(df_resultados)\n",
    "        \n",
    "        print(\"\\n🔥 TOP 3 MODELOS MÁS SENSIBLES A d:\")\n",
    "        top_sensibles = df_resultados.nlargest(3, 'Sensibilidad_Score')\n",
    "        for idx, row in top_sensibles.iterrows():\n",
    "            print(f\"   {row['Modelo']} ({row['Modalidad']}): Score={self._fmt(row['Sensibilidad_Score'])}\")\n",
    "\n",
    "    def _visualizar_pregunta1(self, df_resultados):\n",
    "        # 1.1 Ranking\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "        for idx, modalidad in enumerate(self.modalidades):\n",
    "            if idx >= 2: break\n",
    "            df_sub = df_resultados[df_resultados['Modalidad'] == modalidad].sort_values('Sensibilidad_Score')\n",
    "            ax = axes[idx]\n",
    "            colors = [COLOR_MAP_MODELOS[m] for m in df_sub['Modelo']]\n",
    "            bars = ax.barh(df_sub['Modelo'], df_sub['Sensibilidad_Score'], color=colors, edgecolor='black', alpha=0.8)\n",
    "            ax.set_xlabel('Score de Sensibilidad', fontweight='bold')\n",
    "            ax.set_title(f'P1.1: Sensibilidad a d - {modalidad}', fontweight='bold')\n",
    "            ax.grid(axis='x', alpha=0.3)\n",
    "            \n",
    "            # Anotación formateada\n",
    "            for bar in bars:\n",
    "                width = bar.get_width()\n",
    "                label = self._fmt(width)\n",
    "                ax.text(width, bar.get_y() + bar.get_height()/2, label, va='center', fontsize=9)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / 'P1_1_Ranking_Sensibilidad.png', dpi=300)\n",
    "        plt.close()\n",
    "        \n",
    "        # 1.2 Comparación\n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        piv = df_resultados.pivot(index='Modelo', columns='Modalidad', values='Pendiente')\n",
    "        piv.plot(kind='bar', ax=ax, width=0.7, edgecolor='black', \n",
    "                 color=[COLOR_SIN_DIFF, COLOR_CON_DIFF] if len(piv.columns)==2 else None)\n",
    "        ax.set_ylabel('Pendiente (ECRPS vs d)')\n",
    "        ax.set_title('P1.2: Pendientes de Sensibilidad por Modalidad')\n",
    "        ax.axhline(0, color='black', linestyle='--')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / 'P1_2_Pendientes_Comparacion.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    # ========================================================================\n",
    "    # PREGUNTA 2: PUNTO DE INFLEXIÓN\n",
    "    # ========================================================================\n",
    "    def _pregunta2_punto_inflexion(self):\n",
    "        resultados = []\n",
    "        for modalidad in self.modalidades:\n",
    "            df_mod = self.df[self.df['Modalidad'] == modalidad]\n",
    "            for modelo in self.modelos:\n",
    "                serie = df_mod.groupby('d')[modelo].median().dropna()\n",
    "                if len(serie) >= 5:\n",
    "                    x, y = serie.index.values, serie.values\n",
    "                    try:\n",
    "                        spline = UnivariateSpline(x, y, s=0.1, k=3)\n",
    "                        x_fine = np.linspace(x.min(), x.max(), 100)\n",
    "                        y_second_deriv = spline.derivative(n=2)(x_fine)\n",
    "                        d_inflexion = x_fine[np.argmax(np.abs(y_second_deriv))]\n",
    "                        resultados.append({\n",
    "                            'Modelo': modelo, 'Modalidad': modalidad, 'd_Inflexión': round(d_inflexion, 1),\n",
    "                            'Cambio_Total_%': ((serie.iloc[-1] - serie.iloc[0]) / serie.iloc[0] * 100) if serie.iloc[0] != 0 else 0\n",
    "                        })\n",
    "                    except: pass\n",
    "        \n",
    "        df_resultados = pd.DataFrame(resultados)\n",
    "        df_resultados.to_excel(self.dir_salida / \"P2_Puntos_Inflexion.xlsx\", index=False)\n",
    "        print(f\"   ✅ Excel guardado: P2_Puntos_Inflexion.xlsx\")\n",
    "        self._visualizar_pregunta2(df_resultados)\n",
    "\n",
    "    def _visualizar_pregunta2(self, df_resultados):\n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        for modalidad in self.modalidades:\n",
    "            df_sub = df_resultados[df_resultados['Modalidad'] == modalidad]\n",
    "            color = COLOR_SIN_DIFF if 'SIN' in modalidad else COLOR_CON_DIFF\n",
    "            ax.scatter(df_sub['d_Inflexión'], df_sub['Modelo'], s=200, alpha=0.7, color=color, edgecolor='black', label=modalidad, marker='D')\n",
    "        ax.axvline(df_resultados['d_Inflexión'].mean(), color='gray', linestyle='--', label='Media Global')\n",
    "        ax.set_xlabel('Valor de d en Punto de Inflexión')\n",
    "        ax.set_title('P2.1: Distribución de Puntos de Inflexión')\n",
    "        ax.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / 'P2_1_Distribucion_Inflexion.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    # ========================================================================\n",
    "    # PREGUNTA 3: IMPACTO EN VARIABILIDAD\n",
    "    # ========================================================================\n",
    "    def _pregunta3_variabilidad(self):\n",
    "        resultados = []\n",
    "        for modalidad in self.modalidades:\n",
    "            df_mod = self.df[self.df['Modalidad'] == modalidad]\n",
    "            for d_val in self.valores_d:\n",
    "                df_d = df_mod[df_mod['d'] == d_val]\n",
    "                for modelo in self.modelos:\n",
    "                    datos = df_d[modelo].dropna()\n",
    "                    if len(datos) > 5:\n",
    "                        q75, q25 = np.percentile(datos, [75, 25])\n",
    "                        resultados.append({\n",
    "                            'Modelo': modelo, 'Modalidad': modalidad, 'd': d_val,\n",
    "                            'IQR': q75 - q25,\n",
    "                            'QCD': (q75 - q25) / (q75 + q25) if (q75 + q25) > 0 else 0\n",
    "                        })\n",
    "        \n",
    "        df_resultados = pd.DataFrame(resultados)\n",
    "        df_resultados.to_excel(self.dir_salida / \"P3_Variabilidad_por_d.xlsx\", index=False)\n",
    "        print(f\"   ✅ Excel guardado: P3_Variabilidad_por_d.xlsx\")\n",
    "        self._visualizar_pregunta3(df_resultados)\n",
    "\n",
    "    def _visualizar_pregunta3(self, df_resultados):\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "        for idx, modalidad in enumerate(self.modalidades):\n",
    "            if idx >= 2: break\n",
    "            df_mod = df_resultados[df_resultados['Modalidad'] == modalidad]\n",
    "            ax = axes[idx]\n",
    "            for modelo in self.modelos:\n",
    "                df_m = df_mod[df_mod['Modelo'] == modelo]\n",
    "                if not df_m.empty:\n",
    "                    ax.plot(df_m['d'], df_m['IQR'], marker='o', label=modelo, color=COLOR_MAP_MODELOS[modelo])\n",
    "            ax.set_title(f'P3.1: Evolución IQR - {modalidad}')\n",
    "            ax.set_ylabel('IQR')\n",
    "            ax.set_xlabel('d')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / 'P3_1_Evolucion_IQR.png', dpi=300)\n",
    "        plt.close()\n",
    "        \n",
    "        # Heatmap QCD\n",
    "        for modalidad in self.modalidades:\n",
    "            piv = df_resultados[df_resultados['Modalidad'] == modalidad].pivot(index='Modelo', columns='d', values='QCD')\n",
    "            \n",
    "            # Formatear anotaciones\n",
    "            annot_qcd = piv.applymap(self._fmt)\n",
    "            \n",
    "            fig, ax = plt.subplots(figsize=(12, 6))\n",
    "            sns.heatmap(piv, annot=annot_qcd.values, fmt='', cmap=CMAP_HEATMAP, ax=ax)\n",
    "            ax.set_title(f'P3.2: Robustez Relativa (QCD) - {modalidad}')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(self.dir_salida / f'P3_2_Heatmap_QCD_{modalidad}.png', dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "    # ========================================================================\n",
    "    # PREGUNTA 4: INTERACCIÓN MODALIDAD × d\n",
    "    # ========================================================================\n",
    "    def _pregunta4_interaccion_modalidad(self):\n",
    "        if len(self.modalidades) < 2: return\n",
    "        resultados = []\n",
    "        for modelo in self.modelos:\n",
    "            pendientes = {}\n",
    "            for modalidad in self.modalidades:\n",
    "                df_mod = self.df[self.df['Modalidad'] == modalidad]\n",
    "                serie = df_mod.groupby('d')[modelo].median()\n",
    "                if len(serie) > 3:\n",
    "                    slope, _, _, _ = stats.theilslopes(serie.values, serie.index)\n",
    "                    pendientes[modalidad] = slope\n",
    "            \n",
    "            if len(pendientes) == 2:\n",
    "                mod1, mod2 = self.modalidades\n",
    "                interaccion = pendientes[mod2] - pendientes[mod1]\n",
    "                resultados.append({\n",
    "                    'Modelo': modelo, 'Pendiente_Diff': pendientes.get(mod2,0), 'Pendiente_Base': pendientes.get(mod1,0),\n",
    "                    'Interacción': interaccion,\n",
    "                    'Interpretación': 'Amplifica' if abs(pendientes[mod2]) > abs(pendientes[mod1]) else 'Modera'\n",
    "                })\n",
    "        \n",
    "        df_resultados = pd.DataFrame(resultados)\n",
    "        df_resultados.to_excel(self.dir_salida / \"P4_Interaccion_Modalidad.xlsx\", index=False)\n",
    "        print(f\"   ✅ Excel guardado: P4_Interaccion_Modalidad.xlsx\")\n",
    "        self._visualizar_pregunta4(df_resultados)\n",
    "\n",
    "    def _visualizar_pregunta4(self, df_resultados):\n",
    "        df_sorted = df_resultados.sort_values('Interacción')\n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        colors = ['#27ae60' if x < 0 else '#e74c3c' for x in df_sorted['Interacción']]\n",
    "        bars = ax.barh(df_sorted['Modelo'], df_sorted['Interacción'], color=colors, edgecolor='black', alpha=0.8)\n",
    "        ax.axvline(0, color='black', linestyle='--')\n",
    "        ax.set_xlabel('Efecto de Interacción (Pendiente_Diff - Pendiente_Base)')\n",
    "        ax.set_title('P4.2: Efecto de la Diferenciación sobre Sensibilidad a d')\n",
    "        \n",
    "        for bar in bars:\n",
    "            width = bar.get_width()\n",
    "            label = self._fmt(width)\n",
    "            ax.text(width, bar.get_y() + bar.get_height()/2, label, \n",
    "                   ha='left' if width > 0 else 'right', va='center', fontsize=9, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / 'P4_2_Efecto_Interaccion.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    # ========================================================================\n",
    "    # PREGUNTA 5: SIGNIFICANCIA DE LA DIFERENCIACIÓN (SIEVE BOOTSTRAP)\n",
    "    # ========================================================================\n",
    "    def _pregunta5_consistencia(self):\n",
    "        print(f\"\\n🔎 Analizando significancia estadística (Mann-Whitney U)...\")\n",
    "        resultados = []\n",
    "        if len(self.modalidades) < 2:\n",
    "            print(\"   ⚠️  No es posible comparar (falta modalidad).\")\n",
    "            return\n",
    "\n",
    "        mod_sin = [m for m in self.modalidades if 'SIN' in m][0]\n",
    "        mod_con = [m for m in self.modalidades if 'CON' in m][0]\n",
    "\n",
    "        for modelo in self.modelos:\n",
    "            for d_val in self.valores_d:\n",
    "                datos_sin = self.df[(self.df['Modalidad'] == mod_sin) & (self.df['d'] == d_val)][modelo].dropna()\n",
    "                datos_con = self.df[(self.df['Modalidad'] == mod_con) & (self.df['d'] == d_val)][modelo].dropna()\n",
    "                \n",
    "                if len(datos_sin) > 3 and len(datos_con) > 3:\n",
    "                    stat, p_value = stats.mannwhitneyu(datos_sin, datos_con, alternative='two-sided')\n",
    "                    diff_mediana = datos_sin.median() - datos_con.median()\n",
    "                    resultados.append({\n",
    "                        'Modelo': modelo, 'd': d_val, 'p_value': p_value,\n",
    "                        'Significativo': p_value < 0.05, 'Diff_Mediana': diff_mediana\n",
    "                    })\n",
    "\n",
    "        df_resultados = pd.DataFrame(resultados)\n",
    "        df_resultados.to_excel(self.dir_salida / \"P5_Significancia_Diferenciacion.xlsx\", index=False)\n",
    "        print(f\"   ✅ Excel guardado: P5_Significancia_Diferenciacion.xlsx\")\n",
    "        \n",
    "        self._visualizar_pregunta5(df_resultados)\n",
    "        \n",
    "        print(\"\\n🧐 ANÁLISIS ESPECÍFICO: Sieve Bootstrap\")\n",
    "        df_sb = df_resultados[df_resultados['Modelo'] == 'Sieve Bootstrap'].sort_values('d')\n",
    "        if not df_sb.empty:\n",
    "            significativos = df_sb[df_sb['Significativo']]\n",
    "            if not significativos.empty:\n",
    "                primer_d = significativos['d'].iloc[0]\n",
    "                print(f\"   👉 Para Sieve Bootstrap, la diferenciación es estadísticamente significativa (p < 0.05)\")\n",
    "                print(f\"      a partir de d = {primer_d}\")\n",
    "            else:\n",
    "                print(\"   👉 No se encontraron diferencias significativas para Sieve Bootstrap en ningún d.\")\n",
    "        else:\n",
    "            print(\"   ⚠️  Sieve Bootstrap no encontrado en los resultados.\")\n",
    "\n",
    "    def _visualizar_pregunta5(self, df_resultados):\n",
    "        piv_p = df_resultados.pivot(index='Modelo', columns='d', values='p_value')\n",
    "        log_p = -np.log10(piv_p + 1e-10) \n",
    "        \n",
    "        # Formatear P-values para anotación\n",
    "        annot_p = piv_p.applymap(self._fmt)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        # Usamos 'magma' en minúsculas para evitar KeyError\n",
    "        sns.heatmap(log_p, cmap='magma', annot=annot_p.values, fmt='', \n",
    "                    cbar_kws={'label': '-log10(p-value)'}, ax=ax)\n",
    "        \n",
    "        ax.set_title('P5.1: Significancia Estadística (p-values) - Valores claros = Muy Significativo')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / 'P5_1_Heatmap_Significancia.png', dpi=300)\n",
    "        plt.close()\n",
    "        \n",
    "        # 5.2 Evolución P-value\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        ax.axhline(0.05, color='red', linestyle='--', label='p=0.05')\n",
    "        \n",
    "        df_sb = df_resultados[df_resultados['Modelo'] == 'Sieve Bootstrap']\n",
    "        if not df_sb.empty:\n",
    "            ax.plot(df_sb['d'], df_sb['p_value'], marker='o', linewidth=3, color='#8e44ad', label='Sieve Bootstrap')\n",
    "        \n",
    "        for modelo in self.modelos:\n",
    "            if modelo != 'Sieve Bootstrap':\n",
    "                df_m = df_resultados[df_resultados['Modelo'] == modelo]\n",
    "                ax.plot(df_m['d'], df_m['p_value'], color='gray', alpha=0.15)\n",
    "        \n",
    "        ax.set_yscale('log')\n",
    "        ax.set_ylabel('P-value (Log)')\n",
    "        ax.set_title('P5.2: Evolución de P-value para Sieve Bootstrap')\n",
    "        ax.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / 'P5_2_Sieve_Bootstrap_Significancia.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# EJECUCIÓN\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if Path(RUTA_DATOS).exists():\n",
    "        analizador = AnalizadorSensibilidadD(RUTA_DATOS)\n",
    "        analizador.ejecutar_analisis_completo()\n",
    "    else:\n",
    "        print(f\"\\n⛔ ERROR: No se encontró el archivo: {RUTA_DATOS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b8a52b",
   "metadata": {},
   "source": [
    "# Analisis cambio de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0169f259",
   "metadata": {},
   "source": [
    "## Pre-procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfd6fb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TABLA COMPARATIVA DE MODELOS POR ESCENARIO\n",
      "(Promedio de amplitud de intervalos de predicción)\n",
      "================================================================================\n",
      "             Modelo   ARMA   ARIMA  SETAR Mejor_Escenario\n",
      "              AREPD 0.9345 13.0489 0.6971           SETAR\n",
      "            AV-MCPS 0.6768  3.5050 0.6531           SETAR\n",
      "Block Bootstrapping 0.9049 15.1183 0.6318           SETAR\n",
      "             DeepAR 0.5650  3.6998 0.5845            ARMA\n",
      "         EnCQR-LSTM 0.9515  5.9330 0.8404           SETAR\n",
      "               LSPM 0.7689  1.0868 0.6586           SETAR\n",
      "              LSPMW 0.7931  1.0870 0.6754           SETAR\n",
      "               MCPS 0.6496  3.2780 0.6325           SETAR\n",
      "    Sieve Bootstrap 0.5541  0.5583 0.6254            ARMA\n",
      "================================================================================\n",
      "\n",
      "Tabla comparativa guardada en 'Tabla_Comparativa_Modelos_tamaño.xlsx'\n",
      "\n",
      "Archivo 'Base_Tamaño_3_escenarios.xlsx' creado exitosamente!\n",
      "\n",
      "Total de filas: 126000\n",
      "- ARMA: 42000 filas\n",
      "- ARIMA: 42000 filas\n",
      "- SETAR: 42000 filas\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Leer los tres archivos\n",
    "arma_df = pd.read_excel(\"./datos/resultados_TAMANOS_CRECIENTES_ARMA.xlsx\")\n",
    "arima_df = pd.read_excel(\"./datos/resultados_TAMANOS_CRECIENTES_ARIMA.xlsx\")\n",
    "setar_df = pd.read_excel(\"./datos/resultados_TAMANOS_CRECIENTES_SETAR.xlsx\")\n",
    "\n",
    "# Filtrar los que no tienen \"Promedio\" en la columna \"Paso\"\n",
    "arma_df = arma_df[arma_df['Paso'] != 'Promedio']\n",
    "arima_df = arima_df[arima_df['Paso'] != 'Promedio']\n",
    "setar_df = setar_df[setar_df['Paso'] != 'Promedio']\n",
    "\n",
    "# Lista de modelos (columnas a promediar)\n",
    "modelos = ['AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR',\n",
    "           'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
    "\n",
    "# Crear tabla comparativa\n",
    "comparacion = []\n",
    "\n",
    "for modelo in modelos:\n",
    "    fila = {'Modelo': modelo}\n",
    "    \n",
    "    # Calcular promedio para cada escenario (de la columna del modelo)\n",
    "    arma_promedio = arma_df[modelo].mean() if modelo in arma_df.columns else np.nan\n",
    "    arima_promedio = arima_df[modelo].mean() if modelo in arima_df.columns else np.nan\n",
    "    setar_promedio = setar_df[modelo].mean() if modelo in setar_df.columns else np.nan\n",
    "    \n",
    "    fila['ARMA'] = arma_promedio\n",
    "    fila['ARIMA'] = arima_promedio\n",
    "    fila['SETAR'] = setar_promedio\n",
    "    \n",
    "    # Determinar mejor escenario (menor promedio)\n",
    "    promedios = {\n",
    "        'ARMA': arma_promedio,\n",
    "        'ARIMA': arima_promedio,\n",
    "        'SETAR': setar_promedio\n",
    "    }\n",
    "    \n",
    "    # Filtrar NaN si existen\n",
    "    promedios_validos = {k: v for k, v in promedios.items() if not pd.isna(v)}\n",
    "    \n",
    "    if promedios_validos:\n",
    "        mejor_escenario = min(promedios_validos, key=promedios_validos.get)\n",
    "        fila['Mejor_Escenario'] = mejor_escenario\n",
    "    else:\n",
    "        fila['Mejor_Escenario'] = 'N/A'\n",
    "    \n",
    "    comparacion.append(fila)\n",
    "\n",
    "# Crear DataFrame con la tabla comparativa\n",
    "tabla_comparativa = pd.DataFrame(comparacion)\n",
    "\n",
    "# Redondear valores para mejor visualización\n",
    "columnas_numericas = ['ARMA', 'ARIMA', 'SETAR']\n",
    "tabla_comparativa[columnas_numericas] = tabla_comparativa[columnas_numericas].round(4)\n",
    "\n",
    "# Mostrar tabla comparativa\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TABLA COMPARATIVA DE MODELOS POR ESCENARIO\")\n",
    "print(\"(Promedio de amplitud de intervalos de predicción)\")\n",
    "print(\"=\"*80)\n",
    "print(tabla_comparativa.to_string(index=False))\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Guardar tabla comparativa en Excel\n",
    "tabla_comparativa.to_excel(\"Tabla_Comparativa_Modelos_tamaño.xlsx\", index=False)\n",
    "print(\"Tabla comparativa guardada en 'Tabla_Comparativa_Modelos_tamaño.xlsx'\")\n",
    "\n",
    "# Procesamiento especial para SETAR\n",
    "if 'Descripción' in setar_df.columns:\n",
    "    setar_df = setar_df.drop('Descripción', axis=1)\n",
    "\n",
    "# Agregar columna ESCENARIO a cada DataFrame antes de concatenar\n",
    "arma_df['ESCENARIO'] = 'Lineal - estacionario'\n",
    "arima_df['ESCENARIO'] = 'Lineal - NO estacionario'\n",
    "setar_df['ESCENARIO'] = 'NO lineal - estacionario'\n",
    "\n",
    "# Concatenar los tres dataframes\n",
    "base_consolidada = pd.concat([arma_df, arima_df, setar_df], ignore_index=True)\n",
    "\n",
    "# Guardar en un archivo Excel\n",
    "base_consolidada.to_excel(\"Base_Tamaño_3_escenarios.xlsx\", index=False)\n",
    "\n",
    "print(\"\\nArchivo 'Base_Tamaño_3_escenarios.xlsx' creado exitosamente!\")\n",
    "print(f\"\\nTotal de filas: {len(base_consolidada)}\")\n",
    "print(f\"- ARMA: {len(arma_df)} filas\")\n",
    "print(f\"- ARIMA: {len(arima_df)} filas\")\n",
    "print(f\"- SETAR: {len(setar_df)} filas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6a6937",
   "metadata": {},
   "source": [
    "## Analisis general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "518faae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos...\n",
      "Columnas disponibles: ['Paso', 'Proceso', 'Tipo_Proceso', 'Distribución', 'Varianza', 'N_Train', 'N_Calib', 'N_Total', 'Valor_Observado', 'AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', 'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap', 'ESCENARIO']\n",
      "N_Total únicos: [np.int64(120), np.int64(140), np.int64(160), np.int64(200), np.int64(220), np.int64(240), np.int64(260), np.int64(300), np.int64(320), np.int64(340), np.int64(360), np.int64(400), np.int64(500), np.int64(520), np.int64(540), np.int64(560), np.int64(600), np.int64(700), np.int64(1020), np.int64(1040), np.int64(1060), np.int64(1100), np.int64(1200)]\n",
      "Número de observaciones: 126000\n",
      "\n",
      "================================================================================\n",
      "ANÁLISIS 1: HEATMAPS - Promedio de ECRPS por Proceso y N_Total\n",
      "================================================================================\n",
      "Heatmap guardado: resultados_analisis_ntotal\\heatmap_AREPD.png\n",
      "Heatmap guardado: resultados_analisis_ntotal\\heatmap_AV-MCPS.png\n",
      "Heatmap guardado: resultados_analisis_ntotal\\heatmap_Block_Bootstrapping.png\n",
      "Heatmap guardado: resultados_analisis_ntotal\\heatmap_DeepAR.png\n",
      "Heatmap guardado: resultados_analisis_ntotal\\heatmap_EnCQR-LSTM.png\n",
      "Heatmap guardado: resultados_analisis_ntotal\\heatmap_LSPM.png\n",
      "Heatmap guardado: resultados_analisis_ntotal\\heatmap_LSPMW.png\n",
      "Heatmap guardado: resultados_analisis_ntotal\\heatmap_MCPS.png\n",
      "Heatmap guardado: resultados_analisis_ntotal\\heatmap_Sieve_Bootstrap.png\n",
      "\n",
      "================================================================================\n",
      "ANÁLISIS 2: MEJOR N_TOTAL (Menor ECRPS Promedio)\n",
      "================================================================================\n",
      "ARMA | AREPD: N_Total=140 (ECRPS=0.8919)\n",
      "ARMA | AV-MCPS: N_Total=1200 (ECRPS=0.5962)\n",
      "ARMA | Block Bootstrapping: N_Total=400 (ECRPS=0.8428)\n",
      "ARMA | DeepAR: N_Total=400 (ECRPS=0.5341)\n",
      "ARMA | EnCQR-LSTM: N_Total=1200 (ECRPS=0.7455)\n",
      "ARMA | LSPM: N_Total=1200 (ECRPS=0.7326)\n",
      "ARMA | LSPMW: N_Total=1200 (ECRPS=0.7558)\n",
      "ARMA | MCPS: N_Total=1200 (ECRPS=0.5563)\n",
      "ARMA | Sieve Bootstrap: N_Total=1020 (ECRPS=0.5274)\n",
      "ARIMA | AREPD: N_Total=120 (ECRPS=7.8918)\n",
      "ARIMA | AV-MCPS: N_Total=320 (ECRPS=2.7402)\n",
      "ARIMA | Block Bootstrapping: N_Total=120 (ECRPS=8.7461)\n",
      "ARIMA | DeepAR: N_Total=1100 (ECRPS=2.9367)\n",
      "ARIMA | EnCQR-LSTM: N_Total=240 (ECRPS=4.3085)\n",
      "ARIMA | LSPM: N_Total=1200 (ECRPS=1.0382)\n",
      "ARIMA | LSPMW: N_Total=1200 (ECRPS=1.0354)\n",
      "ARIMA | MCPS: N_Total=160 (ECRPS=2.6655)\n",
      "ARIMA | Sieve Bootstrap: N_Total=1020 (ECRPS=0.5275)\n",
      "SETAR | AREPD: N_Total=560 (ECRPS=0.6606)\n",
      "SETAR | AV-MCPS: N_Total=1060 (ECRPS=0.6157)\n",
      "SETAR | Block Bootstrapping: N_Total=1060 (ECRPS=0.6024)\n",
      "SETAR | DeepAR: N_Total=400 (ECRPS=0.5539)\n",
      "SETAR | EnCQR-LSTM: N_Total=1100 (ECRPS=0.8152)\n",
      "SETAR | LSPM: N_Total=1100 (ECRPS=0.6293)\n",
      "SETAR | LSPMW: N_Total=1060 (ECRPS=0.6484)\n",
      "SETAR | MCPS: N_Total=1060 (ECRPS=0.5666)\n",
      "SETAR | Sieve Bootstrap: N_Total=1100 (ECRPS=0.5878)\n",
      "\n",
      "================================================================================\n",
      "ANÁLISIS 3: Comparaciones DM entre N_Totales\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "ANÁLISIS 4: Resumen Estadístico (ECRPS)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "ANÁLISIS 5: Evolución del ECRPS por Proceso\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "ANÁLISIS 5B: Tendencia Global de Modelos (ECRPS vs N_Total)\n",
      "================================================================================\n",
      "Gráfica de tendencia global guardada: resultados_analisis_ntotal\\tendencia_global_modelos.png\n",
      "\n",
      "================================================================================\n",
      "ANÁLISIS 6: Generando Rankings\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "ANÁLISIS 7: Variabilidad (Desviación Estándar)\n",
      "================================================================================\n",
      "Heatmap de variabilidad (STD) guardado: resultados_analisis_ntotal\\variabilidad_std_general.png\n",
      "\n",
      "✅ Proceso completado. Revisa la carpeta de resultados.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8451"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from itertools import combinations\n",
    "import warnings\n",
    "import gc\n",
    "\n",
    "# Ignorar advertencias\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "# Crear carpeta de resultados\n",
    "output_dir = Path(\"./resultados_analisis_ntotal\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Configuración\n",
    "archivo_excel = \"./Base_Tamaño_3_escenarios.xlsx\"\n",
    "MODELOS = ['AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR',\n",
    "           'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
    "\n",
    "# Cargar datos\n",
    "print(\"Cargando datos...\")\n",
    "try:\n",
    "    df = pd.read_excel(archivo_excel)\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: No se encontró el archivo '{archivo_excel}'.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Columnas disponibles: {df.columns.tolist()}\")\n",
    "print(f\"N_Total únicos: {sorted(df['N_Total'].unique())}\")\n",
    "print(f\"Número de observaciones: {len(df)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# FUNCIÓN DIEBOLD-MARIANO\n",
    "# ============================================================================\n",
    "\n",
    "def diebold_mariano_test(series1, series2):\n",
    "    \"\"\"\n",
    "    Test de Diebold-Mariano.\n",
    "    Asumimos que las series ingresadas ya son las pérdidas (ECRPS), \n",
    "    por lo que comparamos d = L1 - L2 directamente o cuadrática según se desee.\n",
    "    Aquí se mantiene la lógica cuadrática estándar del test sobre la diferencia.\n",
    "    \"\"\"\n",
    "    d = series1**2 - series2**2\n",
    "    d = d.dropna()\n",
    "    \n",
    "    if len(d) < 2:\n",
    "        return np.nan, np.nan\n",
    "    \n",
    "    d_mean = d.mean()\n",
    "    n = len(d)\n",
    "    d_var = d.var() / n\n",
    "    \n",
    "    if d_var <= 0:\n",
    "        return np.nan, np.nan\n",
    "    \n",
    "    dm_stat = d_mean / np.sqrt(d_var)\n",
    "    p_value = 2 * (1 - stats.norm.cdf(abs(dm_stat)))\n",
    "    \n",
    "    return dm_stat, p_value\n",
    "\n",
    "# ============================================================================\n",
    "# ANÁLISIS 1: HEATMAPS - PROMEDIO DE ECRPS POR TIPO_PROCESO Y N_TOTAL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANÁLISIS 1: HEATMAPS - Promedio de ECRPS por Proceso y N_Total\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for modelo in MODELOS:\n",
    "    # Calcular promedio de ECRPS (asumiendo que el valor en excel ya es el score positivo)\n",
    "    pivot_data = df.groupby(['Proceso', 'N_Total'])[modelo].mean().reset_index()\n",
    "    pivot_table = pivot_data.pivot(index='Proceso', columns='N_Total', values=modelo)\n",
    "    \n",
    "    # Crear heatmap\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    \n",
    "    sns.heatmap(pivot_table, \n",
    "                annot=True, \n",
    "                fmt='.2f',  # <--- CAMBIO: Solo 2 dígitos\n",
    "                cmap='RdYlGn_r',  # Rojo=alto ECRPS (malo), Verde=bajo ECRPS (bueno)\n",
    "                cbar_kws={'label': 'ECRPS Promedio', 'shrink': 0.7}, # Barra reducida al 70%\n",
    "                linewidths=0.5,\n",
    "                linecolor='gray',\n",
    "                ax=ax)\n",
    "    \n",
    "    plt.title(f'Heatmap: {modelo}\\nECRPS Promedio por Proceso y N_Total',\n",
    "              fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.xlabel('N_Total (Tamaño de Muestra)', fontsize=11)\n",
    "    plt.ylabel('Tipo de Proceso', fontsize=11)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    archivo_heatmap = output_dir / f\"heatmap_{modelo.replace(' ', '_')}.png\"\n",
    "    plt.savefig(archivo_heatmap, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Heatmap guardado: {archivo_heatmap}\")\n",
    "    plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# ANÁLISIS 2: MEJOR N_TOTAL POR TIPO_PROCESO Y MODELO\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANÁLISIS 2: MEJOR N_TOTAL (Menor ECRPS Promedio)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "resultados_mejor_ntotal = []\n",
    "\n",
    "for tipo_proceso in df['Tipo_Proceso'].unique():\n",
    "    for modelo in MODELOS:\n",
    "        df_filtrado = df[df['Tipo_Proceso'] == tipo_proceso]\n",
    "        \n",
    "        # Calcular ECRPS promedio por N_Total\n",
    "        promedios = df_filtrado.groupby('N_Total')[modelo].mean()\n",
    "        \n",
    "        mejor_ntotal = promedios.idxmin()\n",
    "        mejor_score = promedios.min()\n",
    "        \n",
    "        resultados_mejor_ntotal.append({\n",
    "            'Tipo_Proceso': tipo_proceso,\n",
    "            'Modelo': modelo,\n",
    "            'Mejor_N_Total': mejor_ntotal,\n",
    "            'ECRPS_Promedio': round(mejor_score, 4)\n",
    "        })\n",
    "        \n",
    "        print(f\"{tipo_proceso} | {modelo}: N_Total={mejor_ntotal} (ECRPS={mejor_score:.4f})\")\n",
    "\n",
    "# Guardar en Excel\n",
    "df_mejor_ntotal = pd.DataFrame(resultados_mejor_ntotal)\n",
    "archivo_mejor = output_dir / \"mejor_ntotal_por_modelo_y_tipo.xlsx\"\n",
    "df_mejor_ntotal.to_excel(archivo_mejor, index=False)\n",
    "\n",
    "# ============================================================================\n",
    "# ANÁLISIS 3: COMPARACIÓN ENTRE N_TOTALES CON DIEBOLD-MARIANO\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANÁLISIS 3: Comparaciones DM entre N_Totales\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "resultados_dm = []\n",
    "\n",
    "for tipo_proceso in df['Tipo_Proceso'].unique():\n",
    "    for modelo in MODELOS:\n",
    "        df_filtrado = df[df['Tipo_Proceso'] == tipo_proceso]\n",
    "        ntotales_disponibles = sorted(df_filtrado['N_Total'].unique())\n",
    "        \n",
    "        for ntotal1, ntotal2 in combinations(ntotales_disponibles, 2):\n",
    "            series1 = df_filtrado[df_filtrado['N_Total'] == ntotal1][modelo]\n",
    "            series2 = df_filtrado[df_filtrado['N_Total'] == ntotal2][modelo]\n",
    "            \n",
    "            if len(series1) > 0 and len(series2) > 0:\n",
    "                dm_stat, p_value = diebold_mariano_test(series1, series2)\n",
    "                \n",
    "                mean1 = series1.mean()\n",
    "                mean2 = series2.mean()\n",
    "                \n",
    "                es_significativo = p_value < 0.05 if not np.isnan(p_value) else False\n",
    "                \n",
    "                if es_significativo:\n",
    "                    if mean1 < mean2:\n",
    "                        ganador = ntotal1\n",
    "                        diferencia = \"N_Total={} es significativamente MEJOR\".format(ntotal1)\n",
    "                    else:\n",
    "                        ganador = ntotal2\n",
    "                        diferencia = \"N_Total={} es significativamente MEJOR\".format(ntotal2)\n",
    "                else:\n",
    "                    ganador = None\n",
    "                    diferencia = \"Sin diferencia significativa\"\n",
    "                \n",
    "                resultados_dm.append({\n",
    "                    'Tipo_Proceso': tipo_proceso,\n",
    "                    'Modelo': modelo,\n",
    "                    'N_Total_1': ntotal1,\n",
    "                    'N_Total_2': ntotal2,\n",
    "                    'ECRPS_1': round(mean1, 4),\n",
    "                    'ECRPS_2': round(mean2, 4),\n",
    "                    'P_Value': round(p_value, 4) if not np.isnan(p_value) else None,\n",
    "                    'Significativo': 'Sí' if es_significativo else 'No',\n",
    "                    'Interpretación': diferencia\n",
    "                })\n",
    "\n",
    "df_dm = pd.DataFrame(resultados_dm)\n",
    "archivo_dm = output_dir / \"comparaciones_ntotal_diebold_mariano.xlsx\"\n",
    "with pd.ExcelWriter(archivo_dm, engine='openpyxl') as writer:\n",
    "    df_dm.to_excel(writer, sheet_name='Resultados', index=False)\n",
    "\n",
    "# ============================================================================\n",
    "# ANÁLISIS 4: RESUMEN ESTADÍSTICO\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANÁLISIS 4: Resumen Estadístico (ECRPS)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "resumen_stats = []\n",
    "for tipo_proceso in df['Tipo_Proceso'].unique():\n",
    "    for ntotal in sorted(df['N_Total'].unique()):\n",
    "        df_filtrado = df[(df['Tipo_Proceso'] == tipo_proceso) & (df['N_Total'] == ntotal)]\n",
    "        \n",
    "        for modelo in MODELOS:\n",
    "            vals = df_filtrado[modelo] # Asumimos ECRPS directo\n",
    "            resumen_stats.append({\n",
    "                'Tipo_Proceso': tipo_proceso,\n",
    "                'N_Total': ntotal,\n",
    "                'Modelo': modelo,\n",
    "                'Media': round(vals.mean(), 4),\n",
    "                'Mediana': round(vals.median(), 4),\n",
    "                'Desv_Std': round(vals.std(), 4),\n",
    "                'Min': round(vals.min(), 4),\n",
    "                'Max': round(vals.max(), 4)\n",
    "            })\n",
    "\n",
    "df_resumen = pd.DataFrame(resumen_stats)\n",
    "df_resumen.to_excel(output_dir / \"resumen_estadistico_ntotal.xlsx\", index=False)\n",
    "\n",
    "# ============================================================================\n",
    "# ANÁLISIS 5: GRÁFICO DE LÍNEAS - EVOLUCIÓN POR TIPO DE PROCESO\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANÁLISIS 5: Evolución del ECRPS por Proceso\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for tipo_proceso in df['Tipo_Proceso'].unique():\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    for modelo in MODELOS:\n",
    "        df_filtrado = df[df['Tipo_Proceso'] == tipo_proceso]\n",
    "        promedios = df_filtrado.groupby('N_Total')[modelo].mean()\n",
    "        \n",
    "        ax.plot(promedios.index, promedios.values, marker='o', linewidth=2, label=modelo)\n",
    "    \n",
    "    ax.set_xlabel('N_Total (Tamaño de Muestra)', fontsize=12)\n",
    "    ax.set_ylabel('ECRPS Promedio', fontsize=12)\n",
    "    ax.set_title(f'Evolución del ECRPS por N_Total\\nTipo de Proceso: {tipo_proceso}',\n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='upper right', fontsize=10, bbox_to_anchor=(1.15, 1))\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    archivo_lineas = output_dir / f\"evolucion_ecrps_{tipo_proceso.replace(' ', '_')}.png\"\n",
    "    plt.savefig(archivo_lineas, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# ANÁLISIS 5B: TENDENCIA GLOBAL (TODOS LOS MODELOS EN UNA GRÁFICA)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANÁLISIS 5B: Tendencia Global de Modelos (ECRPS vs N_Total)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Agrupar por N_Total para todos los procesos juntos (Promedio General)\n",
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(MODELOS)))\n",
    "\n",
    "for i, modelo in enumerate(MODELOS):\n",
    "    # Calcular promedio global por N_Total (ignorando tipo de proceso)\n",
    "    promedios_globales = df.groupby('N_Total')[modelo].mean()\n",
    "    \n",
    "    ax.plot(promedios_globales.index, promedios_globales.values, \n",
    "            marker='o', markersize=6, linewidth=2.5, \n",
    "            color=colors[i], label=modelo)\n",
    "\n",
    "ax.set_xlabel('N_Total (Tamaño de Muestra)', fontsize=14)\n",
    "ax.set_ylabel('ECRPS Promedio Global', fontsize=14)\n",
    "ax.set_title('Tendencia Global: ECRPS Promedio por Modelo vs N_Total',\n",
    "             fontsize=18, fontweight='bold', pad=20)\n",
    "\n",
    "# Ajustar leyenda y grid\n",
    "ax.legend(title='Modelos', title_fontsize=12, fontsize=11, \n",
    "          loc='upper left', bbox_to_anchor=(1, 1))\n",
    "ax.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "\n",
    "archivo_global = output_dir / \"tendencia_global_modelos.png\"\n",
    "plt.savefig(archivo_global, dpi=300, bbox_inches='tight')\n",
    "print(f\"Gráfica de tendencia global guardada: {archivo_global}\")\n",
    "plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# ANÁLISIS 6: RANKINGS Y FRECUENCIAS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANÁLISIS 6: Generando Rankings\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "rankings = []\n",
    "for tipo_proceso in df['Tipo_Proceso'].unique():\n",
    "    for ntotal in sorted(df['N_Total'].unique()):\n",
    "        df_filtrado = df[(df['Tipo_Proceso'] == tipo_proceso) & (df['N_Total'] == ntotal)]\n",
    "        \n",
    "        errores_promedio = {}\n",
    "        for modelo in MODELOS:\n",
    "            errores_promedio[modelo] = df_filtrado[modelo].mean()\n",
    "        \n",
    "        ranking_modelos = sorted(errores_promedio.items(), key=lambda x: x[1])\n",
    "        \n",
    "        for rank, (modelo, score) in enumerate(ranking_modelos, 1):\n",
    "            rankings.append({\n",
    "                'Tipo_Proceso': tipo_proceso,\n",
    "                'N_Total': ntotal,\n",
    "                'Rank': rank,\n",
    "                'Modelo': modelo,\n",
    "                'ECRPS_Promedio': score\n",
    "            })\n",
    "\n",
    "df_rankings = pd.DataFrame(rankings)\n",
    "archivo_rankings = output_dir / \"rankings_modelos_por_ntotal.xlsx\"\n",
    "df_rankings.to_excel(archivo_rankings, index=False)\n",
    "\n",
    "# ============================================================================\n",
    "# ANÁLISIS 7: VARIABILIDAD (Heatmaps STD)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANÁLISIS 7: Variabilidad (Desviación Estándar)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "variabilidad_resultados = []\n",
    "\n",
    "# Calcular variabilidad general\n",
    "for modelo in MODELOS:\n",
    "    for ntotal in sorted(df['N_Total'].unique()):\n",
    "        vals = df[df['N_Total'] == ntotal][modelo]\n",
    "        variabilidad_resultados.append({\n",
    "            'Escenario': 'General',\n",
    "            'Modelo': modelo,\n",
    "            'N_Total': ntotal,\n",
    "            'Desv_Std': vals.std(),\n",
    "            'CV': (vals.std() / vals.mean() * 100) if vals.mean() != 0 else 0\n",
    "        })\n",
    "\n",
    "df_variabilidad = pd.DataFrame(variabilidad_resultados)\n",
    "\n",
    "# Generar Heatmap de Desviación Estándar (General)\n",
    "df_esc = df_variabilidad[df_variabilidad['Escenario'] == 'General']\n",
    "pivot_std = df_esc.pivot(index='Modelo', columns='N_Total', values='Desv_Std')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "\n",
    "sns.heatmap(pivot_std, \n",
    "            annot=True, \n",
    "            fmt='.2f',  # <--- CAMBIO: Solo 2 dígitos\n",
    "            cmap='YlOrRd',\n",
    "            cbar_kws={'label': 'Desviación Estándar (ECRPS)', 'shrink': 0.6}, # <--- CAMBIO: Barra reducida\n",
    "            linewidths=0.5,\n",
    "            linecolor='gray',\n",
    "            annot_kws={'size': 9},\n",
    "            square=True,\n",
    "            ax=ax)\n",
    "\n",
    "plt.title('Variabilidad (Desviación Estándar) del ECRPS\\nEscenario General',\n",
    "          fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "\n",
    "archivo_var = output_dir / \"variabilidad_std_general.png\"\n",
    "plt.savefig(archivo_var, dpi=300, bbox_inches='tight')\n",
    "print(f\"Heatmap de variabilidad (STD) guardado: {archivo_var}\")\n",
    "plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# FINALIZAR\n",
    "# ============================================================================\n",
    "print(\"\\n✅ Proceso completado. Revisa la carpeta de resultados.\")\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7966bbd6",
   "metadata": {},
   "source": [
    "# Analisis Simulacion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86610207",
   "metadata": {},
   "source": [
    "## Analisis General - Simulación Base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc245af6",
   "metadata": {},
   "source": [
    "### Pre-procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "378a602a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tabla Comparativa de Modelos (Basada en MEDIA) ---\n",
      "             Modelo  General     ARMA     ARIMA    SETAR Mejor_Escenario\n",
      "Block Bootstrapping 4.275365 0.946781 11.251601 0.627714           SETAR\n",
      "    Sieve Bootstrap 0.570491 0.547725  0.547481 0.616268           ARIMA\n",
      "               LSPM 0.845497 0.811287  1.064804 0.660398           SETAR\n",
      "              LSPMW 1.572319 0.960743  3.079645 0.676570           SETAR\n",
      "              AREPD 3.880255 0.936671 10.031183 0.672910           SETAR\n",
      "               MCPS 1.553139 0.752295  3.218168 0.688955           SETAR\n",
      "            AV-MCPS 1.578091 0.733188  3.324007 0.677078           SETAR\n",
      "             DeepAR 1.836024 0.568693  4.329124 0.610255            ARMA\n",
      "         EnCQR-LSTM 2.675191 1.071557  6.112344 0.841671           SETAR\n",
      "\n",
      "--- Tabla Comparativa de Modelos (Basada en MEDIANA) ---\n",
      "             Modelo  General     ARMA    ARIMA    SETAR Mejor_Escenario\n",
      "Block Bootstrapping 0.989415 0.654169 5.283530 0.540627           SETAR\n",
      "    Sieve Bootstrap 0.504848 0.483753 0.487997 0.535568            ARMA\n",
      "               LSPM 0.617954 0.617367 0.813400 0.551614           SETAR\n",
      "              LSPMW 0.803709 0.671465 1.666194 0.559561           SETAR\n",
      "              AREPD 0.987714 0.650945 4.398461 0.566293           SETAR\n",
      "               MCPS 0.676059 0.612732 1.237445 0.590001           SETAR\n",
      "            AV-MCPS 0.668131 0.597699 1.229916 0.581804           SETAR\n",
      "             DeepAR 0.579363 0.510069 1.029325 0.531675            ARMA\n",
      "         EnCQR-LSTM 1.250342 0.889849 3.776379 0.735301           SETAR\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Leer los archivos\n",
    "arma_df = pd.read_excel(\"./datos/Simulacion/Base/resultados_140_ARMA_FINAL.xlsx\")\n",
    "arima_df = pd.read_excel(\"./datos/Simulacion/Base/resultados_140_ARIMA_FINAL.xlsx\")\n",
    "setar_df = pd.read_excel(\"./datos/Simulacion/Base/resultados_140_SETAR_FINAL.xlsx\")\n",
    "\n",
    "# 2. Asignar la columna ESCENARIO a cada dataframe\n",
    "arma_df['ESCENARIO'] = \"Lineal Estacionario\"\n",
    "arima_df['ESCENARIO'] = \"Lineal No estacionario\"\n",
    "setar_df['ESCENARIO'] = \"No lineal Estacionario\"\n",
    "\n",
    "# 3. Juntarlos uno bajo el otro (Concatenar)\n",
    "df_total = pd.concat([arma_df, arima_df, setar_df], ignore_index=True)\n",
    "\n",
    "# Seleccionar solo las columnas requeridas\n",
    "columnas_deseadas = [\n",
    "    \"Paso\", \"Config\", \"Dist\", \"Var\", \"Block Bootstrapping\", \n",
    "    \"Sieve Bootstrap\", \"LSPM\", \"LSPMW\", \"AREPD\", \"MCPS\", \n",
    "    \"AV-MCPS\", \"DeepAR\", \"EnCQR-LSTM\", \"ESCENARIO\"\n",
    "]\n",
    "df_total = df_total[columnas_deseadas]\n",
    "\n",
    "# Definimos cuáles son las columnas que representan a los modelos predictivos\n",
    "modelos = [\n",
    "    \"Block Bootstrapping\", \"Sieve Bootstrap\", \"LSPM\", \"LSPMW\", \n",
    "    \"AREPD\", \"MCPS\", \"AV-MCPS\", \"DeepAR\", \"EnCQR-LSTM\"\n",
    "]\n",
    "\n",
    "# 4. Guardar el dataframe consolidado\n",
    "df_total.to_excel(\"./datos/Simulacion/Base/dataframe_consolidado.xlsx\", index=False)\n",
    "\n",
    "# 5. Generar y mostrar las tablas (Media y Mediana)\n",
    "metricas = {'MEDIA': 'mean', 'MEDIANA': 'median'}\n",
    "\n",
    "for nombre_metrica, funcion in metricas.items():\n",
    "    # Calculamos el valor general según la métrica (mean o median)\n",
    "    if funcion == 'mean':\n",
    "        resumen_general = df_total[modelos].mean()\n",
    "        resumen_escenarios = df_total.groupby('ESCENARIO')[modelos].mean().T\n",
    "    else:\n",
    "        resumen_general = df_total[modelos].median()\n",
    "        resumen_escenarios = df_total.groupby('ESCENARIO')[modelos].median().T\n",
    "\n",
    "    # Construimos la tabla final para esta métrica\n",
    "    tabla_resumen = pd.DataFrame(index=modelos)\n",
    "    tabla_resumen['General'] = resumen_general\n",
    "    tabla_resumen['ARMA'] = resumen_escenarios['Lineal Estacionario']\n",
    "    tabla_resumen['ARIMA'] = resumen_escenarios['Lineal No estacionario']\n",
    "    tabla_resumen['SETAR'] = resumen_escenarios['No lineal Estacionario']\n",
    "\n",
    "    # Determinar el Mejor_Escenario (valor mínimo entre los tres escenarios)\n",
    "    escenarios_cols = ['ARMA', 'ARIMA', 'SETAR']\n",
    "    tabla_resumen['Mejor_Escenario'] = tabla_resumen[escenarios_cols].idxmin(axis=1)\n",
    "\n",
    "    # Imprimir resultado\n",
    "    print(f\"\\n--- Tabla Comparativa de Modelos (Basada en {nombre_metrica}) ---\")\n",
    "    print(tabla_resumen.reset_index().rename(columns={'index': 'Modelo'}).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abc9573",
   "metadata": {},
   "source": [
    "### Analisis general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b90efcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuevo orden de modelos (basado en Lineal No Estacionario (ARIMA)):\n",
      "1. Sieve Bootstrap: 0.5475\n",
      "2. LSPM: 1.0648\n",
      "3. LSPMW: 3.0796\n",
      "4. MCPS: 3.2182\n",
      "5. AV-MCPS: 3.3240\n",
      "6. DeepAR: 4.3291\n",
      "7. EnCQR-LSTM: 6.1123\n",
      "8. AREPD: 10.0312\n",
      "9. Block Bootstrapping: 11.2516\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 1: RENDIMIENTO POR ESCENARIOS\n",
      "================================================================================\n",
      "✓ Gráfica 1.1 guardada\n",
      "✓ Gráfica 1.2 guardada\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 2: ANÁLISIS POR CONFIG\n",
      "================================================================================\n",
      "✓ Gráfica 2.1 guardada\n",
      "✓ Gráfica 2.1.a guardada\n",
      "✓ Gráfica 2.1.b guardada\n",
      "✓ Gráfica 2.1.c guardada\n",
      "✓ Gráfica 2.2 guardada\n",
      "✓ Gráfica 2.2.a guardada\n",
      "✓ Gráfica 2.2.b guardada\n",
      "✓ Gráfica 2.2.c guardada\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 3: ANÁLISIS POR DIST\n",
      "================================================================================\n",
      "✓ Gráfica 3.1 guardada\n",
      "✓ Gráfica 3.1.a guardada\n",
      "✓ Gráfica 3.1.b guardada\n",
      "✓ Gráfica 3.1.c guardada\n",
      "✓ Gráfica 3.2 guardada\n",
      "✓ Gráfica 3.2.a guardada\n",
      "✓ Gráfica 3.2.b guardada\n",
      "✓ Gráfica 3.2.c guardada\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 4: ANÁLISIS POR VAR\n",
      "================================================================================\n",
      "✓ Gráfica 4.1 guardada\n",
      "✓ Gráfica 4.1.a guardada\n",
      "✓ Gráfica 4.1.b guardada\n",
      "✓ Gráfica 4.1.c guardada\n",
      "✓ Gráfica 4.2 guardada\n",
      "✓ Gráfica 4.2.a guardada\n",
      "✓ Gráfica 4.2.b guardada\n",
      "✓ Gráfica 4.2.c guardada\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 5: ANÁLISIS POR PASO (HORIZONTE)\n",
      "================================================================================\n",
      "✓ Gráfica 5.1 guardada\n",
      "✓ Gráfica 5.1.a guardada\n",
      "✓ Gráfica 5.1.b guardada\n",
      "✓ Gráfica 5.1.c guardada\n",
      "✓ Gráfica 5.2 guardada\n",
      "✓ Gráfica 5.2.a guardada\n",
      "✓ Gráfica 5.2.b guardada\n",
      "✓ Gráfica 5.2.c guardada\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 5.5: ANÁLISIS DE INTERACCIONES\n",
      "================================================================================\n",
      "✓ Gráfica 8 (5.7)  guardada: Subplots por Modelo\n",
      "✓ Gráfica 9 (5.8)  guardada: Subplots por Modelo\n",
      "✓ Gráfica 10 (5.9)  guardada: Subplots por Modelo\n",
      "✓ Gráfica 11 (5.10)  guardada: Subplots por Modelo\n",
      "✓ Gráfica 8 (5.7) .a guardada: Subplots por Modelo\n",
      "✓ Gráfica 9 (5.8) .a guardada: Subplots por Modelo\n",
      "✓ Gráfica 10 (5.9) .a guardada: Subplots por Modelo\n",
      "✓ Gráfica 11 (5.10) .a guardada: Subplots por Modelo\n",
      "✓ Gráfica 8 (5.7) .b guardada: Subplots por Modelo\n",
      "✓ Gráfica 9 (5.8) .b guardada: Subplots por Modelo\n",
      "✓ Gráfica 10 (5.9) .b guardada: Subplots por Modelo\n",
      "✓ Gráfica 11 (5.10) .b guardada: Subplots por Modelo\n",
      "✓ Gráfica 8 (5.7) .c guardada: Subplots por Modelo\n",
      "✓ Gráfica 9 (5.8) .c guardada: Subplots por Modelo\n",
      "✓ Gráfica 10 (5.9) .c guardada: Subplots por Modelo\n",
      "✓ Gráfica 11 (5.10) .c guardada: Subplots por Modelo\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 6: ROBUSTEZ Y TEST DIEBOLD-MARIANO\n",
      "================================================================================\n",
      "✓ Gráfica 6.1 guardada (ordenada de menor a mayor CV)\n",
      "✓ Gráfica 6.2 guardada (Test HLN-DM con h=6, T=5040, df=5039)\n",
      "✓ Gráfica 6.2.a guardada (Test HLN-DM con h=6, T=1680, df=1679)\n",
      "✓ Gráfica 6.2.b guardada (Test HLN-DM con h=6, T=1680, df=1679)\n",
      "✓ Gráfica 6.2.c guardada (Test HLN-DM con h=6, T=1680, df=1679)\n",
      "\n",
      "================================================================================\n",
      "PROCESO COMPLETADO\n",
      "================================================================================\n",
      "\n",
      "Mejoras implementadas:\n",
      "1. ✓ Orden consistente en gráficas 1.1 y 1.2\n",
      "2. ✓ Formato de 2 decimales en heatmap 2.2 general\n",
      "3. ✓ Solo Coeficiente de Variación en gráfica 6.1 (ordenado menor a mayor)\n",
      "4. ✓ Test Diebold-Mariano con corrección HLN y distribución t-Student\n",
      "5. ✓ Horizonte de pronóstico (h) incorporado en el análisis\n",
      "\n",
      "================================================================================\n",
      "ANÁLISIS DE INTERACCIONES (Carpeta: Interacciones/)\n",
      "================================================================================\n",
      "6. ✓ Config × Var: Heatmaps por modelo (matriz 3×3)\n",
      "7. ✓ Config × Dist: Heatmaps por modelo (matriz 3×3)\n",
      "8. ✓ Dist × Paso: Gráficas de líneas por distribución\n",
      "9. ✓ Dist × Var: Gráficas de líneas por distribución\n",
      "10. ✓ Config × Paso: Gráficas de líneas por configuración\n",
      "11. ✓ Var × Horizonte: Gráficas de líneas por varianza\n",
      "================================================================================\n",
      "\n",
      "Total de gráficas generadas en Interacciones/: 24 archivos\n",
      "(6 tipos de interacción × 4 escenarios: General + 3 específicos)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import normaltest\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración general\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Crear carpeta de resultados\n",
    "output_dir = Path(\"./Resultados_analisis/Simulacion_base\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Crear carpeta de interacciones\n",
    "interactions_dir = output_dir / \"Interacciones\"\n",
    "interactions_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_excel(\"./datos/Simulacion/Base/dataframe_consolidado.xlsx\")\n",
    "\n",
    "# 1) CAMBIO DE NOMBRES DE ESCENARIOS\n",
    "df['ESCENARIO'] = df['ESCENARIO'].replace({\n",
    "    \"Lineal Estacionario\": \"Lineal Estacionario (ARMA)\",\n",
    "    \"Lineal No estacionario\": \"Lineal No Estacionario (ARIMA)\",\n",
    "    \"No lineal Estacionario\": \"No lineal Estacionario (SETAR)\"\n",
    "})\n",
    "\n",
    "# Identificar columnas de modelos\n",
    "var_cols = ['Paso', 'Config', 'Dist', 'Var', 'ESCENARIO']\n",
    "original_model_cols = [col for col in df.columns if col not in var_cols]\n",
    "\n",
    "# 2) ORGANIZAR MODELOS POR RENDIMIENTO EN \"Lineal No Estacionario (ARIMA)\" (Menor a mayor)\n",
    "target_scenario = \"Lineal No Estacionario (ARIMA)\"\n",
    "model_order_scores = df[df['ESCENARIO'] == target_scenario][original_model_cols].mean().sort_values()\n",
    "model_cols = list(model_order_scores.index)\n",
    "\n",
    "print(\"Nuevo orden de modelos (basado en Lineal No Estacionario (ARIMA)):\")\n",
    "for i, m in enumerate(model_cols, 1):\n",
    "    print(f\"{i}. {m}: {model_order_scores[m]:.4f}\")\n",
    "\n",
    "# Mapeo de escenarios\n",
    "escenarios_map = {\n",
    "    'Lineal Estacionario (ARMA)': 'Lineal Estacionario (ARMA)',\n",
    "    'Lineal No Estacionario (ARIMA)': 'Lineal No Estacionario (ARIMA)',\n",
    "    'No lineal Estacionario (SETAR)': 'No lineal Estacionario (SETAR)'\n",
    "}\n",
    "\n",
    "# Definir colores para cada modelo\n",
    "palette = sns.color_palette(\"husl\", len(model_cols))\n",
    "model_colors = {model: palette[i] for i, model in enumerate(model_cols)}\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 1: RENDIMIENTO POR ESCENARIOS\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 1: RENDIMIENTO POR ESCENARIOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_performance_by_scenario():\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    scenarios = [\"Lineal Estacionario (ARMA)\", \"Lineal No Estacionario (ARIMA)\", \"No lineal Estacionario (SETAR)\"]\n",
    "    x = np.arange(len(model_cols))\n",
    "    width = 0.25 \n",
    "    \n",
    "    scenario_colors = {\n",
    "        'Lineal Estacionario (ARMA)': '#5D3FD3',    \n",
    "        'Lineal No Estacionario (ARIMA)': '#808080', \n",
    "        'No lineal Estacionario (SETAR)': '#00A36C'  \n",
    "    }\n",
    "    \n",
    "    for idx, scenario in enumerate(scenarios):\n",
    "        means = [df[df['ESCENARIO'] == scenario][model].mean() for model in model_cols]\n",
    "        position = x + (idx - 1) * width\n",
    "        \n",
    "        bars = ax.bar(position, means, width, label=scenario, \n",
    "                     color=scenario_colors[scenario], alpha=0.85, edgecolor='black', linewidth=0.5)\n",
    "        \n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{height:.2f}', ha='center', va='bottom', fontsize=7, rotation=0)\n",
    "    \n",
    "    ax.set_xlabel('Modelo (Ordenados por desempeño en ARIMA)', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('ECRPS Promedio', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Rendimiento de Modelos por Escenario (ECRPS)', fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(model_cols, rotation=45, ha='right', fontsize=9)\n",
    "    ax.legend(loc='upper left', ncol=1, fontsize=10, framealpha=0.9)\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / '1.1_rendimiento_por_escenario.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Gráfica 1.1 guardada\")\n",
    "\n",
    "plot_performance_by_scenario()\n",
    "\n",
    "def plot_relative_performance():\n",
    "    base_scenario = 'Lineal Estacionario (ARMA)'\n",
    "    scenarios_compare = ['Lineal No Estacionario (ARIMA)', 'No lineal Estacionario (SETAR)']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 10))\n",
    "    \n",
    "    y = np.arange(len(model_cols))\n",
    "    height = 0.35  \n",
    "    \n",
    "    for idx, scenario in enumerate(scenarios_compare):\n",
    "        changes = []\n",
    "        for model in model_cols:\n",
    "            base_value = df[df['ESCENARIO'] == base_scenario][model].mean()\n",
    "            scenario_value = df[df['ESCENARIO'] == scenario][model].mean()\n",
    "            pct_change = ((scenario_value - base_value) / base_value) * 100\n",
    "            changes.append(pct_change)\n",
    "        \n",
    "        position = y + idx * height\n",
    "        bars = ax.barh(position, changes, height, label=scenario, alpha=0.85, edgecolor='black', linewidth=0.5)\n",
    "        \n",
    "        for bar, val in zip(bars, changes):\n",
    "            width = bar.get_width()\n",
    "            ax.text(width + (1 if width > 0 else -1), bar.get_y() + bar.get_height()/2.,\n",
    "                   f'{val:+.1f}%', ha='left' if val > 0 else 'right', \n",
    "                   va='center', fontsize=7)\n",
    "    \n",
    "    ax.set_yticks(y + height / 2)\n",
    "    ax.set_yticklabels(model_cols, fontsize=10)\n",
    "    ax.set_xlabel('Cambio Relativo (%)', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(f'Cambio Relativo en ECRPS vs. {base_scenario}', fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.axvline(x=0, color='black', linestyle='-', linewidth=1.5)\n",
    "    ax.legend(loc='best', fontsize=10, framealpha=0.9)\n",
    "    ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / '1.2_cambio_relativo_escenario_base.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Gráfica 1.2 guardada\")\n",
    "\n",
    "plot_relative_performance()\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 2: ANÁLISIS POR CONFIG\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 2: ANÁLISIS POR CONFIG\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_zscore_heatmap_config(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Z-scores de ECRPS por Configuración ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Z-scores de ECRPS por Configuración (General)'\n",
    "    \n",
    "    pivot_data = data_filtered.groupby('Config')[model_cols].mean()\n",
    "    z_scores = pivot_data.apply(lambda x: (x - x.mean()) / x.std(), axis=0)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    sns.heatmap(z_scores.T, annot=True, fmt='.2f', cmap='RdYlGn_r', \n",
    "                center=0, cbar_kws={'label': 'Z-score'}, ax=ax,\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    ax.set_title(title, fontsize=12, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Configuración', fontsize=11)\n",
    "    ax.set_ylabel('Modelo', fontsize=11)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'2.1{suffix}_zscore_config.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 2.1{suffix} guardada\")\n",
    "\n",
    "plot_zscore_heatmap_config()\n",
    "plot_zscore_heatmap_config('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_zscore_heatmap_config('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_zscore_heatmap_config('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "def plot_variability_config(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Desv. Estándar de ECRPS por Configuración ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Desv. Estándar de ECRPS por Configuración (General)'\n",
    "    \n",
    "    pivot_std = data_filtered.groupby('Config')[model_cols].std()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    fmt = '.2f' if suffix == '' else '.4f'\n",
    "    sns.heatmap(pivot_std.T, annot=True, fmt=fmt, cmap='YlOrRd', \n",
    "                cbar_kws={'label': 'Desv. Estándar'}, ax=ax,\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Configuración', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'2.2{suffix}_variabilidad_config.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 2.2{suffix} guardada\")\n",
    "\n",
    "plot_variability_config()\n",
    "plot_variability_config('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_variability_config('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_variability_config('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 3: ANÁLISIS POR DIST\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 3: ANÁLISIS POR DIST\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_zscore_heatmap_dist(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Z-scores de ECRPS por Distribución ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Z-scores de ECRPS por Distribución (General)'\n",
    "    \n",
    "    pivot_data = data_filtered.groupby('Dist')[model_cols].mean()\n",
    "    z_scores = pivot_data.apply(lambda x: (x - x.mean()) / x.std(), axis=0)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    sns.heatmap(z_scores.T, annot=True, fmt='.2f', cmap='RdYlGn_r', \n",
    "                center=0, cbar_kws={'label': 'Z-score'}, ax=ax,\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    ax.set_title(title, fontsize=12, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Distribución', fontsize=11)\n",
    "    ax.set_ylabel('Modelo', fontsize=11)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'3.1{suffix}_zscore_dist.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 3.1{suffix} guardada\")\n",
    "\n",
    "plot_zscore_heatmap_dist()\n",
    "plot_zscore_heatmap_dist('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_zscore_heatmap_dist('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_zscore_heatmap_dist('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "def plot_variability_dist(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Desv. Estándar de ECRPS por Distribución ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Desv. Estándar de ECRPS por Distribución (General)'\n",
    "    \n",
    "    pivot_std = data_filtered.groupby('Dist')[model_cols].std()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    sns.heatmap(pivot_std.T, annot=True, fmt='.4f', cmap='YlOrRd', \n",
    "                cbar_kws={'label': 'Desv. Estándar'}, ax=ax,\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Distribución', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'3.2{suffix}_variabilidad_dist.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 3.2{suffix} guardada\")\n",
    "\n",
    "plot_variability_dist()\n",
    "plot_variability_dist('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_variability_dist('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_variability_dist('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 4: ANÁLISIS POR VAR\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 4: ANÁLISIS POR VAR\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_evolution_var(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Evolución de ECRPS por Varianza ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Evolución de ECRPS por Varianza (General)'\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    var_values = sorted(data_filtered['Var'].unique())\n",
    "    \n",
    "    for model in model_cols:\n",
    "        means = []\n",
    "        for var in var_values:\n",
    "            mean_val = data_filtered[data_filtered['Var'] == var][model].mean()\n",
    "            means.append(mean_val)\n",
    "        \n",
    "        ax.plot(var_values, means, marker='o', label=model, color=model_colors[model],\n",
    "                linewidth=2.5, markersize=7, alpha=0.85)\n",
    "    \n",
    "    ax.set_xlabel('Varianza', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('ECRPS Promedio', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.legend(loc='best', fontsize=9, ncol=2, framealpha=0.9)\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'4.1{suffix}_evolucion_var.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 4.1{suffix} guardada\")\n",
    "\n",
    "plot_evolution_var()\n",
    "plot_evolution_var('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_evolution_var('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_evolution_var('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "def plot_variability_var(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Desv. Estándar de ECRPS por Varianza ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Desv. Estándar de ECRPS por Varianza (General)'\n",
    "    \n",
    "    pivot_std = data_filtered.groupby('Var')[model_cols].std()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    sns.heatmap(pivot_std.T, annot=True, fmt='.4f', cmap='YlOrRd', \n",
    "                cbar_kws={'label': 'Desv. Estándar'}, ax=ax,\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Varianza', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'4.2{suffix}_variabilidad_var.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 4.2{suffix} guardada\")\n",
    "\n",
    "plot_variability_var()\n",
    "plot_variability_var('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_variability_var('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_variability_var('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 5: ANÁLISIS POR PASO (HORIZONTE)\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 5: ANÁLISIS POR PASO (HORIZONTE)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_evolution_paso(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Evolución de ECRPS por Horizonte de Pronóstico ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Evolución de ECRPS por Horizonte de Pronóstico (General)'\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    pasos = sorted(data_filtered['Paso'].unique())\n",
    "    \n",
    "    for model in model_cols:\n",
    "        means = []\n",
    "        for paso in pasos:\n",
    "            mean_val = data_filtered[data_filtered['Paso'] == paso][model].mean()\n",
    "            means.append(mean_val)\n",
    "        \n",
    "        ax.plot(pasos, means, marker='o', label=model, color=model_colors[model],\n",
    "                linewidth=2.5, markersize=7, alpha=0.85)\n",
    "    \n",
    "    ax.set_xlabel('Horizonte de Pronóstico', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('ECRPS Promedio', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.legend(loc='best', fontsize=9, ncol=2, framealpha=0.9)\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'5.1{suffix}_evolucion_paso.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 5.1{suffix} guardada\")\n",
    "\n",
    "plot_evolution_paso()\n",
    "plot_evolution_paso('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_evolution_paso('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_evolution_paso('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "def plot_variability_paso(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Desv. Estándar de ECRPS por Horizonte ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Desv. Estándar de ECRPS por Horizonte (General)'\n",
    "    \n",
    "    pivot_std = data_filtered.groupby('Paso')[model_cols].std()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    sns.heatmap(pivot_std.T, annot=True, fmt='.4f', cmap='YlOrRd', \n",
    "                cbar_kws={'label': 'Desv. Estándar'}, ax=ax,\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Horizonte de Pronóstico', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'5.2{suffix}_variabilidad_paso.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 5.2{suffix} guardada\")\n",
    "\n",
    "plot_variability_paso()\n",
    "plot_variability_paso('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_variability_paso('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_variability_paso('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 5.5: ANÁLISIS DE INTERACCIONES\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 5.5: ANÁLISIS DE INTERACCIONES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Función auxiliar para configurar el grid de modelos\n",
    "def get_model_grid_axes(n_models):\n",
    "    n_cols = 3\n",
    "    n_rows = (n_models + n_cols - 1) // n_cols\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 5 * n_rows))\n",
    "    return fig, axes.flatten(), n_rows, n_cols\n",
    "\n",
    "# INTERACCIÓN 3 (Lista 8): DIST × PASO - Subplots por Modelo\n",
    "def plot_interaction_dist_paso(scenario=None, suffix=''):\n",
    "    data_filtered = df[df['ESCENARIO'] == scenario].copy() if scenario else df.copy()\n",
    "    title = f'Interacción Dist × Paso por Modelo ({\"General\" if not scenario else scenario})'\n",
    "    \n",
    "    fig, axes, n_rows, n_cols = get_model_grid_axes(len(model_cols))\n",
    "    dists = sorted(data_filtered['Dist'].unique())\n",
    "    pasos = sorted(data_filtered['Paso'].unique())\n",
    "    colors_dist = sns.color_palette(\"viridis\", len(dists))\n",
    "\n",
    "    for idx, model in enumerate(model_cols):\n",
    "        ax = axes[idx]\n",
    "        for d_idx, dist in enumerate(dists):\n",
    "            means = [data_filtered[(data_filtered['Dist'] == dist) & (data_filtered['Paso'] == p)][model].mean() for p in pasos]\n",
    "            ax.plot(pasos, means, marker='o', label=dist, color=colors_dist[d_idx], linewidth=2)\n",
    "        \n",
    "        ax.set_title(f'Modelo: {model}', fontweight='bold')\n",
    "        ax.set_xlabel('Horizonte (Paso)')\n",
    "        ax.set_ylabel('ECRPS Promedio')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        if idx == 0: ax.legend(title=\"Distribución\", fontsize=8)\n",
    "\n",
    "    for i in range(len(model_cols), len(axes)): axes[i].set_visible(False)\n",
    "    plt.suptitle(title, fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(interactions_dir / f'5.7{suffix}_interaccion_dist_paso_modelos.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 8 (5.7) {suffix} guardada: Subplots por Modelo\")\n",
    "\n",
    "# INTERACCIÓN 4 (Lista 9): DIST × VAR - Subplots por Modelo\n",
    "def plot_interaction_dist_var(scenario=None, suffix=''):\n",
    "    data_filtered = df[df['ESCENARIO'] == scenario].copy() if scenario else df.copy()\n",
    "    title = f'Interacción Dist × Var por Modelo ({\"General\" if not scenario else scenario})'\n",
    "    \n",
    "    fig, axes, _, _ = get_model_grid_axes(len(model_cols))\n",
    "    dists = sorted(data_filtered['Dist'].unique())\n",
    "    vars_val = sorted(data_filtered['Var'].unique())\n",
    "    colors_dist = sns.color_palette(\"magma\", len(dists))\n",
    "\n",
    "    for idx, model in enumerate(model_cols):\n",
    "        ax = axes[idx]\n",
    "        for d_idx, dist in enumerate(dists):\n",
    "            means = [data_filtered[(data_filtered['Dist'] == dist) & (data_filtered['Var'] == v)][model].mean() for v in vars_val]\n",
    "            ax.plot(vars_val, means, marker='s', label=dist, color=colors_dist[d_idx], linewidth=2)\n",
    "        \n",
    "        ax.set_title(f'Modelo: {model}', fontweight='bold')\n",
    "        ax.set_xlabel('Varianza')\n",
    "        ax.set_ylabel('ECRPS Promedio')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        if idx == 0: ax.legend(title=\"Distribución\", fontsize=8)\n",
    "\n",
    "    for i in range(len(model_cols), len(axes)): axes[i].set_visible(False)\n",
    "    plt.suptitle(title, fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(interactions_dir / f'5.8{suffix}_interaccion_dist_var_modelos.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 9 (5.8) {suffix} guardada: Subplots por Modelo\")\n",
    "\n",
    "# INTERACCIÓN 5 (Lista 10): CONFIG × PASO - Subplots por Modelo\n",
    "def plot_interaction_config_paso(scenario=None, suffix=''):\n",
    "    data_filtered = df[df['ESCENARIO'] == scenario].copy() if scenario else df.copy()\n",
    "    title = f'Interacción Config × Paso por Modelo ({\"General\" if not scenario else scenario})'\n",
    "    \n",
    "    fig, axes, _, _ = get_model_grid_axes(len(model_cols))\n",
    "    configs = sorted(data_filtered['Config'].unique())\n",
    "    pasos = sorted(data_filtered['Paso'].unique())\n",
    "    colors_conf = sns.color_palette(\"tab10\", len(configs))\n",
    "\n",
    "    for idx, model in enumerate(model_cols):\n",
    "        ax = axes[idx]\n",
    "        for c_idx, config in enumerate(configs):\n",
    "            means = [data_filtered[(data_filtered['Config'] == config) & (data_filtered['Paso'] == p)][model].mean() for p in pasos]\n",
    "            ax.plot(pasos, means, marker='^', label=config, color=colors_conf[c_idx], linewidth=2)\n",
    "        \n",
    "        ax.set_title(f'Modelo: {model}', fontweight='bold')\n",
    "        ax.set_xlabel('Horizonte (Paso)')\n",
    "        ax.set_ylabel('ECRPS Promedio')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        if idx == 0: ax.legend(title=\"Config\", fontsize=8)\n",
    "\n",
    "    for i in range(len(model_cols), len(axes)): axes[i].set_visible(False)\n",
    "    plt.suptitle(title, fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(interactions_dir / f'5.9{suffix}_interaccion_config_paso_modelos.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 10 (5.9) {suffix} guardada: Subplots por Modelo\")\n",
    "\n",
    "# INTERACCIÓN 6 (Lista 11): VAR × HORIZONTE - Subplots por Modelo\n",
    "def plot_interaction_var_horizonte(scenario=None, suffix=''):\n",
    "    data_filtered = df[df['ESCENARIO'] == scenario].copy() if scenario else df.copy()\n",
    "    title = f'Interacción Var × Horizonte por Modelo ({\"General\" if not scenario else scenario})'\n",
    "    \n",
    "    fig, axes, _, _ = get_model_grid_axes(len(model_cols))\n",
    "    vars_val = sorted(data_filtered['Var'].unique())\n",
    "    pasos = sorted(data_filtered['Paso'].unique())\n",
    "    colors_var = sns.color_palette(\"rocket\", len(vars_val))\n",
    "\n",
    "    for idx, model in enumerate(model_cols):\n",
    "        ax = axes[idx]\n",
    "        for v_idx, var in enumerate(vars_val):\n",
    "            means = [data_filtered[(data_filtered['Var'] == var) & (data_filtered['Paso'] == p)][model].mean() for p in pasos]\n",
    "            ax.plot(pasos, means, marker='d', label=f'Var {var}', color=colors_var[v_idx], linewidth=2)\n",
    "        \n",
    "        ax.set_title(f'Modelo: {model}', fontweight='bold')\n",
    "        ax.set_xlabel('Horizonte (Paso)')\n",
    "        ax.set_ylabel('ECRPS Promedio')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        if idx == 0: ax.legend(title=\"Varianza\", fontsize=8)\n",
    "\n",
    "    for i in range(len(model_cols), len(axes)): axes[i].set_visible(False)\n",
    "    plt.suptitle(title, fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(interactions_dir / f'5.10{suffix}_interaccion_var_horizonte_modelos.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 11 (5.10) {suffix} guardada: Subplots por Modelo\")\n",
    "\n",
    "\n",
    "# ====================================================================================\n",
    "# EJECUCIÓN DE LAS NUEVAS FUNCIONES\n",
    "# ====================================================================================\n",
    "\n",
    "for sc_name, sc_suf in [ (None, ''), ('Lineal Estacionario (ARMA)', '.a'), \n",
    "                        ('Lineal No Estacionario (ARIMA)', '.b'), \n",
    "                        ('No lineal Estacionario (SETAR)', '.c') ]:\n",
    "    plot_interaction_dist_paso(sc_name, sc_suf)\n",
    "    plot_interaction_dist_var(sc_name, sc_suf)\n",
    "    plot_interaction_config_paso(sc_name, sc_suf)\n",
    "    plot_interaction_var_horizonte(sc_name, sc_suf)\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 6: ROBUSTEZ Y TEST DIEBOLD-MARIANO\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 6: ROBUSTEZ Y TEST DIEBOLD-MARIANO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_robustness():\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    cv_data = []\n",
    "    for model in model_cols:\n",
    "        cv = df[model].std() / df[model].mean()\n",
    "        cv_data.append((model, cv))\n",
    "    \n",
    "    cv_df = pd.DataFrame(cv_data, columns=['Modelo', 'CV'])\n",
    "    \n",
    "    # CAMBIO 1: Ordenar de menor a mayor CV para coherencia\n",
    "    cv_df = cv_df.sort_values('CV')\n",
    "    \n",
    "    colors_cv = ['#2ecc71' if cv < cv_df['CV'].median() else '#e74c3c' \n",
    "                 for cv in cv_df['CV']]\n",
    "    \n",
    "    bars = ax.barh(cv_df['Modelo'], cv_df['CV'], color=colors_cv, alpha=0.8, edgecolor='black')\n",
    "    \n",
    "    for bar, cv in zip(bars, cv_df['CV']):\n",
    "        width = bar.get_width()\n",
    "        ax.text(width + 0.001, bar.get_y() + bar.get_height()/2.,\n",
    "               f'{cv:.4f}', ha='left', va='center', fontsize=9)\n",
    "    \n",
    "    ax.set_xlabel('Coeficiente de Variación', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Robustez: Coeficiente de Variación\\n(Ordenado de menor a mayor - Menor valor indica mayor estabilidad)', \n",
    "                  fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.axvline(x=cv_df['CV'].median(), color='black', linestyle='--', linewidth=1.5, alpha=0.5, label='Mediana')\n",
    "    ax.legend(loc='best', fontsize=10)\n",
    "    ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / '6.1_robustez_coeficiente_variacion.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Gráfica 6.1 guardada (ordenada de menor a mayor CV)\")\n",
    "\n",
    "plot_robustness()\n",
    "\n",
    "def modified_diebold_mariano_test(errors1, errors2, h=1):\n",
    "    \"\"\"\n",
    "    Test Diebold-Mariano modificado con corrección Harvey-Leybourne-Newbold (1997)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    errors1, errors2 : array-like\n",
    "        Errores de pronóstico (ECRPS) de los dos modelos\n",
    "    h : int\n",
    "        Horizonte de pronóstico (forecast horizon)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    hlm_dm_stat : float\n",
    "        Estadístico DM corregido (HLN-DM)\n",
    "    p_value : float\n",
    "        P-valor usando distribución t-Student con T-1 grados de libertad\n",
    "    dm_stat : float\n",
    "        Estadístico DM original (sin corrección)\n",
    "    \"\"\"\n",
    "    # Calcular diferencial de pérdida\n",
    "    d = errors1 - errors2\n",
    "    d_bar = np.mean(d)\n",
    "    T = len(d)\n",
    "    \n",
    "    # Calcular autocovarianzas\n",
    "    def gamma_d(k):\n",
    "        if k == 0:\n",
    "            return np.var(d, ddof=1)\n",
    "        else:\n",
    "            return np.mean((d[k:] - d_bar) * (d[:-k] - d_bar))\n",
    "    \n",
    "    # Estimar la varianza de largo plazo usando Newey-West\n",
    "    # Para h-step-ahead forecasts, incluimos hasta h-1 lags\n",
    "    gamma_0 = gamma_d(0)\n",
    "    gamma_sum = gamma_0\n",
    "    \n",
    "    if h > 1:\n",
    "        for k in range(1, h):\n",
    "            gamma_k = gamma_d(k)\n",
    "            gamma_sum += 2 * gamma_k\n",
    "    \n",
    "    var_d = gamma_sum / T\n",
    "    \n",
    "    if var_d <= 0:\n",
    "        return 0, 1.0, 0\n",
    "    \n",
    "    # Estadístico DM original\n",
    "    dm_stat = d_bar / np.sqrt(var_d)\n",
    "    \n",
    "    # Corrección Harvey-Leybourne-Newbold (1997)\n",
    "    correction_factor = np.sqrt((T + 1 - 2*h + h*(h-1)) / T)\n",
    "    hln_dm_stat = correction_factor * dm_stat\n",
    "    \n",
    "    # P-valor usando t-Student con T-1 grados de libertad\n",
    "    df = T - 1\n",
    "    p_value = 2 * (1 - stats.t.cdf(abs(hln_dm_stat), df))\n",
    "    \n",
    "    return hln_dm_stat, p_value, dm_stat\n",
    "\n",
    "def plot_dm_test_heatmap(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Test Diebold-Mariano Modificado (HLN-DM)\\ncon Corrección de Bonferroni ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Test Diebold-Mariano Modificado (HLN-DM)\\ncon Corrección de Bonferroni (General)'\n",
    "    \n",
    "    # Determinar el horizonte de pronóstico promedio\n",
    "    h_forecast = int(data_filtered['Paso'].mean())\n",
    "    \n",
    "    n_models = len(model_cols)\n",
    "    n_comparisons = n_models * (n_models - 1) / 2\n",
    "    alpha = 0.05\n",
    "    bonferroni_alpha = alpha / n_comparisons\n",
    "    \n",
    "    results_matrix = np.zeros((n_models, n_models))\n",
    "    p_values = np.zeros((n_models, n_models))\n",
    "    dm_stats = np.zeros((n_models, n_models))\n",
    "    \n",
    "    for i, model1 in enumerate(model_cols):\n",
    "        for j, model2 in enumerate(model_cols):\n",
    "            if i == j:\n",
    "                results_matrix[i, j] = 0  \n",
    "                p_values[i, j] = 1.0\n",
    "                dm_stats[i, j] = 0\n",
    "            elif i < j:\n",
    "                errors1 = data_filtered[model1].values\n",
    "                errors2 = data_filtered[model2].values\n",
    "                hln_dm_stat, p_val, dm_original = modified_diebold_mariano_test(\n",
    "                    errors1, errors2, h=h_forecast\n",
    "                )\n",
    "                \n",
    "                p_values[i, j] = p_val\n",
    "                p_values[j, i] = p_val\n",
    "                dm_stats[i, j] = hln_dm_stat\n",
    "                dm_stats[j, i] = -hln_dm_stat\n",
    "                \n",
    "                if p_val < bonferroni_alpha:\n",
    "                    mean1 = np.mean(errors1)\n",
    "                    mean2 = np.mean(errors2)\n",
    "                    if mean1 < mean2:  \n",
    "                        results_matrix[i, j] = 1  \n",
    "                        results_matrix[j, i] = -1  \n",
    "                    else:\n",
    "                        results_matrix[i, j] = -1\n",
    "                        results_matrix[j, i] = 1\n",
    "                else:\n",
    "                    results_matrix[i, j] = 0\n",
    "                    results_matrix[j, i] = 0\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 11))\n",
    "    cmap = plt.cm.colors.ListedColormap(['#e74c3c', '#fff9c4', '#2ecc71'])\n",
    "    bounds = [-1.5, -0.5, 0.5, 1.5]\n",
    "    norm = plt.cm.colors.BoundaryNorm(bounds, cmap.N)\n",
    "    \n",
    "    im = ax.imshow(results_matrix, cmap=cmap, norm=norm, aspect='auto')\n",
    "    ax.set_xticks(np.arange(n_models))\n",
    "    ax.set_yticks(np.arange(n_models))\n",
    "    ax.set_xticklabels(model_cols, rotation=45, ha='right', fontsize=9)\n",
    "    ax.set_yticklabels(model_cols, fontsize=9)\n",
    "    \n",
    "    for i in range(n_models):\n",
    "        for j in range(n_models):\n",
    "            if i == j:\n",
    "                text = '-'\n",
    "                color = 'black'\n",
    "            else:\n",
    "                val = results_matrix[i, j]\n",
    "                p_val = p_values[i, j]\n",
    "                dm_val = dm_stats[i, j]\n",
    "                if val == 1:\n",
    "                    text = f'✓\\nHLN-DM={dm_val:.2f}\\np={p_val:.4f}'\n",
    "                    color = 'white'\n",
    "                elif val == -1:\n",
    "                    text = f'✗\\nHLN-DM={dm_val:.2f}\\np={p_val:.4f}'\n",
    "                    color = 'white'\n",
    "                else:\n",
    "                    text = f'≈\\nHLN-DM={dm_val:.2f}\\np={p_val:.4f}'\n",
    "                    color = 'black'\n",
    "            ax.text(j, i, text, ha='center', va='center', \n",
    "                   color=color, fontsize=6, fontweight='bold')\n",
    "    \n",
    "    # Obtener T para el título\n",
    "    T = len(data_filtered)\n",
    "    df_test = T - 1\n",
    "    \n",
    "    ax.set_title(title + f'\\n(h={h_forecast}, T={T}, df={df_test}, α ajustado={bonferroni_alpha:.5f})', \n",
    "                 fontsize=11, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Modelo (Columna)', fontsize=11)\n",
    "    ax.set_ylabel('Modelo (Fila)', fontsize=11)\n",
    "    \n",
    "    legend_elements = [\n",
    "        plt.Rectangle((0,0),1,1, facecolor='#2ecc71', label='Fila supera columna (p < α)'),\n",
    "        plt.Rectangle((0,0),1,1, facecolor='#e74c3c', label='Columna supera fila (p < α)'),\n",
    "        plt.Rectangle((0,0),1,1, facecolor='#fff9c4', label='Sin diferencia significativa (p ≥ α)')\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='upper left', bbox_to_anchor=(1.05, 1), fontsize=9)\n",
    "    \n",
    "    # Agregar nota metodológica\n",
    "    note_text = ('Nota: Se utiliza el test HLN-DM con corrección para muestras finitas.\\n'\n",
    "                 'Distribución: t-Student. Ajuste: Bonferroni para comparaciones múltiples.')\n",
    "    plt.figtext(0.5, -0.02, note_text, ha='center', fontsize=8, style='italic', \n",
    "                wrap=True, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'6.2{suffix}_dm_test_hln_bonferroni.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Guardar resultados en Excel\n",
    "    results_df = pd.DataFrame(results_matrix, index=model_cols, columns=model_cols)\n",
    "    pvalues_df = pd.DataFrame(p_values, index=model_cols, columns=model_cols)\n",
    "    dmstats_df = pd.DataFrame(dm_stats, index=model_cols, columns=model_cols)\n",
    "    \n",
    "    summary_data = []\n",
    "    for model in model_cols:\n",
    "        idx = model_cols.index(model)\n",
    "        victorias = int(np.sum(results_matrix[idx, :] == 1))\n",
    "        derrotas = int(np.sum(results_matrix[idx, :] == -1))\n",
    "        empates = int(np.sum(results_matrix[idx, :] == 0)) - 1\n",
    "        mean_ecrps = data_filtered[model].mean()\n",
    "        std_ecrps = data_filtered[model].std()\n",
    "        cv_ecrps = std_ecrps / mean_ecrps\n",
    "        summary_data.append({\n",
    "            'Modelo': model,\n",
    "            'Victorias': victorias,\n",
    "            'Derrotas': derrotas,\n",
    "            'Empates': empates,\n",
    "            'Tasa_Victoria': f\"{(victorias / (n_models - 1)) * 100:.1f}%\",\n",
    "            'ECRPS_Promedio': f\"{mean_ecrps:.4f}\",\n",
    "            'ECRPS_Desv_Std': f\"{std_ecrps:.4f}\",\n",
    "            'Coef_Variacion': f\"{cv_ecrps:.4f}\"\n",
    "        })\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    # Información metodológica\n",
    "    method_info = pd.DataFrame({\n",
    "        'Parámetro': ['Horizonte de pronóstico (h)', 'Tamaño muestra (T)', \n",
    "                      'Grados libertad (df)', 'Alpha nominal', \n",
    "                      'Alpha ajustado (Bonferroni)', 'Número comparaciones',\n",
    "                      'Distribución', 'Corrección aplicada'],\n",
    "        'Valor': [h_forecast, T, df_test, alpha, bonferroni_alpha, \n",
    "                  int(n_comparisons), 't-Student', 'Harvey-Leybourne-Newbold (1997)']\n",
    "    })\n",
    "    \n",
    "    with pd.ExcelWriter(output_dir / f'6.2{suffix}_dm_test_hln_resultados.xlsx') as writer:\n",
    "        method_info.to_excel(writer, sheet_name='Metodologia', index=False)\n",
    "        results_df.to_excel(writer, sheet_name='Matriz_Resultados')\n",
    "        pvalues_df.to_excel(writer, sheet_name='P_valores')\n",
    "        dmstats_df.to_excel(writer, sheet_name='Estadisticos_HLN_DM')\n",
    "        summary_df.to_excel(writer, sheet_name='Resumen_Modelos', index=False)\n",
    "    \n",
    "    print(f\"✓ Gráfica 6.2{suffix} guardada (Test HLN-DM con h={h_forecast}, T={T}, df={df_test})\")\n",
    "\n",
    "plot_dm_test_heatmap()\n",
    "plot_dm_test_heatmap('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_dm_test_heatmap('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_dm_test_heatmap('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PROCESO COMPLETADO\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nMejoras implementadas:\")\n",
    "print(\"1. ✓ Orden consistente en gráficas 1.1 y 1.2\")\n",
    "print(\"2. ✓ Formato de 2 decimales en heatmap 2.2 general\")\n",
    "print(\"3. ✓ Solo Coeficiente de Variación en gráfica 6.1 (ordenado menor a mayor)\")\n",
    "print(\"4. ✓ Test Diebold-Mariano con corrección HLN y distribución t-Student\")\n",
    "print(\"5. ✓ Horizonte de pronóstico (h) incorporado en el análisis\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANÁLISIS DE INTERACCIONES (Carpeta: Interacciones/)\")\n",
    "print(\"=\"*80)\n",
    "print(\"6. ✓ Config × Var: Heatmaps por modelo (matriz 3×3)\")\n",
    "print(\"7. ✓ Config × Dist: Heatmaps por modelo (matriz 3×3)\")\n",
    "print(\"8. ✓ Dist × Paso: Gráficas de líneas por distribución\")\n",
    "print(\"9. ✓ Dist × Var: Gráficas de líneas por distribución\")\n",
    "print(\"10. ✓ Config × Paso: Gráficas de líneas por configuración\")\n",
    "print(\"11. ✓ Var × Horizonte: Gráficas de líneas por varianza\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal de gráficas generadas en Interacciones/: {6 * 4} archivos\")\n",
    "print(\"(6 tipos de interacción × 4 escenarios: General + 3 específicos)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f71c0b0",
   "metadata": {},
   "source": [
    "## Analisis Diferenciado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b88955e",
   "metadata": {},
   "source": [
    "### Pre-procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "249b1e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla Comparativa de Desempeño (Promedios):\n",
      "                         ARIMA  ARIMA_Diff Mejor_Escenario\n",
      "Modelo                                                    \n",
      "AREPD                10.031183    0.704149      ARIMA_Diff\n",
      "AV-MCPS               3.324007    0.654257      ARIMA_Diff\n",
      "Block Bootstrapping  11.251601    0.666133      ARIMA_Diff\n",
      "DeepAR                4.329124    0.561822      ARIMA_Diff\n",
      "EnCQR-LSTM            6.112344    0.880288      ARIMA_Diff\n",
      "LSPM                  1.064804    0.648039      ARIMA_Diff\n",
      "LSPMW                 3.079645    0.767172      ARIMA_Diff\n",
      "MCPS                  3.218168    0.677471      ARIMA_Diff\n",
      "Sieve Bootstrap       0.547481    0.546020      ARIMA_Diff\n",
      "\n",
      "Archivo de unión guardado en: ./datos/Simulacion/Diferenciado/resultados_UNION_ARIMA.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Cargar los archivos\n",
    "path_diff = \"./datos/Simulacion/Diferenciado/resultados_140_ARIMA_CON_DIFERENCIACION.xlsx\"\n",
    "path_no_diff = \"./datos/Simulacion/Diferenciado/resultados_140_ARIMA_FINAL.xlsx\"\n",
    "\n",
    "arima_Diff_df = pd.read_excel(path_diff)\n",
    "arima_df = pd.read_excel(path_no_diff)\n",
    "\n",
    "# 2. Agregar la columna 'Diferenciacion' al dataframe que no la tiene\n",
    "arima_df['Diferenciacion'] = 'No'\n",
    "\n",
    "# 3. Unir los dataframes (uno debajo del otro)\n",
    "# El orden de las columnas se ajustará automáticamente\n",
    "df_unido = pd.concat([arima_Diff_df, arima_df], ignore_index=True)\n",
    "\n",
    "# 4. Guardar la unión en la misma carpeta\n",
    "path_salida = \"./datos/Simulacion/Diferenciado/resultados_UNION_ARIMA.xlsx\"\n",
    "df_unido.to_excel(path_salida, index=False)\n",
    "\n",
    "# 5. Crear la tabla comparativa (Resumen)\n",
    "# Definimos las métricas/modelos a comparar\n",
    "modelos_metricas = [\n",
    "    'AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', \n",
    "    'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap'\n",
    "]\n",
    "\n",
    "# Calculamos el promedio para cada caso\n",
    "resumen_no_diff = arima_df[modelos_metricas].mean()\n",
    "resumen_diff = arima_Diff_df[modelos_metricas].mean()\n",
    "\n",
    "# Construir el DataFrame comparativo\n",
    "tabla_comparativa = pd.DataFrame({\n",
    "    'ARIMA': resumen_no_diff,\n",
    "    'ARIMA_Diff': resumen_diff\n",
    "})\n",
    "\n",
    "# Determinar el mejor escenario (el que tenga el valor menor, asumiendo que son errores)\n",
    "tabla_comparativa['Mejor_Escenario'] = np.where(\n",
    "    tabla_comparativa['ARIMA'] < tabla_comparativa['ARIMA_Diff'], \n",
    "    'ARIMA', \n",
    "    'ARIMA_Diff'\n",
    ")\n",
    "\n",
    "# Formatear la tabla para que se vea limpia\n",
    "tabla_comparativa.index.name = 'Modelo'\n",
    "tabla_comparativa = tabla_comparativa.sort_index()\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Tabla Comparativa de Desempeño (Promedios):\")\n",
    "print(tabla_comparativa.to_string())\n",
    "\n",
    "print(f\"\\nArchivo de unión guardado en: {path_salida}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08864bc2",
   "metadata": {},
   "source": [
    "### Analisis general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3ee6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Datos cargados: (3360, 14)\n",
      "Generando gráficos de barras con valores...\n",
      "Generando Heatmaps y Gráfico de Líneas...\n",
      "Calculando tabla DM...\n",
      "Generando Excel detallado (Sin Paso, ordenado por mejora)...\n",
      "\n",
      "ANÁLISIS COMPLETADO. Carpeta: Resultados_analisis\\Simulacion_diff\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Configuración inicial\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "# 1. PREPARACIÓN DE DIRECTORIOS\n",
    "output_dir = Path(\"./Resultados_analisis/Multi_d\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "plots_dir = output_dir / \"Graficos_Analisis\"\n",
    "plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Cargar datos\n",
    "path_excel = \"./datos/Simulacion/Multi_D/resultados_ARIMA_d1_a_d10_DOBLE_MODALIDAD_COMPLETO.xlsx\"\n",
    "try:\n",
    "    df = pd.read_excel(path_excel)\n",
    "    print(f\"✓ Datos cargados: {df.shape}\")\n",
    "    print(f\"✓ Columnas: {df.columns.tolist()}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error crítico: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Identificar columnas\n",
    "var_cols = ['Paso', 'Proceso', 'p', 'd', 'q', 'ARMA_base', 'Distribución', \n",
    "            'Varianza', 'Modalidad', 'Valor_Observado']\n",
    "model_cols = [col for col in df.columns if col not in var_cols]\n",
    "\n",
    "print(f\"✓ Modelos identificados: {model_cols}\")\n",
    "print(f\"✓ Valores únicos de d: {sorted(df['d'].unique())}\")\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 1: COMPARACIÓN INDIVIDUAL POR VALOR DE d\n",
    "# ====================================================================================\n",
    "def plot_individual_comparisons():\n",
    "    print(\"\\n=== Generando gráficos de barras con valores por d ===\")\n",
    "    \n",
    "    # Para cada valor de d\n",
    "    d_values = sorted(df['d'].unique())\n",
    "    \n",
    "    for d_val in d_values:\n",
    "        stats_list = []\n",
    "        subset_d = df[df['d'] == d_val]\n",
    "        \n",
    "        for model in model_cols:\n",
    "            sin = subset_d[subset_d['Modalidad'] == 'SIN_DIFF'][model].mean()\n",
    "            con = subset_d[subset_d['Modalidad'] == 'CON_DIFF'][model].mean()\n",
    "            mejora = ((sin - con) / sin) * 100 if sin != 0 else 0\n",
    "            stats_list.append({'Modelo': model, 'Sin': sin, 'Con': con, 'Mejora': mejora})\n",
    "        \n",
    "        df_stats = pd.DataFrame(stats_list).sort_values(by='Mejora', ascending=False)\n",
    "        \n",
    "        # 1.1 Barras Comparativas por d\n",
    "        fig, ax = plt.subplots(figsize=(14, 6))\n",
    "        x = np.arange(len(df_stats))\n",
    "        width = 0.35\n",
    "        \n",
    "        b1 = ax.bar(x - width/2, df_stats['Sin'], width, label='Sin Dif.', \n",
    "                    color='#e74c3c', edgecolor='black', alpha=0.8)\n",
    "        b2 = ax.bar(x + width/2, df_stats['Con'], width, label='Con Dif.', \n",
    "                    color='#2ecc71', edgecolor='black', alpha=0.8)\n",
    "        \n",
    "        ax.bar_label(b1, padding=3, fmt='%.3f', fontsize=7, rotation=45)\n",
    "        ax.bar_label(b2, padding=3, fmt='%.3f', fontsize=7, rotation=45)\n",
    "        \n",
    "        ax.set_title(f'ECRPS Promedio por Modelo (d={d_val})', fontweight='bold', fontsize=12)\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(df_stats['Modelo'], rotation=45, ha='right')\n",
    "        ax.set_ylabel('ECRPS')\n",
    "        ax.legend()\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(plots_dir / f'1.1_barras_ecrps_d{d_val}.png')\n",
    "        plt.close()\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 2: HEATMAP d vs MODELO\n",
    "# ====================================================================================\n",
    "def plot_heatmap_d_vs_modelo():\n",
    "    print(\"\\n=== Generando Heatmap d vs Modelo ===\")\n",
    "    \n",
    "    results = []\n",
    "    d_values = sorted(df['d'].unique())\n",
    "    \n",
    "    for d_val in d_values:\n",
    "        subset_d = df[df['d'] == d_val]\n",
    "        for model in model_cols:\n",
    "            sin = subset_d[subset_d['Modalidad'] == 'SIN_DIFF'][model].mean()\n",
    "            con = subset_d[subset_d['Modalidad'] == 'CON_DIFF'][model].mean()\n",
    "            mejora = ((sin - con) / sin) * 100 if sin != 0 else 0\n",
    "            results.append({'d': d_val, 'Modelo': model, 'Mejora_%': mejora})\n",
    "    \n",
    "    df_mejora = pd.DataFrame(results)\n",
    "    pivot = df_mejora.pivot(index='Modelo', columns='d', values='Mejora_%')\n",
    "    \n",
    "    plt.figure(figsize=(14, 10))\n",
    "    sns.heatmap(pivot, annot=True, fmt=\".1f\", cmap=\"RdYlGn\", center=0, \n",
    "                cbar_kws={'label': 'Mejora (%)'}, linewidths=0.5)\n",
    "    plt.title(\"Mejora Porcentual (%): Modelo vs Valor de d\", fontweight='bold', fontsize=14)\n",
    "    plt.xlabel(\"Valor de d (Grado de diferenciación)\", fontweight='bold')\n",
    "    plt.ylabel(\"Modelo\", fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plots_dir / '2_heatmap_d_vs_modelo.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Guardar tabla\n",
    "    pivot.to_excel(output_dir / '2_tabla_d_vs_modelo.xlsx')\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 3: HEATMAP SIGNIFICANCIA (d vs Diferenciación)\n",
    "# ====================================================================================\n",
    "def plot_heatmap_significancia():\n",
    "    print(\"\\n=== Generando Heatmap de Significancia d vs Diferenciación ===\")\n",
    "    \n",
    "    results = []\n",
    "    d_values = sorted(df['d'].unique())\n",
    "    \n",
    "    for d_val in d_values:\n",
    "        subset_d = df[df['d'] == d_val]\n",
    "        for model in model_cols:\n",
    "            sin = subset_d[subset_d['Modalidad'] == 'SIN_DIFF'][model].values\n",
    "            con = subset_d[subset_d['Modalidad'] == 'CON_DIFF'][model].values\n",
    "            \n",
    "            if len(sin) > 1 and len(con) > 1:\n",
    "                stat, p_valor = stats.ttest_ind(sin, con)\n",
    "                significativo = 1 if p_valor < 0.05 else 0\n",
    "                # Determinar dirección\n",
    "                if p_valor < 0.05:\n",
    "                    if sin.mean() > con.mean():\n",
    "                        valor = 1  # Diferenciación es mejor\n",
    "                    else:\n",
    "                        valor = -1  # Sin diferenciación es mejor\n",
    "                else:\n",
    "                    valor = 0  # No significativo\n",
    "            else:\n",
    "                valor = 0\n",
    "            \n",
    "            results.append({'d': d_val, 'Modelo': model, 'Significancia': valor})\n",
    "    \n",
    "    df_sig = pd.DataFrame(results)\n",
    "    pivot_sig = df_sig.pivot(index='Modelo', columns='d', values='Significancia')\n",
    "    \n",
    "    plt.figure(figsize=(14, 10))\n",
    "    sns.heatmap(pivot_sig, annot=True, fmt=\".0f\", cmap=\"RdYlGn\", center=0,\n",
    "                cbar_kws={'label': 'Significancia (-1: Sin Dif mejor | 0: No sig. | 1: Con Dif mejor)'},\n",
    "                linewidths=0.5, vmin=-1, vmax=1)\n",
    "    plt.title(\"Significancia Estadística: d vs Diferenciación por Modelo\", fontweight='bold', fontsize=14)\n",
    "    plt.xlabel(\"Valor de d\", fontweight='bold')\n",
    "    plt.ylabel(\"Modelo\", fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plots_dir / '3_heatmap_significancia_d.png')\n",
    "    plt.close()\n",
    "    \n",
    "    pivot_sig.to_excel(output_dir / '3_tabla_significancia_d.xlsx')\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 4: INTERACCIONES d vs Distribución, Config y Varianza\n",
    "# ====================================================================================\n",
    "def plot_interacciones_d():\n",
    "    print(\"\\n=== Generando Interacciones d vs Dist, Config y Varianza ===\")\n",
    "    \n",
    "    # 4.1 d vs Distribución\n",
    "    def get_improvement_d_group(group_col):\n",
    "        results = []\n",
    "        d_values = sorted(df['d'].unique())\n",
    "        for d_val in d_values:\n",
    "            subset_d = df[df['d'] == d_val]\n",
    "            for val in subset_d[group_col].unique():\n",
    "                subset = subset_d[subset_d[group_col] == val]\n",
    "                for model in model_cols:\n",
    "                    sin = subset[subset['Modalidad'] == 'SIN_DIFF'][model].mean()\n",
    "                    con = subset[subset['Modalidad'] == 'CON_DIFF'][model].mean()\n",
    "                    mejora = ((sin - con) / sin) * 100 if sin != 0 else 0\n",
    "                    results.append({'d': d_val, group_col: val, 'Modelo': model, 'Mejora': mejora})\n",
    "        return pd.DataFrame(results)\n",
    "    \n",
    "    # 4.1 Heatmap d vs Distribución (agrupado por modelo)\n",
    "    df_dist = get_improvement_d_group('Distribución')\n",
    "    \n",
    "    for model in model_cols:\n",
    "        subset = df_dist[df_dist['Modelo'] == model]\n",
    "        pivot = subset.pivot(index='d', columns='Distribución', values='Mejora')\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(pivot, annot=True, fmt=\".1f\", cmap=\"RdYlGn\", center=0)\n",
    "        plt.title(f\"Mejora (%) d vs Distribución - {model}\", fontweight='bold')\n",
    "        plt.xlabel(\"Distribución\")\n",
    "        plt.ylabel(\"Valor de d\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(plots_dir / f'4.1_heatmap_d_dist_{model}.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # 4.2 Heatmap d vs Varianza (líneas por modelo)\n",
    "    df_var = get_improvement_d_group('Varianza')\n",
    "    \n",
    "    plt.figure(figsize=(14, 8))\n",
    "    for model in model_cols:\n",
    "        subset = df_var[df_var['Modelo'] == model]\n",
    "        grouped = subset.groupby(['d', 'Varianza'])['Mejora'].mean().reset_index()\n",
    "        for var_val in grouped['Varianza'].unique():\n",
    "            data = grouped[grouped['Varianza'] == var_val]\n",
    "            plt.plot(data['d'], data['Mejora'], marker='o', label=f'{model}-Var{var_val}', alpha=0.7)\n",
    "    \n",
    "    plt.axhline(0, color='black', linestyle='--', alpha=0.5)\n",
    "    plt.title(\"Tendencia Mejora (%): d vs Varianza por Modelo\", fontweight='bold')\n",
    "    plt.xlabel(\"Valor de d\")\n",
    "    plt.ylabel(\"Mejora Porcentual\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plots_dir / '4.2_linea_d_varianza.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # 4.3 Heatmap d vs Config (por modelo)\n",
    "    # Nota: Asumiendo que Config se deriva de (p, q) o ARMA_base\n",
    "    # Si no existe, usar ARMA_base como proxy\n",
    "    if 'ARMA_base' in df.columns:\n",
    "        df_config = get_improvement_d_group('ARMA_base')\n",
    "        \n",
    "        for model in model_cols:\n",
    "            subset = df_config[df_config['Modelo'] == model]\n",
    "            pivot = subset.pivot(index='d', columns='ARMA_base', values='Mejora')\n",
    "            \n",
    "            plt.figure(figsize=(12, 8))\n",
    "            sns.heatmap(pivot, annot=True, fmt=\".1f\", cmap=\"RdYlGn\", center=0)\n",
    "            plt.title(f\"Mejora (%) d vs Configuración Base - {model}\", fontweight='bold')\n",
    "            plt.xlabel(\"Configuración ARMA\")\n",
    "            plt.ylabel(\"Valor de d\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(plots_dir / f'4.3_heatmap_d_config_{model}.png')\n",
    "            plt.close()\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 6: TABLA DM POR VALOR DE d\n",
    "# ====================================================================================\n",
    "def run_dm_analysis():\n",
    "    print(\"\\n=== Calculando Tabla DM por valor de d ===\")\n",
    "    \n",
    "    d_values = sorted(df['d'].unique())\n",
    "    all_results = []\n",
    "    \n",
    "    for d_val in d_values:\n",
    "        subset_d = df[df['d'] == d_val]\n",
    "        \n",
    "        for model in model_cols:\n",
    "            sin = subset_d[subset_d['Modalidad'] == 'SIN_DIFF'][model].values\n",
    "            con = subset_d[subset_d['Modalidad'] == 'CON_DIFF'][model].values\n",
    "            \n",
    "            if len(sin) > 1 and len(con) > 1:\n",
    "                mean_sin, mean_con = sin.mean(), con.mean()\n",
    "                mejora_pct = ((mean_sin - mean_con) / mean_sin) * 100 if mean_sin != 0 else 0\n",
    "                \n",
    "                stat, p_valor = stats.ttest_ind(sin, con)\n",
    "                significativo = 'Sí' if p_valor < 0.05 else 'No'\n",
    "                \n",
    "                if p_valor < 0.05:\n",
    "                    conclusion = \"Diferenciación mejora\" if mejora_pct > 0 else \"Sin dif mejor\"\n",
    "                else:\n",
    "                    conclusion = \"Sin diferencia significativa\"\n",
    "                \n",
    "                all_results.append({\n",
    "                    'd': d_val, 'Modelo': model, \n",
    "                    'ECRPS_Sin_Diff': mean_sin, 'ECRPS_Con_Diff': mean_con,\n",
    "                    'Mejora_%': mejora_pct, 'p_valor': p_valor, \n",
    "                    'Significativo': significativo, 'Conclusion': conclusion\n",
    "                })\n",
    "    \n",
    "    dm_df = pd.DataFrame(all_results).sort_values(by=['d', 'Mejora_%'], ascending=[True, False])\n",
    "    dm_df.to_excel(output_dir / '6_tabla_dm_por_d.xlsx', index=False)\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 9: EXCEL DETALLADO POR d (Agrupado, Ordenado)\n",
    "# ====================================================================================\n",
    "def generate_detailed_excel():\n",
    "    print(\"\\n=== Generando Excel detallado por d (ordenado por mejora) ===\")\n",
    "    file_path = output_dir / \"9_Analisis_Detallado_Modelos_por_d.xlsx\"\n",
    "    \n",
    "    with pd.ExcelWriter(file_path, engine='xlsxwriter') as writer:\n",
    "        for model in model_cols:\n",
    "            # Agrupar por d, ARMA_base, Distribución, Varianza (promediando Pasos)\n",
    "            temp = df.groupby(['d', 'ARMA_base', 'Distribución', 'Varianza', 'Modalidad'])[model].mean().reset_index()\n",
    "            \n",
    "            # Pivotar\n",
    "            detailed = temp.pivot_table(\n",
    "                index=['d', 'ARMA_base', 'Distribución', 'Varianza'],\n",
    "                columns='Modalidad',\n",
    "                values=model\n",
    "            ).reset_index()\n",
    "            \n",
    "            detailed.columns.name = None\n",
    "            detailed = detailed.rename(columns={\n",
    "                'SIN_DIFF': 'ECRPS_Sin_Dif', \n",
    "                'CON_DIFF': 'ECRPS_Con_Dif'\n",
    "            })\n",
    "            \n",
    "            detailed['Mejora_Absoluta'] = detailed['ECRPS_Sin_Dif'] - detailed['ECRPS_Con_Dif']\n",
    "            detailed['Mejora_%'] = (detailed['Mejora_Absoluta'] / detailed['ECRPS_Sin_Dif']) * 100\n",
    "            \n",
    "            # Ordenar por d y luego por mejora\n",
    "            detailed = detailed.sort_values(by=['d', 'Mejora_%'], ascending=[True, False])\n",
    "            \n",
    "            sheet_name = model[:31]\n",
    "            detailed.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "            \n",
    "            # Formatos condicionales\n",
    "            workbook = writer.book\n",
    "            worksheet = writer.sheets[sheet_name]\n",
    "            fmt_green = workbook.add_format({'bg_color': '#C6EFCE', 'font_color': '#006100'})\n",
    "            fmt_red = workbook.add_format({'bg_color': '#FFC7CE', 'font_color': '#9C0006'})\n",
    "            \n",
    "            # Aplicar a columna Mejora_%\n",
    "            col_idx = detailed.columns.get_loc('Mejora_%')\n",
    "            worksheet.conditional_format(1, col_idx, len(detailed), col_idx, {\n",
    "                'type': 'cell', 'criteria': '>', 'value': 0, 'format': fmt_green\n",
    "            })\n",
    "            worksheet.conditional_format(1, col_idx, len(detailed), col_idx, {\n",
    "                'type': 'cell', 'criteria': '<', 'value': 0, 'format': fmt_red\n",
    "            })\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN ADICIONAL: GRÁFICOS PREVIOS MANTENIDOS\n",
    "# ====================================================================================\n",
    "def plot_mejora_general():\n",
    "    \"\"\"Gráfico general de mejora promedio por modelo (todos los d)\"\"\"\n",
    "    print(\"\\n=== Generando gráfico general de mejora ===\")\n",
    "    \n",
    "    stats_list = []\n",
    "    for model in model_cols:\n",
    "        sin = df[df['Modalidad'] == 'SIN_DIFF'][model].mean()\n",
    "        con = df[df['Modalidad'] == 'CON_DIFF'][model].mean()\n",
    "        mejora = ((sin - con) / sin) * 100 if sin != 0 else 0\n",
    "        stats_list.append({'Modelo': model, 'Mejora_%': mejora})\n",
    "    \n",
    "    df_stats = pd.DataFrame(stats_list).sort_values(by='Mejora_%', ascending=False)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    colors = ['#2ecc71' if m > 0 else '#e74c3c' for m in df_stats['Mejora_%']]\n",
    "    bars = ax.barh(df_stats['Modelo'], df_stats['Mejora_%'], color=colors, edgecolor='black')\n",
    "    ax.bar_label(bars, padding=5, fmt='%.1f%%', fontweight='bold')\n",
    "    ax.axvline(0, color='black', lw=1)\n",
    "    ax.set_title('Mejora Porcentual Global con Diferenciación (Todos los d)', fontweight='bold')\n",
    "    ax.set_xlabel('Mejora (%)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plots_dir / '0_mejora_global.png')\n",
    "    plt.close()\n",
    "\n",
    "# ====================================================================================\n",
    "# EJECUCIÓN PRINCIPAL\n",
    "# ====================================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"INICIANDO ANÁLISIS MULTI-D\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    plot_mejora_general()\n",
    "    plot_individual_comparisons()\n",
    "    plot_heatmap_d_vs_modelo()\n",
    "    plot_heatmap_significancia()\n",
    "    plot_interacciones_d()\n",
    "    run_dm_analysis()\n",
    "    generate_detailed_excel()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"✓ ANÁLISIS COMPLETADO EXITOSAMENTE\")\n",
    "    print(f\"✓ Resultados guardados en: {output_dir}\")\n",
    "    print(f\"✓ Gráficos guardados en: {plots_dir}\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e6b598",
   "metadata": {},
   "source": [
    "## Aumento d ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b73a5d",
   "metadata": {},
   "source": [
    "### Pre-procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d843823c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "TEST DIEBOLD-MARIANO MODIFICADO (HLN): Comparación SIN_DIFF vs CON_DIFF por valor de d\n",
      "====================================================================================================\n",
      "\n",
      "H0: No hay diferencia significativa entre las modalidades\n",
      "H1: Hay diferencia significativa entre las modalidades\n",
      "\n",
      "Significancia: *** p<0.01, ** p<0.05, * p<0.10, No = no significativo\n",
      "\n",
      "\n",
      " d  N_obs  ECRPS_SIN_DIFF  ECRPS_CON_DIFF    Diferencia  DM_stat  HLN-DM_stat  p_valor Significativo\n",
      " 1   1680    5.495070e-01    5.485800e-01  9.280000e-04   0.8532       0.8529   0.3938            No\n",
      " 2   1680    2.884661e+01    2.883279e+01  1.382000e-02   2.1456       2.1449   0.0321            **\n",
      " 3   1680    2.725984e+01    2.726032e+01 -4.790000e-04  -0.0538      -0.0538   0.9571            No\n",
      " 4   1680    2.704997e+01    2.704544e+01  4.532000e-03   0.3388       0.3387   0.7349            No\n",
      " 5   1680    3.451632e+01    2.821125e+01  6.305071e+00   5.9399       5.9381   0.0000           ***\n",
      " 7   1680    6.686329e+04    1.261129e+03  6.560216e+04  24.3102      24.3030   0.0000           ***\n",
      "10   1680    1.890294e+09    8.453933e+07  1.805754e+09  24.9067      24.8992   0.0000           ***\n",
      "\n",
      "====================================================================================================\n",
      "RESUMEN\n",
      "====================================================================================================\n",
      "\n",
      "Total de comparaciones: 7\n",
      "Diferencias significativas: 4 (57.1%)\n",
      "No significativas: 3 (42.9%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Cargar datos\n",
    "base = pd.read_excel(\"./datos/Simulacion/Multi_D/resultados_ARIMA_d1_a_d10_DOBLE_MODALIDAD_COMPLETO.xlsx\")\n",
    "\n",
    "# Seleccionar columnas necesarias\n",
    "columnas_seleccionadas = ['Paso', 'Proceso', 'p', 'd', 'q', 'ARMA_base', \n",
    "                          'Distribución', 'Varianza', 'Modalidad', 'Sieve Bootstrap']\n",
    "datos = base[columnas_seleccionadas].copy()\n",
    "\n",
    "# Renombrar columna para claridad\n",
    "datos.rename(columns={'Sieve Bootstrap': 'ECRPS'}, inplace=True)\n",
    "\n",
    "def modified_diebold_mariano_test(errors1, errors2, h=1):\n",
    "    \"\"\"\n",
    "    Test Diebold-Mariano modificado con corrección Harvey-Leybourne-Newbold (1997)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    errors1, errors2 : array-like\n",
    "        Errores de pronóstico (ECRPS) de los dos modelos\n",
    "    h : int\n",
    "        Horizonte de pronóstico (forecast horizon)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    hln_dm_stat : float\n",
    "        Estadístico DM corregido (HLN-DM)\n",
    "    p_value : float\n",
    "        P-valor usando distribución t-Student con T-1 grados de libertad\n",
    "    dm_stat : float\n",
    "        Estadístico DM original (sin corrección)\n",
    "    \"\"\"\n",
    "    # Calcular diferencial de pérdida\n",
    "    d = errors1 - errors2\n",
    "    d_bar = np.mean(d)\n",
    "    T = len(d)\n",
    "    \n",
    "    # Calcular autocovarianzas\n",
    "    def gamma_d(k):\n",
    "        if k == 0:\n",
    "            return np.var(d, ddof=1)\n",
    "        else:\n",
    "            return np.mean((d[k:] - d_bar) * (d[:-k] - d_bar))\n",
    "    \n",
    "    # Estimar la varianza de largo plazo usando Newey-West\n",
    "    # Para h-step-ahead forecasts, incluimos hasta h-1 lags\n",
    "    gamma_0 = gamma_d(0)\n",
    "    gamma_sum = gamma_0\n",
    "    \n",
    "    if h > 1:\n",
    "        for k in range(1, h):\n",
    "            gamma_k = gamma_d(k)\n",
    "            gamma_sum += 2 * gamma_k\n",
    "    \n",
    "    var_d = gamma_sum / T\n",
    "    \n",
    "    if var_d <= 0:\n",
    "        return 0, 1.0, 0\n",
    "    \n",
    "    # Estadístico DM original\n",
    "    dm_stat = d_bar / np.sqrt(var_d)\n",
    "    \n",
    "    # Corrección Harvey-Leybourne-Newbold (1997)\n",
    "    correction_factor = np.sqrt((T + 1 - 2*h + h*(h-1)) / T)\n",
    "    hln_dm_stat = correction_factor * dm_stat\n",
    "    \n",
    "    # P-valor usando t-Student con T-1 grados de libertad\n",
    "    df = T - 1\n",
    "    p_value = 2 * (1 - stats.t.cdf(abs(hln_dm_stat), df))\n",
    "    \n",
    "    return hln_dm_stat, p_value, dm_stat\n",
    "\n",
    "# Obtener valores únicos de d\n",
    "valores_d = sorted(datos['d'].unique())\n",
    "\n",
    "# Lista para almacenar resultados\n",
    "resultados = []\n",
    "\n",
    "# Iterar sobre cada valor de d\n",
    "for d_val in valores_d:\n",
    "    # Filtrar datos para el d actual\n",
    "    datos_d = datos[datos['d'] == d_val].copy()\n",
    "    \n",
    "    # Separar por modalidad\n",
    "    sin_diff = datos_d[datos_d['Modalidad'] == 'SIN_DIFF']['ECRPS'].values\n",
    "    con_diff = datos_d[datos_d['Modalidad'] == 'CON_DIFF']['ECRPS'].values\n",
    "    \n",
    "    # Verificar que ambas modalidades tengan datos\n",
    "    if len(sin_diff) == 0 or len(con_diff) == 0:\n",
    "        print(f\"Advertencia: d={d_val} no tiene datos para ambas modalidades\")\n",
    "        continue\n",
    "    \n",
    "    # Verificar que tengan la misma longitud\n",
    "    if len(sin_diff) != len(con_diff):\n",
    "        print(f\"Advertencia: d={d_val} tiene diferente número de observaciones entre modalidades\")\n",
    "        min_len = min(len(sin_diff), len(con_diff))\n",
    "        sin_diff = sin_diff[:min_len]\n",
    "        con_diff = con_diff[:min_len]\n",
    "    \n",
    "    # Calcular estadísticas descriptivas\n",
    "    ecrps_sin_diff_mean = np.mean(sin_diff)\n",
    "    ecrps_con_diff_mean = np.mean(con_diff)\n",
    "    diferencia = ecrps_sin_diff_mean - ecrps_con_diff_mean\n",
    "    \n",
    "    # Realizar test Diebold-Mariano modificado\n",
    "    hln_dm_stat, p_value, dm_stat = modified_diebold_mariano_test(sin_diff, con_diff, h=1)\n",
    "    \n",
    "    # Determinar significancia (niveles comunes: 0.01, 0.05, 0.10)\n",
    "    if p_value < 0.01:\n",
    "        significativo = \"***\"\n",
    "    elif p_value < 0.05:\n",
    "        significativo = \"**\"\n",
    "    elif p_value < 0.10:\n",
    "        significativo = \"*\"\n",
    "    else:\n",
    "        significativo = \"No\"\n",
    "    \n",
    "    # Agregar a resultados\n",
    "    resultados.append({\n",
    "        'd': d_val,\n",
    "        'N_obs': len(sin_diff),\n",
    "        'ECRPS_SIN_DIFF': ecrps_sin_diff_mean,\n",
    "        'ECRPS_CON_DIFF': ecrps_con_diff_mean,\n",
    "        'Diferencia': diferencia,\n",
    "        'DM_stat': dm_stat,\n",
    "        'HLN-DM_stat': hln_dm_stat,\n",
    "        'p_valor': p_value,\n",
    "        'Significativo': significativo\n",
    "    })\n",
    "\n",
    "# Crear DataFrame con resultados\n",
    "resultados_df = pd.DataFrame(resultados)\n",
    "\n",
    "# Formatear para mejor visualización\n",
    "resultados_df['ECRPS_SIN_DIFF'] = resultados_df['ECRPS_SIN_DIFF'].round(6)\n",
    "resultados_df['ECRPS_CON_DIFF'] = resultados_df['ECRPS_CON_DIFF'].round(6)\n",
    "resultados_df['Diferencia'] = resultados_df['Diferencia'].round(6)\n",
    "resultados_df['DM_stat'] = resultados_df['DM_stat'].round(4)\n",
    "resultados_df['HLN-DM_stat'] = resultados_df['HLN-DM_stat'].round(4)\n",
    "resultados_df['p_valor'] = resultados_df['p_valor'].round(4)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"TEST DIEBOLD-MARIANO MODIFICADO (HLN): Comparación SIN_DIFF vs CON_DIFF por valor de d\")\n",
    "print(\"=\"*100)\n",
    "print(\"\\nH0: No hay diferencia significativa entre las modalidades\")\n",
    "print(\"H1: Hay diferencia significativa entre las modalidades\")\n",
    "print(\"\\nSignificancia: *** p<0.01, ** p<0.05, * p<0.10, No = no significativo\")\n",
    "print(\"\\n\")\n",
    "print(resultados_df.to_string(index=False))\n",
    "\n",
    "# Resumen de resultados\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"RESUMEN\")\n",
    "print(\"=\"*100)\n",
    "n_significativos = len(resultados_df[resultados_df['Significativo'] != 'No'])\n",
    "n_total = len(resultados_df)\n",
    "print(f\"\\nTotal de comparaciones: {n_total}\")\n",
    "print(f\"Diferencias significativas: {n_significativos} ({100*n_significativos/n_total:.1f}%)\")\n",
    "print(f\"No significativas: {n_total - n_significativos} ({100*(n_total-n_significativos)/n_total:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6425b70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================================================================\n",
      "TEST DIEBOLD-MARIANO MODIFICADO (HLN): Comparación Sin Diferenciación (No) vs Con Diferenciación (Si)\n",
      "========================================================================================================================\n",
      "\n",
      "H0: No hay diferencia significativa entre aplicar o no diferenciación\n",
      "H1: Hay diferencia significativa entre aplicar o no diferenciación\n",
      "\n",
      "Significancia: *** p<0.01, ** p<0.05, * p<0.10, No = no significativo\n",
      "========================================================================================================================\n",
      "\n",
      "\n",
      "             Método  N_obs  ECRPS_Sin_Diff  ECRPS_Con_Diff  Diferencia  DM_stat  HLN-DM_stat  p_valor Significativo\n",
      "Block Bootstrapping   1680       11.251601        0.666133   10.585468  22.5804      22.5736   0.0000           ***\n",
      "    Sieve Bootstrap   1680        0.547481        0.546020    0.001461   1.7771       1.7766   0.0758             *\n",
      "               LSPM   1680        1.064804        0.648039    0.416766  24.1811      24.1739   0.0000           ***\n",
      "              LSPMW   1680        3.079645        0.767172    2.312473  26.6766      26.6686   0.0000           ***\n",
      "              AREPD   1680       10.031183        0.704149    9.327035  21.1620      21.1557   0.0000           ***\n",
      "               MCPS   1680        3.218168        0.677471    2.540697  18.7579      18.7524   0.0000           ***\n",
      "            AV-MCPS   1680        3.324007        0.654257    2.669750  21.1745      21.1682   0.0000           ***\n",
      "             DeepAR   1680        4.329124        0.561822    3.767302  12.4578      12.4541   0.0000           ***\n",
      "         EnCQR-LSTM   1680        6.112344        0.880288    5.232056  29.0849      29.0763   0.0000           ***\n",
      "\n",
      "========================================================================================================================\n",
      "RESUMEN\n",
      "========================================================================================================================\n",
      "\n",
      "Total de métodos comparados: 9\n",
      "Diferencias significativas: 9 (100.0%)\n",
      "No significativas: 0 (0.0%)\n",
      "\n",
      "Métodos con diferencias significativas:\n",
      "             Método Significativo  p_valor\n",
      "Block Bootstrapping           ***   0.0000\n",
      "    Sieve Bootstrap             *   0.0758\n",
      "               LSPM           ***   0.0000\n",
      "              LSPMW           ***   0.0000\n",
      "              AREPD           ***   0.0000\n",
      "               MCPS           ***   0.0000\n",
      "            AV-MCPS           ***   0.0000\n",
      "             DeepAR           ***   0.0000\n",
      "         EnCQR-LSTM           ***   0.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Cargar datos\n",
    "base = pd.read_excel(\"./datos/Simulacion/Diferenciado/resultados_UNION_ARIMA.xlsx\")\n",
    "\n",
    "def modified_diebold_mariano_test(errors1, errors2, h=1):\n",
    "    \"\"\"\n",
    "    Test Diebold-Mariano modificado con corrección Harvey-Leybourne-Newbold (1997)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    errors1, errors2 : array-like\n",
    "        Errores de pronóstico (ECRPS) de los dos modelos\n",
    "    h : int\n",
    "        Horizonte de pronóstico (forecast horizon)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    hln_dm_stat : float\n",
    "        Estadístico DM corregido (HLN-DM)\n",
    "    p_value : float\n",
    "        P-valor usando distribución t-Student con T-1 grados de libertad\n",
    "    dm_stat : float\n",
    "        Estadístico DM original (sin corrección)\n",
    "    \"\"\"\n",
    "    # Calcular diferencial de pérdida\n",
    "    d = errors1 - errors2\n",
    "    d_bar = np.mean(d)\n",
    "    T = len(d)\n",
    "    \n",
    "    # Calcular autocovarianzas\n",
    "    def gamma_d(k):\n",
    "        if k == 0:\n",
    "            return np.var(d, ddof=1)\n",
    "        else:\n",
    "            return np.mean((d[k:] - d_bar) * (d[:-k] - d_bar))\n",
    "    \n",
    "    # Estimar la varianza de largo plazo usando Newey-West\n",
    "    # Para h-step-ahead forecasts, incluimos hasta h-1 lags\n",
    "    gamma_0 = gamma_d(0)\n",
    "    gamma_sum = gamma_0\n",
    "    \n",
    "    if h > 1:\n",
    "        for k in range(1, h):\n",
    "            gamma_k = gamma_d(k)\n",
    "            gamma_sum += 2 * gamma_k\n",
    "    \n",
    "    var_d = gamma_sum / T\n",
    "    \n",
    "    if var_d <= 0:\n",
    "        return 0, 1.0, 0\n",
    "    \n",
    "    # Estadístico DM original\n",
    "    dm_stat = d_bar / np.sqrt(var_d)\n",
    "    \n",
    "    # Corrección Harvey-Leybourne-Newbold (1997)\n",
    "    correction_factor = np.sqrt((T + 1 - 2*h + h*(h-1)) / T)\n",
    "    hln_dm_stat = correction_factor * dm_stat\n",
    "    \n",
    "    # P-valor usando t-Student con T-1 grados de libertad\n",
    "    df = T - 1\n",
    "    p_value = 2 * (1 - stats.t.cdf(abs(hln_dm_stat), df))\n",
    "    \n",
    "    return hln_dm_stat, p_value, dm_stat\n",
    "\n",
    "# Separar por diferenciación\n",
    "sin_diff = base[base['Diferenciacion'] == 'No'].copy()\n",
    "con_diff = base[base['Diferenciacion'] == 'Si'].copy()\n",
    "\n",
    "# Métodos a comparar (todos excepto las columnas de configuración)\n",
    "metodos = ['Block Bootstrapping', 'Sieve Bootstrap', 'LSPM', 'LSPMW', \n",
    "           'AREPD', 'MCPS', 'AV-MCPS', 'DeepAR', 'EnCQR-LSTM']\n",
    "\n",
    "# Lista para almacenar resultados\n",
    "resultados = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"TEST DIEBOLD-MARIANO MODIFICADO (HLN): Comparación Sin Diferenciación (No) vs Con Diferenciación (Si)\")\n",
    "print(\"=\"*120)\n",
    "print(\"\\nH0: No hay diferencia significativa entre aplicar o no diferenciación\")\n",
    "print(\"H1: Hay diferencia significativa entre aplicar o no diferenciación\")\n",
    "print(\"\\nSignificancia: *** p<0.01, ** p<0.05, * p<0.10, No = no significativo\")\n",
    "print(\"=\"*120)\n",
    "\n",
    "# Iterar sobre cada método\n",
    "for metodo in metodos:\n",
    "    # Obtener valores de ECRPS para cada modalidad\n",
    "    ecrps_sin = sin_diff[metodo].values\n",
    "    ecrps_con = con_diff[metodo].values\n",
    "    \n",
    "    # Verificar que ambas modalidades tengan datos\n",
    "    if len(ecrps_sin) == 0 or len(ecrps_con) == 0:\n",
    "        print(f\"\\nAdvertencia: {metodo} no tiene datos para ambas modalidades\")\n",
    "        continue\n",
    "    \n",
    "    # Verificar que tengan la misma longitud\n",
    "    if len(ecrps_sin) != len(ecrps_con):\n",
    "        print(f\"\\nAdvertencia: {metodo} tiene diferente número de observaciones\")\n",
    "        min_len = min(len(ecrps_sin), len(ecrps_con))\n",
    "        ecrps_sin = ecrps_sin[:min_len]\n",
    "        ecrps_con = ecrps_con[:min_len]\n",
    "    \n",
    "    # Calcular estadísticas descriptivas\n",
    "    ecrps_sin_mean = np.mean(ecrps_sin)\n",
    "    ecrps_con_mean = np.mean(ecrps_con)\n",
    "    diferencia = ecrps_sin_mean - ecrps_con_mean\n",
    "    \n",
    "    # Realizar test Diebold-Mariano modificado\n",
    "    hln_dm_stat, p_value, dm_stat = modified_diebold_mariano_test(ecrps_sin, ecrps_con, h=1)\n",
    "    \n",
    "    # Determinar significancia\n",
    "    if p_value < 0.01:\n",
    "        significativo = \"***\"\n",
    "    elif p_value < 0.05:\n",
    "        significativo = \"**\"\n",
    "    elif p_value < 0.10:\n",
    "        significativo = \"*\"\n",
    "    else:\n",
    "        significativo = \"No\"\n",
    "    \n",
    "    # Agregar a resultados\n",
    "    resultados.append({\n",
    "        'Método': metodo,\n",
    "        'N_obs': len(ecrps_sin),\n",
    "        'ECRPS_Sin_Diff': ecrps_sin_mean,\n",
    "        'ECRPS_Con_Diff': ecrps_con_mean,\n",
    "        'Diferencia': diferencia,\n",
    "        'DM_stat': dm_stat,\n",
    "        'HLN-DM_stat': hln_dm_stat,\n",
    "        'p_valor': p_value,\n",
    "        'Significativo': significativo\n",
    "    })\n",
    "\n",
    "# Crear DataFrame con resultados\n",
    "resultados_df = pd.DataFrame(resultados)\n",
    "\n",
    "# Formatear para mejor visualización\n",
    "resultados_df['ECRPS_Sin_Diff'] = resultados_df['ECRPS_Sin_Diff'].round(6)\n",
    "resultados_df['ECRPS_Con_Diff'] = resultados_df['ECRPS_Con_Diff'].round(6)\n",
    "resultados_df['Diferencia'] = resultados_df['Diferencia'].round(6)\n",
    "resultados_df['DM_stat'] = resultados_df['DM_stat'].round(4)\n",
    "resultados_df['HLN-DM_stat'] = resultados_df['HLN-DM_stat'].round(4)\n",
    "resultados_df['p_valor'] = resultados_df['p_valor'].round(4)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"\\n\")\n",
    "print(resultados_df.to_string(index=False))\n",
    "\n",
    "# Resumen de resultados\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"RESUMEN\")\n",
    "print(\"=\"*120)\n",
    "n_significativos = len(resultados_df[resultados_df['Significativo'] != 'No'])\n",
    "n_total = len(resultados_df)\n",
    "print(f\"\\nTotal de métodos comparados: {n_total}\")\n",
    "print(f\"Diferencias significativas: {n_significativos} ({100*n_significativos/n_total:.1f}%)\")\n",
    "print(f\"No significativas: {n_total - n_significativos} ({100*(n_total-n_significativos)/n_total:.1f}%)\")\n",
    "\n",
    "# Mostrar cuáles métodos tienen diferencias significativas\n",
    "if n_significativos > 0:\n",
    "    print(\"\\nMétodos con diferencias significativas:\")\n",
    "    metodos_sig = resultados_df[resultados_df['Significativo'] != 'No'][['Método', 'Significativo', 'p_valor']]\n",
    "    print(metodos_sig.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3b604c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Datos cargados: (23520, 19)\n",
      "✓ Columnas: ['Paso', 'Proceso', 'p', 'd', 'q', 'ARMA_base', 'Distribución', 'Varianza', 'Modalidad', 'Valor_Observado', 'AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', 'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
      "✓ Modelos identificados: ['AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', 'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
      "✓ Valores únicos de d: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(7), np.int64(10)]\n",
      "\n",
      "================================================================================\n",
      "INICIANDO ANÁLISIS MULTI-D COMPLETO\n",
      "================================================================================\n",
      "\n",
      "=== NUEVO 1: Heatmaps ECRPS por Modalidad ===\n",
      "\n",
      "=== NUEVO 2: Sensibilidad al Incremento de d ===\n",
      "\n",
      "=== NUEVO 3: Test Diebold-Mariano ===\n",
      "\n",
      "=== MODIFICADO 1.2: Heatmaps por d ===\n",
      "\n",
      "=== MODIFICADO 3: Heatmaps por Proceso ===\n",
      "\n",
      "=== MODIFICADO 4: Heatmaps por Distribución ===\n",
      "\n",
      "=== MODIFICADO 5: Matrices Varianza ===\n",
      "\n",
      "=== MODIFICADO 9: Excel con d ===\n",
      "\n",
      "=== Heatmap d vs Modelo ===\n",
      "\n",
      "================================================================================\n",
      "✓ ANÁLISIS COMPLETADO\n",
      "✓ Resultados: Resultados_analisis\\Multi_d\n",
      "✓ Gráficos: Resultados_analisis\\Multi_d\\Graficos_Analisis\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Configuración inicial\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "# ====================================================================================\n",
    "# 1. PREPARACIÓN DE DIRECTORIOS\n",
    "# ====================================================================================\n",
    "output_dir = Path(\"./Resultados_analisis/Multi_d\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "plots_dir = output_dir / \"Graficos_Analisis\"\n",
    "plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Cargar datos\n",
    "path_excel = \"./datos/Simulacion/Multi_D/resultados_ARIMA_d1_a_d10_DOBLE_MODALIDAD_COMPLETO.xlsx\"\n",
    "try:\n",
    "    df = pd.read_excel(path_excel)\n",
    "    print(f\"✓ Datos cargados: {df.shape}\")\n",
    "    print(f\"✓ Columnas: {df.columns.tolist()}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error crítico: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Identificar columnas\n",
    "var_cols = ['Paso', 'Proceso', 'p', 'd', 'q', 'ARMA_base', 'Distribución', \n",
    "            'Varianza', 'Modalidad', 'Valor_Observado']\n",
    "model_cols = [col for col in df.columns if col not in var_cols]\n",
    "print(f\"✓ Modelos identificados: {model_cols}\")\n",
    "print(f\"✓ Valores únicos de d: {sorted(df['d'].unique())}\")\n",
    "\n",
    "# ====================================================================================\n",
    "# TEST DE DIEBOLD-MARIANO CON CORRECCIÓN\n",
    "# ====================================================================================\n",
    "def diebold_mariano_test(errors1, errors2, h=1):\n",
    "    \"\"\"Test de Diebold-Mariano con corrección Harvey, Leybourne y Newbold\"\"\"\n",
    "    d = errors1**2 - errors2**2\n",
    "    n = len(d)\n",
    "    d_mean = np.mean(d)\n",
    "    gamma_0 = np.var(d, ddof=1)\n",
    "    dm_stat = d_mean / np.sqrt(gamma_0 / n)\n",
    "    dm_stat_corrected = dm_stat * np.sqrt((n + 1 - 2*h + h*(h-1)/n) / n)\n",
    "    p_value = 2 * (1 - stats.t.cdf(np.abs(dm_stat_corrected), df=n-1))\n",
    "    return dm_stat_corrected, p_value\n",
    "\n",
    "# ====================================================================================\n",
    "# NUEVO 1: HEATMAPS ECRPS POR MODALIDAD\n",
    "# ====================================================================================\n",
    "def plot_heatmaps_ecrps_por_modalidad():\n",
    "    print(\"\\n=== NUEVO 1: Heatmaps ECRPS por Modalidad ===\")\n",
    "    d_values = sorted(df['d'].unique())\n",
    "    \n",
    "    for modalidad in ['SIN_DIFF', 'CON_DIFF']:\n",
    "        matrix_data = []\n",
    "        for model in model_cols:\n",
    "            row = []\n",
    "            for d_val in d_values:\n",
    "                subset = df[(df['d'] == d_val) & (df['Modalidad'] == modalidad)]\n",
    "                avg_ecrps = subset[model].mean()\n",
    "                row.append(avg_ecrps)\n",
    "            matrix_data.append(row)\n",
    "        \n",
    "        df_heatmap = pd.DataFrame(matrix_data, index=model_cols, columns=[f'd={d}' for d in d_values])\n",
    "        \n",
    "        plt.figure(figsize=(14, 10))\n",
    "        annot_matrix = df_heatmap.applymap(lambda x: f'{x:.2e}' if abs(x) >= 1000 else f'{x:.2f}')\n",
    "        sns.heatmap(df_heatmap, annot=annot_matrix, fmt='', cmap='RdYlGn_r', \n",
    "                   cbar_kws={'label': 'ECRPS'}, linewidths=0.5, center=df_heatmap.mean().mean())\n",
    "        plt.title(f'Heatmap ECRPS - Modalidad: {modalidad}', fontweight='bold', fontsize=14)\n",
    "        plt.xlabel('Orden de Diferenciación (d)', fontweight='bold')\n",
    "        plt.ylabel('Modelo', fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(plots_dir / f'NUEVO_1_heatmap_ecrps_{modalidad}.png')\n",
    "        plt.close()\n",
    "        df_heatmap.to_excel(output_dir / f'NUEVO_1_tabla_ecrps_{modalidad}.xlsx')\n",
    "\n",
    "# ====================================================================================\n",
    "# NUEVO 2: SENSIBILIDAD AL INCREMENTO DE d\n",
    "# ====================================================================================\n",
    "def plot_sensibilidad_incremento_d():\n",
    "    print(\"\\n=== NUEVO 2: Sensibilidad al Incremento de d ===\")\n",
    "    d_values = sorted(df['d'].unique())\n",
    "    sensibilidad = []\n",
    "    \n",
    "    for model in model_cols:\n",
    "        cambios = []\n",
    "        for i in range(len(d_values) - 1):\n",
    "            avg_d1 = df[df['d'] == d_values[i]][model].mean()\n",
    "            avg_d2 = df[df['d'] == d_values[i+1]][model].mean()\n",
    "            cambios.append(abs(avg_d2 - avg_d1))\n",
    "        \n",
    "        sensibilidad_modelo = np.mean(cambios)\n",
    "        std_entre_d = np.std([df[df['d'] == d][model].mean() for d in d_values])\n",
    "        sensibilidad.append({'Modelo': model, 'Sensibilidad_Media': sensibilidad_modelo, \n",
    "                           'Std_entre_d': std_entre_d})\n",
    "    \n",
    "    df_sens = pd.DataFrame(sensibilidad).sort_values('Sensibilidad_Media', ascending=False)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    colors = plt.cm.RdYlGn_r(np.linspace(0.3, 0.9, len(df_sens)))\n",
    "    \n",
    "    bars1 = ax1.barh(df_sens['Modelo'], df_sens['Sensibilidad_Media'], color=colors, edgecolor='black')\n",
    "    ax1.bar_label(bars1, fmt='%.3f', padding=5, fontsize=8)\n",
    "    ax1.set_xlabel('Sensibilidad Media', fontweight='bold')\n",
    "    ax1.set_title('Sensibilidad por Cambio Promedio', fontweight='bold')\n",
    "    ax1.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    bars2 = ax2.barh(df_sens['Modelo'], df_sens['Std_entre_d'], color=colors, edgecolor='black')\n",
    "    ax2.bar_label(bars2, fmt='%.3f', padding=5, fontsize=8)\n",
    "    ax2.set_xlabel('Desviación Estándar', fontweight='bold')\n",
    "    ax2.set_title('Sensibilidad por Variabilidad', fontweight='bold')\n",
    "    ax2.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plots_dir / 'NUEVO_2_sensibilidad_incremento_d.png')\n",
    "    plt.close()\n",
    "    df_sens.to_excel(output_dir / 'NUEVO_2_tabla_sensibilidad.xlsx', index=False)\n",
    "    \n",
    "    # Trayectorias\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    for model in model_cols:\n",
    "        trayectoria = [df[df['d'] == d][model].mean() for d in d_values]\n",
    "        plt.plot(d_values, trayectoria, marker='o', label=model, linewidth=2, alpha=0.7)\n",
    "    plt.xlabel('Orden de Diferenciación (d)', fontweight='bold', fontsize=12)\n",
    "    plt.ylabel('ECRPS Promedio', fontweight='bold', fontsize=12)\n",
    "    plt.title('Trayectorias de ECRPS según d', fontweight='bold', fontsize=14)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plots_dir / 'NUEVO_2_trayectorias_d.png')\n",
    "    plt.close()\n",
    "\n",
    "# ====================================================================================\n",
    "# NUEVO 3: TEST DIEBOLD-MARIANO\n",
    "# ====================================================================================\n",
    "def plot_heatmap_diebold_mariano():\n",
    "    print(\"\\n=== NUEVO 3: Test Diebold-Mariano ===\")\n",
    "    d_values = sorted(df['d'].unique())\n",
    "    results = []\n",
    "    \n",
    "    for model in model_cols:\n",
    "        for d_val in d_values:\n",
    "            sin_diff = df[(df['d'] == d_val) & (df['Modalidad'] == 'SIN_DIFF')][model].values\n",
    "            con_diff = df[(df['d'] == d_val) & (df['Modalidad'] == 'CON_DIFF')][model].values\n",
    "            \n",
    "            if len(sin_diff) > 5 and len(con_diff) > 5:\n",
    "                dm_stat, p_value = diebold_mariano_test(sin_diff, con_diff)\n",
    "                results.append({'Modelo': model, 'd': d_val, 'DM_stat': dm_stat, \n",
    "                              'p_valor': p_value, 'Significativo': 'Sí' if p_value < 0.05 else 'No'})\n",
    "    \n",
    "    df_dm = pd.DataFrame(results)\n",
    "    pivot_pvalor = df_dm.pivot(index='Modelo', columns='d', values='p_valor')\n",
    "    pivot_dm_stat = df_dm.pivot(index='Modelo', columns='d', values='DM_stat')\n",
    "    \n",
    "    # Heatmap p-valores\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    sns.heatmap(pivot_pvalor, annot=True, fmt='.3f', cmap='RdYlGn', \n",
    "               cbar_kws={'label': 'p-valor'}, linewidths=0.5, vmin=0, vmax=0.1, center=0.05)\n",
    "    plt.title('Test DM: P-valores (SIN_DIFF vs CON_DIFF)', fontweight='bold', fontsize=14)\n",
    "    plt.xlabel('Orden de Diferenciación (d)', fontweight='bold')\n",
    "    plt.ylabel('Modelo', fontweight='bold')\n",
    "    plt.figtext(0.5, -0.02, 'Valores < 0.05: diferencias significativas', \n",
    "               ha='center', fontsize=10, style='italic')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plots_dir / 'NUEVO_3_heatmap_dm_pvalor.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Heatmap estadísticos\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    sns.heatmap(pivot_dm_stat, annot=True, fmt='.2f', cmap='RdBu_r', \n",
    "               cbar_kws={'label': 'Estadístico DM'}, linewidths=0.5, center=0)\n",
    "    plt.title('Test DM: Estadísticos', fontweight='bold', fontsize=14)\n",
    "    plt.xlabel('Orden de Diferenciación (d)', fontweight='bold')\n",
    "    plt.ylabel('Modelo', fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plots_dir / 'NUEVO_3_heatmap_dm_stat.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    df_dm.to_excel(output_dir / 'NUEVO_3_tabla_diebold_mariano.xlsx', index=False)\n",
    "    pivot_pvalor.to_excel(output_dir / 'NUEVO_3_matriz_pvalores.xlsx')\n",
    "\n",
    "# ====================================================================================\n",
    "# MODIFICADO 1.2: HEATMAPS POR d\n",
    "# ====================================================================================\n",
    "def plot_heatmaps_mejora_por_d():\n",
    "    print(\"\\n=== MODIFICADO 1.2: Heatmaps por d ===\")\n",
    "    d_values = sorted(df['d'].unique())\n",
    "    \n",
    "    for d_val in d_values:\n",
    "        subset_d = df[df['d'] == d_val]\n",
    "        mejoras = []\n",
    "        for model in model_cols:\n",
    "            sin = subset_d[subset_d['Modalidad'] == 'SIN_DIFF'][model].mean()\n",
    "            con = subset_d[subset_d['Modalidad'] == 'CON_DIFF'][model].mean()\n",
    "            mejora_pct = ((sin - con) / sin) * 100 if sin != 0 else 0\n",
    "            mejoras.append(mejora_pct)\n",
    "        \n",
    "        df_mejora = pd.DataFrame([mejoras], columns=model_cols, index=[f'd={d_val}'])\n",
    "        \n",
    "        plt.figure(figsize=(16, 3))\n",
    "        sns.heatmap(df_mejora, annot=True, fmt='.2f', cmap='RdYlGn', center=0,\n",
    "                   cbar_kws={'label': 'Mejora (%)'}, linewidths=1)\n",
    "        plt.title(f'Mejora (CON_DIFF vs SIN_DIFF) - d={d_val}', fontweight='bold')\n",
    "        plt.xlabel('Modelo', fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(plots_dir / f'MOD_1.2_mejora_d{d_val}.png')\n",
    "        plt.close()\n",
    "\n",
    "# ====================================================================================\n",
    "# MODIFICADO 3: HEATMAPS POR PROCESO\n",
    "# ====================================================================================\n",
    "def plot_heatmaps_mejora_por_proceso():\n",
    "    print(\"\\n=== MODIFICADO 3: Heatmaps por Proceso ===\")\n",
    "    d_values = sorted(df['d'].unique())\n",
    "    \n",
    "    for model in model_cols:\n",
    "        mejoras_proceso = []\n",
    "        procesos = sorted(df['Proceso'].unique())\n",
    "        \n",
    "        for proceso in procesos:\n",
    "            mejoras_d = []\n",
    "            for d_val in d_values:\n",
    "                subset = df[(df['d'] == d_val) & (df['Proceso'] == proceso)]\n",
    "                sin = subset[subset['Modalidad'] == 'SIN_DIFF'][model].mean()\n",
    "                con = subset[subset['Modalidad'] == 'CON_DIFF'][model].mean()\n",
    "                mejora_pct = ((sin - con) / sin) * 100 if sin != 0 else 0\n",
    "                mejoras_d.append(mejora_pct)\n",
    "            mejoras_proceso.append(mejoras_d)\n",
    "        \n",
    "        df_mejora = pd.DataFrame(mejoras_proceso, index=procesos, \n",
    "                                columns=[f'd={d}' for d in d_values])\n",
    "        \n",
    "        plt.figure(figsize=(14, max(8, len(procesos) * 0.5)))\n",
    "        sns.heatmap(df_mejora, annot=True, fmt='.1f', cmap='RdYlGn', center=0,\n",
    "                   cbar_kws={'label': 'Mejora (%)'}, linewidths=0.5)\n",
    "        plt.title(f'Mejora por Proceso - {model}', fontweight='bold')\n",
    "        plt.xlabel('Orden de Diferenciación (d)', fontweight='bold')\n",
    "        plt.ylabel('Proceso ARMA', fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        safe_name = model.replace(' ', '_').replace('/', '_')\n",
    "        plt.savefig(plots_dir / f'MOD_3_proceso_{safe_name}.png')\n",
    "        plt.close()\n",
    "        df_mejora.to_excel(output_dir / f'MOD_3_proceso_{safe_name}.xlsx')\n",
    "\n",
    "# ====================================================================================\n",
    "# MODIFICADO 4: HEATMAPS POR DISTRIBUCIÓN\n",
    "# ====================================================================================\n",
    "def plot_heatmaps_mejora_por_distribucion():\n",
    "    print(\"\\n=== MODIFICADO 4: Heatmaps por Distribución ===\")\n",
    "    d_values = sorted(df['d'].unique())\n",
    "    \n",
    "    for model in model_cols:\n",
    "        mejoras_dist = []\n",
    "        distribuciones = sorted(df['Distribución'].unique())\n",
    "        \n",
    "        for dist in distribuciones:\n",
    "            mejoras_d = []\n",
    "            for d_val in d_values:\n",
    "                subset = df[(df['d'] == d_val) & (df['Distribución'] == dist)]\n",
    "                sin = subset[subset['Modalidad'] == 'SIN_DIFF'][model].mean()\n",
    "                con = subset[subset['Modalidad'] == 'CON_DIFF'][model].mean()\n",
    "                mejora_pct = ((sin - con) / sin) * 100 if sin != 0 else 0\n",
    "                mejoras_d.append(mejora_pct)\n",
    "            mejoras_dist.append(mejoras_d)\n",
    "        \n",
    "        df_mejora = pd.DataFrame(mejoras_dist, index=distribuciones, \n",
    "                                columns=[f'd={d}' for d in d_values])\n",
    "        \n",
    "        plt.figure(figsize=(14, max(6, len(distribuciones) * 1.5)))\n",
    "        sns.heatmap(df_mejora, annot=True, fmt='.1f', cmap='RdYlGn', center=0,\n",
    "                   cbar_kws={'label': 'Mejora (%)'}, linewidths=0.5)\n",
    "        plt.title(f'Mejora por Distribución - {model}', fontweight='bold')\n",
    "        plt.xlabel('d', fontweight='bold')\n",
    "        plt.ylabel('Distribución', fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        safe_name = model.replace(' ', '_').replace('/', '_')\n",
    "        plt.savefig(plots_dir / f'MOD_4_dist_{safe_name}.png')\n",
    "        plt.close()\n",
    "        df_mejora.to_excel(output_dir / f'MOD_4_dist_{safe_name}.xlsx')\n",
    "\n",
    "# ====================================================================================\n",
    "# MODIFICADO 5: MATRICES VARIANZA\n",
    "# ====================================================================================\n",
    "def plot_matrices_mejora_por_varianza():\n",
    "    print(\"\\n=== MODIFICADO 5: Matrices Varianza ===\")\n",
    "    d_values = sorted(df['d'].unique())\n",
    "    varianzas = sorted(df['Varianza'].unique())\n",
    "    \n",
    "    for model in model_cols:\n",
    "        mejoras_var = []\n",
    "        for d_val in d_values:\n",
    "            mejoras_por_var = []\n",
    "            for var in varianzas:\n",
    "                subset = df[(df['d'] == d_val) & (df['Varianza'] == var)]\n",
    "                sin = subset[subset['Modalidad'] == 'SIN_DIFF'][model].mean()\n",
    "                con = subset[subset['Modalidad'] == 'CON_DIFF'][model].mean()\n",
    "                mejora_pct = ((sin - con) / sin) * 100 if sin != 0 else 0\n",
    "                mejoras_por_var.append(mejora_pct)\n",
    "            mejoras_var.append(mejoras_por_var)\n",
    "        \n",
    "        df_mejora = pd.DataFrame(mejoras_var, index=[f'd={d}' for d in d_values], \n",
    "                                columns=[f'Var={v}' for v in varianzas])\n",
    "        \n",
    "        plt.figure(figsize=(max(10, len(varianzas) * 2), 10))\n",
    "        sns.heatmap(df_mejora, annot=True, fmt='.1f', cmap='RdYlGn', center=0,\n",
    "                   cbar_kws={'label': 'Mejora (%)'}, linewidths=0.5)\n",
    "        plt.title(f'Mejora por Varianza - {model}', fontweight='bold')\n",
    "        plt.xlabel('Varianza', fontweight='bold')\n",
    "        plt.ylabel('d', fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        safe_name = model.replace(' ', '_').replace('/', '_')\n",
    "        plt.savefig(plots_dir / f'MOD_5_var_{safe_name}.png')\n",
    "        plt.close()\n",
    "        df_mejora.to_excel(output_dir / f'MOD_5_var_{safe_name}.xlsx')\n",
    "\n",
    "# ====================================================================================\n",
    "# MODIFICADO 9: EXCEL DETALLADO CON d\n",
    "# ====================================================================================\n",
    "def generate_detailed_excel_with_d():\n",
    "    print(\"\\n=== MODIFICADO 9: Excel con d ===\")\n",
    "    file_path = output_dir / \"MOD_9_Detallado_Con_d.xlsx\"\n",
    "    \n",
    "    with pd.ExcelWriter(file_path, engine='xlsxwriter') as writer:\n",
    "        for model in model_cols:\n",
    "            temp = df.groupby(['d', 'Proceso', 'ARMA_base', 'Distribución', \n",
    "                              'Varianza', 'Modalidad'])[model].mean().reset_index()\n",
    "            \n",
    "            detailed = temp.pivot_table(\n",
    "                index=['d', 'Proceso', 'ARMA_base', 'Distribución', 'Varianza'],\n",
    "                columns='Modalidad', values=model).reset_index()\n",
    "            \n",
    "            detailed.columns.name = None\n",
    "            detailed = detailed.rename(columns={'SIN_DIFF': 'ECRPS_Sin_Dif', \n",
    "                                               'CON_DIFF': 'ECRPS_Con_Dif'})\n",
    "            \n",
    "            detailed['Mejora_Absoluta'] = detailed['ECRPS_Sin_Dif'] - detailed['ECRPS_Con_Dif']\n",
    "            detailed['Mejora_%'] = (detailed['Mejora_Absoluta'] / detailed['ECRPS_Sin_Dif']) * 100\n",
    "            detailed = detailed.sort_values(by=['d', 'Mejora_%'], ascending=[True, False])\n",
    "            \n",
    "            sheet_name = model.replace(' ', '_').replace('/', '_')[:31]\n",
    "            detailed.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "            \n",
    "            workbook = writer.book\n",
    "            worksheet = writer.sheets[sheet_name]\n",
    "            fmt_green = workbook.add_format({'bg_color': '#C6EFCE', 'font_color': '#006100'})\n",
    "            fmt_red = workbook.add_format({'bg_color': '#FFC7CE', 'font_color': '#9C0006'})\n",
    "            \n",
    "            col_idx = detailed.columns.get_loc('Mejora_%')\n",
    "            worksheet.conditional_format(1, col_idx, len(detailed), col_idx, \n",
    "                                       {'type': 'cell', 'criteria': '>', 'value': 0, 'format': fmt_green})\n",
    "            worksheet.conditional_format(1, col_idx, len(detailed), col_idx,\n",
    "                                       {'type': 'cell', 'criteria': '<', 'value': 0, 'format': fmt_red})\n",
    "\n",
    "# ====================================================================================\n",
    "# FUNCIONES ORIGINALES\n",
    "# ====================================================================================\n",
    "def plot_heatmap_d_vs_modelo():\n",
    "    print(\"\\n=== Heatmap d vs Modelo ===\")\n",
    "    results = []\n",
    "    d_values = sorted(df['d'].unique())\n",
    "    \n",
    "    for d_val in d_values:\n",
    "        subset_d = df[df['d'] == d_val]\n",
    "        for model in model_cols:\n",
    "            sin = subset_d[subset_d['Modalidad'] == 'SIN_DIFF'][model].mean()\n",
    "            con = subset_d[subset_d['Modalidad'] == 'CON_DIFF'][model].mean()\n",
    "            mejora = ((sin - con) / sin) * 100 if sin != 0 else 0\n",
    "            results.append({'d': d_val, 'Modelo': model, 'Mejora_%': mejora})\n",
    "    \n",
    "    df_mejora = pd.DataFrame(results)\n",
    "    pivot = df_mejora.pivot(index='Modelo', columns='d', values='Mejora_%')\n",
    "    \n",
    "    plt.figure(figsize=(14, 10))\n",
    "    sns.heatmap(pivot, annot=True, fmt=\".1f\", cmap=\"RdYlGn\", center=0, \n",
    "                cbar_kws={'label': 'Mejora (%)'}, linewidths=0.5)\n",
    "    plt.title(\"Mejora: Modelo vs d\", fontweight='bold', fontsize=14)\n",
    "    plt.xlabel(\"Valor de d\", fontweight='bold')\n",
    "    plt.ylabel(\"Modelo\", fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plots_dir / '2_heatmap_d_vs_modelo.png')\n",
    "    plt.close()\n",
    "    pivot.to_excel(output_dir / '2_tabla_d_vs_modelo.xlsx')\n",
    "\n",
    "# ====================================================================================\n",
    "# EJECUCIÓN PRINCIPAL\n",
    "# ====================================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"INICIANDO ANÁLISIS MULTI-D COMPLETO\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Nuevas funciones\n",
    "    plot_heatmaps_ecrps_por_modalidad()\n",
    "    plot_sensibilidad_incremento_d()\n",
    "    plot_heatmap_diebold_mariano()\n",
    "    \n",
    "    # Modificadas\n",
    "    plot_heatmaps_mejora_por_d()\n",
    "    plot_heatmaps_mejora_por_proceso()\n",
    "    plot_heatmaps_mejora_por_distribucion()\n",
    "    plot_matrices_mejora_por_varianza()\n",
    "    generate_detailed_excel_with_d()\n",
    "    \n",
    "    # Originales\n",
    "    plot_heatmap_d_vs_modelo()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"✓ ANÁLISIS COMPLETADO\")\n",
    "    print(f\"✓ Resultados: {output_dir}\")\n",
    "    print(f\"✓ Gráficos: {plots_dir}\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b8a52b",
   "metadata": {},
   "source": [
    "## Analisis cambio de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0169f259",
   "metadata": {},
   "source": [
    "### Pre-procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfd6fb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TABLA COMPARATIVA DE MODELOS POR ESCENARIO\n",
      "(Promedio de amplitud de intervalos de predicción)\n",
      "================================================================================\n",
      "             Modelo   ARMA   ARIMA  SETAR Mejor_Escenario\n",
      "              AREPD 0.9345 13.0489 0.6971           SETAR\n",
      "            AV-MCPS 0.6768  3.5050 0.6531           SETAR\n",
      "Block Bootstrapping 0.9049 15.1183 0.6318           SETAR\n",
      "             DeepAR 0.5650  3.6998 0.5845            ARMA\n",
      "         EnCQR-LSTM 0.9515  5.9330 0.8404           SETAR\n",
      "               LSPM 0.7689  1.0868 0.6586           SETAR\n",
      "              LSPMW 0.7931  1.0870 0.6754           SETAR\n",
      "               MCPS 0.6496  3.2780 0.6325           SETAR\n",
      "    Sieve Bootstrap 0.5541  0.5583 0.6254            ARMA\n",
      "================================================================================\n",
      "\n",
      "Tabla comparativa guardada en 'Tabla_Comparativa_Modelos_tamaño.xlsx'\n",
      "\n",
      "Archivo 'Base_Tamaño_3_escenarios.xlsx' creado exitosamente!\n",
      "\n",
      "Total de filas: 126000\n",
      "- ARMA: 42000 filas\n",
      "- ARIMA: 42000 filas\n",
      "- SETAR: 42000 filas\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Leer los tres archivos\n",
    "arma_df = pd.read_excel(\"./datos/Simulacion/Tamaño/resultados_TAMANOS_CRECIENTES_ARMA.xlsx\")\n",
    "arima_df = pd.read_excel(\"./datos/Simulacion/Tamaño/resultados_TAMANOS_CRECIENTES_ARIMA.xlsx\")\n",
    "setar_df = pd.read_excel(\"./datos/Simulacion/Tamaño/resultados_TAMANOS_CRECIENTES_SETAR.xlsx\")\n",
    "\n",
    "\n",
    "arma_df['ESCENARIO'] = \"Lineal Estacionario\"\n",
    "arima_df['ESCENARIO'] = \"Lineal No estacionario\"\n",
    "setar_df['ESCENARIO'] = \"No lineal Estacionario\"\n",
    "\n",
    "# Filtrar los que no tienen \"Promedio\" en la columna \"Paso\"\n",
    "arma_df = arma_df[arma_df['Paso'] != 'Promedio']\n",
    "arima_df = arima_df[arima_df['Paso'] != 'Promedio']\n",
    "setar_df = setar_df[setar_df['Paso'] != 'Promedio']\n",
    "\n",
    "# Lista de modelos (columnas a promediar)\n",
    "modelos = ['AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR',\n",
    "           'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
    "\n",
    "# Crear tabla comparativa\n",
    "comparacion = []\n",
    "\n",
    "for modelo in modelos:\n",
    "    fila = {'Modelo': modelo}\n",
    "    \n",
    "    # Calcular promedio para cada escenario (de la columna del modelo)\n",
    "    arma_promedio = arma_df[modelo].mean() if modelo in arma_df.columns else np.nan\n",
    "    arima_promedio = arima_df[modelo].mean() if modelo in arima_df.columns else np.nan\n",
    "    setar_promedio = setar_df[modelo].mean() if modelo in setar_df.columns else np.nan\n",
    "    \n",
    "    fila['ARMA'] = arma_promedio\n",
    "    fila['ARIMA'] = arima_promedio\n",
    "    fila['SETAR'] = setar_promedio\n",
    "    \n",
    "    # Determinar mejor escenario (menor promedio)\n",
    "    promedios = {\n",
    "        'ARMA': arma_promedio,\n",
    "        'ARIMA': arima_promedio,\n",
    "        'SETAR': setar_promedio\n",
    "    }\n",
    "    \n",
    "    # Filtrar NaN si existen\n",
    "    promedios_validos = {k: v for k, v in promedios.items() if not pd.isna(v)}\n",
    "    \n",
    "    if promedios_validos:\n",
    "        mejor_escenario = min(promedios_validos, key=promedios_validos.get)\n",
    "        fila['Mejor_Escenario'] = mejor_escenario\n",
    "    else:\n",
    "        fila['Mejor_Escenario'] = 'N/A'\n",
    "    \n",
    "    comparacion.append(fila)\n",
    "\n",
    "# Crear DataFrame con la tabla comparativa\n",
    "tabla_comparativa = pd.DataFrame(comparacion)\n",
    "\n",
    "# Redondear valores para mejor visualización\n",
    "columnas_numericas = ['ARMA', 'ARIMA', 'SETAR']\n",
    "tabla_comparativa[columnas_numericas] = tabla_comparativa[columnas_numericas].round(4)\n",
    "\n",
    "# Mostrar tabla comparativa\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TABLA COMPARATIVA DE MODELOS POR ESCENARIO\")\n",
    "print(\"(Promedio de amplitud de intervalos de predicción)\")\n",
    "print(\"=\"*80)\n",
    "print(tabla_comparativa.to_string(index=False))\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "\n",
    "# Procesamiento especial para SETAR\n",
    "if 'Descripción' in setar_df.columns:\n",
    "    setar_df = setar_df.drop('Descripción', axis=1)\n",
    "\n",
    "# Concatenar los tres dataframes\n",
    "base_consolidada = pd.concat([arma_df, arima_df, setar_df], ignore_index=True)\n",
    "\n",
    "# Guardar en un archivo Excel\n",
    "base_consolidada.to_excel(\"./datos/Simulacion/Tamaño/Base_Tamaño_3_escenarios.xlsx\", index=False)\n",
    "\n",
    "print(\"\\nArchivo 'Base_Tamaño_3_escenarios.xlsx' creado exitosamente!\")\n",
    "print(f\"\\nTotal de filas: {len(base_consolidada)}\")\n",
    "print(f\"- ARMA: {len(arma_df)} filas\")\n",
    "print(f\"- ARIMA: {len(arima_df)} filas\")\n",
    "print(f\"- SETAR: {len(setar_df)} filas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6a6937",
   "metadata": {},
   "source": [
    "### Analisis general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "518faae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Columnas cargadas: ['Paso', 'Proceso', 'Tipo_Proceso', 'Distribución', 'Varianza', 'N_Train', 'N_Calib', 'N_Total', 'Valor_Observado', 'AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', 'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap', 'ESCENARIO']\n",
      "================================================================================\n",
      "ANÁLISIS DE IMPACTO DE TAMAÑO DE MUESTRA (N_Train, N_Calib)\n",
      "================================================================================\n",
      "\n",
      "Modelos identificados: 9\n",
      "N_Train únicos: [np.int64(100), np.int64(200), np.int64(300), np.int64(500), np.int64(1000)]\n",
      "N_Calib únicos: [np.int64(20), np.int64(40), np.int64(60), np.int64(100), np.int64(200)]\n",
      "Escenarios: ['Lineal Estacionario (ARMA)' 'Lineal No Estacionario (ARIMA)'\n",
      " 'No lineal Estacionario (SETAR)']\n",
      "\n",
      "================================================================================\n",
      "CREANDO ESTRUCTURA DE CARPETAS POR N_TRAIN\n",
      "================================================================================\n",
      "✓ Carpeta creada: N_Train_100\n",
      "✓ Carpeta creada: N_Train_200\n",
      "✓ Carpeta creada: N_Train_300\n",
      "✓ Carpeta creada: N_Train_500\n",
      "✓ Carpeta creada: N_Train_1000\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 1: ANÁLISIS POR N_TRAIN (GRÁFICAS INDIVIDUALES)\n",
      "================================================================================\n",
      "\n",
      "Procesando N_Train = 100\n",
      "✓ Gráficas de barras guardadas: N_Train=100, General\n",
      "✓ Heatmap guardado: N_Train=100, General\n",
      "✓ Mejor N_Calib guardado: N_Train=100, General\n",
      "✓ Gráficas de barras guardadas: N_Train=100, Lineal_Estacionario_ARMA\n",
      "✓ Heatmap guardado: N_Train=100, Lineal_Estacionario_ARMA\n",
      "✓ Mejor N_Calib guardado: N_Train=100, Lineal_Estacionario_ARMA\n",
      "✓ Gráficas de barras guardadas: N_Train=100, Lineal_No_Estacionario_ARIMA\n",
      "✓ Heatmap guardado: N_Train=100, Lineal_No_Estacionario_ARIMA\n",
      "✓ Mejor N_Calib guardado: N_Train=100, Lineal_No_Estacionario_ARIMA\n",
      "✓ Gráficas de barras guardadas: N_Train=100, No_lineal_Estacionario_SETAR\n",
      "✓ Heatmap guardado: N_Train=100, No_lineal_Estacionario_SETAR\n",
      "✓ Mejor N_Calib guardado: N_Train=100, No_lineal_Estacionario_SETAR\n",
      "\n",
      "Procesando N_Train = 200\n",
      "✓ Gráficas de barras guardadas: N_Train=200, General\n",
      "✓ Heatmap guardado: N_Train=200, General\n",
      "✓ Mejor N_Calib guardado: N_Train=200, General\n",
      "✓ Gráficas de barras guardadas: N_Train=200, Lineal_Estacionario_ARMA\n",
      "✓ Heatmap guardado: N_Train=200, Lineal_Estacionario_ARMA\n",
      "✓ Mejor N_Calib guardado: N_Train=200, Lineal_Estacionario_ARMA\n",
      "✓ Gráficas de barras guardadas: N_Train=200, Lineal_No_Estacionario_ARIMA\n",
      "✓ Heatmap guardado: N_Train=200, Lineal_No_Estacionario_ARIMA\n",
      "✓ Mejor N_Calib guardado: N_Train=200, Lineal_No_Estacionario_ARIMA\n",
      "✓ Gráficas de barras guardadas: N_Train=200, No_lineal_Estacionario_SETAR\n",
      "✓ Heatmap guardado: N_Train=200, No_lineal_Estacionario_SETAR\n",
      "✓ Mejor N_Calib guardado: N_Train=200, No_lineal_Estacionario_SETAR\n",
      "\n",
      "Procesando N_Train = 300\n",
      "✓ Gráficas de barras guardadas: N_Train=300, General\n",
      "✓ Heatmap guardado: N_Train=300, General\n",
      "✓ Mejor N_Calib guardado: N_Train=300, General\n",
      "✓ Gráficas de barras guardadas: N_Train=300, Lineal_Estacionario_ARMA\n",
      "✓ Heatmap guardado: N_Train=300, Lineal_Estacionario_ARMA\n",
      "✓ Mejor N_Calib guardado: N_Train=300, Lineal_Estacionario_ARMA\n",
      "✓ Gráficas de barras guardadas: N_Train=300, Lineal_No_Estacionario_ARIMA\n",
      "✓ Heatmap guardado: N_Train=300, Lineal_No_Estacionario_ARIMA\n",
      "✓ Mejor N_Calib guardado: N_Train=300, Lineal_No_Estacionario_ARIMA\n",
      "✓ Gráficas de barras guardadas: N_Train=300, No_lineal_Estacionario_SETAR\n",
      "✓ Heatmap guardado: N_Train=300, No_lineal_Estacionario_SETAR\n",
      "✓ Mejor N_Calib guardado: N_Train=300, No_lineal_Estacionario_SETAR\n",
      "\n",
      "Procesando N_Train = 500\n",
      "✓ Gráficas de barras guardadas: N_Train=500, General\n",
      "✓ Heatmap guardado: N_Train=500, General\n",
      "✓ Mejor N_Calib guardado: N_Train=500, General\n",
      "✓ Gráficas de barras guardadas: N_Train=500, Lineal_Estacionario_ARMA\n",
      "✓ Heatmap guardado: N_Train=500, Lineal_Estacionario_ARMA\n",
      "✓ Mejor N_Calib guardado: N_Train=500, Lineal_Estacionario_ARMA\n",
      "✓ Gráficas de barras guardadas: N_Train=500, Lineal_No_Estacionario_ARIMA\n",
      "✓ Heatmap guardado: N_Train=500, Lineal_No_Estacionario_ARIMA\n",
      "✓ Mejor N_Calib guardado: N_Train=500, Lineal_No_Estacionario_ARIMA\n",
      "✓ Gráficas de barras guardadas: N_Train=500, No_lineal_Estacionario_SETAR\n",
      "✓ Heatmap guardado: N_Train=500, No_lineal_Estacionario_SETAR\n",
      "✓ Mejor N_Calib guardado: N_Train=500, No_lineal_Estacionario_SETAR\n",
      "\n",
      "Procesando N_Train = 1000\n",
      "✓ Gráficas de barras guardadas: N_Train=1000, General\n",
      "✓ Heatmap guardado: N_Train=1000, General\n",
      "✓ Mejor N_Calib guardado: N_Train=1000, General\n",
      "✓ Gráficas de barras guardadas: N_Train=1000, Lineal_Estacionario_ARMA\n",
      "✓ Heatmap guardado: N_Train=1000, Lineal_Estacionario_ARMA\n",
      "✓ Mejor N_Calib guardado: N_Train=1000, Lineal_Estacionario_ARMA\n",
      "✓ Gráficas de barras guardadas: N_Train=1000, Lineal_No_Estacionario_ARIMA\n",
      "✓ Heatmap guardado: N_Train=1000, Lineal_No_Estacionario_ARIMA\n",
      "✓ Mejor N_Calib guardado: N_Train=1000, Lineal_No_Estacionario_ARIMA\n",
      "✓ Gráficas de barras guardadas: N_Train=1000, No_lineal_Estacionario_SETAR\n",
      "✓ Heatmap guardado: N_Train=1000, No_lineal_Estacionario_SETAR\n",
      "✓ Mejor N_Calib guardado: N_Train=1000, No_lineal_Estacionario_SETAR\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 2: TESTS DE DIEBOLD-MARIANO (MÁS APROPIADO PARA SERIES TEMPORALES)\n",
      "================================================================================\n",
      "\n",
      "Tests DM para N_Train = 100\n",
      "✓ Test DM guardado: N_Train=100, General\n",
      "✓ Test DM guardado: N_Train=100, Lineal_Estacionario_ARMA\n",
      "✓ Test DM guardado: N_Train=100, Lineal_No_Estacionario_ARIMA\n",
      "✓ Test DM guardado: N_Train=100, No_lineal_Estacionario_SETAR\n",
      "\n",
      "Tests DM para N_Train = 200\n",
      "✓ Test DM guardado: N_Train=200, General\n",
      "✓ Test DM guardado: N_Train=200, Lineal_Estacionario_ARMA\n",
      "✓ Test DM guardado: N_Train=200, Lineal_No_Estacionario_ARIMA\n",
      "✓ Test DM guardado: N_Train=200, No_lineal_Estacionario_SETAR\n",
      "\n",
      "Tests DM para N_Train = 300\n",
      "✓ Test DM guardado: N_Train=300, General\n",
      "✓ Test DM guardado: N_Train=300, Lineal_Estacionario_ARMA\n",
      "✓ Test DM guardado: N_Train=300, Lineal_No_Estacionario_ARIMA\n",
      "✓ Test DM guardado: N_Train=300, No_lineal_Estacionario_SETAR\n",
      "\n",
      "Tests DM para N_Train = 500\n",
      "✓ Test DM guardado: N_Train=500, General\n",
      "✓ Test DM guardado: N_Train=500, Lineal_Estacionario_ARMA\n",
      "✓ Test DM guardado: N_Train=500, Lineal_No_Estacionario_ARIMA\n",
      "✓ Test DM guardado: N_Train=500, No_lineal_Estacionario_SETAR\n",
      "\n",
      "Tests DM para N_Train = 1000\n",
      "✓ Test DM guardado: N_Train=1000, General\n",
      "✓ Test DM guardado: N_Train=1000, Lineal_Estacionario_ARMA\n",
      "✓ Test DM guardado: N_Train=1000, Lineal_No_Estacionario_ARIMA\n",
      "✓ Test DM guardado: N_Train=1000, No_lineal_Estacionario_SETAR\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 3: ANÁLISIS DE INTERACCIONES\n",
      "================================================================================\n",
      "\n",
      "Interacciones para N_Train = 100\n",
      "\n",
      "Interacciones para N_Train = 200\n",
      "\n",
      "Interacciones para N_Train = 300\n",
      "\n",
      "Interacciones para N_Train = 500\n",
      "\n",
      "Interacciones para N_Train = 1000\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 4: COMPARACIONES ENTRE DIFERENTES N_TRAIN\n",
      "================================================================================\n",
      "✓ Comparaciones entre N_Train guardadas\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración general\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Crear carpeta de resultados\n",
    "output_dir = Path(\"./Resultados_analisis/Tamaño\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_excel(\"./datos/Simulacion/Tamaño/Base_Tamaño_3_escenarios.xlsx\")\n",
    "\n",
    "print(f\"✓ Columnas cargadas: {df.columns.tolist()}\")\n",
    "\n",
    "# Renombrar escenarios\n",
    "df['ESCENARIO'] = df['ESCENARIO'].replace({\n",
    "    \"Lineal Estacionario\": \"Lineal Estacionario (ARMA)\",\n",
    "    \"Lineal No estacionario\": \"Lineal No Estacionario (ARIMA)\",\n",
    "    \"No lineal Estacionario\": \"No lineal Estacionario (SETAR)\"\n",
    "})\n",
    "\n",
    "# Identificar columnas\n",
    "var_cols = ['Paso', 'Proceso', 'Tipo_Proceso', 'Distribución', 'Varianza', \n",
    "            'N_Train', 'N_Calib', 'N_Total', 'Valor_Observado', 'ESCENARIO']\n",
    "model_cols = [col for col in df.columns if col not in var_cols]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ANÁLISIS DE IMPACTO DE TAMAÑO DE MUESTRA (N_Train, N_Calib)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nModelos identificados: {len(model_cols)}\")\n",
    "print(f\"N_Train únicos: {sorted(df['N_Train'].unique())}\")\n",
    "print(f\"N_Calib únicos: {sorted(df['N_Calib'].unique())}\")\n",
    "print(f\"Escenarios: {df['ESCENARIO'].unique()}\")\n",
    "\n",
    "# Crear columna combinada\n",
    "df['Config_Tamaño'] = df['N_Train'].astype(str) + '-' + df['N_Calib'].astype(str)\n",
    "\n",
    "# ====================================================================================\n",
    "# CREAR ESTRUCTURA DE CARPETAS POR N_TRAIN\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CREANDO ESTRUCTURA DE CARPETAS POR N_TRAIN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Obtener valores únicos de N_Train\n",
    "n_train_values = sorted(df['N_Train'].unique())\n",
    "\n",
    "# Crear carpetas por N_Train\n",
    "train_dirs = {}\n",
    "for n_train in n_train_values:\n",
    "    train_dir = output_dir / f\"N_Train_{n_train}\"\n",
    "    train_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Subcarpetas\n",
    "    (train_dir / \"Comparaciones\").mkdir(exist_ok=True)\n",
    "    (train_dir / \"Interacciones\").mkdir(exist_ok=True)\n",
    "    (train_dir / \"Rankings\").mkdir(exist_ok=True)\n",
    "    (train_dir / \"Tests_Estadisticos\").mkdir(exist_ok=True)\n",
    "    \n",
    "    train_dirs[n_train] = train_dir\n",
    "    print(f\"✓ Carpeta creada: N_Train_{n_train}\")\n",
    "\n",
    "# Carpeta para comparaciones entre N_Train\n",
    "comparacion_dir = output_dir / \"Comparaciones_Entre_N_Train\"\n",
    "comparacion_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# ====================================================================================\n",
    "# FUNCIÓN AUXILIAR: Test Diebold-Mariano Modificado\n",
    "# ====================================================================================\n",
    "\n",
    "def modified_diebold_mariano_test(errors1, errors2, h=1):\n",
    "    \"\"\"\n",
    "    Test Diebold-Mariano modificado con corrección Harvey-Leybourne-Newbold\n",
    "    Más apropiado para series temporales que ANOVA\n",
    "    \"\"\"\n",
    "    d = errors1 - errors2\n",
    "    d_bar = np.mean(d)\n",
    "    T = len(d)\n",
    "    \n",
    "    def gamma_d(k):\n",
    "        if k == 0:\n",
    "            return np.var(d, ddof=1)\n",
    "        else:\n",
    "            return np.mean((d[k:] - d_bar) * (d[:-k] - d_bar))\n",
    "    \n",
    "    gamma_0 = gamma_d(0)\n",
    "    gamma_sum = gamma_0\n",
    "    \n",
    "    if h > 1:\n",
    "        for k in range(1, h):\n",
    "            gamma_k = gamma_d(k)\n",
    "            gamma_sum += 2 * gamma_k\n",
    "    \n",
    "    var_d = gamma_sum / T\n",
    "    \n",
    "    if var_d <= 0:\n",
    "        return 0, 1.0, 0\n",
    "    \n",
    "    dm_stat = d_bar / np.sqrt(var_d)\n",
    "    correction_factor = np.sqrt((T + 1 - 2*h + h*(h-1)) / T)\n",
    "    hln_dm_stat = correction_factor * dm_stat\n",
    "    \n",
    "    df_test = T - 1\n",
    "    p_value = 2 * (1 - stats.t.cdf(abs(hln_dm_stat), df_test))\n",
    "    \n",
    "    return hln_dm_stat, p_value, dm_stat\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 1: ANÁLISIS POR N_TRAIN (SEPARADO)\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 1: ANÁLISIS POR N_TRAIN (GRÁFICAS INDIVIDUALES)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_ntrain_comparison_bars(n_train, scenario=None):\n",
    "    \"\"\"Gráfica de barras ordenadas por N_Calib para un N_Train específico\"\"\"\n",
    "    \n",
    "    if scenario:\n",
    "        data = df[(df['N_Train'] == n_train) & (df['ESCENARIO'] == scenario)].copy()\n",
    "        suffix = scenario.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        title = f'Impacto de N_Calib (N_Train={n_train})\\n{scenario}'\n",
    "    else:\n",
    "        data = df[df['N_Train'] == n_train].copy()\n",
    "        suffix = 'General'\n",
    "        title = f'Impacto de N_Calib (N_Train={n_train})\\nTodos los Escenarios'\n",
    "    \n",
    "    n_calib_values = sorted(data['N_Calib'].unique())\n",
    "    \n",
    "    for model in model_cols:\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        means = [data[data['N_Calib'] == nc][model].mean() for nc in n_calib_values]\n",
    "        stds = [data[data['N_Calib'] == nc][model].std() for nc in n_calib_values]\n",
    "        \n",
    "        colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(n_calib_values)))\n",
    "        bars = ax.bar(range(len(n_calib_values)), means, color=colors, \n",
    "                     alpha=0.85, edgecolor='black', linewidth=1.5,\n",
    "                     yerr=stds, capsize=5)\n",
    "        \n",
    "        ax.set_xticks(range(len(n_calib_values)))\n",
    "        ax.set_xticklabels([f'N_Calib={nc}' for nc in n_calib_values], \n",
    "                          rotation=45, ha='right')\n",
    "        ax.set_ylabel('ECRPS Promedio', fontsize=11, fontweight='bold')\n",
    "        ax.set_xlabel('Tamaño de Muestra de Calibración', fontsize=11, fontweight='bold')\n",
    "        ax.set_title(f'{title}\\nModelo: {model}', fontsize=12, fontweight='bold')\n",
    "        ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "        \n",
    "        # Anotar valores\n",
    "        for bar, mean, std in zip(bars, means, stds):\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height + std,\n",
    "                   f'{mean:.4f}\\n±{std:.4f}',\n",
    "                   ha='center', va='bottom', fontsize=8)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        save_path = train_dirs[n_train] / \"Comparaciones\" / f'bars_{model}_{suffix}.png'\n",
    "        plt.savefig(save_path, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    print(f\"✓ Gráficas de barras guardadas: N_Train={n_train}, {suffix}\")\n",
    "\n",
    "def plot_ntrain_heatmap_relative_change(n_train, scenario=None):\n",
    "    \"\"\"Heatmap de cambios relativos para un N_Train específico\"\"\"\n",
    "    \n",
    "    if scenario:\n",
    "        data = df[(df['N_Train'] == n_train) & (df['ESCENARIO'] == scenario)].copy()\n",
    "        suffix = scenario.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        title = f'Cambio Relativo vs N_Calib Base (N_Train={n_train})\\n{scenario}'\n",
    "    else:\n",
    "        data = df[df['N_Train'] == n_train].copy()\n",
    "        suffix = 'General'\n",
    "        title = f'Cambio Relativo vs N_Calib Base (N_Train={n_train})\\nTodos los Escenarios'\n",
    "    \n",
    "    n_calib_values = sorted(data['N_Calib'].unique())\n",
    "    pivot_data = data.groupby('N_Calib')[model_cols].mean()\n",
    "    \n",
    "    if len(n_calib_values) > 1:\n",
    "        baseline = n_calib_values[0]\n",
    "        relative_changes = ((pivot_data - pivot_data.loc[baseline]) / \n",
    "                           pivot_data.loc[baseline] * 100)\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        sns.heatmap(relative_changes.T, annot=True, fmt='.2f', cmap='RdYlGn_r',\n",
    "                   center=0, ax=ax, cbar_kws={'label': 'Cambio Porcentual (%)'},\n",
    "                   linewidths=1, linecolor='gray', vmin=-50, vmax=50)\n",
    "        \n",
    "        ax.set_title(title, fontsize=12, fontweight='bold', pad=15)\n",
    "        ax.set_xlabel(f'N_Calib (Base: {baseline})', fontsize=11, fontweight='bold')\n",
    "        ax.set_ylabel('Modelo', fontsize=11, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        save_path = train_dirs[n_train] / \"Comparaciones\" / f'heatmap_cambios_{suffix}.png'\n",
    "        plt.savefig(save_path, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"✓ Heatmap guardado: N_Train={n_train}, {suffix}\")\n",
    "\n",
    "def plot_ntrain_best_config(n_train, scenario=None):\n",
    "    \"\"\"Identificar y graficar mejor N_Calib por modelo para un N_Train\"\"\"\n",
    "    \n",
    "    if scenario:\n",
    "        data = df[(df['N_Train'] == n_train) & (df['ESCENARIO'] == scenario)].copy()\n",
    "        suffix = scenario.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        title = f'Mejor N_Calib por Modelo (N_Train={n_train})\\n{scenario}'\n",
    "    else:\n",
    "        data = df[df['N_Train'] == n_train].copy()\n",
    "        suffix = 'General'\n",
    "        title = f'Mejor N_Calib por Modelo (N_Train={n_train})\\nTodos los Escenarios'\n",
    "    \n",
    "    best_configs = {}\n",
    "    for model in model_cols:\n",
    "        config_means = data.groupby('N_Calib')[model].mean()\n",
    "        best_ncalib = config_means.idxmin()\n",
    "        best_value = config_means.min()\n",
    "        best_configs[model] = {'N_Calib': best_ncalib, 'ECRPS': best_value}\n",
    "    \n",
    "    best_df = pd.DataFrame(best_configs).T\n",
    "    best_df = best_df.sort_values('ECRPS')\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    n_calib_unique = sorted(data['N_Calib'].unique())\n",
    "    color_map = {nc: plt.cm.Set3(i/len(n_calib_unique)) \n",
    "                 for i, nc in enumerate(n_calib_unique)}\n",
    "    colors = [color_map[nc] for nc in best_df['N_Calib']]\n",
    "    \n",
    "    bars = ax.barh(best_df.index, best_df['ECRPS'], color=colors, \n",
    "                  alpha=0.85, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    for bar, (model, row) in zip(bars, best_df.iterrows()):\n",
    "        width = bar.get_width()\n",
    "        ax.text(width + width*0.01, bar.get_y() + bar.get_height()/2.,\n",
    "               f\"{row['ECRPS']:.4f} (N_Calib={row['N_Calib']})\", \n",
    "               ha='left', va='center', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    ax.set_xlabel('ECRPS Promedio (Mejor N_Calib)', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=11, fontweight='bold')\n",
    "    ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "    ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    # Leyenda\n",
    "    from matplotlib.patches import Rectangle\n",
    "    legend_elements = [Rectangle((0,0),1,1, facecolor=color_map[nc], \n",
    "                                 edgecolor='black', label=f'N_Calib={nc}') \n",
    "                      for nc in n_calib_unique]\n",
    "    ax.legend(handles=legend_elements, title='Mejor N_Calib', \n",
    "             loc='lower right', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = train_dirs[n_train] / \"Rankings\" / f'best_ncalib_{suffix}.png'\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Guardar Excel\n",
    "    best_df.to_excel(train_dirs[n_train] / \"Rankings\" / f'best_ncalib_{suffix}.xlsx')\n",
    "    print(f\"✓ Mejor N_Calib guardado: N_Train={n_train}, {suffix}\")\n",
    "    \n",
    "    return best_df\n",
    "\n",
    "# Ejecutar análisis por N_Train\n",
    "for n_train in n_train_values:\n",
    "    print(f\"\\nProcesando N_Train = {n_train}\")\n",
    "    \n",
    "    # General\n",
    "    plot_ntrain_comparison_bars(n_train, None)\n",
    "    plot_ntrain_heatmap_relative_change(n_train, None)\n",
    "    plot_ntrain_best_config(n_train, None)\n",
    "    \n",
    "    # Por escenario\n",
    "    for scenario in df['ESCENARIO'].unique():\n",
    "        plot_ntrain_comparison_bars(n_train, scenario)\n",
    "        plot_ntrain_heatmap_relative_change(n_train, scenario)\n",
    "        plot_ntrain_best_config(n_train, scenario)\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 2: TESTS ESTADÍSTICOS (DIEBOLD-MARIANO)\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 2: TESTS DE DIEBOLD-MARIANO (MÁS APROPIADO PARA SERIES TEMPORALES)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def dm_test_between_configs(n_train, scenario=None):\n",
    "    \"\"\"\n",
    "    Test DM comparando diferentes N_Calib para un N_Train fijo\n",
    "    Más apropiado que ANOVA para series temporales\n",
    "    \"\"\"\n",
    "    \n",
    "    if scenario:\n",
    "        data = df[(df['N_Train'] == n_train) & (df['ESCENARIO'] == scenario)].copy()\n",
    "        suffix = scenario.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        title = f'Test Diebold-Mariano: N_Calib (N_Train={n_train})\\n{scenario}'\n",
    "    else:\n",
    "        data = df[df['N_Train'] == n_train].copy()\n",
    "        suffix = 'General'\n",
    "        title = f'Test Diebold-Mariano: N_Calib (N_Train={n_train})\\nTodos los Escenarios'\n",
    "    \n",
    "    n_calib_values = sorted(data['N_Calib'].unique())\n",
    "    \n",
    "    if len(n_calib_values) < 2:\n",
    "        print(f\"  ⚠ Solo hay un N_Calib para N_Train={n_train}, {suffix}\")\n",
    "        return\n",
    "    \n",
    "    h_forecast = int(data['Paso'].mean())\n",
    "    \n",
    "    # Test DM para cada modelo\n",
    "    results_summary = []\n",
    "    \n",
    "    for model in model_cols:\n",
    "        # Comparar todas las parejas de N_Calib\n",
    "        comparisons = []\n",
    "        \n",
    "        for i, nc1 in enumerate(n_calib_values):\n",
    "            for nc2 in n_calib_values[i+1:]:\n",
    "                errors1 = data[data['N_Calib'] == nc1][model].values\n",
    "                errors2 = data[data['N_Calib'] == nc2][model].values\n",
    "                \n",
    "                min_len = min(len(errors1), len(errors2))\n",
    "                errors1 = errors1[:min_len]\n",
    "                errors2 = errors2[:min_len]\n",
    "                \n",
    "                hln_dm_stat, p_val, _ = modified_diebold_mariano_test(\n",
    "                    errors1, errors2, h=h_forecast\n",
    "                )\n",
    "                \n",
    "                mean1 = np.mean(errors1)\n",
    "                mean2 = np.mean(errors2)\n",
    "                \n",
    "                comparisons.append({\n",
    "                    'N_Calib_1': nc1,\n",
    "                    'N_Calib_2': nc2,\n",
    "                    'DM_Stat': hln_dm_stat,\n",
    "                    'P_Value': p_val,\n",
    "                    'Mean_1': mean1,\n",
    "                    'Mean_2': mean2,\n",
    "                    'Significativo': 'Sí' if p_val < 0.05 else 'No',\n",
    "                    'Mejor': nc1 if mean1 < mean2 else nc2\n",
    "                })\n",
    "        \n",
    "        comp_df = pd.DataFrame(comparisons)\n",
    "        sig_count = (comp_df['Significativo'] == 'Sí').sum()\n",
    "        \n",
    "        results_summary.append({\n",
    "            'Modelo': model,\n",
    "            'Comparaciones_Significativas': f\"{sig_count}/{len(comparisons)}\",\n",
    "            'Proporcion_Sig': sig_count / len(comparisons) if len(comparisons) > 0 else 0,\n",
    "            'Mejor_N_Calib': data.groupby('N_Calib')[model].mean().idxmin(),\n",
    "            'ECRPS_Mejor': data.groupby('N_Calib')[model].mean().min()\n",
    "        })\n",
    "        \n",
    "        # Guardar comparaciones detalladas\n",
    "        comp_df.to_excel(\n",
    "            train_dirs[n_train] / \"Tests_Estadisticos\" / f'dm_comparaciones_{model}_{suffix}.xlsx',\n",
    "            index=False\n",
    "        )\n",
    "    \n",
    "    results_df = pd.DataFrame(results_summary)\n",
    "    results_df = results_df.sort_values('Proporcion_Sig', ascending=False)\n",
    "    \n",
    "    # Visualización\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    colors = plt.cm.RdYlGn(results_df['Proporcion_Sig'])\n",
    "    bars = ax.barh(results_df['Modelo'], results_df['Proporcion_Sig'], \n",
    "                  color=colors, alpha=0.85, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    for bar, (_, row) in zip(bars, results_df.iterrows()):\n",
    "        width = bar.get_width()\n",
    "        ax.text(width + 0.02, bar.get_y() + bar.get_height()/2.,\n",
    "               f\"{row['Comparaciones_Significativas']}\\n(Mejor: N_Calib={row['Mejor_N_Calib']})\",\n",
    "               ha='left', va='center', fontsize=8, fontweight='bold')\n",
    "    \n",
    "    ax.set_xlabel('Proporción de Comparaciones Significativas (DM test, α=0.05)', \n",
    "                 fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=11, fontweight='bold')\n",
    "    ax.set_title(title + f'\\n(h={h_forecast})', fontsize=12, fontweight='bold')\n",
    "    ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    ax.set_xlim(0, 1.1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = train_dirs[n_train] / \"Tests_Estadisticos\" / f'dm_summary_{suffix}.png'\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Guardar resumen\n",
    "    results_df.to_excel(\n",
    "        train_dirs[n_train] / \"Tests_Estadisticos\" / f'dm_summary_{suffix}.xlsx',\n",
    "        index=False\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ Test DM guardado: N_Train={n_train}, {suffix}\")\n",
    "\n",
    "# Ejecutar tests DM\n",
    "for n_train in n_train_values:\n",
    "    print(f\"\\nTests DM para N_Train = {n_train}\")\n",
    "    \n",
    "    dm_test_between_configs(n_train, None)\n",
    "    \n",
    "    for scenario in df['ESCENARIO'].unique():\n",
    "        dm_test_between_configs(n_train, scenario)\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 3: INTERACCIONES (GRÁFICAS INDIVIDUALES)\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 3: ANÁLISIS DE INTERACCIONES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_interaction_paso(n_train, model, scenario=None):\n",
    "    \"\"\"Interacción N_Calib × Horizonte para un modelo específico\"\"\"\n",
    "    \n",
    "    if scenario:\n",
    "        data = df[(df['N_Train'] == n_train) & (df['ESCENARIO'] == scenario)].copy()\n",
    "        suffix = scenario.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        title = f'Interacción N_Calib × Horizonte (N_Train={n_train})\\n{scenario}\\nModelo: {model}'\n",
    "    else:\n",
    "        data = df[df['N_Train'] == n_train].copy()\n",
    "        suffix = 'General'\n",
    "        title = f'Interacción N_Calib × Horizonte (N_Train={n_train})\\nModelo: {model}'\n",
    "    \n",
    "    n_calib_values = sorted(data['N_Calib'].unique())\n",
    "    pasos = sorted(data['Paso'].unique())\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    colors = plt.cm.viridis(np.linspace(0.2, 0.9, len(n_calib_values)))\n",
    "    \n",
    "    for idx, nc in enumerate(n_calib_values):\n",
    "        means = [data[(data['N_Calib'] == nc) & (data['Paso'] == p)][model].mean() \n",
    "                for p in pasos]\n",
    "        ax.plot(pasos, means, marker='o', label=f'N_Calib={nc}',\n",
    "               color=colors[idx], linewidth=2.5, markersize=8)\n",
    "    \n",
    "    ax.set_xlabel('Horizonte de Pronóstico (Paso)', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('ECRPS Promedio', fontsize=11, fontweight='bold')\n",
    "    ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "    ax.legend(title='Calibración', fontsize=9, loc='best')\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = train_dirs[n_train] / \"Interacciones\" / f'paso_{model}_{suffix}.png'\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_interaction_varianza(n_train, model, scenario=None):\n",
    "    \"\"\"Interacción N_Calib × Varianza para un modelo específico\"\"\"\n",
    "    \n",
    "    if scenario:\n",
    "        data = df[(df['N_Train'] == n_train) & (df['ESCENARIO'] == scenario)].copy()\n",
    "        suffix = scenario.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        title = f'Interacción N_Calib × Varianza (N_Train={n_train})\\n{scenario}\\nModelo: {model}'\n",
    "    else:\n",
    "        data = df[df['N_Train'] == n_train].copy()\n",
    "        suffix = 'General'\n",
    "        title = f'Interacción N_Calib × Varianza (N_Train={n_train})\\nModelo: {model}'\n",
    "    \n",
    "    n_calib_values = sorted(data['N_Calib'].unique())\n",
    "    varianzas = sorted(data['Varianza'].unique())\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    colors = plt.cm.plasma(np.linspace(0.2, 0.9, len(n_calib_values)))\n",
    "    \n",
    "    for idx, nc in enumerate(n_calib_values):\n",
    "        means = [data[(data['N_Calib'] == nc) & (data['Varianza'] == v)][model].mean() \n",
    "                for v in varianzas]\n",
    "        ax.plot(varianzas, means, marker='s', label=f'N_Calib={nc}',\n",
    "               color=colors[idx], linewidth=2.5, markersize=8)\n",
    "    \n",
    "    ax.set_xlabel('Varianza del Proceso', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('ECRPS Promedio', fontsize=11, fontweight='bold')\n",
    "    ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "    ax.legend(title='Calibración', fontsize=9, loc='best')\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = train_dirs[n_train] / \"Interacciones\" / f'varianza_{model}_{suffix}.png'\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Ejecutar interacciones\n",
    "for n_train in n_train_values:\n",
    "    print(f\"\\nInteracciones para N_Train = {n_train}\")\n",
    "    \n",
    "    for model in model_cols:\n",
    "        # General\n",
    "        plot_interaction_paso(n_train, model, None)\n",
    "        plot_interaction_varianza(n_train, model, None)\n",
    "        \n",
    "        # Por escenario\n",
    "        for scenario in df['ESCENARIO'].unique():\n",
    "            plot_interaction_paso(n_train, model, scenario)\n",
    "            plot_interaction_varianza(n_train, model, scenario)\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 4: COMPARACIONES ENTRE N_TRAIN\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 4: COMPARACIONES ENTRE DIFERENTES N_TRAIN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def compare_ntrain_values(model, scenario=None):\n",
    "    \"\"\"Compara el efecto de diferentes N_Train para un modelo\"\"\"\n",
    "    \n",
    "    if scenario:\n",
    "        data = df[df['ESCENARIO'] == scenario].copy()\n",
    "        suffix = scenario.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        title = f'Comparación Entre N_Train\\n{scenario}\\nModelo: {model}'\n",
    "    else:\n",
    "        data = df.copy()\n",
    "        suffix = 'General'\n",
    "        title = f'Comparación Entre N_Train\\nModelo: {model}'\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    \n",
    "    n_train_vals = sorted(data['N_Train'].unique())\n",
    "    colors = plt.cm.Set2(np.linspace(0, 1, len(n_train_vals)))\n",
    "    \n",
    "    for idx, nt in enumerate(n_train_vals):\n",
    "        data_nt = data[data['N_Train'] == nt]\n",
    "        n_calib_vals = sorted(data_nt['N_Calib'].unique())\n",
    "        \n",
    "        means = [data_nt[data_nt['N_Calib'] == nc][model].mean() for nc in n_calib_vals]\n",
    "        \n",
    "        ax.plot(n_calib_vals, means, marker='o', label=f'N_Train={nt}',\n",
    "               color=colors[idx], linewidth=2.5, markersize=8)\n",
    "    \n",
    "    ax.set_xlabel('N_Calib', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('ECRPS Promedio', fontsize=11, fontweight='bold')\n",
    "    ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "    ax.legend(title='Entrenamiento', fontsize=9, loc='best')\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = comparacion_dir / f'ntrain_comparison_{model}_{suffix}.png'\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Ejecutar comparaciones entre N_Train\n",
    "for model in model_cols:\n",
    "    compare_ntrain_values(model, None)\n",
    "    for scenario in df['ESCENARIO'].unique():\n",
    "        compare_ntrain_values(model, scenario)\n",
    "\n",
    "print(f\"✓ Comparaciones entre N_Train guardadas\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0a2b92",
   "metadata": {},
   "source": [
    "## Analisis proporciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52209586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Columnas cargadas: ['Paso', 'Proceso', 'Distribución', 'Varianza', 'N_Train', 'N_Calib', 'Prop_Calib', 'Block Bootstrapping', 'Sieve Bootstrap', 'LSPM', 'LSPMW', 'AREPD', 'MCPS', 'AV-MCPS', 'DeepAR', 'EnCQR-LSTM', 'Tipo_Proceso']\n",
      "✓ Dimensiones: (7800, 17)\n",
      "⚠ ADVERTENCIA: Se encontraron valores NaN en Paso\n",
      "\n",
      "================================================================================\n",
      "ANÁLISIS DE IMPACTO DE PROPORCIONES DE CALIBRACIÓN\n",
      "================================================================================\n",
      "\n",
      "Datos después de limpieza: 7200 filas, 18 columnas\n",
      "Tamaño base de datos: 240\n",
      "Proporciones decimales: [np.float64(0.1), np.float64(0.2), np.float64(0.3), np.float64(0.4), np.float64(0.5)]\n",
      "Proporciones (%): [np.int64(10), np.int64(20), np.int64(30), np.int64(40), np.int64(50)]\n",
      "Pasos únicos: [np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0), np.float64(5.0), np.float64(6.0), np.float64(7.0), np.float64(8.0), np.float64(9.0), np.float64(10.0), np.float64(11.0), np.float64(12.0)]\n",
      "N_Train únicos: [np.int64(120), np.int64(144), np.int64(168), np.int64(192), np.int64(216)]\n",
      "N_Calib únicos: [np.int64(24), np.int64(48), np.int64(72), np.int64(96), np.int64(120)]\n",
      "Tipos de proceso: ['Lineal Estacionario (ARMA)' 'Lineal No Estacionario (ARIMA)'\n",
      " 'No Lineal Estacionario (SETAR)']\n",
      "\n",
      "Modelos identificados (9): ['Block Bootstrapping', 'Sieve Bootstrap', 'LSPM', 'LSPMW', 'AREPD', 'MCPS', 'AV-MCPS', 'DeepAR', 'EnCQR-LSTM']\n",
      "\n",
      "================================================================================\n",
      "CREANDO ESTRUCTURA DE CARPETAS POR PROPORCIÓN\n",
      "================================================================================\n",
      "✓ Carpeta creada: Proporcion_10% (N_Train=216, N_Calib=24)\n",
      "✓ Carpeta creada: Proporcion_20% (N_Train=192, N_Calib=48)\n",
      "✓ Carpeta creada: Proporcion_30% (N_Train=168, N_Calib=72)\n",
      "✓ Carpeta creada: Proporcion_40% (N_Train=144, N_Calib=96)\n",
      "✓ Carpeta creada: Proporcion_50% (N_Train=120, N_Calib=120)\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 1: ANÁLISIS DESCRIPTIVO POR PROPORCIÓN\n",
      "================================================================================\n",
      "\n",
      "Procesando Proporción 10%\n",
      "✓ Análisis descriptivo guardado: Prop=10%, General\n",
      "✓ Análisis descriptivo guardado: Prop=10%, Lineal_Estacionario_ARMA\n",
      "✓ Análisis descriptivo guardado: Prop=10%, Lineal_No_Estacionario_ARIMA\n",
      "✓ Análisis descriptivo guardado: Prop=10%, No_Lineal_Estacionario_SETAR\n",
      "\n",
      "Procesando Proporción 20%\n",
      "✓ Análisis descriptivo guardado: Prop=20%, General\n",
      "✓ Análisis descriptivo guardado: Prop=20%, Lineal_Estacionario_ARMA\n",
      "✓ Análisis descriptivo guardado: Prop=20%, Lineal_No_Estacionario_ARIMA\n",
      "✓ Análisis descriptivo guardado: Prop=20%, No_Lineal_Estacionario_SETAR\n",
      "\n",
      "Procesando Proporción 30%\n",
      "✓ Análisis descriptivo guardado: Prop=30%, General\n",
      "✓ Análisis descriptivo guardado: Prop=30%, Lineal_Estacionario_ARMA\n",
      "✓ Análisis descriptivo guardado: Prop=30%, Lineal_No_Estacionario_ARIMA\n",
      "✓ Análisis descriptivo guardado: Prop=30%, No_Lineal_Estacionario_SETAR\n",
      "\n",
      "Procesando Proporción 40%\n",
      "✓ Análisis descriptivo guardado: Prop=40%, General\n",
      "✓ Análisis descriptivo guardado: Prop=40%, Lineal_Estacionario_ARMA\n",
      "✓ Análisis descriptivo guardado: Prop=40%, Lineal_No_Estacionario_ARIMA\n",
      "✓ Análisis descriptivo guardado: Prop=40%, No_Lineal_Estacionario_SETAR\n",
      "\n",
      "Procesando Proporción 50%\n",
      "✓ Análisis descriptivo guardado: Prop=50%, General\n",
      "✓ Análisis descriptivo guardado: Prop=50%, Lineal_Estacionario_ARMA\n",
      "✓ Análisis descriptivo guardado: Prop=50%, Lineal_No_Estacionario_ARIMA\n",
      "✓ Análisis descriptivo guardado: Prop=50%, No_Lineal_Estacionario_SETAR\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 2: TESTS DM ENTRE MODELOS (MISMA PROPORCIÓN)\n",
      "================================================================================\n",
      "\n",
      "Tests DM para Proporción 10%\n",
      "✓ Test DM entre modelos guardado: Prop=10%, General\n",
      "✓ Test DM entre modelos guardado: Prop=10%, Lineal_Estacionario_ARMA\n",
      "✓ Test DM entre modelos guardado: Prop=10%, Lineal_No_Estacionario_ARIMA\n",
      "✓ Test DM entre modelos guardado: Prop=10%, No_Lineal_Estacionario_SETAR\n",
      "\n",
      "Tests DM para Proporción 20%\n",
      "✓ Test DM entre modelos guardado: Prop=20%, General\n",
      "✓ Test DM entre modelos guardado: Prop=20%, Lineal_Estacionario_ARMA\n",
      "✓ Test DM entre modelos guardado: Prop=20%, Lineal_No_Estacionario_ARIMA\n",
      "✓ Test DM entre modelos guardado: Prop=20%, No_Lineal_Estacionario_SETAR\n",
      "\n",
      "Tests DM para Proporción 30%\n",
      "✓ Test DM entre modelos guardado: Prop=30%, General\n",
      "✓ Test DM entre modelos guardado: Prop=30%, Lineal_Estacionario_ARMA\n",
      "✓ Test DM entre modelos guardado: Prop=30%, Lineal_No_Estacionario_ARIMA\n",
      "✓ Test DM entre modelos guardado: Prop=30%, No_Lineal_Estacionario_SETAR\n",
      "\n",
      "Tests DM para Proporción 40%\n",
      "✓ Test DM entre modelos guardado: Prop=40%, General\n",
      "✓ Test DM entre modelos guardado: Prop=40%, Lineal_Estacionario_ARMA\n",
      "✓ Test DM entre modelos guardado: Prop=40%, Lineal_No_Estacionario_ARIMA\n",
      "✓ Test DM entre modelos guardado: Prop=40%, No_Lineal_Estacionario_SETAR\n",
      "\n",
      "Tests DM para Proporción 50%\n",
      "✓ Test DM entre modelos guardado: Prop=50%, General\n",
      "✓ Test DM entre modelos guardado: Prop=50%, Lineal_Estacionario_ARMA\n",
      "✓ Test DM entre modelos guardado: Prop=50%, Lineal_No_Estacionario_ARIMA\n",
      "✓ Test DM entre modelos guardado: Prop=50%, No_Lineal_Estacionario_SETAR\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 3: TESTS DM ENTRE PROPORCIONES (MISMO MODELO)\n",
      "================================================================================\n",
      "\n",
      "Ejecutando Tests DM entre proporciones...\n",
      "  Modelo: Block Bootstrapping\n",
      "✓ Test DM entre proporciones guardado: Modelo=Block Bootstrapping, General\n",
      "✓ Test DM entre proporciones guardado: Modelo=Block Bootstrapping, Lineal_Estacionario_ARMA\n",
      "✓ Test DM entre proporciones guardado: Modelo=Block Bootstrapping, Lineal_No_Estacionario_ARIMA\n",
      "✓ Test DM entre proporciones guardado: Modelo=Block Bootstrapping, No_Lineal_Estacionario_SETAR\n",
      "  Modelo: Sieve Bootstrap\n",
      "✓ Test DM entre proporciones guardado: Modelo=Sieve Bootstrap, General\n",
      "✓ Test DM entre proporciones guardado: Modelo=Sieve Bootstrap, Lineal_Estacionario_ARMA\n",
      "✓ Test DM entre proporciones guardado: Modelo=Sieve Bootstrap, Lineal_No_Estacionario_ARIMA\n",
      "✓ Test DM entre proporciones guardado: Modelo=Sieve Bootstrap, No_Lineal_Estacionario_SETAR\n",
      "  Modelo: LSPM\n",
      "✓ Test DM entre proporciones guardado: Modelo=LSPM, General\n",
      "✓ Test DM entre proporciones guardado: Modelo=LSPM, Lineal_Estacionario_ARMA\n",
      "✓ Test DM entre proporciones guardado: Modelo=LSPM, Lineal_No_Estacionario_ARIMA\n",
      "✓ Test DM entre proporciones guardado: Modelo=LSPM, No_Lineal_Estacionario_SETAR\n",
      "  Modelo: LSPMW\n",
      "✓ Test DM entre proporciones guardado: Modelo=LSPMW, General\n",
      "✓ Test DM entre proporciones guardado: Modelo=LSPMW, Lineal_Estacionario_ARMA\n",
      "✓ Test DM entre proporciones guardado: Modelo=LSPMW, Lineal_No_Estacionario_ARIMA\n",
      "✓ Test DM entre proporciones guardado: Modelo=LSPMW, No_Lineal_Estacionario_SETAR\n",
      "  Modelo: AREPD\n",
      "✓ Test DM entre proporciones guardado: Modelo=AREPD, General\n",
      "✓ Test DM entre proporciones guardado: Modelo=AREPD, Lineal_Estacionario_ARMA\n",
      "✓ Test DM entre proporciones guardado: Modelo=AREPD, Lineal_No_Estacionario_ARIMA\n",
      "✓ Test DM entre proporciones guardado: Modelo=AREPD, No_Lineal_Estacionario_SETAR\n",
      "  Modelo: MCPS\n",
      "✓ Test DM entre proporciones guardado: Modelo=MCPS, General\n",
      "✓ Test DM entre proporciones guardado: Modelo=MCPS, Lineal_Estacionario_ARMA\n",
      "✓ Test DM entre proporciones guardado: Modelo=MCPS, Lineal_No_Estacionario_ARIMA\n",
      "✓ Test DM entre proporciones guardado: Modelo=MCPS, No_Lineal_Estacionario_SETAR\n",
      "  Modelo: AV-MCPS\n",
      "✓ Test DM entre proporciones guardado: Modelo=AV-MCPS, General\n",
      "✓ Test DM entre proporciones guardado: Modelo=AV-MCPS, Lineal_Estacionario_ARMA\n",
      "✓ Test DM entre proporciones guardado: Modelo=AV-MCPS, Lineal_No_Estacionario_ARIMA\n",
      "✓ Test DM entre proporciones guardado: Modelo=AV-MCPS, No_Lineal_Estacionario_SETAR\n",
      "  Modelo: DeepAR\n",
      "✓ Test DM entre proporciones guardado: Modelo=DeepAR, General\n",
      "✓ Test DM entre proporciones guardado: Modelo=DeepAR, Lineal_Estacionario_ARMA\n",
      "✓ Test DM entre proporciones guardado: Modelo=DeepAR, Lineal_No_Estacionario_ARIMA\n",
      "✓ Test DM entre proporciones guardado: Modelo=DeepAR, No_Lineal_Estacionario_SETAR\n",
      "  Modelo: EnCQR-LSTM\n",
      "✓ Test DM entre proporciones guardado: Modelo=EnCQR-LSTM, General\n",
      "✓ Test DM entre proporciones guardado: Modelo=EnCQR-LSTM, Lineal_Estacionario_ARMA\n",
      "✓ Test DM entre proporciones guardado: Modelo=EnCQR-LSTM, Lineal_No_Estacionario_ARIMA\n",
      "✓ Test DM entre proporciones guardado: Modelo=EnCQR-LSTM, No_Lineal_Estacionario_SETAR\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 4: COMPARACIONES VISUALES ENTRE PROPORCIONES\n",
      "================================================================================\n",
      "\n",
      "Generando comparaciones visuales...\n",
      "✓ Evolución guardada: Modelo=Block Bootstrapping, General\n",
      "✓ Evolución guardada: Modelo=Block Bootstrapping, Lineal_Estacionario_ARMA\n",
      "✓ Evolución guardada: Modelo=Block Bootstrapping, Lineal_No_Estacionario_ARIMA\n",
      "✓ Evolución guardada: Modelo=Block Bootstrapping, No_Lineal_Estacionario_SETAR\n",
      "✓ Evolución guardada: Modelo=Sieve Bootstrap, General\n",
      "✓ Evolución guardada: Modelo=Sieve Bootstrap, Lineal_Estacionario_ARMA\n",
      "✓ Evolución guardada: Modelo=Sieve Bootstrap, Lineal_No_Estacionario_ARIMA\n",
      "✓ Evolución guardada: Modelo=Sieve Bootstrap, No_Lineal_Estacionario_SETAR\n",
      "✓ Evolución guardada: Modelo=LSPM, General\n",
      "✓ Evolución guardada: Modelo=LSPM, Lineal_Estacionario_ARMA\n",
      "✓ Evolución guardada: Modelo=LSPM, Lineal_No_Estacionario_ARIMA\n",
      "✓ Evolución guardada: Modelo=LSPM, No_Lineal_Estacionario_SETAR\n",
      "✓ Evolución guardada: Modelo=LSPMW, General\n",
      "✓ Evolución guardada: Modelo=LSPMW, Lineal_Estacionario_ARMA\n",
      "✓ Evolución guardada: Modelo=LSPMW, Lineal_No_Estacionario_ARIMA\n",
      "✓ Evolución guardada: Modelo=LSPMW, No_Lineal_Estacionario_SETAR\n",
      "✓ Evolución guardada: Modelo=AREPD, General\n",
      "✓ Evolución guardada: Modelo=AREPD, Lineal_Estacionario_ARMA\n",
      "✓ Evolución guardada: Modelo=AREPD, Lineal_No_Estacionario_ARIMA\n",
      "✓ Evolución guardada: Modelo=AREPD, No_Lineal_Estacionario_SETAR\n",
      "✓ Evolución guardada: Modelo=MCPS, General\n",
      "✓ Evolución guardada: Modelo=MCPS, Lineal_Estacionario_ARMA\n",
      "✓ Evolución guardada: Modelo=MCPS, Lineal_No_Estacionario_ARIMA\n",
      "✓ Evolución guardada: Modelo=MCPS, No_Lineal_Estacionario_SETAR\n",
      "✓ Evolución guardada: Modelo=AV-MCPS, General\n",
      "✓ Evolución guardada: Modelo=AV-MCPS, Lineal_Estacionario_ARMA\n",
      "✓ Evolución guardada: Modelo=AV-MCPS, Lineal_No_Estacionario_ARIMA\n",
      "✓ Evolución guardada: Modelo=AV-MCPS, No_Lineal_Estacionario_SETAR\n",
      "✓ Evolución guardada: Modelo=DeepAR, General\n",
      "✓ Evolución guardada: Modelo=DeepAR, Lineal_Estacionario_ARMA\n",
      "✓ Evolución guardada: Modelo=DeepAR, Lineal_No_Estacionario_ARIMA\n",
      "✓ Evolución guardada: Modelo=DeepAR, No_Lineal_Estacionario_SETAR\n",
      "✓ Evolución guardada: Modelo=EnCQR-LSTM, General\n",
      "✓ Evolución guardada: Modelo=EnCQR-LSTM, Lineal_Estacionario_ARMA\n",
      "✓ Evolución guardada: Modelo=EnCQR-LSTM, Lineal_No_Estacionario_ARIMA\n",
      "✓ Evolución guardada: Modelo=EnCQR-LSTM, No_Lineal_Estacionario_SETAR\n",
      "✓ Comparación todos los modelos guardada: General\n",
      "✓ Comparación todos los modelos guardada: Lineal_Estacionario_ARMA\n",
      "✓ Comparación todos los modelos guardada: Lineal_No_Estacionario_ARIMA\n",
      "✓ Comparación todos los modelos guardada: No_Lineal_Estacionario_SETAR\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 5: ANÁLISIS DE INTERACCIONES\n",
      "================================================================================\n",
      "\n",
      "Generando análisis de interacciones...\n",
      "  Proporción 10%\n",
      "  Proporción 20%\n",
      "  Proporción 30%\n",
      "  Proporción 40%\n",
      "  Proporción 50%\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 6: HEATMAPS GLOBALES\n",
      "================================================================================\n",
      "✓ Heatmap global guardado: General\n",
      "✓ Heatmap global guardado: Lineal_Estacionario_ARMA\n",
      "✓ Heatmap global guardado: Lineal_No_Estacionario_ARIMA\n",
      "✓ Heatmap global guardado: No_Lineal_Estacionario_SETAR\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 6.5: ANÁLISIS DE SENSIBILIDAD\n",
      "================================================================================\n",
      "\n",
      "Ejecutando análisis de sensibilidad...\n",
      "✓ Análisis de sensibilidad guardado: General\n",
      "  - Modelo más sensible: DeepAR (54.66%)\n",
      "  - Modelo más robusto: Sieve Bootstrap (0.64%)\n",
      "✓ Análisis de sensibilidad guardado: Lineal_Estacionario_ARMA\n",
      "  - Modelo más sensible: LSPMW (26.30%)\n",
      "  - Modelo más robusto: Sieve Bootstrap (0.71%)\n",
      "✓ Análisis de sensibilidad guardado: Lineal_No_Estacionario_ARIMA\n",
      "  - Modelo más sensible: DeepAR (103.48%)\n",
      "  - Modelo más robusto: Sieve Bootstrap (1.05%)\n",
      "✓ Análisis de sensibilidad guardado: No_Lineal_Estacionario_SETAR\n",
      "  - Modelo más sensible: LSPM (4.74%)\n",
      "  - Modelo más robusto: Block Bootstrapping (0.78%)\n",
      "\n",
      "================================================================================\n",
      "RESUMEN COMPARATIVO DE SENSIBILIDAD POR TIPO DE PROCESO\n",
      "================================================================================\n",
      "\n",
      "General:\n",
      "  Sensibilidad promedio: 24.11%\n",
      "  Modelo más sensible: DeepAR (54.66%)\n",
      "  Modelo más robusto: Sieve Bootstrap (0.64%)\n",
      "\n",
      "Lineal Estacionario (ARMA):\n",
      "  Sensibilidad promedio: 8.81%\n",
      "  Modelo más sensible: LSPMW (26.30%)\n",
      "  Modelo más robusto: Sieve Bootstrap (0.71%)\n",
      "\n",
      "Lineal No Estacionario (ARIMA):\n",
      "  Sensibilidad promedio: 38.03%\n",
      "  Modelo más sensible: DeepAR (103.48%)\n",
      "  Modelo más robusto: Sieve Bootstrap (1.05%)\n",
      "\n",
      "No Lineal Estacionario (SETAR):\n",
      "  Sensibilidad promedio: 2.54%\n",
      "  Modelo más sensible: LSPM (4.74%)\n",
      "  Modelo más robusto: Block Bootstrapping (0.78%)\n",
      "\n",
      "✓ Análisis de sensibilidad completo\n",
      "\n",
      "================================================================================\n",
      "GENERANDO RESUMEN FINAL\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "✓✓✓ ANÁLISIS COMPLETO FINALIZADO ✓✓✓\n",
      "================================================================================\n",
      "\n",
      "Resultados guardados en: Resultados_analisis\\Proporciones\n",
      "Total de imágenes generadas: 581\n",
      "Total de archivos Excel generados: 121\n",
      "\n",
      "Estructura de carpetas:\n",
      "  - 5 carpetas por proporción\n",
      "  - Comparaciones entre proporciones\n",
      "  - Tests DM globales\n",
      "  - Resumen final\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración general\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Crear carpeta de resultados\n",
    "output_dir = Path(\"./Resultados_analisis/Proporciones\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_excel(\"./datos/Simulacion/proporciones/resultados_PROPORCIONES_240_TODOS.xlsx\")\n",
    "\n",
    "print(f\"✓ Columnas cargadas: {df.columns.tolist()}\")\n",
    "print(f\"✓ Dimensiones: {df.shape}\")\n",
    "\n",
    "# ====================================================================================\n",
    "# RENOMBRAR Y PREPARAR DATOS\n",
    "# ====================================================================================\n",
    "\n",
    "# Renombrar Tipo_Proceso\n",
    "tipo_proceso_map = {\n",
    "    \"ARMA\": \"Lineal Estacionario (ARMA)\",\n",
    "    \"ARIMA\": \"Lineal No Estacionario (ARIMA)\",\n",
    "    \"SETAR\": \"No Lineal Estacionario (SETAR)\"\n",
    "}\n",
    "\n",
    "df['Tipo_Proceso'] = df['Tipo_Proceso'].replace(tipo_proceso_map)\n",
    "\n",
    "# Limpiar y convertir Prop_Calib de manera robusta\n",
    "def clean_prop_calib(value):\n",
    "    \"\"\"Limpia y convierte valores de proporción a entero\"\"\"\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    \n",
    "    # Convertir a string y limpiar\n",
    "    value_str = str(value).strip()\n",
    "    \n",
    "    # Si tiene %, extraer el número\n",
    "    if '%' in value_str:\n",
    "        # Tomar solo hasta el primer %\n",
    "        value_str = value_str.split('%')[0]\n",
    "    \n",
    "    # Convertir a float\n",
    "    try:\n",
    "        value_num = float(value_str)\n",
    "        # Si es decimal (0.10, 0.20), multiplicar por 100\n",
    "        if value_num < 1:\n",
    "            return int(value_num * 100)\n",
    "        # Si ya es porcentaje (10, 20), devolverlo como entero\n",
    "        else:\n",
    "            return int(value_num)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "df['Prop_Calib_Pct'] = df['Prop_Calib'].apply(clean_prop_calib)\n",
    "\n",
    "# Verificar que no haya NaN\n",
    "if df['Prop_Calib_Pct'].isna().any():\n",
    "    print(\"⚠ ADVERTENCIA: Se encontraron valores NaN en Prop_Calib_Pct\")\n",
    "    print(f\"Valores originales problemáticos: {df[df['Prop_Calib_Pct'].isna()]['Prop_Calib'].unique()}\")\n",
    "    # Eliminar filas con NaN\n",
    "    df = df.dropna(subset=['Prop_Calib_Pct'])\n",
    "\n",
    "# Actualizar Prop_Calib también como decimal\n",
    "df['Prop_Calib'] = df['Prop_Calib_Pct'] / 100\n",
    "\n",
    "# **NUEVO: Limpiar columna Paso**\n",
    "def clean_paso(value):\n",
    "    \"\"\"Limpia y convierte valores de Paso a entero\"\"\"\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    \n",
    "    # Convertir a string y limpiar\n",
    "    value_str = str(value).strip()\n",
    "    \n",
    "    # Extraer solo números\n",
    "    import re\n",
    "    numbers = re.findall(r'\\d+', value_str)\n",
    "    \n",
    "    if numbers:\n",
    "        return int(numbers[0])  # Tomar el primer número encontrado\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df['Paso'] = df['Paso'].apply(clean_paso)\n",
    "\n",
    "# Verificar Paso\n",
    "if df['Paso'].isna().any():\n",
    "    print(\"⚠ ADVERTENCIA: Se encontraron valores NaN en Paso\")\n",
    "    df = df.dropna(subset=['Paso'])\n",
    "\n",
    "# **NUEVO: Limpiar otras columnas numéricas que puedan tener problemas**\n",
    "numeric_cols = ['N_Train', 'N_Calib', 'Varianza']\n",
    "for col in numeric_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Limpiar columnas de modelos (asegurar que son numéricas)\n",
    "for model in model_cols:\n",
    "    df[model] = pd.to_numeric(df[model], errors='coerce')\n",
    "\n",
    "# Eliminar filas con NaN en columnas críticas\n",
    "critical_cols = ['Paso', 'Prop_Calib_Pct', 'N_Train', 'N_Calib'] + model_cols\n",
    "df = df.dropna(subset=critical_cols)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANÁLISIS DE IMPACTO DE PROPORCIONES DE CALIBRACIÓN\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nDatos después de limpieza: {df.shape[0]} filas, {df.shape[1]} columnas\")\n",
    "print(f\"Tamaño base de datos: 240\")\n",
    "print(f\"Proporciones decimales: {sorted(df['Prop_Calib'].unique())}\")\n",
    "print(f\"Proporciones (%): {sorted(df['Prop_Calib_Pct'].unique())}\")\n",
    "print(f\"Pasos únicos: {sorted(df['Paso'].unique())}\")\n",
    "print(f\"N_Train únicos: {sorted(df['N_Train'].unique())}\")\n",
    "print(f\"N_Calib únicos: {sorted(df['N_Calib'].unique())}\")\n",
    "print(f\"Tipos de proceso: {df['Tipo_Proceso'].unique()}\")\n",
    "\n",
    "# Identificar columnas de modelos\n",
    "var_cols = ['Paso', 'Proceso', 'Distribución', 'Varianza', \n",
    "            'N_Train', 'N_Calib', 'Prop_Calib', 'Prop_Calib_Pct', 'Tipo_Proceso']\n",
    "model_cols = [col for col in df.columns if col not in var_cols]\n",
    "\n",
    "print(f\"\\nModelos identificados ({len(model_cols)}): {model_cols}\")\n",
    "\n",
    "# ====================================================================================\n",
    "# ESTRUCTURA DE CARPETAS POR PROPORCIÓN\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CREANDO ESTRUCTURA DE CARPETAS POR PROPORCIÓN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "prop_values = sorted(df['Prop_Calib_Pct'].unique())\n",
    "prop_dirs = {}\n",
    "\n",
    "for prop_pct in prop_values:\n",
    "    prop_dir = output_dir / f\"Proporcion_{prop_pct}pct\"\n",
    "    prop_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Subcarpetas\n",
    "    (prop_dir / \"Comparaciones_Modelos\").mkdir(exist_ok=True)\n",
    "    (prop_dir / \"Tests_DM\").mkdir(exist_ok=True)\n",
    "    (prop_dir / \"Interacciones\").mkdir(exist_ok=True)\n",
    "    (prop_dir / \"Rankings\").mkdir(exist_ok=True)\n",
    "    \n",
    "    prop_dirs[prop_pct] = prop_dir\n",
    "    \n",
    "    n_calib = df[df['Prop_Calib_Pct'] == prop_pct]['N_Calib'].iloc[0]\n",
    "    n_train = df[df['Prop_Calib_Pct'] == prop_pct]['N_Train'].iloc[0]\n",
    "    print(f\"✓ Carpeta creada: Proporcion_{prop_pct}% (N_Train={n_train}, N_Calib={n_calib})\")\n",
    "\n",
    "# Carpetas para comparaciones entre proporciones\n",
    "comparacion_dir = output_dir / \"Comparaciones_Entre_Proporciones\"\n",
    "comparacion_dir.mkdir(exist_ok=True)\n",
    "\n",
    "dm_global_dir = output_dir / \"Tests_DM_Global\"\n",
    "dm_global_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# ====================================================================================\n",
    "# FUNCIÓN: TEST DIEBOLD-MARIANO\n",
    "# ====================================================================================\n",
    "\n",
    "def modified_diebold_mariano_test(errors1, errors2, h=1):\n",
    "    \"\"\"\n",
    "    Test Diebold-Mariano modificado con corrección Harvey-Leybourne-Newbold\n",
    "    \n",
    "    Referencias:\n",
    "    - Diebold & Mariano (1995)\n",
    "    - Harvey, Leybourne & Newbold (1997)\n",
    "    \"\"\"\n",
    "    d = errors1 - errors2\n",
    "    d_bar = np.mean(d)\n",
    "    T = len(d)\n",
    "    \n",
    "    def gamma_d(k):\n",
    "        if k == 0:\n",
    "            return np.var(d, ddof=1)\n",
    "        else:\n",
    "            return np.mean((d[k:] - d_bar) * (d[:-k] - d_bar))\n",
    "    \n",
    "    gamma_0 = gamma_d(0)\n",
    "    gamma_sum = gamma_0\n",
    "    \n",
    "    if h > 1:\n",
    "        for k in range(1, h):\n",
    "            gamma_k = gamma_d(k)\n",
    "            gamma_sum += 2 * gamma_k\n",
    "    \n",
    "    var_d = gamma_sum / T\n",
    "    \n",
    "    if var_d <= 0:\n",
    "        return 0, 1.0, 0\n",
    "    \n",
    "    dm_stat = d_bar / np.sqrt(var_d)\n",
    "    \n",
    "    # Corrección Harvey-Leybourne-Newbold para muestras pequeñas\n",
    "    correction_factor = np.sqrt((T + 1 - 2*h + h*(h-1)) / T)\n",
    "    hln_dm_stat = correction_factor * dm_stat\n",
    "    \n",
    "    df_test = T - 1\n",
    "    p_value = 2 * (1 - stats.t.cdf(abs(hln_dm_stat), df_test))\n",
    "    \n",
    "    return hln_dm_stat, p_value, dm_stat\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 1: ANÁLISIS DESCRIPTIVO POR PROPORCIÓN\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 1: ANÁLISIS DESCRIPTIVO POR PROPORCIÓN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_descriptive_by_proportion(prop_pct, tipo_proceso=None):\n",
    "    \"\"\"Análisis descriptivo para una proporción específica\"\"\"\n",
    "    \n",
    "    if tipo_proceso:\n",
    "        data = df[(df['Prop_Calib_Pct'] == prop_pct) & \n",
    "                  (df['Tipo_Proceso'] == tipo_proceso)].copy()\n",
    "        suffix = tipo_proceso.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        title_suffix = f'\\n{tipo_proceso}'\n",
    "    else:\n",
    "        data = df[df['Prop_Calib_Pct'] == prop_pct].copy()\n",
    "        suffix = 'General'\n",
    "        title_suffix = '\\nTodos los Procesos'\n",
    "    \n",
    "    n_calib = data['N_Calib'].iloc[0]\n",
    "    n_train = data['N_Train'].iloc[0]\n",
    "    \n",
    "    # Calcular estadísticos\n",
    "    stats_data = []\n",
    "    for model in model_cols:\n",
    "        stats_data.append({\n",
    "            'Modelo': model,\n",
    "            'Media': data[model].mean(),\n",
    "            'Mediana': data[model].median(),\n",
    "            'Desv_Std': data[model].std(),\n",
    "            'CV': data[model].std() / data[model].mean(),\n",
    "            'Min': data[model].min(),\n",
    "            'Max': data[model].max(),\n",
    "            'Q1': data[model].quantile(0.25),\n",
    "            'Q3': data[model].quantile(0.75)\n",
    "        })\n",
    "    \n",
    "    stats_df = pd.DataFrame(stats_data).sort_values('Media')\n",
    "    \n",
    "    # Gráfica 1: Barras ordenadas con media\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    colors = plt.cm.RdYlGn_r(np.linspace(0.2, 0.8, len(stats_df)))\n",
    "    bars = ax.barh(stats_df['Modelo'], stats_df['Media'], \n",
    "                  color=colors, alpha=0.85, edgecolor='black', linewidth=1.5,\n",
    "                  xerr=stats_df['Desv_Std'], capsize=5)\n",
    "    \n",
    "    for bar, (_, row) in zip(bars, stats_df.iterrows()):\n",
    "        width = bar.get_width()\n",
    "        ax.text(width + width*0.02, bar.get_y() + bar.get_height()/2.,\n",
    "               f\"{row['Media']:.4f}\\n±{row['Desv_Std']:.4f}\",\n",
    "               ha='left', va='center', fontsize=8, fontweight='bold')\n",
    "    \n",
    "    ax.set_xlabel('ECRPS Promedio', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=11, fontweight='bold')\n",
    "    ax.set_title(f'Ranking de Modelos - Proporción {prop_pct}%' + \n",
    "                f'{title_suffix}\\n(N_Train={n_train}, N_Calib={n_calib})',\n",
    "                fontsize=12, fontweight='bold')\n",
    "    ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = prop_dirs[prop_pct] / \"Rankings\" / f'ranking_media_{suffix}.png'\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Gráfica 2: Coeficiente de Variación (estabilidad)\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    cv_sorted = stats_df.sort_values('CV')\n",
    "    median_cv = cv_sorted['CV'].median()\n",
    "    colors_cv = ['#2ecc71' if cv < median_cv else '#e74c3c' for cv in cv_sorted['CV']]\n",
    "    \n",
    "    bars = ax.barh(cv_sorted['Modelo'], cv_sorted['CV'], \n",
    "                  color=colors_cv, alpha=0.85, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    ax.axvline(x=median_cv, color='black', linestyle='--', \n",
    "              linewidth=2, label=f'Mediana = {median_cv:.4f}')\n",
    "    \n",
    "    for bar, (_, row) in zip(bars, cv_sorted.iterrows()):\n",
    "        width = bar.get_width()\n",
    "        ax.text(width + 0.005, bar.get_y() + bar.get_height()/2.,\n",
    "               f\"{row['CV']:.4f}\",\n",
    "               ha='left', va='center', fontsize=8, fontweight='bold')\n",
    "    \n",
    "    ax.set_xlabel('Coeficiente de Variación (Desv.Std / Media)', \n",
    "                 fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=11, fontweight='bold')\n",
    "    ax.set_title(f'Estabilidad de Modelos - Proporción {prop_pct}%' + \n",
    "                f'{title_suffix}\\n(Menor CV = Más Estable)',\n",
    "                fontsize=12, fontweight='bold')\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = prop_dirs[prop_pct] / \"Rankings\" / f'estabilidad_cv_{suffix}.png'\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Guardar estadísticos\n",
    "    stats_df.to_excel(\n",
    "        prop_dirs[prop_pct] / \"Rankings\" / f'estadisticos_{suffix}.xlsx',\n",
    "        index=False\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ Análisis descriptivo guardado: Prop={prop_pct}%, {suffix}\")\n",
    "    \n",
    "    return stats_df\n",
    "\n",
    "# Ejecutar análisis descriptivo\n",
    "for prop_pct in prop_values:\n",
    "    print(f\"\\nProcesando Proporción {prop_pct}%\")\n",
    "    \n",
    "    # General\n",
    "    plot_descriptive_by_proportion(prop_pct, None)\n",
    "    \n",
    "    # Por tipo de proceso\n",
    "    for tipo_proceso in df['Tipo_Proceso'].unique():\n",
    "        plot_descriptive_by_proportion(prop_pct, tipo_proceso)\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 2: TESTS DIEBOLD-MARIANO ENTRE MODELOS (MISMA PROPORCIÓN)\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 2: TESTS DM ENTRE MODELOS (MISMA PROPORCIÓN)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def dm_test_between_models(prop_pct, tipo_proceso=None):\n",
    "    \"\"\"\n",
    "    Test DM comparando todos los modelos para una proporción fija\n",
    "    Identifica cuál modelo es significativamente mejor\n",
    "    \"\"\"\n",
    "    \n",
    "    if tipo_proceso:\n",
    "        data = df[(df['Prop_Calib_Pct'] == prop_pct) & \n",
    "                  (df['Tipo_Proceso'] == tipo_proceso)].copy()\n",
    "        suffix = tipo_proceso.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        title_suffix = f'\\n{tipo_proceso}'\n",
    "    else:\n",
    "        data = df[df['Prop_Calib_Pct'] == prop_pct].copy()\n",
    "        suffix = 'General'\n",
    "        title_suffix = '\\nTodos los Procesos'\n",
    "    \n",
    "    n_calib = data['N_Calib'].iloc[0]\n",
    "    n_train = data['N_Train'].iloc[0]\n",
    "    h_forecast = int(data['Paso'].mean())\n",
    "    \n",
    "    # Matriz de comparaciones\n",
    "    n_models = len(model_cols)\n",
    "    n_comparisons = n_models * (n_models - 1) / 2\n",
    "    alpha = 0.05\n",
    "    bonferroni_alpha = alpha / n_comparisons\n",
    "    \n",
    "    results_matrix = np.zeros((n_models, n_models))\n",
    "    p_values = np.zeros((n_models, n_models))\n",
    "    dm_stats = np.zeros((n_models, n_models))\n",
    "    \n",
    "    # Extraer datos de modelos\n",
    "    model_data = {model: data[model].values for model in model_cols}\n",
    "    \n",
    "    for i, model1 in enumerate(model_cols):\n",
    "        for j, model2 in enumerate(model_cols):\n",
    "            if i == j:\n",
    "                results_matrix[i, j] = 0\n",
    "                p_values[i, j] = 1.0\n",
    "                dm_stats[i, j] = 0\n",
    "            elif i < j:\n",
    "                errors1 = model_data[model1]\n",
    "                errors2 = model_data[model2]\n",
    "                \n",
    "                # Asegurar mismo tamaño\n",
    "                min_len = min(len(errors1), len(errors2))\n",
    "                errors1 = errors1[:min_len]\n",
    "                errors2 = errors2[:min_len]\n",
    "                \n",
    "                hln_dm_stat, p_val, _ = modified_diebold_mariano_test(\n",
    "                    errors1, errors2, h=h_forecast\n",
    "                )\n",
    "                \n",
    "                p_values[i, j] = p_val\n",
    "                p_values[j, i] = p_val\n",
    "                dm_stats[i, j] = hln_dm_stat\n",
    "                dm_stats[j, i] = -hln_dm_stat\n",
    "                \n",
    "                # Decisión con corrección Bonferroni\n",
    "                if p_val < bonferroni_alpha:\n",
    "                    mean1 = np.mean(errors1)\n",
    "                    mean2 = np.mean(errors2)\n",
    "                    if mean1 < mean2:\n",
    "                        results_matrix[i, j] = 1  # Modelo 1 es mejor\n",
    "                        results_matrix[j, i] = -1\n",
    "                    else:\n",
    "                        results_matrix[i, j] = -1\n",
    "                        results_matrix[j, i] = 1  # Modelo 2 es mejor\n",
    "                else:\n",
    "                    results_matrix[i, j] = 0\n",
    "                    results_matrix[j, i] = 0\n",
    "    \n",
    "    # Visualización: Matriz de comparaciones\n",
    "    fig, ax = plt.subplots(figsize=(16, 14))\n",
    "    \n",
    "    cmap = plt.cm.colors.ListedColormap(['#e74c3c', '#fff9c4', '#2ecc71'])\n",
    "    bounds = [-1.5, -0.5, 0.5, 1.5]\n",
    "    norm = plt.cm.colors.BoundaryNorm(bounds, cmap.N)\n",
    "    \n",
    "    im = ax.imshow(results_matrix, cmap=cmap, norm=norm, aspect='auto')\n",
    "    \n",
    "    ax.set_xticks(np.arange(n_models))\n",
    "    ax.set_yticks(np.arange(n_models))\n",
    "    ax.set_xticklabels(model_cols, rotation=45, ha='right', fontsize=9)\n",
    "    ax.set_yticklabels(model_cols, fontsize=9)\n",
    "    \n",
    "    # Anotaciones\n",
    "    for i in range(n_models):\n",
    "        for j in range(n_models):\n",
    "            if i == j:\n",
    "                text = '-'\n",
    "                color = 'black'\n",
    "                fontsize = 10\n",
    "            else:\n",
    "                val = results_matrix[i, j]\n",
    "                p_val = p_values[i, j]\n",
    "                dm_val = dm_stats[i, j]\n",
    "                \n",
    "                if val == 1:\n",
    "                    text = f'✓\\nDM={dm_val:.2f}\\np={p_val:.4f}'\n",
    "                    color = 'white'\n",
    "                elif val == -1:\n",
    "                    text = f'✗\\nDM={dm_val:.2f}\\np={p_val:.4f}'\n",
    "                    color = 'white'\n",
    "                else:\n",
    "                    text = f'≈\\np={p_val:.4f}'\n",
    "                    color = 'black'\n",
    "                fontsize = 7\n",
    "                \n",
    "            ax.text(j, i, text, ha='center', va='center', \n",
    "                   color=color, fontsize=fontsize, fontweight='bold')\n",
    "    \n",
    "    T = min(len(v) for v in model_data.values())\n",
    "    df_test = T - 1\n",
    "    \n",
    "    ax.set_title(f'Test Diebold-Mariano: Comparación Entre Modelos\\n' +\n",
    "                f'Proporción {prop_pct}% (N_Train={n_train}, N_Calib={n_calib})' +\n",
    "                title_suffix +\n",
    "                f'\\n(h={h_forecast}, T={T}, df={df_test}, α Bonf={bonferroni_alpha:.5f})',\n",
    "                fontsize=12, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Modelo (Columna)', fontsize=10, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo (Fila)', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # Leyenda\n",
    "    legend_elements = [\n",
    "        plt.Rectangle((0,0),1,1, facecolor='#2ecc71', \n",
    "                     label='Fila supera significativamente a columna'),\n",
    "        plt.Rectangle((0,0),1,1, facecolor='#e74c3c', \n",
    "                     label='Columna supera significativamente a fila'),\n",
    "        plt.Rectangle((0,0),1,1, facecolor='#fff9c4', \n",
    "                     label='Sin diferencia significativa')\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='upper left', \n",
    "             bbox_to_anchor=(1.02, 1), fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = prop_dirs[prop_pct] / \"Tests_DM\" / f'dm_matriz_{suffix}.png'\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Resumen: Victorias por modelo\n",
    "    summary_data = []\n",
    "    for idx, model in enumerate(model_cols):\n",
    "        victorias = int(np.sum(results_matrix[idx, :] == 1))\n",
    "        derrotas = int(np.sum(results_matrix[idx, :] == -1))\n",
    "        empates = int(np.sum(results_matrix[idx, :] == 0)) - 1\n",
    "        tasa_victoria = (victorias / (n_models - 1)) * 100\n",
    "        \n",
    "        summary_data.append({\n",
    "            'Modelo': model,\n",
    "            'Victorias': victorias,\n",
    "            'Derrotas': derrotas,\n",
    "            'Empates': empates,\n",
    "            'Tasa_Victoria_%': tasa_victoria,\n",
    "            'ECRPS_Medio': data[model].mean()\n",
    "        })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data).sort_values('Tasa_Victoria_%', ascending=False)\n",
    "    \n",
    "    # Gráfica: Resumen de victorias\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    colors_victory = plt.cm.RdYlGn(summary_df['Tasa_Victoria_%'] / 100)\n",
    "    bars = ax.barh(summary_df['Modelo'], summary_df['Tasa_Victoria_%'],\n",
    "                  color=colors_victory, alpha=0.85, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    for bar, (_, row) in zip(bars, summary_df.iterrows()):\n",
    "        width = bar.get_width()\n",
    "        ax.text(width + 2, bar.get_y() + bar.get_height()/2.,\n",
    "               f\"{row['Tasa_Victoria_%']:.1f}%\\n({row['Victorias']}/{n_models-1})\",\n",
    "               ha='left', va='center', fontsize=8, fontweight='bold')\n",
    "    \n",
    "    ax.set_xlabel('Tasa de Victoria (%)', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=11, fontweight='bold')\n",
    "    ax.set_title(f'Resumen Test DM: Tasa de Victoria por Modelo\\n' +\n",
    "                f'Proporción {prop_pct}%{title_suffix}',\n",
    "                fontsize=12, fontweight='bold')\n",
    "    ax.set_xlim(0, 110)\n",
    "    ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = prop_dirs[prop_pct] / \"Tests_DM\" / f'dm_resumen_victorias_{suffix}.png'\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Guardar resultados\n",
    "    results_df = pd.DataFrame(results_matrix, index=model_cols, columns=model_cols)\n",
    "    pvalues_df = pd.DataFrame(p_values, index=model_cols, columns=model_cols)\n",
    "    dmstats_df = pd.DataFrame(dm_stats, index=model_cols, columns=model_cols)\n",
    "    \n",
    "    with pd.ExcelWriter(prop_dirs[prop_pct] / \"Tests_DM\" / f'dm_completo_{suffix}.xlsx') as writer:\n",
    "        results_df.to_excel(writer, sheet_name='Matriz_Resultados')\n",
    "        pvalues_df.to_excel(writer, sheet_name='P_valores')\n",
    "        dmstats_df.to_excel(writer, sheet_name='Estadisticos_DM')\n",
    "        summary_df.to_excel(writer, sheet_name='Resumen', index=False)\n",
    "    \n",
    "    print(f\"✓ Test DM entre modelos guardado: Prop={prop_pct}%, {suffix}\")\n",
    "    \n",
    "    return summary_df\n",
    "\n",
    "# Ejecutar tests DM entre modelos\n",
    "for prop_pct in prop_values:\n",
    "    print(f\"\\nTests DM para Proporción {prop_pct}%\")\n",
    "    \n",
    "    dm_test_between_models(prop_pct, None)\n",
    "    \n",
    "    for tipo_proceso in df['Tipo_Proceso'].unique():\n",
    "        dm_test_between_models(prop_pct, tipo_proceso)\n",
    "# ====================================================================================\n",
    "# SECCIÓN 3: TESTS DM ENTRE PROPORCIONES (MISMO MODELO)\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 3: TESTS DM ENTRE PROPORCIONES (MISMO MODELO)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def dm_test_between_proportions(model, tipo_proceso=None):\n",
    "    \"\"\"\n",
    "    Test DM comparando diferentes proporciones para un modelo fijo\n",
    "    Identifica la proporción óptima para cada modelo\n",
    "    \"\"\"\n",
    "    \n",
    "    if tipo_proceso:\n",
    "        data = df[df['Tipo_Proceso'] == tipo_proceso].copy()\n",
    "        suffix = tipo_proceso.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        title_suffix = f'\\n{tipo_proceso}'\n",
    "    else:\n",
    "        data = df.copy()\n",
    "        suffix = 'General'\n",
    "        title_suffix = '\\nTodos los Procesos'\n",
    "    \n",
    "    prop_pcts = sorted(data['Prop_Calib_Pct'].unique())\n",
    "    h_forecast = int(data['Paso'].mean())\n",
    "    \n",
    "    # Matriz de comparaciones\n",
    "    n_props = len(prop_pcts)\n",
    "    n_comparisons = n_props * (n_props - 1) / 2\n",
    "    alpha = 0.05\n",
    "    bonferroni_alpha = alpha / n_comparisons\n",
    "    \n",
    "    results_matrix = np.zeros((n_props, n_props))\n",
    "    p_values = np.zeros((n_props, n_props))\n",
    "    dm_stats = np.zeros((n_props, n_props))\n",
    "    means = np.zeros(n_props)\n",
    "    \n",
    "    # Extraer datos por proporción\n",
    "    prop_data = {}\n",
    "    for prop_pct in prop_pcts:\n",
    "        prop_data[prop_pct] = data[data['Prop_Calib_Pct'] == prop_pct][model].values\n",
    "    \n",
    "    for i, prop1 in enumerate(prop_pcts):\n",
    "        means[i] = np.mean(prop_data[prop1])\n",
    "        \n",
    "        for j, prop2 in enumerate(prop_pcts):\n",
    "            if i == j:\n",
    "                results_matrix[i, j] = 0\n",
    "                p_values[i, j] = 1.0\n",
    "                dm_stats[i, j] = 0\n",
    "            elif i < j:\n",
    "                errors1 = prop_data[prop1]\n",
    "                errors2 = prop_data[prop2]\n",
    "                \n",
    "                min_len = min(len(errors1), len(errors2))\n",
    "                errors1 = errors1[:min_len]\n",
    "                errors2 = errors2[:min_len]\n",
    "                \n",
    "                hln_dm_stat, p_val, _ = modified_diebold_mariano_test(\n",
    "                    errors1, errors2, h=h_forecast\n",
    "                )\n",
    "                \n",
    "                p_values[i, j] = p_val\n",
    "                p_values[j, i] = p_val\n",
    "                dm_stats[i, j] = hln_dm_stat\n",
    "                dm_stats[j, i] = -hln_dm_stat\n",
    "                \n",
    "                if p_val < bonferroni_alpha:\n",
    "                    mean1 = np.mean(errors1)\n",
    "                    mean2 = np.mean(errors2)\n",
    "                    if mean1 < mean2:\n",
    "                        results_matrix[i, j] = 1\n",
    "                        results_matrix[j, i] = -1\n",
    "                    else:\n",
    "                        results_matrix[i, j] = -1\n",
    "                        results_matrix[j, i] = 1\n",
    "                else:\n",
    "                    results_matrix[i, j] = 0\n",
    "                    results_matrix[j, i] = 0\n",
    "    \n",
    "    # Visualización: Matriz\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    \n",
    "    cmap = plt.cm.colors.ListedColormap(['#e74c3c', '#fff9c4', '#2ecc71'])\n",
    "    bounds = [-1.5, -0.5, 0.5, 1.5]\n",
    "    norm = plt.cm.colors.BoundaryNorm(bounds, cmap.N)\n",
    "    \n",
    "    im = ax.imshow(results_matrix, cmap=cmap, norm=norm, aspect='auto')\n",
    "    \n",
    "    prop_labels = [f'{p}%' for p in prop_pcts]\n",
    "    ax.set_xticks(np.arange(n_props))\n",
    "    ax.set_yticks(np.arange(n_props))\n",
    "    ax.set_xticklabels(prop_labels, fontsize=10)\n",
    "    ax.set_yticklabels(prop_labels, fontsize=10)\n",
    "    \n",
    "    for i in range(n_props):\n",
    "        for j in range(n_props):\n",
    "            if i == j:\n",
    "                text = f'-\\n{means[i]:.4f}'\n",
    "                color = 'black'\n",
    "                fontsize = 9\n",
    "            else:\n",
    "                val = results_matrix[i, j]\n",
    "                p_val = p_values[i, j]\n",
    "                dm_val = dm_stats[i, j]\n",
    "                \n",
    "                if val == 1:\n",
    "                    text = f'✓\\nDM={dm_val:.2f}\\np={p_val:.4f}'\n",
    "                    color = 'white'\n",
    "                elif val == -1:\n",
    "                    text = f'✗\\nDM={dm_val:.2f}\\np={p_val:.4f}'\n",
    "                    color = 'white'\n",
    "                else:\n",
    "                    text = f'≈\\np={p_val:.4f}'\n",
    "                    color = 'black'\n",
    "                fontsize = 8\n",
    "                \n",
    "            ax.text(j, i, text, ha='center', va='center', \n",
    "                   color=color, fontsize=fontsize, fontweight='bold')\n",
    "    \n",
    "    T = min(len(v) for v in prop_data.values())\n",
    "    df_test = T - 1\n",
    "    \n",
    "    ax.set_title(f'Test DM: Comparación Entre Proporciones\\n' +\n",
    "                f'Modelo: {model}{title_suffix}\\n' +\n",
    "                f'(h={h_forecast}, T={T}, df={df_test}, α Bonf={bonferroni_alpha:.5f})',\n",
    "                fontsize=11, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Proporción de Calibración (%)', fontsize=10, fontweight='bold')\n",
    "    ax.set_ylabel('Proporción de Calibración (%)', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    legend_elements = [\n",
    "        plt.Rectangle((0,0),1,1, facecolor='#2ecc71', \n",
    "                     label='Fila supera significativamente a columna'),\n",
    "        plt.Rectangle((0,0),1,1, facecolor='#e74c3c', \n",
    "                     label='Columna supera significativamente a fila'),\n",
    "        plt.Rectangle((0,0),1,1, facecolor='#fff9c4',\n",
    "                     label='Sin diferencia significativa')\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='upper left', \n",
    "             bbox_to_anchor=(1.02, 1), fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = comparacion_dir / f'dm_proporciones_{model}_{suffix}.png'\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Guardar resultados\n",
    "    results_df = pd.DataFrame(results_matrix, \n",
    "                             index=[f'{p}%' for p in prop_pcts], \n",
    "                             columns=[f'{p}%' for p in prop_pcts])\n",
    "    pvalues_df = pd.DataFrame(p_values, \n",
    "                             index=[f'{p}%' for p in prop_pcts], \n",
    "                             columns=[f'{p}%' for p in prop_pcts])\n",
    "    dmstats_df = pd.DataFrame(dm_stats, \n",
    "                             index=[f'{p}%' for p in prop_pcts], \n",
    "                             columns=[f'{p}%' for p in prop_pcts])\n",
    "    \n",
    "    with pd.ExcelWriter(comparacion_dir / f'dm_proporciones_completo_{model}_{suffix}.xlsx') as writer:\n",
    "        results_df.to_excel(writer, sheet_name='Matriz_Resultados')\n",
    "        pvalues_df.to_excel(writer, sheet_name='P_valores')\n",
    "        dmstats_df.to_excel(writer, sheet_name='Estadisticos_DM')\n",
    "    \n",
    "    # Resumen: Victorias por proporción\n",
    "    summary_data = []\n",
    "    for idx, prop in enumerate(prop_pcts):\n",
    "        victorias = int(np.sum(results_matrix[idx, :] == 1))\n",
    "        derrotas = int(np.sum(results_matrix[idx, :] == -1))\n",
    "        empates = int(np.sum(results_matrix[idx, :] == 0)) - 1\n",
    "        \n",
    "        summary_data.append({\n",
    "            'Proporcion_%': prop,\n",
    "            'Victorias': victorias,\n",
    "            'Derrotas': derrotas,\n",
    "            'Empates': empates,\n",
    "            'ECRPS_Medio': means[idx]\n",
    "        })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    # Gráfica: Resumen victorias\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    colors_bar = plt.cm.RdYlGn(summary_df['Victorias'] / (n_props - 1))\n",
    "    bars = ax.bar(range(len(summary_df)), summary_df['Victorias'],\n",
    "                  color=colors_bar, alpha=0.85, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    ax.set_xticks(range(len(summary_df)))\n",
    "    ax.set_xticklabels([f\"{p}%\" for p in summary_df['Proporcion_%']])\n",
    "    ax.set_ylabel('Número de Victorias', fontsize=11, fontweight='bold')\n",
    "    ax.set_xlabel('Proporción de Calibración', fontsize=11, fontweight='bold')\n",
    "    ax.set_title(f'Resumen Test DM: Victorias por Proporción\\n' +\n",
    "                f'Modelo: {model}{title_suffix}',\n",
    "                fontsize=12, fontweight='bold')\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    for bar, (_, row) in zip(bars, summary_df.iterrows()):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "               f\"{int(row['Victorias'])}/{n_props-1}\",\n",
    "               ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = comparacion_dir / f'dm_proporciones_resumen_{model}_{suffix}.png'\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    summary_df.to_excel(\n",
    "        comparacion_dir / f'dm_proporciones_resumen_{model}_{suffix}.xlsx',\n",
    "        index=False\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ Test DM entre proporciones guardado: Modelo={model}, {suffix}\")\n",
    "    \n",
    "    return summary_df\n",
    "\n",
    "# Ejecutar tests DM entre proporciones\n",
    "print(\"\\nEjecutando Tests DM entre proporciones...\")\n",
    "for model in model_cols:\n",
    "    print(f\"  Modelo: {model}\")\n",
    "    dm_test_between_proportions(model, None)\n",
    "    \n",
    "    for tipo_proceso in df['Tipo_Proceso'].unique():\n",
    "        dm_test_between_proportions(model, tipo_proceso)\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 4: COMPARACIONES VISUALES ENTRE PROPORCIONES\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 4: COMPARACIONES VISUALES ENTRE PROPORCIONES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_evolution_across_proportions(model, tipo_proceso=None):\n",
    "    \"\"\"Gráfica de evolución del ECRPS a través de proporciones\"\"\"\n",
    "    \n",
    "    if tipo_proceso:\n",
    "        data = df[df['Tipo_Proceso'] == tipo_proceso].copy()\n",
    "        suffix = tipo_proceso.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        title_suffix = f'\\n{tipo_proceso}'\n",
    "    else:\n",
    "        data = df.copy()\n",
    "        suffix = 'General'\n",
    "        title_suffix = '\\nTodos los Procesos'\n",
    "    \n",
    "    prop_pcts = sorted(data['Prop_Calib_Pct'].unique())\n",
    "    \n",
    "    means = [data[data['Prop_Calib_Pct'] == p][model].mean() for p in prop_pcts]\n",
    "    stds = [data[data['Prop_Calib_Pct'] == p][model].std() for p in prop_pcts]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    ax.plot(prop_pcts, means, marker='o', linewidth=2.5, markersize=10,\n",
    "           color='#3498db', label='Media')\n",
    "    ax.fill_between(prop_pcts, \n",
    "                    np.array(means) - np.array(stds),\n",
    "                    np.array(means) + np.array(stds),\n",
    "                    alpha=0.3, color='#3498db', label='±1 Desv.Std')\n",
    "    \n",
    "    ax.set_xlabel('Proporción de Calibración (%)', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('ECRPS Promedio', fontsize=11, fontweight='bold')\n",
    "    ax.set_title(f'Evolución del ECRPS: {model}{title_suffix}',\n",
    "                fontsize=12, fontweight='bold')\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    # Anotar valores\n",
    "    for x, y, std in zip(prop_pcts, means, stds):\n",
    "        ax.annotate(f'{y:.4f}\\n±{std:.4f}',\n",
    "                   xy=(x, y), xytext=(0, 10),\n",
    "                   textcoords='offset points', ha='center',\n",
    "                   fontsize=8, bbox=dict(boxstyle='round,pad=0.3', \n",
    "                   facecolor='white', alpha=0.7))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = comparacion_dir / f'evolucion_{model}_{suffix}.png'\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"✓ Evolución guardada: Modelo={model}, {suffix}\")\n",
    "\n",
    "def plot_all_models_comparison(tipo_proceso=None):\n",
    "    \"\"\"Comparación de todos los modelos a través de proporciones\"\"\"\n",
    "    \n",
    "    if tipo_proceso:\n",
    "        data = df[df['Tipo_Proceso'] == tipo_proceso].copy()\n",
    "        suffix = tipo_proceso.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        title_suffix = f'\\n{tipo_proceso}'\n",
    "    else:\n",
    "        data = df.copy()\n",
    "        suffix = 'General'\n",
    "        title_suffix = '\\nTodos los Procesos'\n",
    "    \n",
    "    prop_pcts = sorted(data['Prop_Calib_Pct'].unique())\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    colors = plt.cm.tab20(np.linspace(0, 1, len(model_cols)))\n",
    "    \n",
    "    for idx, model in enumerate(model_cols):\n",
    "        means = [data[data['Prop_Calib_Pct'] == p][model].mean() for p in prop_pcts]\n",
    "        ax.plot(prop_pcts, means, marker='o', linewidth=2, markersize=7,\n",
    "               color=colors[idx], label=model, alpha=0.8)\n",
    "    \n",
    "    ax.set_xlabel('Proporción de Calibración (%)', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('ECRPS Promedio', fontsize=11, fontweight='bold')\n",
    "    ax.set_title(f'Comparación de Todos los Modelos{title_suffix}',\n",
    "                fontsize=12, fontweight='bold')\n",
    "    ax.legend(fontsize=8, loc='best', ncol=2)\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = comparacion_dir / f'todos_modelos_{suffix}.png'\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"✓ Comparación todos los modelos guardada: {suffix}\")\n",
    "\n",
    "# Ejecutar comparaciones visuales\n",
    "print(\"\\nGenerando comparaciones visuales...\")\n",
    "for model in model_cols:\n",
    "    plot_evolution_across_proportions(model, None)\n",
    "    for tipo_proceso in df['Tipo_Proceso'].unique():\n",
    "        plot_evolution_across_proportions(model, tipo_proceso)\n",
    "\n",
    "plot_all_models_comparison(None)\n",
    "for tipo_proceso in df['Tipo_Proceso'].unique():\n",
    "    plot_all_models_comparison(tipo_proceso)\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 5: INTERACCIONES ENTRE PROPORCIONES Y OTRAS VARIABLES\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 5: ANÁLISIS DE INTERACCIONES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_interaction_prop_paso(prop_pct, model, tipo_proceso=None):\n",
    "    \"\"\"Interacción Proporción × Horizonte\"\"\"\n",
    "    \n",
    "    if tipo_proceso:\n",
    "        data = df[(df['Prop_Calib_Pct'] == prop_pct) & \n",
    "                  (df['Tipo_Proceso'] == tipo_proceso)].copy()\n",
    "        suffix = tipo_proceso.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        title_suffix = f'\\n{tipo_proceso}'\n",
    "    else:\n",
    "        data = df[df['Prop_Calib_Pct'] == prop_pct].copy()\n",
    "        suffix = 'General'\n",
    "        title_suffix = '\\nTodos los Procesos'\n",
    "    \n",
    "    pasos = sorted(data['Paso'].unique())\n",
    "    \n",
    "    means = [data[data['Paso'] == p][model].mean() for p in pasos]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    ax.plot(pasos, means, marker='o', linewidth=2.5, markersize=10,\n",
    "           color='#e74c3c')\n",
    "    \n",
    "    ax.set_xlabel('Horizonte de Pronóstico (Paso)', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('ECRPS Promedio', fontsize=11, fontweight='bold')\n",
    "    ax.set_title(f'Interacción Horizonte: Proporción {prop_pct}%{title_suffix}\\n' +\n",
    "                f'Modelo: {model}',\n",
    "                fontsize=12, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = prop_dirs[prop_pct] / \"Interacciones\" / f'paso_{model}_{suffix}.png'\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_interaction_prop_varianza(prop_pct, model, tipo_proceso=None):\n",
    "    \"\"\"Interacción Proporción × Varianza\"\"\"\n",
    "    \n",
    "    if tipo_proceso:\n",
    "        data = df[(df['Prop_Calib_Pct'] == prop_pct) & \n",
    "                  (df['Tipo_Proceso'] == tipo_proceso)].copy()\n",
    "        suffix = tipo_proceso.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        title_suffix = f'\\n{tipo_proceso}'\n",
    "    else:\n",
    "        data = df[df['Prop_Calib_Pct'] == prop_pct].copy()\n",
    "        suffix = 'General'\n",
    "        title_suffix = '\\nTodos los Procesos'\n",
    "    \n",
    "    varianzas = sorted(data['Varianza'].unique())\n",
    "    \n",
    "    means = [data[data['Varianza'] == v][model].mean() for v in varianzas]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    ax.plot(varianzas, means, marker='s', linewidth=2.5, markersize=10,\n",
    "           color='#9b59b6')\n",
    "    \n",
    "    ax.set_xlabel('Varianza del Proceso', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('ECRPS Promedio', fontsize=11, fontweight='bold')\n",
    "    ax.set_title(f'Interacción Varianza: Proporción {prop_pct}%{title_suffix}\\n' +\n",
    "                f'Modelo: {model}',\n",
    "                fontsize=12, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = prop_dirs[prop_pct] / \"Interacciones\" / f'varianza_{model}_{suffix}.png'\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Ejecutar interacciones\n",
    "print(\"\\nGenerando análisis de interacciones...\")\n",
    "for prop_pct in prop_values:\n",
    "    print(f\"  Proporción {prop_pct}%\")\n",
    "    for model in model_cols:\n",
    "        plot_interaction_prop_paso(prop_pct, model, None)\n",
    "        plot_interaction_prop_varianza(prop_pct, model, None)\n",
    "        \n",
    "        for tipo_proceso in df['Tipo_Proceso'].unique():\n",
    "            plot_interaction_prop_paso(prop_pct, model, tipo_proceso)\n",
    "            plot_interaction_prop_varianza(prop_pct, model, tipo_proceso)\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 6: HEATMAPS GLOBALES\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 6: HEATMAPS GLOBALES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_global_heatmap_models_vs_proportions(tipo_proceso=None):\n",
    "    \"\"\"Heatmap: Modelos × Proporciones\"\"\"\n",
    "    \n",
    "    if tipo_proceso:\n",
    "        data = df[df['Tipo_Proceso'] == tipo_proceso].copy()\n",
    "        suffix = tipo_proceso.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        title_suffix = f'\\n{tipo_proceso}'\n",
    "    else:\n",
    "        data = df.copy()\n",
    "        suffix = 'General'\n",
    "        title_suffix = '\\nTodos los Procesos'\n",
    "    \n",
    "    pivot_data = data.groupby('Prop_Calib_Pct')[model_cols].mean()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 10))\n",
    "    \n",
    "    sns.heatmap(pivot_data.T, annot=True, fmt='.4f', cmap='RdYlGn_r',\n",
    "               ax=ax, cbar_kws={'label': 'ECRPS Promedio'},\n",
    "               linewidths=1, linecolor='gray')\n",
    "    \n",
    "    ax.set_xlabel('Proporción de Calibración (%)', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=11, fontweight='bold')\n",
    "    ax.set_title(f'Heatmap Global: Modelos × Proporciones{title_suffix}',\n",
    "                fontsize=12, fontweight='bold', pad=15)\n",
    "    \n",
    "    # Formato ejes\n",
    "    ax.set_xticklabels([f'{int(x)}%' for x in pivot_data.index], rotation=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = comparacion_dir / f'heatmap_global_{suffix}.png'\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Guardar datos\n",
    "    pivot_data.to_excel(comparacion_dir / f'heatmap_global_data_{suffix}.xlsx')\n",
    "    \n",
    "    print(f\"✓ Heatmap global guardado: {suffix}\")\n",
    "\n",
    "# Ejecutar heatmaps globales\n",
    "plot_global_heatmap_models_vs_proportions(None)\n",
    "for tipo_proceso in df['Tipo_Proceso'].unique():\n",
    "    plot_global_heatmap_models_vs_proportions(tipo_proceso)\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 6.5: ANÁLISIS DE SENSIBILIDAD (MODELOS MÁS AFECTADOS POR CAMBIOS)\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 6.5: ANÁLISIS DE SENSIBILIDAD\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Crear carpeta para análisis de sensibilidad\n",
    "sensibilidad_dir = output_dir / \"Analisis_Sensibilidad\"\n",
    "sensibilidad_dir.mkdir(exist_ok=True)\n",
    "\n",
    "def analyze_sensitivity_to_proportions(tipo_proceso=None):\n",
    "    \"\"\"\n",
    "    Identifica qué modelos son más sensibles a cambios en la proporción de calibración\n",
    "    \"\"\"\n",
    "    \n",
    "    if tipo_proceso:\n",
    "        data = df[df['Tipo_Proceso'] == tipo_proceso].copy()\n",
    "        suffix = tipo_proceso.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        title_suffix = f'\\n{tipo_proceso}'\n",
    "    else:\n",
    "        data = df.copy()\n",
    "        suffix = 'General'\n",
    "        title_suffix = '\\nTodos los Procesos'\n",
    "    \n",
    "    prop_pcts = sorted(data['Prop_Calib_Pct'].unique())\n",
    "    \n",
    "    if len(prop_pcts) < 2:\n",
    "        print(f\"  ⚠ No hay suficientes proporciones para análisis de sensibilidad: {suffix}\")\n",
    "        return\n",
    "    \n",
    "    sensitivity_metrics = []\n",
    "    \n",
    "    for model in model_cols:\n",
    "        # Calcular métricas por proporción\n",
    "        means_by_prop = []\n",
    "        for prop in prop_pcts:\n",
    "            mean_val = data[data['Prop_Calib_Pct'] == prop][model].mean()\n",
    "            means_by_prop.append(mean_val)\n",
    "        \n",
    "        means_array = np.array(means_by_prop)\n",
    "        \n",
    "        # Métricas de sensibilidad\n",
    "        baseline = means_array[0]  # Primera proporción como referencia\n",
    "        \n",
    "        # 1. Rango de variación absoluta\n",
    "        rango_absoluto = means_array.max() - means_array.min()\n",
    "        \n",
    "        # 2. Rango de variación relativa (%)\n",
    "        rango_relativo = (rango_absoluto / baseline) * 100\n",
    "        \n",
    "        # 3. Desviación estándar de las medias\n",
    "        volatilidad = np.std(means_array)\n",
    "        \n",
    "        # 4. Coeficiente de variación de las medias\n",
    "        cv_medias = volatilidad / np.mean(means_array)\n",
    "        \n",
    "        # 5. Cambio máximo entre proporciones consecutivas\n",
    "        cambios_consecutivos = np.abs(np.diff(means_array))\n",
    "        max_cambio_consecutivo = cambios_consecutivos.max()\n",
    "        max_cambio_consecutivo_pct = (max_cambio_consecutivo / baseline) * 100\n",
    "        \n",
    "        # 6. Tendencia (correlación con proporción)\n",
    "        from scipy.stats import pearsonr, spearmanr\n",
    "        corr_pearson, p_pearson = pearsonr(prop_pcts, means_array)\n",
    "        corr_spearman, p_spearman = spearmanr(prop_pcts, means_array)\n",
    "        \n",
    "        # 7. Mejor y peor proporción\n",
    "        best_prop_idx = means_array.argmin()\n",
    "        worst_prop_idx = means_array.argmax()\n",
    "        \n",
    "        sensitivity_metrics.append({\n",
    "            'Modelo': model,\n",
    "            'Rango_Absoluto': rango_absoluto,\n",
    "            'Rango_Relativo_%': rango_relativo,\n",
    "            'Volatilidad': volatilidad,\n",
    "            'CV_Medias': cv_medias,\n",
    "            'Max_Cambio_Consecutivo': max_cambio_consecutivo,\n",
    "            'Max_Cambio_Consecutivo_%': max_cambio_consecutivo_pct,\n",
    "            'Correlacion_Pearson': corr_pearson,\n",
    "            'P_value_Pearson': p_pearson,\n",
    "            'Correlacion_Spearman': corr_spearman,\n",
    "            'P_value_Spearman': p_spearman,\n",
    "            'Mejor_Proporcion_%': prop_pcts[best_prop_idx],\n",
    "            'Peor_Proporcion_%': prop_pcts[worst_prop_idx],\n",
    "            'ECRPS_Mejor': means_array[best_prop_idx],\n",
    "            'ECRPS_Peor': means_array[worst_prop_idx],\n",
    "            'Media_Global': means_array.mean()\n",
    "        })\n",
    "    \n",
    "    sensitivity_df = pd.DataFrame(sensitivity_metrics)\n",
    "    \n",
    "    # ============================================================================\n",
    "    # GRÁFICA 1: Ranking de Sensibilidad (Rango Relativo)\n",
    "    # ============================================================================\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    sens_sorted = sensitivity_df.sort_values('Rango_Relativo_%', ascending=False)\n",
    "    \n",
    "    colors = plt.cm.RdYlGn_r(sens_sorted['Rango_Relativo_%'] / sens_sorted['Rango_Relativo_%'].max())\n",
    "    bars = ax.barh(sens_sorted['Modelo'], sens_sorted['Rango_Relativo_%'],\n",
    "                  color=colors, alpha=0.85, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    for bar, (_, row) in zip(bars, sens_sorted.iterrows()):\n",
    "        width = bar.get_width()\n",
    "        ax.text(width + width*0.02, bar.get_y() + bar.get_height()/2.,\n",
    "               f\"{row['Rango_Relativo_%']:.2f}%\\n(Δ={row['Rango_Absoluto']:.4f})\",\n",
    "               ha='left', va='center', fontsize=8, fontweight='bold')\n",
    "    \n",
    "    ax.set_xlabel('Variación Relativa Máxima (%)', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=11, fontweight='bold')\n",
    "    ax.set_title(f'Sensibilidad a Cambios en Proporción de Calibración{title_suffix}\\n' +\n",
    "                '(Mayor valor = Más sensible a cambios)',\n",
    "                fontsize=12, fontweight='bold')\n",
    "    ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    # Línea de referencia (mediana)\n",
    "    median_sens = sens_sorted['Rango_Relativo_%'].median()\n",
    "    ax.axvline(x=median_sens, color='red', linestyle='--', linewidth=2,\n",
    "              label=f'Mediana = {median_sens:.2f}%')\n",
    "    ax.legend(fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = sensibilidad_dir / f'sensibilidad_ranking_{suffix}.png'\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # ============================================================================\n",
    "    # GRÁFICA 2: Clasificación por Sensibilidad\n",
    "    # ============================================================================\n",
    "    \n",
    "    # Clasificar modelos\n",
    "    q33 = sensitivity_df['Rango_Relativo_%'].quantile(0.33)\n",
    "    q66 = sensitivity_df['Rango_Relativo_%'].quantile(0.66)\n",
    "    \n",
    "    def classify_sensitivity(value):\n",
    "        if value < q33:\n",
    "            return 'Baja'\n",
    "        elif value < q66:\n",
    "            return 'Media'\n",
    "        else:\n",
    "            return 'Alta'\n",
    "    \n",
    "    sensitivity_df['Clasificacion'] = sensitivity_df['Rango_Relativo_%'].apply(classify_sensitivity)\n",
    "    \n",
    "    class_counts = sensitivity_df['Clasificacion'].value_counts()\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Subplot 1: Pie chart\n",
    "    colors_pie = ['#2ecc71', '#f39c12', '#e74c3c']\n",
    "    explode = (0.05, 0.05, 0.1)\n",
    "    ax1.pie(class_counts.values, labels=class_counts.index, autopct='%1.1f%%',\n",
    "           colors=colors_pie, explode=explode, startangle=90,\n",
    "           textprops={'fontsize': 11, 'fontweight': 'bold'})\n",
    "    ax1.set_title(f'Distribución de Sensibilidad{title_suffix}',\n",
    "                 fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Subplot 2: Scatter - Sensibilidad vs Performance\n",
    "    for clase, color, marker in [('Baja', '#2ecc71', 'o'), \n",
    "                                  ('Media', '#f39c12', 's'), \n",
    "                                  ('Alta', '#e74c3c', '^')]:\n",
    "        mask = sensitivity_df['Clasificacion'] == clase\n",
    "        ax2.scatter(sensitivity_df[mask]['Rango_Relativo_%'],\n",
    "                   sensitivity_df[mask]['Media_Global'],\n",
    "                   c=color, s=150, alpha=0.7, edgecolors='black',\n",
    "                   linewidth=1.5, marker=marker, label=clase)\n",
    "    \n",
    "    ax2.set_xlabel('Sensibilidad (Variación Relativa %)', fontsize=11, fontweight='bold')\n",
    "    ax2.set_ylabel('ECRPS Promedio Global', fontsize=11, fontweight='bold')\n",
    "    ax2.set_title('Sensibilidad vs Performance', fontsize=12, fontweight='bold')\n",
    "    ax2.legend(title='Clasificación', fontsize=10)\n",
    "    ax2.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    # Anotar modelos\n",
    "    for _, row in sensitivity_df.iterrows():\n",
    "        ax2.annotate(row['Modelo'], \n",
    "                    xy=(row['Rango_Relativo_%'], row['Media_Global']),\n",
    "                    xytext=(5, 5), textcoords='offset points',\n",
    "                    fontsize=7, alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = sensibilidad_dir / f'sensibilidad_clasificacion_{suffix}.png'\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # ============================================================================\n",
    "    # GRÁFICA 3: Correlación con Proporción (Tendencia)\n",
    "    # ============================================================================\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    corr_sorted = sensitivity_df.sort_values('Correlacion_Spearman')\n",
    "    \n",
    "    # Colores según dirección de correlación\n",
    "    colors_corr = ['#e74c3c' if x < 0 else '#2ecc71' \n",
    "                   for x in corr_sorted['Correlacion_Spearman']]\n",
    "    \n",
    "    bars = ax.barh(corr_sorted['Modelo'], corr_sorted['Correlacion_Spearman'],\n",
    "                  color=colors_corr, alpha=0.85, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    for bar, (_, row) in zip(bars, corr_sorted.iterrows()):\n",
    "        width = bar.get_width()\n",
    "        x_pos = width + (0.02 if width > 0 else -0.02)\n",
    "        ha = 'left' if width > 0 else 'right'\n",
    "        \n",
    "        # Significancia\n",
    "        sig = '***' if row['P_value_Spearman'] < 0.001 else \\\n",
    "              '**' if row['P_value_Spearman'] < 0.01 else \\\n",
    "              '*' if row['P_value_Spearman'] < 0.05 else 'ns'\n",
    "        \n",
    "        ax.text(x_pos, bar.get_y() + bar.get_height()/2.,\n",
    "               f\"{row['Correlacion_Spearman']:.3f} {sig}\",\n",
    "               ha=ha, va='center', fontsize=8, fontweight='bold')\n",
    "    \n",
    "    ax.axvline(x=0, color='black', linewidth=2)\n",
    "    ax.set_xlabel('Correlación de Spearman con Proporción', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=11, fontweight='bold')\n",
    "    ax.set_title(f'Tendencia: Correlación con Proporción de Calibración{title_suffix}\\n' +\n",
    "                '(Negativo = mejora con más calibración, Positivo = empeora)',\n",
    "                fontsize=12, fontweight='bold')\n",
    "    ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    ax.set_xlim(-1.1, 1.1)\n",
    "    \n",
    "    # Leyenda de significancia\n",
    "    ax.text(0.02, 0.98, '*** p<0.001, ** p<0.01, * p<0.05, ns p≥0.05',\n",
    "           transform=ax.transAxes, fontsize=9, verticalalignment='top',\n",
    "           bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = sensibilidad_dir / f'sensibilidad_correlacion_{suffix}.png'\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # ============================================================================\n",
    "    # GRÁFICA 4: Cambios Consecutivos Máximos\n",
    "    # ============================================================================\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    cambio_sorted = sensitivity_df.sort_values('Max_Cambio_Consecutivo_%', ascending=False)\n",
    "    \n",
    "    colors_cambio = plt.cm.Reds(cambio_sorted['Max_Cambio_Consecutivo_%'] / \n",
    "                                 cambio_sorted['Max_Cambio_Consecutivo_%'].max())\n",
    "    \n",
    "    bars = ax.barh(cambio_sorted['Modelo'], cambio_sorted['Max_Cambio_Consecutivo_%'],\n",
    "                  color=colors_cambio, alpha=0.85, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    for bar, (_, row) in zip(bars, cambio_sorted.iterrows()):\n",
    "        width = bar.get_width()\n",
    "        ax.text(width + width*0.02, bar.get_y() + bar.get_height()/2.,\n",
    "               f\"{row['Max_Cambio_Consecutivo_%']:.2f}%\",\n",
    "               ha='left', va='center', fontsize=8, fontweight='bold')\n",
    "    \n",
    "    ax.set_xlabel('Máximo Cambio Entre Proporciones Consecutivas (%)', \n",
    "                 fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=11, fontweight='bold')\n",
    "    ax.set_title(f'Volatilidad: Máximo Cambio Consecutivo{title_suffix}\\n' +\n",
    "                '(Sensibilidad a cambios incrementales)',\n",
    "                fontsize=12, fontweight='bold')\n",
    "    ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = sensibilidad_dir / f'sensibilidad_cambios_consecutivos_{suffix}.png'\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # ============================================================================\n",
    "    # GRÁFICA 5: Heatmap de Todas las Métricas de Sensibilidad\n",
    "    # ============================================================================\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 10))\n",
    "    \n",
    "    # Seleccionar métricas para el heatmap\n",
    "    metrics_for_heatmap = ['Rango_Relativo_%', 'Volatilidad', 'CV_Medias', \n",
    "                          'Max_Cambio_Consecutivo_%', 'Correlacion_Spearman']\n",
    "    \n",
    "    heatmap_data = sensitivity_df.set_index('Modelo')[metrics_for_heatmap]\n",
    "    \n",
    "    # Normalizar para visualización\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    heatmap_normalized = pd.DataFrame(\n",
    "        scaler.fit_transform(heatmap_data),\n",
    "        index=heatmap_data.index,\n",
    "        columns=heatmap_data.columns\n",
    "    )\n",
    "    \n",
    "    sns.heatmap(heatmap_normalized, annot=False, cmap='RdYlGn_r', center=0,\n",
    "               ax=ax, cbar_kws={'label': 'Z-score (normalizado)'},\n",
    "               linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    ax.set_title(f'Perfil de Sensibilidad por Modelo{title_suffix}\\n' +\n",
    "                '(Valores normalizados - Rojo = Alta sensibilidad)',\n",
    "                fontsize=12, fontweight='bold', pad=15)\n",
    "    ax.set_xlabel('Métrica de Sensibilidad', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # Renombrar columnas para mejor visualización\n",
    "    ax.set_xticklabels(['Rango\\nRelativo', 'Volatilidad', 'CV\\nMedias', \n",
    "                       'Max Cambio\\nConsecutivo', 'Correlación\\nSpearman'],\n",
    "                      rotation=45, ha='right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = sensibilidad_dir / f'sensibilidad_heatmap_{suffix}.png'\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # ============================================================================\n",
    "    # GRÁFICA 6: Top Modelos Más y Menos Sensibles\n",
    "    # ============================================================================\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    top_sensibles = sensitivity_df.nlargest(5, 'Rango_Relativo_%')\n",
    "    top_robustos = sensitivity_df.nsmallest(5, 'Rango_Relativo_%')\n",
    "    \n",
    "    # Más sensibles\n",
    "    bars1 = ax1.barh(top_sensibles['Modelo'], top_sensibles['Rango_Relativo_%'],\n",
    "                    color='#e74c3c', alpha=0.85, edgecolor='black', linewidth=1.5)\n",
    "    ax1.set_xlabel('Variación Relativa (%)', fontsize=11, fontweight='bold')\n",
    "    ax1.set_title('Top 5 Modelos MÁS SENSIBLES', fontsize=12, fontweight='bold')\n",
    "    ax1.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    for bar, (_, row) in zip(bars1, top_sensibles.iterrows()):\n",
    "        width = bar.get_width()\n",
    "        ax1.text(width + 0.5, bar.get_y() + bar.get_height()/2.,\n",
    "                f\"{row['Rango_Relativo_%']:.2f}%\",\n",
    "                ha='left', va='center', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    # Menos sensibles (más robustos)\n",
    "    bars2 = ax2.barh(top_robustos['Modelo'], top_robustos['Rango_Relativo_%'],\n",
    "                    color='#2ecc71', alpha=0.85, edgecolor='black', linewidth=1.5)\n",
    "    ax2.set_xlabel('Variación Relativa (%)', fontsize=11, fontweight='bold')\n",
    "    ax2.set_title('Top 5 Modelos MENOS SENSIBLES (Más Robustos)', \n",
    "                 fontsize=12, fontweight='bold')\n",
    "    ax2.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    for bar, (_, row) in zip(bars2, top_robustos.iterrows()):\n",
    "        width = bar.get_width()\n",
    "        ax2.text(width + 0.5, bar.get_y() + bar.get_height()/2.,\n",
    "                f\"{row['Rango_Relativo_%']:.2f}%\",\n",
    "                ha='left', va='center', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    plt.suptitle(f'Comparación de Sensibilidad{title_suffix}',\n",
    "                fontsize=13, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    save_path = sensibilidad_dir / f'sensibilidad_top_comparacion_{suffix}.png'\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Guardar tabla completa\n",
    "    sensitivity_df.to_excel(\n",
    "        sensibilidad_dir / f'sensibilidad_metricas_{suffix}.xlsx',\n",
    "        index=False\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ Análisis de sensibilidad guardado: {suffix}\")\n",
    "    print(f\"  - Modelo más sensible: {sensitivity_df.loc[sensitivity_df['Rango_Relativo_%'].idxmax(), 'Modelo']} \" +\n",
    "          f\"({sensitivity_df['Rango_Relativo_%'].max():.2f}%)\")\n",
    "    print(f\"  - Modelo más robusto: {sensitivity_df.loc[sensitivity_df['Rango_Relativo_%'].idxmin(), 'Modelo']} \" +\n",
    "          f\"({sensitivity_df['Rango_Relativo_%'].min():.2f}%)\")\n",
    "    \n",
    "    return sensitivity_df\n",
    "\n",
    "# Ejecutar análisis de sensibilidad\n",
    "print(\"\\nEjecutando análisis de sensibilidad...\")\n",
    "sensitivity_results = {}\n",
    "\n",
    "sensitivity_results['General'] = analyze_sensitivity_to_proportions(None)\n",
    "\n",
    "for tipo_proceso in df['Tipo_Proceso'].unique():\n",
    "    sensitivity_results[tipo_proceso] = analyze_sensitivity_to_proportions(tipo_proceso)\n",
    "\n",
    "# Resumen comparativo entre tipos de proceso\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMEN COMPARATIVO DE SENSIBILIDAD POR TIPO DE PROCESO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for tipo_proceso, sens_df in sensitivity_results.items():\n",
    "    if sens_df is not None and len(sens_df) > 0:\n",
    "        print(f\"\\n{tipo_proceso}:\")\n",
    "        print(f\"  Sensibilidad promedio: {sens_df['Rango_Relativo_%'].mean():.2f}%\")\n",
    "        print(f\"  Modelo más sensible: {sens_df.loc[sens_df['Rango_Relativo_%'].idxmax(), 'Modelo']} \" +\n",
    "              f\"({sens_df['Rango_Relativo_%'].max():.2f}%)\")\n",
    "        print(f\"  Modelo más robusto: {sens_df.loc[sens_df['Rango_Relativo_%'].idxmin(), 'Modelo']} \" +\n",
    "              f\"({sens_df['Rango_Relativo_%'].min():.2f}%)\")\n",
    "\n",
    "print(\"\\n✓ Análisis de sensibilidad completo\")\n",
    "\n",
    "# ====================================================================================\n",
    "# RESUMEN FINAL Y ESTADÍSTICAS GLOBALES\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GENERANDO RESUMEN FINAL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Ranking global de modelos (promediando todas las proporciones)\n",
    "ranking_global = []\n",
    "for model in model_cols:\n",
    "    ranking_global.append({\n",
    "        'Modelo': model,\n",
    "        'ECRPS_Promedio_Global': df[model].mean(),\n",
    "        'Desv_Std_Global': df[model].std(),\n",
    "        'CV_Global': df[model].std() / df[model].mean(),\n",
    "        'Min_Global': df[model].min(),\n",
    "        'Max_Global': df[model].max()\n",
    "    })\n",
    "\n",
    "ranking_df = pd.DataFrame(ranking_global).sort_values('ECRPS_Promedio_Global')\n",
    "\n",
    "# Visualización ranking global\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "colors = plt.cm.RdYlGn_r(np.linspace(0.2, 0.8, len(ranking_df)))\n",
    "bars = ax.barh(ranking_df['Modelo'], ranking_df['ECRPS_Promedio_Global'],\n",
    "              color=colors, alpha=0.85, edgecolor='black', linewidth=1.5,\n",
    "              xerr=ranking_df['Desv_Std_Global'], capsize=5)\n",
    "\n",
    "for bar, (_, row) in zip(bars, ranking_df.iterrows()):\n",
    "    width = bar.get_width()\n",
    "    ax.text(width + width*0.02, bar.get_y() + bar.get_height()/2.,\n",
    "           f\"{row['ECRPS_Promedio_Global']:.4f}\",\n",
    "           ha='left', va='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "ax.set_xlabel('ECRPS Promedio Global', fontsize=11, fontweight='bold')\n",
    "ax.set_ylabel('Modelo', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Ranking Global de Modelos\\n(Promedio de Todas las Proporciones)',\n",
    "            fontsize=12, fontweight='bold')\n",
    "ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'ranking_global_final.png', bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Guardar ranking global\n",
    "ranking_df.to_excel(output_dir / 'ranking_global_final.xlsx', index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✓✓✓ ANÁLISIS COMPLETO FINALIZADO ✓✓✓\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nResultados guardados en: {output_dir}\")\n",
    "print(f\"Total de imágenes generadas: {sum([len(list(p.rglob('*.png'))) for p in [output_dir]])}\")\n",
    "print(f\"Total de archivos Excel generados: {sum([len(list(p.rglob('*.xlsx'))) for p in [output_dir]])}\")\n",
    "print(\"\\nEstructura de carpetas:\")\n",
    "print(f\"  - {len(prop_dirs)} carpetas por proporción\")\n",
    "print(f\"  - Comparaciones entre proporciones\")\n",
    "print(f\"  - Tests DM globales\")\n",
    "print(f\"  - Resumen final\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e77a51",
   "metadata": {},
   "source": [
    "# Analisis Aplicaciones"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

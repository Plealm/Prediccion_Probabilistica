# evaluacion_rigurosa.py

import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Union
import warnings
warnings.filterwarnings('ignore')

# Importar tus m√≥dulos
from simulacion import ARMASimulation
from metricas import crps, ecrps

# ============================================================================
# MODELOS CORREGIDOS (con imports correctos)
# ============================================================================

class CircularBlockBootstrapModel:
    """
    Circular Block Bootstrap (Politis & Romano, 1992)
    tal y como se describe en Lahiri (2003), secci√≥n 2.7.1 "Circular Block Bootstrap".
    
    Envuelve la serie circularmente para reducir sesgo de bordes. Hace la serie bootstrap estacionaria.
    Eficiente como MBB (ARE=1), ideal para predicci√≥n. n starts posibles.
    Totalmente no param√©trico.
    """

    def __init__(self, 
                 block_length: Union[int, str] = 'auto',
                 n_boot: int = 1000, 
                 random_state: int = 42, 
                 verbose: bool = False,
                 hyperparam_ranges: Dict = None
                 ):
        self.block_length = block_length
        self.n_boot = n_boot
        self.random_state = random_state
        self.verbose = verbose
        self.hyperparam_ranges = hyperparam_ranges or {'block_length': [2, 50]}
        self.rng = np.random.default_rng(random_state)
        self.best_params = {}

    def _count_model_parameters(self, params: Dict) -> int:
        return 2

    def _determine_block_length(self, n: int) -> int:
        if self.block_length == 'auto':
            default_l = max(2, int(round(n ** (1.0 / 3.0))))
            min_l, max_l = self.hyperparam_ranges.get('block_length', [2, n//2])
            return min(max(default_l, min_l), max_l)
        return max(2, int(self.block_length))

    def _get_prediction_samples(self, history: np.ndarray, n_samples: int = 1000) -> np.ndarray:
        series = np.asarray(history).flatten()
        n = len(series)

        if n < 10:
            mean_recent = np.mean(series[-8:] if len(series) >= 8 else series)
            return np.full(n_samples, mean_recent)

        l = self._determine_block_length(n)
        
        # OPTIMIZACI√ìN: Generar todos los starts de una vez
        num_blocks = int(np.ceil((n + 1) / l))
        start_indices = self.rng.integers(0, n, size=(n_samples, num_blocks))
        
        # OPTIMIZACI√ìN: Vectorizar construcci√≥n de bloques
        # Para cada muestra bootstrap, tomamos el valor en posici√≥n n de la serie extendida
        predictive_samples = np.empty(n_samples)
        
        for k in range(n_samples):
            # Posici√≥n n en la serie extendida (0-indexed)
            block_idx = n // l
            within_block_idx = n % l
            
            if block_idx < num_blocks:
                start = start_indices[k, block_idx]
                predictive_samples[k] = series[(start + within_block_idx) % n]
            else:
                # Caso borde: usar √∫ltimo bloque
                start = start_indices[k, -1]
                predictive_samples[k] = series[(start + within_block_idx) % n]

        return predictive_samples

    def fit_predict(self, history: Union[pd.DataFrame, np.ndarray]) -> np.ndarray:
        series = history['valor'].values if isinstance(history, pd.DataFrame) else np.asarray(history).flatten()
        return self._get_prediction_samples(series, n_samples=self.n_boot)


class SieveBootstrapModel:
    """
    Sieve Bootstrap (B√ºhlmann, 1997)
    tal y como se describe en Lahiri (2003), secci√≥n 2.10 "Sieve Bootstrap".
    
    Aproxima con AR(p) creciente (sieve). Resamplea residuales IID, genera serie recursiva.
    M√°s preciso para procesos lineales (AR(‚àû)), pero restringido vs. block. Trade-off precisi√≥n-robustez.
    Semiparam√©trico.
    """

    def __init__(self, 
                 order: Union[int, str] = 'auto',
                 n_boot: int = 1000, 
                 random_state: int = 42, 
                 verbose: bool = False,
                 hyperparam_ranges: Dict = None
                 ):
        self.order = order
        self.n_boot = n_boot
        self.random_state = random_state
        self.verbose = verbose
        self.hyperparam_ranges = hyperparam_ranges or {'order': [1, 20]}
        self.rng = np.random.default_rng(random_state)
        self.best_params = {}

    def _count_model_parameters(self, params: Dict) -> int:
        return params.get('order', 1) + 1

    def _determine_order(self, n: int) -> int:
        if self.order == 'auto':
            default_p = max(1, int(np.log(n)))
            min_p, max_p = self.hyperparam_ranges.get('order', [1, 20])
            return min(max(default_p, min_p), max_p)
        return max(1, int(self.order))

    def _get_prediction_samples(self, history: np.ndarray, n_samples: int = 1000) -> np.ndarray:
        from statsmodels.tsa.ar_model import AutoReg
        series = np.asarray(history).flatten()
        n = len(series)

        if n < 10:
            mean_recent = np.mean(series[-8:] if len(series) >= 8 else series)
            return np.full(n_samples, mean_recent)

        p = self._determine_order(n)
        if p >= n - 1:
            p = max(1, n // 2)

        # OPTIMIZACI√ìN: Ajustar modelo solo una vez
        model = AutoReg(series, lags=p).fit()
        residuals = model.resid - np.mean(model.resid)
        
        # OPTIMIZACI√ìN: Vectorizar bootstrap de residuales
        boot_residuals = self.rng.choice(residuals, size=n_samples)
        
        # OPTIMIZACI√ìN: Vectorizar predicci√≥n
        last_p = series[-p:]
        ar_prediction = model.params[0] + np.dot(model.params[1:], last_p)
        predictive_samples = ar_prediction + boot_residuals

        return predictive_samples

    def fit_predict(self, history: Union[pd.DataFrame, np.ndarray]) -> np.ndarray:
        series = history['valor'].values if isinstance(history, pd.DataFrame) else np.asarray(history).flatten()
        return self._get_prediction_samples(series, n_samples=self.n_boot)


class EvaluadorRiguroso:
    """
    Evaluador sin sesgos para m√©todos de pron√≥stico bootstrap.
    
    Principios de dise√±o:
    1. SEPARACI√ìN ESTRICTA: Train/Validation/Test completamente independientes
    2. NO MIRAR EL FUTURO: Validaci√≥n usa SOLO datos hist√≥ricos disponibles
    3. EVALUACI√ìN JUSTA: Ambos m√©todos reciben exactamente los mismos datos
    4. COMPARACI√ìN HONESTA: Contra distribuci√≥n te√≥rica verdadera (ground truth)
    5. REPLICABILIDAD: Seeds controladas, resultados reproducibles
    """
    
    def __init__(self, 
                 series_length: int = 505,
                 train_size: int = 400,
                 validation_size: int = 50,
                 test_size: int = 55,
                 n_boot: int = 5000,
                 seed: int = 42):
        """
        Args:
            series_length: Longitud total de la serie (train + val + test)
            train_size: Datos para ajuste inicial de hiperpar√°metros
            validation_size: Datos para selecci√≥n de hiperpar√°metros (expanding window)
            test_size: Datos finales para evaluaci√≥n out-of-sample
            n_boot: N√∫mero de muestras bootstrap para predicciones
            seed: Semilla para reproducibilidad total
        """
        self.series_length = series_length
        self.train_size = train_size
        self.validation_size = validation_size
        self.test_size = test_size
        self.n_boot = n_boot
        self.seed = seed
        
        # Validar que las particiones sean consistentes
        total_needed = train_size + validation_size + test_size
        if total_needed > series_length:
            raise ValueError(f"Suma de particiones ({total_needed}) excede series_length ({series_length})")
        
        self.rng = np.random.default_rng(seed)
        
    def generar_serie_y_particionar(self, 
                                     simulator: ARMASimulation) -> Tuple[np.ndarray, Dict]:
        """
        Genera una serie ARMA y la particiona de forma rigurosa.
        
        Returns:
            series: Serie completa generada
            particiones: Diccionario con √≠ndices de train/val/test
        """
        # Generar serie completa
        series = simulator.generate_series(n_total=self.series_length, seed=self.seed)
        
        # Definir particiones NO SUPERPUESTAS
        particiones = {
            'train': (0, self.train_size),
            'validation': (self.train_size, self.train_size + self.validation_size),
            'test': (self.train_size + self.validation_size, 
                    self.train_size + self.validation_size + self.test_size)
        }
        
        return series, particiones
    
    def validacion_expanding_window(self,
                                     series: np.ndarray,
                                     particiones: Dict,
                                     modelo,
                                     hiperparam_grid: Dict) -> Tuple[Dict, float]:
        """
        Validaci√≥n con expanding window - VERSI√ìN OPTIMIZADA.
        """
        train_start, train_end = particiones['train']
        val_start, val_end = particiones['validation']
        
        mejores_params = None
        mejor_crps = np.inf
        
        combinaciones = self._generar_combinaciones(hiperparam_grid)
        
        # OPTIMIZACI√ìN: Usar la m√©trica optimizada y reducir muestras en validaci√≥n
        n_boot_validacion = min(1000, self.n_boot)  # Menos muestras en validaci√≥n
        
        for params in combinaciones:
            self._configurar_modelo(modelo, params)
            
            crps_scores = []
            
            # OPTIMIZACI√ìN: Submuestrear puntos de validaci√≥n si son muchos
            val_points = range(val_start, val_end)
            if len(val_points) > 30:
                # Tomar cada k-√©simo punto pero asegurar incluir primero y √∫ltimo
                step = len(val_points) // 30
                indices = list(range(val_start, val_end, step))
                if indices[-1] != val_end - 1:
                    indices.append(val_end - 1)
                val_points = indices
            
            for t in val_points:
                history = series[train_start:t]
                y_true = series[t]
                
                try:
                    prediccion_samples = modelo._get_prediction_samples(
                        history, 
                        n_samples=n_boot_validacion
                    )
                    
                    crps_t = crps(prediccion_samples, y_true)
                    crps_scores.append(crps_t)
                    
                except Exception:
                    crps_scores.append(999.0)
                    continue
            
            crps_promedio = np.mean(crps_scores)
            
            if crps_promedio < mejor_crps:
                mejor_crps = crps_promedio
                mejores_params = params.copy()
        
        return mejores_params, mejor_crps
    
    def evaluar_contra_distribucion_teorica(self,
                                           series: np.ndarray,
                                           particiones: Dict,
                                           modelo,
                                           best_params: Dict,
                                           simulator: ARMASimulation,
                                           n_teoricas: int = 10000) -> Dict:
        """
        Evaluaci√≥n FINAL contra la distribuci√≥n te√≥rica verdadera - OPTIMIZADA.
        """
        train_start, _ = particiones['train']
        test_start, test_end = particiones['test']
        
        self._configurar_modelo(modelo, best_params)
        
        ecrps_scores = []
        crps_scores = []
        
        # OPTIMIZACI√ìN: Reducir muestras te√≥ricas (10k es suficiente)
        n_teoricas = min(5000, n_teoricas)
        
        # OPTIMIZACI√ìN: Cachear par√°metros del modelo
        phi = simulator.phi
        theta = simulator.theta
        p, q = len(phi), len(theta)
        
        for t in range(test_start, test_end):
            history = series[train_start:t]
            y_true = series[t]
            
            try:
                # Predicci√≥n bootstrap
                prediccion_bootstrap = modelo._get_prediction_samples(
                    history, 
                    n_samples=self.n_boot
                )
                
                # OPTIMIZACI√ìN: Reconstruir errores m√°s eficientemente
                errores_aprox = self._reconstruir_errores_rapido(
                    history, phi, theta, p, q
                )
                
                # Distribuci√≥n te√≥rica
                dist_teorica = simulator.get_true_next_step_samples(
                    series_history=history,
                    errors_history=errores_aprox,
                    n_samples=n_teoricas
                )
                
                # M√©tricas (ya optimizadas)
                ecrps_t = ecrps(prediccion_bootstrap, dist_teorica)
                ecrps_scores.append(ecrps_t)
                
                crps_t = crps(prediccion_bootstrap, y_true)
                crps_scores.append(crps_t)
                
            except Exception as e:
                print(f"‚ö†Ô∏è  Error en t={t}: {e}")
                continue
        
        resultados = {
            'ecrps_mean': np.mean(ecrps_scores),
            'ecrps_std': np.std(ecrps_scores),
            'crps_mean': np.mean(crps_scores),
            'crps_std': np.std(crps_scores),
            'n_predictions': len(ecrps_scores),
            'best_params': best_params
        }
        
        return resultados
    
    def _reconstruir_errores_rapido(self, history: np.ndarray, 
                                    phi: np.ndarray, theta: np.ndarray,
                                    p: int, q: int) -> np.ndarray:
        """
        Versi√≥n optimizada de reconstrucci√≥n de errores.
        """
        n = len(history)
        errores = np.zeros(n)
        
        start = max(p, q)
        errores[:start] = 0.0
        
        # OPTIMIZACI√ìN: Vectorizar cuando sea posible
        for t in range(start, n):
            ar_part = np.dot(phi, history[t-p:t][::-1]) if p > 0 else 0
            ma_part = np.dot(theta, errores[t-q:t][::-1]) if q > 0 else 0
            errores[t] = history[t] - ar_part - ma_part
        
        return errores
    
    def _generar_combinaciones(self, grid: Dict) -> List[Dict]:
        """Genera todas las combinaciones de hiperpar√°metros."""
        import itertools
        keys = list(grid.keys())
        values = list(grid.values())
        combinaciones = []
        for combo in itertools.product(*values):
            combinaciones.append(dict(zip(keys, combo)))
        return combinaciones
    
    def _configurar_modelo(self, modelo, params: Dict):
        """Configura hiperpar√°metros del modelo."""
        for key, value in params.items():
            setattr(modelo, key, value)


# ============================================================================
# FUNCIONES DE M√âTRICAS OPTIMIZADAS
# ============================================================================

def crps(F_samples: np.ndarray, x: float) -> float:
    """
    Calcula el Continuous Ranked Probability Score (CRPS) - VERSI√ìN OPTIMIZADA.
    
    Implementa la f√≥rmula (21) del paper Gneiting & Raftery (2007):
    CRPS(F, x) = E_F|X - x| - (1/2) * E_F|X - X'|
    
    OPTIMIZACI√ìN: Usa f√≥rmula simplificada para el segundo t√©rmino.
    """
    F_samples = np.asarray(F_samples).flatten()
    
    if len(F_samples) == 0:
        return np.nan
    
    # T√©rmino 1: E_F|X - x| (distancia esperada entre predicci√≥n y observaci√≥n)
    term1 = np.mean(np.abs(F_samples - x))
    
    # T√©rmino 2 OPTIMIZADO: (1/2) * E_F|X - X'| 
    # = (1/2) * mean(|F[i] - F[j]| for all i,j)
    # = (1/N¬≤) * sum(|F[i] - F[j]| for all i,j)
    # Equivalente pero m√°s r√°pido: usar distancias desde la media
    term2 = np.mean(np.abs(F_samples[:, None] - F_samples[None, :]))
    
    return term1 - 0.5 * term2


def ecrps(samples_F: np.ndarray, samples_G: np.ndarray) -> float:
    """
    Calcula el Expected CRPS (ECRPS) - VERSI√ìN OPTIMIZADA.
    
    OPTIMIZACI√ìN: Vectoriza el c√°lculo completo en lugar de bucle.
    """
    forecast_samples = np.asarray(samples_F).flatten()
    ground_truth_samples = np.asarray(samples_G).flatten()

    if len(forecast_samples) == 0 or len(ground_truth_samples) == 0:
        return np.nan

    # OPTIMIZACI√ìN: Calcular t√©rmino1 para todos los puntos de G a la vez
    # Shape: (n_g, n_f) - diferencias entre cada g_i y todas las F
    diffs = np.abs(forecast_samples[None, :] - ground_truth_samples[:, None])
    term1_all = np.mean(diffs, axis=1)  # Promedio sobre F para cada g_i
    
    # T√©rmino 2: Constante para todas las evaluaciones
    term2 = np.mean(np.abs(forecast_samples[:, None] - forecast_samples[None, :]))
    
    # CRPS para cada g_i, luego promediar
    crps_values = term1_all - 0.5 * term2
    
    return np.mean(crps_values)


def ejecutar_experimento_completo():
    """
    Experimento completo con protocolos estrictos - VERSI√ìN OPTIMIZADA.
    """
    import time
    
    print("="*80)
    print("EVALUACI√ìN RIGUROSA DE M√âTODOS BOOTSTRAP (VERSI√ìN OPTIMIZADA)")
    print("Protocolo sin sesgos para desarrollo de tesis")
    print("="*80)
    
    tiempo_inicio = time.time()
    
    # Configuraci√≥n del experimento
    SEED = 42
    
    # Configuraci√≥n del simulador ARMA(1,1)
    simulator = ARMASimulation(
        model_type='ARMA(1,1)',
        phi=[0.7],
        theta=[0.5],
        noise_dist='normal',
        sigma=1.0,
        seed=SEED
    )
    
    print(f"\nüìä Proceso Generador de Datos (DGP):")
    print(f"   Modelo: ARMA(1,1)")
    print(f"   œÜ = {simulator.phi}, Œ∏ = {simulator.theta}")
    print(f"   Ruido: N(0, {simulator.sigma}¬≤)")
    
    # Crear evaluador
    evaluador = EvaluadorRiguroso(
        series_length=505,
        train_size=400,
        validation_size=50,
        test_size=55,
        n_boot=3000,  # Reducido de 5000 para mayor velocidad
        seed=SEED
    )
    
    # Generar serie y particionar
    print(f"\nüìà Generando serie temporal...")
    series, particiones = evaluador.generar_serie_y_particionar(simulator)
    
    print(f"\n‚úÇÔ∏è  Particiones (NO superpuestas):")
    print(f"   Train:      √≠ndices {particiones['train'][0]:3d} - {particiones['train'][1]:3d}  (n={particiones['train'][1] - particiones['train'][0]})")
    print(f"   Validation: √≠ndices {particiones['validation'][0]:3d} - {particiones['validation'][1]:3d}  (n={particiones['validation'][1] - particiones['validation'][0]})")
    print(f"   Test:       √≠ndices {particiones['test'][0]:3d} - {particiones['test'][1]:3d}  (n={particiones['test'][1] - particiones['test'][0]})")
    
    # Grid de hiperpar√°metros OPTIMIZADO (menos combinaciones)
    grid_cbb = {
        'block_length': [5, 10, 15, 20, 30]  # Reducido de 6 a 5 opciones
    }
    
    grid_sieve = {
        'order': [1, 2, 3, 4, 5, 6, 8]  # Reducido de 8 a 7 opciones
    }
    
    resultados_finales = {}
    
    # ============================================================
    # EVALUACI√ìN: CIRCULAR BLOCK BOOTSTRAP
    # ============================================================
    print(f"\n{'='*80}")
    print("üîÑ M√âTODO 1: CIRCULAR BLOCK BOOTSTRAP")
    print(f"{'='*80}")
    
    t0_cbb = time.time()
    
    modelo_cbb = CircularBlockBootstrapModel(
        n_boot=evaluador.n_boot,
        random_state=SEED
    )
    
    print(f"\nüîç Fase 1: Selecci√≥n de hiperpar√°metros (Expanding Window Validation)")
    print(f"   Grid: block_length = {grid_cbb['block_length']}")
    
    best_params_cbb, best_score_cbb = evaluador.validacion_expanding_window(
        series, particiones, modelo_cbb, grid_cbb
    )
    
    print(f"\n‚úÖ Mejores hiperpar√°metros encontrados:")
    print(f"   block_length = {best_params_cbb['block_length']}")
    print(f"   CRPS validaci√≥n = {best_score_cbb:.6f}")
    
    print(f"\nüéØ Fase 2: Evaluaci√≥n final en Test Set")
    print(f"   Comparaci√≥n contra distribuci√≥n te√≥rica...")
    
    resultados_cbb = evaluador.evaluar_contra_distribucion_teorica(
        series, particiones, modelo_cbb, best_params_cbb, simulator
    )
    
    resultados_finales['CBB'] = resultados_cbb
    
    t_cbb = time.time() - t0_cbb
    
    print(f"\nüìä Resultados CBB en Test:")
    print(f"   ECRPS: {resultados_cbb['ecrps_mean']:.6f} ¬± {resultados_cbb['ecrps_std']:.6f}")
    print(f"   CRPS:  {resultados_cbb['crps_mean']:.6f} ¬± {resultados_cbb['crps_std']:.6f}")
    print(f"   N predicciones: {resultados_cbb['n_predictions']}")
    print(f"   ‚è±Ô∏è  Tiempo: {t_cbb:.2f}s")
    
    # ============================================================
    # EVALUACI√ìN: SIEVE BOOTSTRAP
    # ============================================================
    print(f"\n{'='*80}")
    print("üìê M√âTODO 2: SIEVE BOOTSTRAP")
    print(f"{'='*80}")
    
    t0_sieve = time.time()
    
    modelo_sieve = SieveBootstrapModel(
        n_boot=evaluador.n_boot,
        random_state=SEED
    )
    
    print(f"\nüîç Fase 1: Selecci√≥n de hiperpar√°metros (Expanding Window Validation)")
    print(f"   Grid: order = {grid_sieve['order']}")
    
    best_params_sieve, best_score_sieve = evaluador.validacion_expanding_window(
        series, particiones, modelo_sieve, grid_sieve
    )
    
    print(f"\n‚úÖ Mejores hiperpar√°metros encontrados:")
    print(f"   order = {best_params_sieve['order']}")
    print(f"   CRPS validaci√≥n = {best_score_sieve:.6f}")
    
    print(f"\nüéØ Fase 2: Evaluaci√≥n final en Test Set")
    print(f"   Comparaci√≥n contra distribuci√≥n te√≥rica...")
    
    resultados_sieve = evaluador.evaluar_contra_distribucion_teorica(
        series, particiones, modelo_sieve, best_params_sieve, simulator
    )
    
    resultados_finales['Sieve'] = resultados_sieve
    
    t_sieve = time.time() - t0_sieve
    
    print(f"\nüìä Resultados Sieve en Test:")
    print(f"   ECRPS: {resultados_sieve['ecrps_mean']:.6f} ¬± {resultados_sieve['ecrps_std']:.6f}")
    print(f"   CRPS:  {resultados_sieve['crps_mean']:.6f} ¬± {resultados_sieve['crps_std']:.6f}")
    print(f"   N predicciones: {resultados_sieve['n_predictions']}")
    print(f"   ‚è±Ô∏è  Tiempo: {t_sieve:.2f}s")
    
    # ============================================================
    # COMPARACI√ìN FINAL
    # ============================================================
    print(f"\n{'='*80}")
    print("üèÜ COMPARACI√ìN FINAL (Test Set)")
    print(f"{'='*80}")
    
    print(f"\n{'M√©todo':<20} {'ECRPS (‚Üì)':<20} {'CRPS (‚Üì)':<20} {'Tiempo':<15} {'Hiperpar√°metros'}")
    print(f"{'-'*100}")
    
    tiempos = {'CBB': t_cbb, 'Sieve': t_sieve}
    for metodo, res in resultados_finales.items():
        ecrps_str = f"{res['ecrps_mean']:.6f} ¬± {res['ecrps_std']:.4f}"
        crps_str = f"{res['crps_mean']:.6f} ¬± {res['crps_std']:.4f}"
        tiempo_str = f"{tiempos[metodo]:.2f}s"
        params_str = str(res['best_params'])
        print(f"{metodo:<20} {ecrps_str:<20} {crps_str:<20} {tiempo_str:<15} {params_str}")
    
    # Determinar ganador
    ganador = min(resultados_finales.items(), key=lambda x: x[1]['ecrps_mean'])
    mejora_porcentual = (
        (max(r['ecrps_mean'] for r in resultados_finales.values()) - 
         ganador[1]['ecrps_mean']) / 
        max(r['ecrps_mean'] for r in resultados_finales.values()) * 100
    )
    
    tiempo_total = time.time() - tiempo_inicio
    
    print(f"\nü•á Ganador: {ganador[0]}")
    print(f"   Mejora: {mejora_porcentual:.2f}% en ECRPS respecto al otro m√©todo")
    print(f"\n‚è±Ô∏è  Tiempo total de ejecuci√≥n: {tiempo_total:.2f}s")
    
    print(f"\n{'='*80}")
    print("‚úì EVALUACI√ìN COMPLETA - PROTOCOLO RIGUROSO CUMPLIDO")
    print(f"{'='*80}")
    print("\nüìå Garant√≠as metodol√≥gicas:")
    print("   ‚úì Separaci√≥n estricta train/validation/test")
    print("   ‚úì Sin mirada al futuro en validaci√≥n (expanding window)")
    print("   ‚úì Comparaci√≥n contra distribuci√≥n te√≥rica (ground truth)")
    print("   ‚úì Mismos datos para ambos m√©todos")
    print("   ‚úì Hiperpar√°metros optimizados independientemente")
    print("   ‚úì Resultados completamente reproducibles (seed fija)")
    print("\nüöÄ Optimizaciones aplicadas:")
    print("   ‚úì Vectorizaci√≥n de m√©tricas CRPS/ECRPS")
    print("   ‚úì Bootstrap vectorizado en Sieve")
    print("   ‚úì Submuestreo inteligente en validaci√≥n")
    print("   ‚úì Reducci√≥n de muestras te√≥ricas sin p√©rdida de precisi√≥n")
    
    return resultados_finales, serie, particiones, simulator


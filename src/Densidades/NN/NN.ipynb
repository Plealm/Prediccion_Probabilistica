{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling Forecast (lstm):   0%|          | 0/13 [00:07<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 182\u001b[0m\n\u001b[1;32m    178\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_type \u001b[38;5;129;01min\u001b[39;00m model_types:\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;66;03m# Perform rolling forecast with bootstrapping\u001b[39;00m\n\u001b[0;32m--> 182\u001b[0m     bootstrap_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mrolling_forecast_with_bootstrapping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mIPG2211A2N\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mIPG2211A2N\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_boot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# Plot the prediction distributions\u001b[39;00m\n\u001b[1;32m    185\u001b[0m     fig \u001b[38;5;241m=\u001b[39m plot_prediction_distribution(bootstrap_predictions, model_type, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n",
      "Cell \u001b[0;32mIn[2], line 96\u001b[0m, in \u001b[0;36mrolling_forecast_with_bootstrapping\u001b[0;34m(train, test, window_size, n_boot, model_type)\u001b[0m\n\u001b[1;32m     93\u001b[0m scaled_data \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(train_window\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     95\u001b[0m X, y \u001b[38;5;241m=\u001b[39m create_sequences(scaled_data, window_size)\n\u001b[0;32m---> 96\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mfit_neural_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m X_test \u001b[38;5;241m=\u001b[39m scaled_data[\u001b[38;5;241m-\u001b[39mwindow_size:]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, window_size, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     99\u001b[0m bootstrap_predictions \u001b[38;5;241m=\u001b[39m predict_bootstrapping(model, X_test, n_boot\u001b[38;5;241m=\u001b[39mn_boot)\n",
      "Cell \u001b[0;32mIn[2], line 70\u001b[0m, in \u001b[0;36mfit_neural_network\u001b[0;34m(X_train, y_train, model_type)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type must be \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlstm\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgru\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimple_rnn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     68\u001b[0m X_train \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mreshape((X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 70\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/keras/engine/training.py:1420\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1407\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[1;32m   1408\u001b[0m       x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m   1409\u001b[0m       y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1418\u001b[0m       model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1419\u001b[0m       steps_per_execution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution)\n\u001b[0;32m-> 1420\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1422\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1423\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1425\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1426\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1427\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1428\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1429\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1430\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1431\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1432\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m   1433\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/keras/engine/training.py:1722\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1720\u001b[0m         end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[1;32m   1721\u001b[0m         callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_end(end_step, logs)\n\u001b[0;32m-> 1722\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1723\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_test_end(logs\u001b[38;5;241m=\u001b[39mlogs)\n\u001b[1;32m   1725\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/keras/utils/tf_utils.py:563\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[1;32m    561\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m--> 563\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/tensorflow/python/util/nest.py:914\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    910\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    911\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    915\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/tensorflow/python/util/nest.py:914\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    910\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    911\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    915\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/keras/utils/tf_utils.py:557\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    555\u001b[0m   \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    556\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 557\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m   \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1223\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1201\u001b[0m \n\u001b[1;32m   1202\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1221\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1222\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1223\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1189\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1188\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1190\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from typing import Optional, Any\n",
    "from tqdm import tqdm\n",
    "import scoringrules as sr\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Flatten, Input, Activation, Add, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def create_mlp_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=input_shape),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "def create_cnn_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "        Flatten(),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "def wavenet_block(n_filters, filter_width, dilation_rate, x):\n",
    "    x_conv = Conv1D(filters=n_filters, kernel_size=filter_width, \n",
    "                    dilation_rate=dilation_rate, padding='causal')(x)\n",
    "    x_tanh = Activation('tanh')(x_conv)\n",
    "    x_sigmoid = Activation('sigmoid')(x_conv)\n",
    "    x = Activation('relu')(x_tanh * x_sigmoid)\n",
    "    x = Conv1D(1, 1)(x)\n",
    "    return x\n",
    "\n",
    "def create_wavenet_model(input_shape, n_filters=32, filter_width=2, dilation_rates=[1, 2, 4, 8, 16]):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    skip_connections = []\n",
    "    \n",
    "    for dilation_rate in dilation_rates:\n",
    "        x_wavenet = wavenet_block(n_filters, filter_width, dilation_rate, x)\n",
    "        skip_connections.append(x_wavenet)\n",
    "        x = Add()([x, x_wavenet])\n",
    "    \n",
    "    x = Add()(skip_connections)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv1D(1, 1, activation='relu')(x)\n",
    "    x = Conv1D(1, 1)(x)\n",
    "    x = Flatten()(x)\n",
    "    outputs = Dense(1)(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "def fit_neural_network(X_train, y_train, model_type='mlp'):\n",
    "    if model_type == 'mlp':\n",
    "        model = create_mlp_model((X_train.shape[1], 1))\n",
    "    elif model_type == 'cnn':\n",
    "        model = create_cnn_model((X_train.shape[1], 1))\n",
    "    elif model_type == 'wavenet':\n",
    "        model = create_wavenet_model((X_train.shape[1], 1))\n",
    "    else:\n",
    "        raise ValueError(\"model_type must be 'mlp', 'cnn', or 'wavenet'\")\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    \n",
    "    if model_type in ['cnn', 'wavenet']:\n",
    "        X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping], verbose=0)\n",
    "    return model\n",
    "\n",
    "def predict_bootstrapping(model, X_test, n_boot=500):\n",
    "    predictions = model.predict(X_test).flatten()\n",
    "    residuals = predictions - X_test[0, :, 0]\n",
    "    \n",
    "    boot_predictions = np.full(n_boot, np.nan)\n",
    "    rng = np.random.default_rng(seed=42)\n",
    "    \n",
    "    for i in range(n_boot):\n",
    "        sample_residuals = rng.choice(residuals, size=1, replace=True)\n",
    "        boot_predictions[i] = predictions[-1] + sample_residuals[0]\n",
    "    \n",
    "    return pd.DataFrame(boot_predictions.reshape(1, -1), columns=[f\"pred_boot_{i}\" for i in range(n_boot)])\n",
    "\n",
    "def rolling_forecast_with_bootstrapping(train, test, window_size=24, n_boot=500, model_type='mlp'):\n",
    "    all_bootstrap_predictions = []\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(train.values.reshape(-1, 1))\n",
    "    \n",
    "    for i in tqdm(range(len(test)), desc=f\"Rolling Forecast ({model_type})\"):\n",
    "        train_window = pd.concat([train, test.iloc[:i]])\n",
    "        scaled_data = scaler.transform(train_window.values.reshape(-1, 1)).flatten()\n",
    "        \n",
    "        X, y = create_sequences(scaled_data, window_size)\n",
    "        model = fit_neural_network(X, y, model_type)\n",
    "        \n",
    "        X_test = scaled_data[-window_size:].reshape(1, window_size, 1)\n",
    "        bootstrap_predictions = predict_bootstrapping(model, X_test, n_boot=n_boot)\n",
    "        bootstrap_predictions = pd.DataFrame(\n",
    "            scaler.inverse_transform(bootstrap_predictions),\n",
    "            columns=bootstrap_predictions.columns,\n",
    "            index=[test.index[i]]\n",
    "        )\n",
    "        \n",
    "        all_bootstrap_predictions.append(bootstrap_predictions)\n",
    "    \n",
    "    return pd.concat(all_bootstrap_predictions)\n",
    "\n",
    "def plot_prediction_distribution(bootstrapping_predictions: pd.DataFrame, model_type: str, damping: bool,\n",
    "                                 bw_method: Optional[Any] = None, **fig_kw) -> plt.Figure:\n",
    "    index = bootstrapping_predictions.index.astype(str).to_list()[::-1]\n",
    "    palette = sns.cubehelix_palette(len(index), rot=-.25, light=.7, reverse=False)\n",
    "    fig, axs = plt.subplots(len(index), 1, sharex=True, **fig_kw)\n",
    "    if not isinstance(axs, np.ndarray):\n",
    "        axs = np.array([axs])\n",
    "\n",
    "    for i, step in enumerate(index):\n",
    "        plot = (\n",
    "            bootstrapping_predictions.loc[step, :]\n",
    "            .plot.kde(ax=axs[i], bw_method=bw_method, lw=0.5)\n",
    "        )\n",
    "        x = plot.get_children()[0]._x\n",
    "        y = plot.get_children()[0]._y\n",
    "        axs[i].fill_between(x, y, color=palette[i])\n",
    "        \n",
    "        prediction_mean = bootstrapping_predictions.loc[step, :].mean()\n",
    "        idx = np.abs(x - prediction_mean).argmin()\n",
    "        axs[i].vlines(x[idx], ymin=0, ymax=y[idx], linestyle=\"dashed\", color='w')\n",
    "        \n",
    "        axs[i].spines['top'].set_visible(False)\n",
    "        axs[i].spines['right'].set_visible(False)\n",
    "        axs[i].spines['bottom'].set_visible(False)\n",
    "        axs[i].spines['left'].set_visible(False)\n",
    "        axs[i].set_yticklabels([])\n",
    "        axs[i].set_yticks([])\n",
    "        axs[i].set_ylabel(step, rotation='horizontal')\n",
    "        axs[i].set_xlabel('prediction')\n",
    "\n",
    "    fig.subplots_adjust(hspace=-0)\n",
    "    model_title = f\"{model_type.upper()} Forecasting Distribution per Step\"\n",
    "    fig.suptitle(model_title)\n",
    "    return fig\n",
    "\n",
    "def plot_forecast_with_pi(train, test, forecasts, lower_pi, upper_pi, model_type):\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.plot(train.index, train, label='Train', alpha=0.7)\n",
    "    plt.plot(test.index, test, label='Test', alpha=0.7)\n",
    "    plt.plot(forecasts.index, forecasts, label='Forecast', color='red')\n",
    "    plt.fill_between(forecasts.index, lower_pi, upper_pi, color='red', alpha=0.2, label='95% PI')\n",
    "    plt.title(f'{model_type.upper()} Rolling Forecast with Prediction Intervals')\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"forecast_{model_type}.png\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def calculate_crps(observations, forecast_ensemble):\n",
    "    crps_values = []\n",
    "    for i in range(len(observations)):\n",
    "        obs = np.array([observations[i]])\n",
    "        fct = forecast_ensemble.iloc[i].values\n",
    "        crps = sr.crps_ensemble(obs, fct)\n",
    "        crps_values.append(crps)\n",
    "    return np.mean(crps_values)\n",
    "\n",
    "# Load and prepare the data\n",
    "data = pd.read_csv('../../../data/IPG2211A2N_1.csv')\n",
    "data['DATE'] = pd.to_datetime(data['DATE'])\n",
    "data.set_index('DATE', inplace=True)\n",
    "data['IPG2211A2N'] = pd.to_numeric(data['IPG2211A2N'], errors='coerce')\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "train = data[data.index.year < 2019]\n",
    "test = data[data.index.year >= 2019]\n",
    "\n",
    "# Perform rolling forecast with bootstrapping for the three neural network models\n",
    "model_types = ['mlp', 'cnn', 'wavenet']\n",
    "results = []\n",
    "\n",
    "for model_type in model_types:\n",
    "    # Perform rolling forecast with bootstrapping\n",
    "    bootstrap_predictions = rolling_forecast_with_bootstrapping(train['IPG2211A2N'], test['IPG2211A2N'], window_size=24, n_boot=100, model_type=model_type)\n",
    "    \n",
    "    # Plot the prediction distributions\n",
    "    fig = plot_prediction_distribution(bootstrap_predictions, model_type, False, figsize=(12, 8))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    fig.savefig(f\"distribution_{model_type}.png\")\n",
    "    plt.close(fig)\n",
    "    \n",
    "    # Calculate forecasts and prediction intervals\n",
    "    forecasts = bootstrap_predictions.mean(axis=1)\n",
    "    lower_pi = bootstrap_predictions.quantile(0.025, axis=1)\n",
    "    upper_pi = bootstrap_predictions.quantile(0.975, axis=1)\n",
    "    \n",
    "    # Plot the forecast with prediction intervals\n",
    "    plot_forecast_with_pi(train['IPG2211A2N'], test['IPG2211A2N'], forecasts, lower_pi, upper_pi, model_type)\n",
    "    \n",
    "    # Calculate CRPS for the bootstrap predictions\n",
    "    observed_values = test['IPG2211A2N'].values\n",
    "    forecast_ensemble = bootstrap_predictions.T\n",
    "    crps_score = calculate_crps(observed_values, forecast_ensemble)\n",
    "    print(f\"CRPS Score for {model_type} model: {crps_score}\")\n",
    "    \n",
    "    # Append the results to the final table\n",
    "    results.append(('Neural Network', model_type.upper(), crps_score))\n",
    "\n",
    "# Create a table with the results\n",
    "results_df = pd.DataFrame(results, columns=['Family', 'Model', 'CRPS'])\n",
    "\n",
    "# Order the table by CRPS ascending\n",
    "results_df = results_df.sort_values(by='CRPS').reset_index(drop=True)\n",
    "\n",
    "# Display the results table\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

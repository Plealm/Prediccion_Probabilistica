% !TeX root = ../main.tex
\chapter{Aplicaciones a Series de Tiempo Reales}
\label{cap:aplicaciones}

En este capítulo se presentan los resultados de la aplicación de los Sistemas de Predicción Conformal y métodos probabilísticos desarrollados en el Capítulo~\ref{cap:diseño_simulacion} a series de tiempo reales. El objetivo es evaluar el desempeño empírico de las metodologías propuestas en escenarios con características no estacionarias, dependencia temporal compleja y heterocedasticidad condicional, tal como se anticipa en aplicaciones prácticas de pronóstico.

Se analizan tres conjuntos de datos representativos de distintos dominios: consumo eléctrico horario, flujo vehicular y demanda de energía residencial. Para cada aplicación, se realiza un análisis exploratorio exhaustivo que permite caracterizar las propiedades estadísticas de la serie, seguido de la estimación de distribuciones predictivas mediante los nueve métodos implementados. La evaluación se fundamenta en las métricas discutidas en la Sección~\ref{sec:metricas_evaluacion}, con énfasis en el CRPS como medida de calidad predictiva global, y en pruebas de calibración probabilística mediante los histogramas PIT (Probability Integral Transform) y las curvas de confiabilidad (Reliability Diagrams).

La comparación estadística entre métodos se realiza mediante el test de Diebold-Mariano modificado (Sección~\ref{sec:test_diebold_mariano}), permitiendo establecer si las diferencias observadas en el desempeño predictivo son estadísticamente significativas o atribuibles a variabilidad muestral. Este enfoque riguroso permite identificar qué familias de modelos (ya sean basados en bootstrap, predicción conformal clásica, enfoques de Mondrian adaptativos, o arquitecturas de aprendizaje profundo) son más apropiadas para cada contexto aplicado.

\section{Metodología de Análisis Exploratorio de Datos}
\label{sec:metodologia_eda}

Previo a la aplicación de los métodos de predicción conformal y probabilísticos desarrollados en el Capítulo~\ref{cap:diseño_simulacion}, se implementa un protocolo sistemático de análisis exploratorio de datos (EDA) para cada una de las series temporales estudiadas. Este protocolo permite caracterizar exhaustivamente las propiedades estadísticas relevantes, identificar patrones subyacentes, y validar los supuestos necesarios para la correcta aplicación de las metodologías propuestas.

El análisis exploratorio no solo cumple una función descriptiva, sino que fundamenta decisiones críticas de modelado: la necesidad de transformaciones estabilizadoras, la selección de arquitecturas de modelos apropiadas, la configuración de hiperparámetros, y la elección de métricas de evaluación robustas. Esta sección describe en detalle el procedimiento estándar aplicado a todas las series analizadas en este capítulo.

\subsection{Estructura del Protocolo de Análisis}
\label{subsec:eda_estructura}

El protocolo de análisis exploratorio se estructura en seis etapas fundamentales, cada una diseñada para revelar aspectos específicos de la dinámica temporal:

\begin{enumerate}
\item \textbf{Transformación de estabilización de varianza}: Aplicación de Box-Cox para reducir heterocedasticidad.
\item \textbf{Eliminación de tendencia}: Extracción de movimientos de largo plazo mediante suavizado LOWESS.
\item \textbf{Análisis de estacionariedad}: Caracterización mediante funciones ACF/PACF y tests formales.
\item \textbf{Tests de estacionariedad y linealidad}: Validación mediante batería de tests estadísticos.
\item \textbf{Diagnóstico de residuos}: Tests de normalidad e independencia.
\item \textbf{Análisis espectral}: Identificación de frecuencias dominantes mediante periodogramas.
\end{enumerate}

Las subsecciones siguientes detallan cada una de estas etapas, especificando los métodos estadísticos empleados, los criterios de interpretación, y las implicaciones para el modelado predictivo.

\subsection{Transformación Box-Cox}
\label{subsec:eda_boxcox}

La heterocedasticidad estructural (varianza que cambia sistemáticamente con el nivel de la serie) viola supuestos clave de muchos métodos estadísticos, incluyendo la predicción conformal basada en intercambiabilidad. Para abordar este problema, se aplica la transformación de Box-Cox si toda la serie toma valores positivos\parencite{BoxCox1964}:

\begin{equation}
y_t^{(\lambda)} = \begin{cases}
\frac{y_t^\lambda - 1}{\lambda} & \text{si } \lambda \neq 0 \\
\log(y_t) & \text{si } \lambda = 0
\end{cases}
\label{eq:boxcox}
\end{equation}

donde $\lambda$ es el parámetro de transformación.

\paragraph{Estimación del parámetro óptimo:} Se emplea el método de Guerrero \parencite{Guerrero1993}, específicamente diseñado para series temporales con múltiples componentes estacionales. Este método busca el valor $\hat{\lambda}$ que minimiza el coeficiente de variación de las desviaciones estándar calculadas sobre subseries correspondientes a cada período estacional.

\paragraph{Criterios de aplicación:} La transformación se aplica cuando:
\begin{itemize}
\item La serie presenta valores estrictamente positivos (o puede desplazarse mediante un offset).
\item Existe evidencia visual de heterocedasticidad estructural (patrón de ``embudo'').
\item El parámetro estimado $\hat{\lambda}$ difiere sustancialmente de 1 (transformación identidad).
\end{itemize}

\paragraph{Interpretación:}
\begin{itemize}
\item $\lambda \approx 1$: No se requiere transformación.
\item $\lambda \approx 0.5$: Transformación tipo raíz cuadrada.
\item $\lambda \approx 0$: Transformación logarítmica.
\end{itemize}

Esta estabilización mejora la validez de los intervalos de predicción conformal y facilita la convergencia de algoritmos de optimización en modelos de aprendizaje profundo.

\subsection{Eliminación de Tendencia mediante LOWESS}
\label{subsec:eda_detrending}

Muchos métodos de predicción conformal asumen intercambiabilidad aproximada de los residuos, lo cual requiere que la serie no presente movimientos persistentes de largo plazo. Para cumplir este requisito, se elimina la tendencia mediante suavizado LOWESS (Locally Weighted Scatterplot Smoothing).

\paragraph{Método LOWESS:} El suavizado se define mediante regresión ponderada localmente:
\begin{equation}
\hat{T}_t = \text{LOWESS}(y_t; f)
\label{eq:lowess}
\end{equation}
donde $f \in (0,1]$ es la fracción de datos utilizados en cada ventana local (típicamente $f = 0.05$ para capturar movimientos suaves).

La serie sin tendencia se define entonces como:
\begin{equation}
y_t^{(d)} = y_t - \hat{T}_t
\label{eq:detrended}
\end{equation}

\paragraph{Selección del parámetro $f$:} Un valor pequeño de $f$ (e.g., 0.05) produce un suavizado que sigue cambios graduales sin eliminar estructura estacional de alta frecuencia. Valores mayores generan tendencias más suaves pero pueden introducir sesgo.

\paragraph{Validación:} Se verifica que:
\begin{itemize}
\item La varianza de $y_t^{(d)}$ sea sustancialmente menor que la de $y_t$.
\item La serie $y_t^{(d)}$ oscile alrededor de media cero sin tendencia persistente.
\end{itemize}

\subsection{Análisis de Estacionariedad}
\label{subsec:eda_estacionariedad_analisis}

El análisis de la estructura de dependencia temporal es fundamental para seleccionar órdenes de modelos autorregresivos y evaluar si métodos basados en intercambiabilidad son apropiados.

\paragraph{Función de Autocorrelación (ACF):} La ACF en el rezago $k$ se define como:
\begin{equation}
\rho(k) = \frac{\text{Cov}(y_t, y_{t-k})}{\text{Var}(y_t)}
\label{eq:acf}
\end{equation}

Se grafican los valores $\hat{\rho}(k)$ para $k = 1, 2, \ldots, K$ junto con bandas de confianza aproximadas $\pm 1.96/\sqrt{n}$ bajo la hipótesis nula de ruido blanco.

\paragraph{Interpretación de la ACF:}
\begin{itemize}
\item Decaimiento exponencial rápido: Proceso de memoria corta (e.g., AR de orden bajo).
\item Decaimiento hiperbólico lento: Posible no estacionariedad o memoria larga.
\item Picos periódicos (e.g., en $k = 24, 48, 72$): Estacionalidad residual.
\item Todos los rezagos dentro de bandas: Evidencia de independencia (ruido blanco).
\end{itemize}

\paragraph{Función de Autocorrelación Parcial (PACF):} La PACF mide la correlación entre $y_t$ y $y_{t-k}$ después de eliminar el efecto lineal de las variables intermedias. Un corte abrupto en rezago $p$ sugiere un proceso AR($p$).

\subsection{Tests de Estacionariedad y Linealidad}
\label{subsec:eda_tests}

Se implementa una batería completa de tests estadísticos para validar supuestos fundamentales de los modelos predictivos.
\subsubsection{Tests de Estacionariedad}

\paragraph{Test de Dickey-Fuller Aumentado (ADF):}
El test ADF \parencite{DickeyFuller1979} parte del modelo autorregresivo aumentado:
\begin{equation}
\Delta y_t = \alpha + \beta t + \gamma y_{t-1} + \sum_{j=1}^{p} \delta_j \Delta y_{t-j} + \varepsilon_t
\end{equation}
donde el parámetro de interés es $\gamma$. El sistema completo de hipótesis es:
\begin{equation}
H_0: \gamma = 0 \quad \text{(raíz unitaria, serie no estacionaria)}
\end{equation}
\begin{equation}
H_1: \gamma < 0 \quad \text{(serie estacionaria, alternativa de una cola)}
\end{equation}

La hipótesis alternativa es \textit{unilateral}: solo se contempla $\gamma < 0$, es decir, reversión estacionaria. Un proceso explosivo ($\gamma > 0$) no es distinguible de la raíz unitaria bajo este contraste, lo que constituye una limitación conocida del test. Un $p$-valor menor a 0.05 lleva a rechazar $H_0$, concluyendo que la serie es estacionaria. En la implementación utilizada (\texttt{adf.test} del paquete \texttt{tseries} en R), el test incluye constante y se selecciona automáticamente el orden de rezagos $p$ mediante el criterio de información de Akaike.

\paragraph{Test de Kwiatkowski-Phillips-Schmidt-Shin (KPSS):}
El test KPSS \parencite{KPSS1992} invierte la lógica del ADF descomponiendo la serie como:
\begin{equation}
y_t = \xi t + r_t + \varepsilon_t, \quad r_t = r_{t-1} + u_t, \quad u_t \sim \text{i.i.d.}(0, \sigma_u^2)
\end{equation}
donde $r_t$ es un paseo aleatorio. El sistema de hipótesis es:
\begin{equation}
H_0: \sigma_u^2 = 0 \quad \text{(serie estacionaria, componente aleatorio degenerado)}
\end{equation}
\begin{equation}
H_1: \sigma_u^2 > 0 \quad \text{(serie no estacionaria, raíz unitaria presente)}
\end{equation}

La hipótesis alternativa es \textit{unilateral superior}: la no estacionariedad se entiende únicamente como integración de orden 1, no como proceso explosivo. El estadístico KPSS se construye sobre los residuos parciales acumulados de la regresión de $y_t$ sobre determinísticos:
\begin{equation}
\hat{\eta} = \frac{1}{n^2} \sum_{t=1}^{n} \hat{S}_t^2 \Big/ \hat{\sigma}^2_\varepsilon
\end{equation}
donde $\hat{S}_t = \sum_{i=1}^{t} \hat{\varepsilon}_i$ es la suma parcial de residuos. No rechazar $H_0$ ($p > 0.05$) apoya la estacionariedad.

\paragraph{Estrategia combinada ADF-KPSS:}
Dado que los dos tests tienen hipótesis nulas opuestas y alternativas unilaterales distintas, su uso conjunto permite cuatro configuraciones interpretativas:
\begin{itemize}
    \item \textbf{ADF rechazado + KPSS no rechazado} ($p_{\text{ADF}} < 0.05$, $p_{\text{KPSS}} > 0.05$): Evidencia consistente de estacionariedad. Configuración ideal buscada.
    \item \textbf{ADF no rechazado + KPSS rechazado} ($p_{\text{ADF}} > 0.05$, $p_{\text{KPSS}} < 0.05$): Evidencia consistente de no estacionariedad.
    \item \textbf{Ambos rechazados}: Los tests son contradictorios; posible presencia de raíz unitaria fraccional o quiebres estructurales.
    \item \textbf{Ninguno rechazado}: Los tests son contradictorios; la muestra puede ser insuficiente para distinguir entre ambas hipótesis.
\end{itemize}
Cabe destacar que ninguno de los dos tests cubre la hipótesis de proceso explosivo ($\gamma > 0$ o raíz mayor que 1). Sin embargo, dado el contexto de la serie analizada, esta posibilidad no es relevante.

% ─────────────────────────────────────────────────────────────────────────────
\subsubsection{Tests de Linealidad}

La presencia de estructura no lineal justifica el uso de métodos más sofisticados que los modelos ARMA lineales.

\paragraph{Test BDS:}
El test BDS \parencite{BDS1996} evalúa si los residuos de un modelo ajustado son independientes e idénticamente distribuidos. El sistema de hipótesis es:
\begin{equation}
H_0: \{\varepsilon_t\} \text{ son i.i.d.}
\end{equation}
\begin{equation}
H_1: \{\varepsilon_t\} \text{ presentan alguna forma de dependencia (lineal o no lineal)}
\end{equation}

La hipótesis alternativa es \textit{omnidireccional}: el test no discrimina entre dependencia lineal residual, heterocedasticidad condicional o no linealidad determinista; detecta cualquier desviación de la i.i.d. El estadístico se construye sobre la integral de correlación $C_{m,n}(\varepsilon)$, que mide la fracción de pares de vectores de embedding $m$-dimensional que se encuentran a distancia menor que $\varepsilon$:
\begin{equation}
W_{m,n} = \frac{\sqrt{n}\left[C_{m,n}(\varepsilon) - C_{1,n}(\varepsilon)^m\right]}{\sigma_m(\varepsilon)} \xrightarrow{d} \mathcal{N}(0,1)
\end{equation}
Rechazo de $H_0$ ($p < 0.05$) indica dependencia no lineal no capturada por modelos lineales. En la implementación utilizada se empleó $m = 2$ y $\varepsilon = 0.5\,\hat{\sigma}$.

\paragraph{Test de McLeod-Li:}
El test de McLeod-Li \parencite{McLeodLi1983} aplica el estadístico de Ljung-Box sobre los residuos al cuadrado $\hat{\varepsilon}_t^2$ para detectar efectos ARCH. El sistema de hipótesis es:
\begin{equation}
H_0: \rho_k^{(2)} = 0 \;\forall\, k = 1,\ldots,K \quad \text{(no hay autocorrelación en } \hat{\varepsilon}_t^2\text{)}
\end{equation}
\begin{equation}
H_1: \exists\, k \leq K \text{ tal que } \rho_k^{(2)} \neq 0 \quad \text{(heterocedasticidad condicional presente)}
\end{equation}

La hipótesis alternativa es \textit{bilateral en los rezagos}: cualquier autocorrelación en los cuadrados, positiva o negativa, lleva al rechazo. El estadístico es:
\begin{equation}
Q_{\text{LB}}^{(2)}(K) = n(n+2) \sum_{k=1}^{K} \frac{\hat{\rho}_k^{(2)}}{n-k} \sim \chi^2(K)
\label{eq:mcleod_li}
\end{equation}
Rechazo ($p < 0.05$) implica varianza condicional no constante (agrupamiento de volatilidad), justificando el uso de distribuciones predictivas adaptativas. Se utilizó $K = 24$ rezagos.

\paragraph{Test de Tsay:}
El test de Tsay \parencite{Tsay1986} evalúa si términos de interacción no lineal tienen poder explicativo sobre los residuos de un ajuste lineal. El sistema de hipótesis es:
\begin{equation}
H_0: \text{La estructura condicional de } y_t \text{ es lineal en sus rezagos}
\end{equation}
\begin{equation}
H_1: \text{Existen interacciones cuadráticas o cruzadas significativas entre rezagos}
\end{equation}

La hipótesis alternativa es \textit{específica en la forma}: la no linealidad contemplada es de tipo polinómico de orden 2 (cuadrados e interacciones cruzadas de rezagos), no formas arbitrarias. El test procede en dos etapas: primero se ajusta un modelo AR lineal y se obtienen residuos $\hat{u}_t$; luego se regresa $\hat{u}_t^2$ sobre el conjunto expandido de regresores no lineales y se evalúa la significancia conjunta mediante un estadístico $F$. Un $p$-valor menor a 0.05 indica presencia de no linealidad cuadrática. En la implementación utilizada se fijó \texttt{lag = 1}, \texttt{order = 3}.

\paragraph{Exponente de Hurst:}
El exponente de Hurst $H$ \parencite{Hurst1951}, estimado mediante el método de rango reescalado (R/S), cuantifica la memoria de largo alcance de la serie. No constituye un contraste formal de hipótesis con $p$-valor, sino un índice continuo con la siguiente interpretación:
\begin{equation}
\mathbb{E}\left[\frac{R(n)}{S(n)}\right] \propto n^H
\end{equation}
\begin{itemize}
    \item $H = 0.5$: Proceso sin memoria (random walk o ruido blanco).
    \item $H > 0.5$: Persistencia; las tendencias pasadas tienen mayor probabilidad de continuar.
    \item $H < 0.5$: Anti-persistencia; reversión a la media más frecuente que en un proceso aleatorio.
\end{itemize}
Valores $H > 0.5$ sugieren que modelos con memoria explícita de largo plazo, como las redes LSTM, pueden capturar mejor la dinámica que modelos de ventana corta. Se utilizó \texttt{max\_lag = 50} en la estimación.

\subsection{Diagnóstico de Residuos}
\label{subsec:eda_diagnostico_residuos}

Tras remover tendencia, los residuos ideales deben aproximarse a ruido blanco: secuencia de variables aleatorias independientes e idénticamente distribuidas.

\paragraph{Test de Jarque-Bera:}
El test de Jarque-Bera \parencite{JarqueBera1987} contrasta la hipótesis nula de normalidad
de los residuos comparando simultáneamente la asimetría y la curtosis de la distribución
empírica con los valores teóricos gaussianos. El sistema completo de hipótesis es:
\begin{align}
H_0 &: S = 0 \;\text{ y }\; K = 3 \quad \text{(distribución normal)}\\
H_1 &: S \neq 0 \;\text{ o }\; K \neq 3 \quad \text{(asimetría o curtosis incompatibles con normalidad)}
\end{align}
La hipótesis alternativa es \textit{bilateral y compuesta}: el test rechaza tanto distribuciones
leptocúrticas ($K > 3$, colas pesadas) como platicúrticas ($K < 3$, colas ligeras), y tanto
asimetría positiva como negativa. El estadístico conjunto es:
\begin{equation}
JB = \frac{n}{6} \left( S^2 + \frac{(K-3)^2}{4} \right) \xrightarrow{d} \chi^2_2
\label{eq:jarque_bera}
\end{equation}
donde $n$ es el tamaño muestral, $S = \hat{\mu}_3 / \hat{\sigma}^3$ es el coeficiente de
asimetría muestral y $K = \hat{\mu}_4 / \hat{\sigma}^4$ es la curtosis muestral. Los 2 grados
de libertad corresponden a los dos momentos contrastados de forma conjunta. Un $p$-valor menor
a 0.05 lleva a rechazar $H_0$, indicando que los residuos presentan colas más pesadas que la
gaussiana (leptocurtosis) o asimetría significativa; ambas condiciones justifican el abandono
de métricas cuadráticas como el MSE en favor de métricas basadas en distribuciones predictivas
completas como el CRPS o la \textit{Quantile Loss}.

\paragraph{Test de Ljung-Box:}
El test de Ljung-Box \parencite{LjungBox1978} es una extensión del test de Box-Pierce
que corrige el sesgo en muestras finitas. Contrasta la hipótesis
nula de que los primeros $K$ rezagos de la función de autocorrelación son conjuntamente nulos.
El sistema completo de hipótesis es:
\begin{align}
H_0 &: \rho_1 = \rho_2 = \cdots = \rho_K = 0
      \quad \text{(residuos no correlacionados, ruido blanco)}\\
H_1 &: \exists\, k \leq K \text{ tal que } \rho_k \neq 0
      \quad \text{(autocorrelación presente en algún rezago)}
\end{align}
La hipótesis alternativa es \textit{bilateral en cada rezago y conjunta en todos}:
el test no discrimina entre autocorrelación positiva ($\rho_k > 0$, inercia) o negativa
($\rho_k < 0$, oscilación), ni especifica en qué rezago particular reside la dependencia.
El estadístico, con corrección de muestra finita respecto a Box-Pierce, es:
\begin{equation}
Q_{\text{LB}}(K) = n(n+2) \sum_{k=1}^{K} \frac{\hat{\rho}_k^2}{n-k} \;\sim\; \chi^2_K
\label{eq:ljung_box}
\end{equation}
donde $\hat{\rho}_k$ es la autocorrelación muestral en el rezago $k$ y los $K$ grados de
libertad reflejan los rezagos contrastados conjuntamente. En la implementación utilizada se
fijó $K = 24$, lo que permite detectar dependencias en ciclos de hasta dos años bajo
frecuencia mensual. Rechazo de $H_0$ ($p < 0.05$) indica que la serie no es ruido blanco:
queda estructura temporal sistemática que los modelos predictivos (ARIMA, LSTM) están
diseñados para capturar. En la etapa de diagnóstico exploratorio previo al modelado, la
presencia de autocorrelación residual es un resultado esperado y deseable, pues confirma
que existe señal predictiva aprovechable.

\paragraph{Gráficos de diagnóstico:}
\begin{itemize}
\item \textbf{Histograma}: Compara distribución empírica con normal teórica.
\item \textbf{ACF de residuos}: Debe estar mayormente dentro de bandas de confianza.
\item \textbf{QQ-plot}: Cuantiles empíricos vs. teóricos; desviaciones indican no normalidad.
\end{itemize}

\subsection{Análisis Espectral}
\label{subsec:eda_espectral}

El análisis espectral descompone la varianza de la serie en contribuciones de diferentes frecuencias, permitiendo identificar ciclos que pueden no ser evidentes en el dominio temporal.

\paragraph{Periodograma:} El periodograma estima la densidad espectral de potencia:
\begin{equation}
I(\omega_k) = \frac{1}{n} \left| \sum_{t=1}^{n} y_t e^{-i \omega_k t} \right|^2
\label{eq:periodograma}
\end{equation}
donde $\omega_k = 2\pi k / n$ para $k = 0, 1, \ldots, \lfloor n/2 \rfloor$.

Los picos en $I(\omega_k)$ identifican las frecuencias dominantes. Para series horarias:
\begin{itemize}
\item Pico en $\omega \approx 2\pi/24$: Ciclo diario.
\item Pico en $\omega \approx 2\pi/168$: Ciclo semanal.
\end{itemize}

\paragraph{Método de Welch:} Para reducir la variabilidad del periodograma clásico, se aplica el método de Welch \parencite{Welch1967}, que promedia periodogramas de segmentos superpuestos de la serie, produciendo estimaciones más suaves y robustas de las frecuencias dominantes.

\paragraph{Implicaciones:} La confirmación espectral de estacionalidades valida la configuración de períodos estacionales en los modelos. Frecuencias dominantes identifican:
\begin{itemize}
\item Longitud de bloque apropiada en Circular Block Bootstrap (CBB).
\item Períodos estacionales en descomposiciones multi-temporales.
\item Covariables temporales relevantes para LSPM/MCPS.
\end{itemize}

\subsection{Aplicación del Protocolo}
\label{subsec:eda_aplicacion}

El protocolo de análisis exploratorio descrito en las secciones precedentes se aplica
de forma sistemática a cada serie temporal estudiada en este capítulo. Su ejecución
rigurosa cumple dos propósitos complementarios: por un lado, caracterizar las
propiedades estadísticas relevantes de cada serie (estacionariedad, linealidad,
memoria, distribución de residuos); por otro, contextualizar el comportamiento de
los modelos predictivos frente a dinámicas temporales con características
sustancialmente distintas entre sí.

Es importante señalar que los modelos reciben la serie original sin ningún tipo de
preprocesamiento o transformación previa. Esta decisión es deliberada: se busca
evaluar las capacidades predictivas de cada modelo ante la complejidad inherente
de los datos reales, sin que el tratamiento de la serie distorsione la comparación.
El análisis exploratorio cumple entonces una función diagnóstica y de caracterización,
no de intervención sobre los datos.

En las secciones subsecuentes, se aplica este protocolo a tres conjuntos de datos
con perfiles estadísticos contrastantes:

\begin{enumerate}
    \item \textbf{Dataset Electricity}
          (Sección~\ref{sec:aplicacion_electricidad}):
          consumo eléctrico horario de un cliente residencial.
    \item \textbf{Dataset Traffic}
          (Sección~\ref{sec:aplicacion_trafico}):
          flujo vehicular horario en una autopista urbana.
    \item \textbf{Dataset Exchange Rate}
          (Sección~\ref{sec:aplicacion_exchange}):
          tasas de cambio horarias entre pares de divisas.
\end{enumerate}

Para cada conjunto de datos se presentan: los hallazgos del análisis exploratorio,
la configuración específica de los modelos, los resultados de desempeño predictivo,
la comparación estadística entre métodos, y el análisis de calibración probabilística.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Electricidad
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Serie de Consumo Eléctrico: Dataset Electricity}
\label{sec:aplicacion_electricidad}

\subsection{Descripción del Problema y Contexto}
\label{subsec:elec_contexto}

El pronóstico de demanda eléctrica constituye un problema fundamental en la operación de sistemas de potencia modernos. La predicción precisa de la carga permite a los operadores de red optimizar la generación, reducir costos operativos, minimizar el uso de plantas de respaldo contaminantes y garantizar la estabilidad del suministro \parencite{Salinas2020}.

El dataset \textit{Electricity} proviene del repositorio de GluonTS \parencite{gluonts_jmlr} y contiene mediciones horarias de consumo eléctrico (en kWh) de un cliente residencial. Para este estudio se seleccionó una ventana temporal de 2160 observaciones, equivalente a aproximadamente 90 días, lo cual resulta suficiente para capturar múltiples ciclos estacionales y evaluar la capacidad de adaptación de los modelos predictivos.

\subsection{Resultados del Análisis Exploratorio}
\label{subsec:elec_eda_resultados}

La aplicación del protocolo de análisis exploratorio descrito en la Sección~\ref{sec:metodologia_eda} permitió identificar las siguientes características estadísticas relevantes para el modelado predictivo.

\subsubsection{Transformación de Estabilización de Varianza}

El parámetro óptimo de la transformación Box-Cox, estimado mediante el método de Guerrero, resultó en $\hat{\lambda} = -0.1181$. Este valor negativo cercano a cero sugiere la necesidad de una transformación logarítmica modificada para estabilizar la varianza a lo largo del tiempo, facilitando así el ajuste de modelos que asumen varianza constante.

La Figura~\ref{fig:transformaciones_electricity} presenta la evolución de la serie a través de las etapas de transformación. El panel superior muestra la serie original con sus patrones estacionales claramente visibles. El panel central exhibe la serie tras la aplicación de la transformación Box-Cox, donde se observa una estabilización notable de la amplitud de las fluctuaciones. Finalmente, el panel inferior presenta la serie transformada tras la eliminación de tendencia mediante LOWESS, revelando la componente estocástica estacionaria sobre la cual se construyen los modelos predictivos.

\begin{figure}[p]
    \centering
    
    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[height=0.3\textheight, width=0.85\textwidth, keepaspectratio]{Imagenes/Cap5_elec_serie_original.png}
        \caption{Serie original.}
        \label{fig:original}
    \end{subfigure}
    \vfill
        
    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[height=0.3\textheight, width=0.85\textwidth, keepaspectratio]{Imagenes/Cap5_elec_serie_box_cox.png}
        \caption{Serie con transformación Box-Cox ($\lambda = -0.1181$).}
        \label{fig:boxcox}
    \end{subfigure}
    \vfill
    
    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[height=0.3\textheight, width=0.85\textwidth, keepaspectratio]{Imagenes/Cap5_elec_serie_trend.png}
        \caption{Serie transformada sin componente de tendencia.}
        \label{fig:detrended}
    \end{subfigure}

    \caption{Proceso de transformación de la serie de consumo eléctrico.}
    \label{fig:transformaciones_electricity}
\end{figure}    

\subsubsection{Eliminación de Tendencia}

Se aplicó suavizado LOWESS con parámetro de ancho de banda $f = 0.05$ para remover la componente de tendencia suave presente en la serie transformada. Este procedimiento logró reducir significativamente la varianza de la serie y centrar los residuos alrededor de cero, cumpliendo así con el requisito de media constante necesario para el análisis de estacionariedad.

\subsubsection{Validación de Estacionariedad}

Las pruebas estadísticas aplicadas a la serie transformada y sin tendencia confirmaron el logro de estacionariedad débil. El test aumentado de Dickey-Fuller (ADF) arrojó un valor p inferior a 0.01, permitiendo rechazar la hipótesis nula de presencia de raíz unitaria con alta significancia estadística. De forma complementaria, el test de Kwiatkowski-Phillips-Schmidt-Shin (KPSS) produjo un valor p superior a 0.10, no permitiendo rechazar la hipótesis nula de estacionariedad. Esta convergencia de evidencia desde ambas perspectivas confirma robustamente la estacionariedad de la serie preprocesada.

El análisis de la función de autocorrelación (ACF) reveló un patrón de decaimiento exponencial característico de procesos autorregresivos estacionarios. Los picos más significativos aparecen en los rezagos 1, 2, 3, 4, 168, 336 y 504 con correlaciones de 0.598, 0.433, 0.318, 0.252, 0.229, 0.164 y 0.141 respectivamente. La presencia de correlaciones elevadas en múltiplos de 168 horas (7 días) confirma inequívocamente la existencia de estacionalidad semanal como componente dominante de la serie. Adicionalmente, se observan picos menores en el rezago 144 horas (6 días) y 96 horas (4 días), sugiriendo patrones de consumo asociados con días intermedios de la semana.

Por su parte, la función de autocorrelación parcial (PACF) mostró un corte significativo en el rezago 1 con correlación parcial de 0.598, seguido de valores mucho menores en rezagos superiores. Los siguientes picos relevantes aparecen en los rezagos 25, 145, 2, 97 y 167 con correlaciones parciales de -0.126, -0.121, 0.116, -0.101 y 0.097 respectivamente. Este patrón sugiere que un modelo autorregresivo de orden bajo, complementado con variables estacionales, podría capturar adecuadamente la estructura lineal de dependencia temporal.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{Imagenes/Cap5_elec_acf_pacf.png}
    \caption{Funciones de autocorrelación y autocorrelación parcial para la serie de consumo eléctrico.}
    \label{fig:acf_pacf_electricity}
\end{figure}


\subsubsection{Evaluación de No Linealidad}

La aplicación de múltiples tests de no linealidad proporcionó evidencia robusta de estructura no lineal en la serie. El test BDS (Brock-Dechert-Scheinkman) rechazó la hipótesis nula de independencia e identidad distribucional con un valor p inferior a 0.001, indicando la presencia de dependencias temporales complejas no capturables por modelos lineales simples. El test de McLeod-Li, aplicado sobre los residuos al cuadrado, también produjo un valor p menor a 0.001, evidenciando efectos ARCH (Autoregressive Conditional Heteroskedasticity) significativos. Adicionalmente, el test de Tsay para no linealidad cuadrática arrojó un valor p inferior a 0.01, confirmando la presencia de componentes cuadráticas en la función de dependencia temporal.

El exponente de Hurst estimado resultó en $H = 0.62$, valor que excede el umbral de 0.5 característico del movimiento Browniano estándar, indicando así la existencia de persistencia moderada en la serie. Este hallazgo es consistente con procesos que exhiben memoria de largo plazo, justificando la exploración de modelos capaces de capturar tales estructuras de dependencia.

\subsubsection{Diagnóstico de Distribución de Residuos}

El test de Jarque-Bera aplicado a los residuos de un modelo AR preliminar rechazó la hipótesis de normalidad con un valor p inferior a 0.001, revelando la presencia de leptocurtosis (colas más pesadas que la distribución normal). Esta desviación de normalidad justifica el uso de métricas de evaluación robustas como el CRPS (Continuous Ranked Probability Score), el cual no asume forma distribucional específica. El test de Ljung-Box sobre los residuos produjo un valor p menor a 0.05, indicando la presencia de autocorrelación residual, fenómeno esperado dada la complejidad de las estructuras de dependencia temporal identificadas previamente.

\subsubsection{Análisis Espectral}

El periodograma de Welch, aplicado para identificar componentes periódicas dominantes, reveló un pico espectral principal en la frecuencia $f_1 = 0.0117$ ciclos por hora, correspondiente a un período de aproximadamente 85.33 horas (3.6 días). Sin embargo, el análisis detallado de las diez frecuencias con mayor densidad espectral proporciona una caracterización más completa de la estructura periódica. Las frecuencias dominantes son 0.0120 (83.08 horas), 0.1667 (6 horas), 0.0356 (28.05 horas), 0.0111 (90 horas), 0.0417 (24 horas), 0.0477 (20.97 horas), 0.0185 (54 horas), 0.0060 (166.15 horas $\approx$ 7 días), 0.0125 (80 horas) y 0.0199 (50.23 horas).

La presencia del pico en 24 horas confirma la estacionalidad diaria, mientras que el pico en 166.15 horas (aproximadamente 7 días) valida la estacionalidad semanal identificada previamente en el ACF. La multiplicidad de picos espectrales sugiere una estructura compleja con patrones superpuestos a diferentes escalas temporales. Estos hallazgos espectrales validan la inclusión de variables indicadoras temporales en los modelos y justifican la selección de longitudes de bloque específicas para métodos bootstrap.

\subsubsection{Implicaciones para la Estrategia de Modelado}

Los hallazgos del análisis exploratorio conducen a decisiones metodológicas específicas. La evidencia robusta de no linealidad, efectos ARCH y desviaciones de normalidad justifica la priorización de modelos no lineales y basados en redes neuronales (LSTM, EnCQR-LSTM) sobre alternativas puramente autorregresivas lineales (ARMA). La selección del CRPS como métrica principal de evaluación se fundamenta en su robustez ante distribuciones no gaussianas y su capacidad para evaluar simultáneamente precisión y calibración. Para el método Circular Block Bootstrap (CBB), se establece una longitud de bloque $\ell = 24$ horas, alineada con uno de los ciclos estacionales identificados espectralmente. Finalmente, el parámetro de decaimiento temporal $\rho = 0.95$ para el modelo LSPMW se configura considerando el exponente de Hurst estimado de 0.62, el cual indica persistencia moderada.

\subsubsection{Síntesis del Análisis Exploratorio}

El Cuadro~\ref{tab:elec_eda_summary} resume los hallazgos principales del análisis exploratorio y sus implicaciones directas para la configuración de modelos.

\begin{table}[htbp]
\centering
\caption{Resumen de características identificadas en el análisis exploratorio del dataset Electricity y sus implicaciones metodológicas.}
\label{tab:elec_eda_summary}
\small
\begin{tabular}{p{4cm}p{5cm}p{5cm}}
\toprule
\textbf{Característica} & \textbf{Hallazgo Principal} & \textbf{Implicación Metodológica} \\
\midrule
Transformación Box-Cox & $\lambda = -0.1181$ (cercano a log) & Estabilización de varianza requerida \\
\addlinespace
Estacionariedad & ADF: $p < 0.01$ \newline KPSS: $p > 0.10$ & Serie estacionaria tras preprocesamiento \\
\addlinespace
Estructura temporal (ACF) & Picos en 1, 2, 3, 168, 336h \newline Corr. máxima: 0.598 (lag 1) & Dependencia AR de corto plazo + estacionalidad semanal \\
\addlinespace
Estructura temporal (PACF) & Corte principal en lag 1 (0.598) \newline Valores menores en lags superiores & Modelo AR(1) con componentes estacionales \\
\addlinespace
No linealidad & BDS, McLeod-Li, Tsay: $p < 0.01$ \newline Hurst: $H = 0.62$ & Priorizar modelos no lineales y LSTM \\
\addlinespace
Distribución residuos & Jarque-Bera: $p < 0.001$ \newline Leptocurtosis presente & Usar CRPS en lugar de métricas gaussianas \\
\addlinespace
Análisis espectral & Picos: 24h, 85h, 166h ($\approx$ 7 días) \newline Estructura multi-escala & Longitud bloque CBB: $\ell = 24$ \newline Variables indicadoras temporales \\
\addlinespace
Persistencia & Exponente Hurst: 0.62 & Parámetro decaimiento LSPMW: $\rho = 0.95$ \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Configuración Experimental}
\label{subsec:elec_configuracion}

\subsubsection{Partición de Datos}

La serie de 2160 observaciones original (sin el pre-procesamiento) se dividió siguiendo el esquema implementado en el código experimental. El conjunto de prueba se fijó en 24 observaciones (correspondientes a un día completo de predicciones horarias). Del resto de datos disponibles (2136 observaciones), se asignó el 15\% al conjunto de validación, resultando en aproximadamente 320 observaciones, mientras que el 85\% restante (aproximadamente 1816 observaciones) conformó el conjunto de entrenamiento. 

Esta configuración garantiza que el conjunto de entrenamiento capture múltiples ciclos semanales completos (más de 10 semanas) para el ajuste inicial de parámetros, mientras que el conjunto de validación proporciona suficientes datos para una optimización robusta de hiperparámetros. El conjunto de prueba, aunque más reducido, permite evaluar el desempeño en un horizonte operativo realista de un día completo.

\subsubsection{Horizonte de Predicción}

Se estableció un horizonte de predicción de $h = 1$ paso adelante, correspondiente a una hora futura. Esta configuración permite aislar la capacidad intrínseca de los modelos para generar distribuciones predictivas bien calibradas sin la complejidad adicional introducida por horizontes multi-paso, donde los errores tienden a propagarse y amplificarse.

\subsection{Resultados}
\label{subsec:elec_resultados}

\subsubsection{Desempeño Predictivo Global}

El Cuadro~\ref{tab:elec_ranking} presenta el ranking de modelos según su desempeño en el conjunto de prueba, ordenados por la mediana del CRPS. Esta métrica, robusta ante valores atípicos y apropiada para comparar distribuciones predictivas completas, permite una evaluación integral de la capacidad predictiva y la calibración simultáneamente.

\begin{table}[htbp]
\centering
\caption{Ranking de modelos según desempeño en dataset Electricity.}
\label{tab:elec_ranking}
\begin{tabular}{clcc}
\toprule
\textbf{Rango} & \textbf{Modelo} & \textbf{CRPS Media} & \textbf{CRPS Mediana} \\
\midrule
1 & LSPM & 3.666 & 1.497 \\
2 & MCPS & 2.361 & 1.508 \\
3 & Sieve Bootstrap & 3.148 & 1.514 \\
4 & AV-MCPS & 2.742 & 1.791 \\
5 & EnCQR-LSTM & 3.062 & 1.904 \\
6 & DeepAR & 2.974 & 1.995 \\
7 & AREPD & 3.428 & 2.259 \\
8 & Block Bootstrapping & 3.552 & 2.337 \\
9 & LSPMW & 3.384 & 2.550 \\
\bottomrule
\end{tabular}
\end{table}



Los tres modelos superiores (LSPM, MCPS y Sieve Bootstrap) exhiben medianas de CRPS notablemente cercanas entre sí (1.497, 1.508 y 1.514 respectivamente), con diferencias inferiores al 1.2\%. Este resultado valida la hipótesis de que modelos lineales con residuos adecuadamente estudentizados, tras aplicar las transformaciones identificadas en el análisis exploratorio, logran capturar eficientemente la estructura de dependencia temporal dominante en esta serie. La proximidad en desempeño sugiere que las transformaciones aplicadas lograron simplificar satisfactoriamente la dinámica subyacente. Las densidades de estos tres modelos en los seis primeros pasos se puede visualizar en

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\textwidth]{Imagenes/electricity_serie_0_TypeA_Top3_Mejores}
    \caption{Distribución de las densidades de los tres mejores modelos en los primeros seis pasos del dataset Electricity.}
    \label{fig:elec_distr}
\end{figure}


La Figura~\ref{fig:elec_boxplot_crps} presenta la distribución completa de los valores CRPS para cada modelo a lo largo de las 24 predicciones. La visualización mediante diagramas de caja permite apreciar no solo las medianas (línea central), sino también la dispersión y presencia de valores atípicos en el desempeño de cada método. Los tres modelos superiores muestran dispersiones compactas y medianas bajas, mientras que los modelos en posiciones inferiores exhiben mayor variabilidad y medianas más elevadas.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{Imagenes/Cap5_elec_boxplot_crps.png}
    \caption{Distribución de valores CRPS por modelo en el conjunto de prueba del dataset Electricity.}
    \label{fig:elec_boxplot_crps}
\end{figure}

Los métodos adaptativos AV-MCPS y LSPMW, diseñados para ajustarse a cambios distribucionales temporales, no superaron a sus contrapartes no adaptativas (MCPS y LSPM). Este resultado es consistente con la naturaleza de la serie, la cual exhibe estacionalidad estable sin cambios estructurales abruptos durante el período de prueba. En contextos donde la dinámica subyacente evoluciona gradualmente sin quiebres distribucionales significativos, la adaptatividad explícita no confiere ventajas sustanciales y puede incluso introducir variabilidad innecesaria.

Los modelos de aprendizaje profundo (DeepAR y EnCQR-LSTM) alcanzaron desempeño intermedio, posicionándose en los rangos 5 y 6 respectivamente. Esta ubicación intermedia puede atribuirse al tamaño de muestra relativamente limitado (aproximadamente 1816 observaciones de entrenamiento), el cual puede resultar insuficiente para explotar plenamente la capacidad representacional de arquitecturas neuronales profundas. Estas arquitecturas típicamente requieren decenas de miles de observaciones para calibrar adecuadamente sus numerosos parámetros y superar a modelos más parsimoniosos en regímenes de datos limitados.

\subsubsection{Comparación Estadística Formal}

Para evaluar si las diferencias observadas en desempeño predictivo resultan estadísticamente significativas, se aplicó el test de Diebold-Mariano modificado con corrección de Bonferroni entre todos los modelos evaluados. Este test, equipado con asintótica de suavizado fijo (fixed-smoothing asymptotics), resulta más robusto en muestras pequeñas que el test DM estándar, manteniendo buen desempeño asintótico.

La Figura \ref{fig:hln_dm_pvalues} presenta la matriz completa de p-valores para las 36 comparaciones pareadas realizadas. Dado el número de comparaciones múltiples, se aplicó corrección de Bonferroni ($\alpha_{\text{Bonf}} = 0.05/36 = 0.00139$), resultando en un umbral de significancia altamente conservador. Las celdas en tonos rojizos indican p-valores bajos (evidencia de diferencia significativa), mientras que tonos verdosos señalan p-valores altos (modelos estadísticamente indistinguibles). Los asteriscos denotan significancia: *** para $p < \alpha_{\text{Bonf}}$ y * para $p < 0.05$.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{Imagenes/Cap5_elec_HLN_DM_Pvalues_Matrix.png}
    \caption{Matriz de p-valores del test Diebold-Mariano modificado (HLN) para el dataset Electricity.}
    \label{fig:hln_dm_pvalues}
\end{figure}

Los resultados revelan patrones notables. Las comparaciones entre los tres modelos superiores (LSPM, MCPS, Sieve Bootstrap) muestran p-valores sustancialmente superiores al umbral de Bonferroni: LSPM vs MCPS ($p = 0.301$), LSPM vs Sieve Bootstrap ($p = 0.365$), y MCPS vs Sieve Bootstrap ($p = 0.320$). Ninguna de estas comparaciones alcanza significancia estadística, confirmando que los modelos líderes poseen capacidad predictiva estadísticamente equivalente para esta serie particular.

En contraste, se observan algunas diferencias estadísticamente significativas al nivel $p < 0.05$ (aunque no sobreviven la corrección de Bonferroni) entre modelos de rendimiento dispar. Por ejemplo, Block Bootstrapping vs MCPS ($p = 0.065$) y DeepAR vs MCPS ($p = 0.079$) muestran tendencias hacia diferenciación, aunque no concluyentes bajo el criterio conservador adoptado.

Esta homogeneidad de desempeño entre los modelos superiores sugiere que, para series con características similares a Electricity (estacionalidad estable, ausencia de quiebres estructurales, baja volatilidad), múltiples enfoques metodológicos bien configurados convergen hacia soluciones óptimas de desempeño comparable. La clave reside en la correcta aplicación del protocolo de preprocesamiento guiado por el análisis exploratorio y en la optimización rigurosa de hiperparámetros, más que en la sofisticación algorítmica del modelo empleado. Este hallazgo refuerza la importancia del diseño experimental y la validación cruzada en aplicaciones de predicción probabilística.

\subsubsection{Análisis de Calibración Distribucional}

La calibración de las distribuciones predictivas se evaluó mediante histogramas de transformación PIT (Probability Integral Transform) y curvas de confiabilidad. Una distribución predictiva perfectamente calibrada produce valores PIT distribuidos uniformemente en el intervalo [0,1], manifestándose como un histograma plano. Desviaciones de esta uniformidad señalan problemas de calibración: histogramas en forma de U invertida indican sobredispersión (intervalos predictivos excesivamente amplios), mientras que histogramas en forma de U denotan sobreconfianza (intervalos excesivamente estrechos).

La Figura~\ref{fig:elec_pit} presenta los histogramas PIT para todos los modelos evaluados. Los modelos LSPM, MCPS y Sieve Bootstrap produjeron histogramas aproximadamente uniformes, confirmando calibración adecuada de sus distribuciones predictivas. Los modelos Block Bootstrapping y LSPMW exhibieron forma de U invertida, indicando que sus intervalos predictivos tienden a ser excesivamente conservadores (más amplios de lo necesario). Por su parte, AV-MCPS y EnCQR-LSTM mostraron ligera forma de U, sugiriendo sobreconfianza leve en sus predicciones puntuales.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.95\textwidth]{Imagenes/Cap5_elec_pit_histograms.png}
    \caption{Histogramas de transformación PIT para todos los modelos en el dataset Electricity. }
    \label{fig:elec_pit}
\end{figure}

Las curvas de confiabilidad, presentadas en la Figura~\ref{fig:elec_reliability}, comparan frecuencias empíricas de cobertura contra niveles nominales para el rango 10\%-90\%. Los tres modelos superiores mantuvieron sus curvas próximas a la diagonal de calibración perfecta a lo largo de todos los niveles de confianza evaluados, confirmando calibración correcta tanto en las colas como en el centro de las distribuciones predictivas. Este resultado es particularmente relevante para aplicaciones operativas, donde la confiabilidad de intervalos de predicción en distintos niveles de confianza resulta crucial para la toma de decisiones.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.95\textwidth]{Imagenes/Cap5_elec_reliability.png}
    \caption{Curvas de confiabilidad para los modelos evaluados en el dataset Electricity. }
    \label{fig:elec_reliability}
\end{figure}

\subsection{Síntesis del Estudio del Dataset Electricity}
\label{subsec:elec_sintesis}

El análisis integral del dataset Electricity condujo a conclusiones metodológicas y prácticas relevantes. El protocolo de análisis exploratorio aplicado logró identificar correctamente las características estructurales clave (estacionalidad múltiple, no linealidad moderada, distribuciones no gaussianas), las cuales se reflejaron consistentemente en el desempeño relativo de los modelos evaluados. Los tres modelos superiores (LSPM, MCPS y Sieve Bootstrap), configurados según las directrices emergentes del análisis exploratorio, produjeron desempeño óptimo y estadísticamente indistinguible, validando la robustez del protocolo de preprocesamiento aplicado.

La adaptatividad explícita, incorporada en modelos como AV-MCPS y LSPMW, no confirió ventajas en esta serie caracterizada por cambios distribucionales graduales sin quiebres estructurales abruptos. Este hallazgo sugiere que la adaptatividad debe implementarse selectivamente en contextos donde la evidencia empírica o el conocimiento del dominio señalen la presencia de cambios no estacionarios significativos. En series con dinámica estable, la complejidad adicional de mecanismos adaptativos puede resultar innecesaria o incluso contraproducente.

La presencia confirmada de no normalidad (leptocurtosis) y efectos ARCH justificó plenamente el uso del CRPS como métrica de evaluación principal, así como la validación exhaustiva de calibración mediante diagnósticos PIT. Estas prácticas resultan esenciales para garantizar no solo precisión puntual sino también confiabilidad distribucional de las predicciones, aspecto frecuentemente descuidado en aplicaciones prácticas de pronóstico.

\subsubsection{Recomendaciones para la Práctica}

Basándose en los hallazgos empíricos, se derivan las siguientes recomendaciones para el pronóstico de series con características similares. En primer lugar, debe priorizarse el uso de modelos LSPM o MCPS debido a su parsimonia, interpretabilidad y desempeño óptimo demostrado. Estos modelos, al requerir menos hiperparámetros y ser computacionalmente eficientes, resultan particularmente atractivos para implementaciones operativas.

En segundo lugar, la aplicación de transformación Box-Cox con parámetro estimado mediante el método de Guerrero debe incorporarse rutinariamente para estabilizar la varianza antes del modelado. Esta transformación, aunque simple, demostró ser crucial para homogeneizar la escala de variación y facilitar el ajuste de modelos.

En tercer lugar, la validación de calibración mediante histogramas PIT debe complementar sistemáticamente las métricas tradicionales de precisión puntual. La calibración distribucional, frecuentemente ignorada en la práctica, resulta esencial para garantizar que los intervalos de predicción reportados posean las propiedades de cobertura declaradas, aspecto crítico para la toma de decisiones bajo incertidumbre.

Finalmente, el Sieve Bootstrap debe considerarse como alternativa robusta cuando existan dudas sobre la especificación exacta del modelo generador de datos. Su naturaleza no paramétrica lo torna resiliente ante errores de especificación, proporcionando un mecanismo de cuantificación de incertidumbre confiable incluso cuando los supuestos distribucionales resultan inciertos.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Trafico
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Serie de Tráfico Vial: Dataset Traffic}
\label{sec:aplicacion_trafico}
\subsection{Descripción del Problema y Contexto}
\label{subsec:traffic_contexto}

El pronóstico de flujo vehicular constituye un componente esencial de los sistemas inteligentes de transporte modernos. La predicción precisa del tráfico permite optimizar la gestión de semáforos, reducir congestión, mejorar la planificación de rutas y disminuir emisiones mediante una distribución más eficiente del flujo vehicular en redes urbanas.

El dataset \textit{Traffic} contiene mediciones horarias de ocupación de sensores de tráfico en carreteras del área metropolitana. Para este estudio se utilizó una serie temporal de 2160 observaciones horarias, equivalente a aproximadamente 90 días, proporcionando una ventana suficiente para capturar patrones estacionales recurrentes y evaluar la robustez de los modelos ante variaciones típicas del tráfico urbano.

\subsection{Resultados del Análisis Exploratorio}
\label{subsec:traffic_eda_resultados}

La aplicación del protocolo de análisis exploratorio reveló características estructurales que difieren significativamente del dataset Electricity, justificando así la evaluación comparativa en contextos diversos.

\subsubsection{Transformación de Estabilización de Varianza}

El parámetro óptimo de la transformación Box-Cox, estimado mediante el método de Guerrero, resultó en $\hat{\lambda} = 0.0512$. Este valor positivo sugiere una transformación logarítmica, indicando una relación no lineal moderada entre media y varianza en la serie original.

La Figura~\ref{fig:transformaciones_traffic} presenta la evolución de la serie a través de las etapas de transformación. El panel superior muestra la serie original de tráfico con patrones estacionales y fluctuaciones características del flujo vehicular urbano. El panel central exhibe la serie tras la aplicación de la transformación Box-Cox, donde se aprecia una homogeneización de la escala de variación. El panel inferior presenta la serie transformada tras la eliminación de tendencia mediante LOWESS, revelando la componente estocástica estacionaria.

\begin{figure}[p]
    \centering
    
    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[height=0.3\textheight, width=0.85\textwidth, keepaspectratio]{Imagenes/Cap5_traffic_serie_original.png}
        \caption{Serie original.}
        \label{fig:traffic_original}
    \end{subfigure}
    \vfill
        
    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[height=0.3\textheight, width=0.85\textwidth, keepaspectratio]{Imagenes/Cap5_traffic_serie_box_cox.png}
        \caption{Serie con transformación Box-Cox ($\lambda = 0.0512$).}
        \label{fig:traffic_boxcox}
    \end{subfigure}
    \vfill
    
    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[height=0.3\textheight, width=0.85\textwidth, keepaspectratio]{Imagenes/Cap5_traffic_serie_trend.png}
        \caption{Serie transformada sin componente de tendencia.}
        \label{fig:traffic_detrended}
    \end{subfigure}

    \caption{Proceso de transformación de la serie de tráfico vehicular.}
    \label{fig:transformaciones_traffic}
\end{figure}

\subsubsection{Eliminación de Tendencia y Validación de Estacionariedad}

Se aplicó suavizado LOWESS con parámetro de ancho de banda $f = 0.05$ para remover la componente de tendencia suave. Las pruebas estadísticas confirmaron el logro de estacionariedad tras las transformaciones aplicadas. El test aumentado de Dickey-Fuller arrojó un valor p inferior a 0.01, rechazando la presencia de raíz unitaria. El test KPSS produjo un valor p superior a 0.10, consistente con la hipótesis de estacionariedad. 

El análisis de la función de autocorrelación reveló una estructura de dependencia temporal más compleja que en Electricity, como se aprecia en la Figura~\ref{fig:traffic_acf_pacf}. Se observaron picos significativos en múltiplos de 24 horas (marcados con líneas verticales naranjas en 24h, 168h y 336h), confirmando estacionalidad diaria y semanal, aunque con correlaciones moderadas que sugieren mayor aleatoriedad en los patrones de tráfico comparado con el consumo eléctrico residencial. La función de autocorrelación parcial mostró un patrón de decaimiento más irregular, consistente con una estructura autorregresiva de orden variable que justifica el uso de métodos adaptativos.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.95\textwidth]{Imagenes/Cap5_traffic_acf_pacf.png}
    \caption{Funciones de autocorrelación (ACF) y autocorrelación parcial (PACF) para la serie de tráfico transformada.}
    \label{fig:traffic_acf_pacf}
\end{figure}

\subsubsection{Evaluación de No Linealidad y Distribución}

Los tests de no linealidad (BDS, McLeod-Li, Tsay) rechazaron consistentemente la hipótesis de estructura lineal simple con valores p inferiores a 0.01. El exponente de Hurst estimado fue $\hat{H} = 0.58$, indicando persistencia leve pero menor que el $\hat{H} = 0.62$ observado en Electricity. Este valor más cercano a 0.5 es consistente con la naturaleza más impredecible del tráfico vehicular, donde eventos aleatorios (accidentes, condiciones climáticas) introducen mayor estocasticidad.

El test de Jarque-Bera rechazó normalidad de residuos ($p < 0.001$), evidenciando leptocurtosis y justificando nuevamente el uso de CRPS como métrica de evaluación robusta. La presencia de colas pesadas es más pronunciada que en Electricity, reflejando la mayor frecuencia de eventos extremos en el tráfico urbano.

\subsection{Configuración Experimental}
\label{subsec:traffic_configuracion}

La partición de datos siguió el mismo esquema que en Electricity. El conjunto de prueba se fijó en 24 observaciones (un día completo), mientras que del resto de datos (2136 observaciones), el 15\% se asignó a validación ($\approx$320 observaciones) y el 85\% a entrenamiento ($\approx$1816 observaciones). El horizonte de predicción se mantuvo en $h = 1$ paso adelante (una hora futura), permitiendo comparaciones directas entre ambos datasets.

\subsection{Resultados}
\label{subsec:traffic_resultados}

\subsubsection{Desempeño Predictivo Global}

El Cuadro~\ref{tab:traffic_ranking} presenta el ranking de modelos según desempeño en el conjunto de prueba. Notablemente, los resultados difieren sustancialmente de aquellos observados en Electricity, revelando que la efectividad relativa de los métodos es altamente dependiente de las características específicas de cada serie.

\begin{table}[htbp]
\centering
\caption{Ranking de modelos según desempeño en dataset Traffic.}
\label{tab:traffic_ranking}
\small
\begin{tabular}{clcccccc}
\toprule
\textbf{Rango} & \textbf{Modelo} & \textbf{Victorias} & \textbf{Derrotas} & \textbf{Empates} &\textbf{CRPS Media} & \textbf{CRPS Mediana} \\
\midrule
1 & Sieve Bootstrap & 1 & 0 & 7 & 0.00202 & 0.00171 \\
2 & DeepAR & 1 & 0 & 7 & 0.00321 & 0.00247 \\
3 & EnCQR-LSTM & 1 & 0 & 7 & 0.00286 & 0.00274 \\
4 & AV-MCPS & 0 & 0 & 8 &  0.00233 & 0.00170 \\
5 & LSPM & 0 & 0 & 8 &  0.00416 & 0.00371 \\
6 & MCPS & 0 & 0 & 8 &  0.00265 & 0.00224 \\
7 & LSPMW & 0 & 0 & 8 &  0.01089 & 0.01119 \\
8 & Block Bootstrapping & 0 & 1 & 7 &  0.01075 & 0.01054 \\
9 & AREPD & 0 & 2 & 6 &  0.01086 & 0.01107 \\
\bottomrule
\end{tabular}
\end{table}

Los resultados revelan un cambio dramático en el ordenamiento relativo de los modelos comparado con Electricity. Sieve Bootstrap emerge como el método superior con la mediana de CRPS más baja (0.00171), seguido cercanamente por AV-MCPS (0.00170, rango 4) y DeepAR (0.00247, rango 2). Esta reconfiguración del ranking contrasta notablemente con Electricity, donde LSPM, MCPS y Sieve Bootstrap dominaban con desempeño estadísticamente indistinguible.

La Figura~\ref{fig:traffic_boxplot_crps} presenta la distribución completa de valores CRPS para cada modelo a lo largo de las 24 predicciones horarias. La visualización revela patrones distintivos ausentes en Electricity. Sieve Bootstrap y AV-MCPS exhiben dispersiones notablemente compactas con medianas bajas y escasos valores atípicos. En contraste, LSPM, LSPMW y AREPD muestran dispersiones amplias con múltiples valores atípicos extremos, indicando episodios de predicción particularmente deficiente.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.95\textwidth]{Imagenes/Cap5_traffic_boxplot_crps.png}
    \caption{Distribución de valores CRPS por modelo en el conjunto de prueba del dataset Traffic.}
    \label{fig:traffic_boxplot_crps}
\end{figure}

El desempeño superior de Sieve Bootstrap en esta serie puede atribuirse a su capacidad para capturar estructuras autorregresivas complejas sin imponer formas funcionales rígidas. La naturaleza más errática del tráfico vehicular, con interrupciones impredecibles y patrones menos regulares que el consumo eléctrico residencial, favorece métodos no paramétricos que adaptan flexiblemente el orden del modelo autorregresivo mediante criterios de información como AIC.

Particularmente notable es el desempeño de AV-MCPS, que alcanza la segunda mejor mediana de CRPS (0.00170) a pesar de ubicarse en el rango 4 según victorias totales. Este modelo adaptativo logra capturar eficientemente cambios en la volatilidad del tráfico, justificando su diseño para series con variabilidad temporal heterogénea. El contraste con su desempeño modesto en Electricity (rango 4, mediana 1.791) valida la hipótesis de que la adaptatividad confiere ventajas primordialmente en series con cambios distribucionales más pronunciados.

Los modelos de aprendizaje profundo (DeepAR y EnCQR-LSTM) muestran mejora relativa en Traffic comparado con Electricity. En Electricity ocuparon rangos 6 y 5 con medianas 1.995 y 1.904; aquí ascienden a rangos 2 y 3 con medianas 0.00247 y 0.00274. Este resultado sugiere que la estructura menos regular del tráfico vehicular proporciona patrones más complejos que estos modelos pueden explotar mediante sus arquitecturas recurrentes, aunque el tamaño de muestra sigue limitando su capacidad para superar consistentemente a métodos más parsimoniosos.

El deterioro pronunciado de LSPM (rango 5, CRPS mediana 0.00371) representa el hallazgo más revelador. El modelo que dominó en Electricity (rango 1, mediana 1.497) exhibe aquí desempeño mediocre, evidenciando que su efectividad está condicionada a series con estructura lineal fuerte tras transformaciones. La naturaleza más compleja y menos predecible del tráfico excede las capacidades de este enfoque lineal simple con residuos estudentizados.

La Figura~\ref{fig:traffic_top3_evolucion} ilustra la evolución paso a paso de las distribuciones predictivas para los tres mejores modelos durante los primeros seis pasos de pronóstico. Cada panel muestra las densidades predictivas superpuestas junto con el valor real observado (línea vertical discontinua negra). Los valores de CRPS, presentados mediante parches de color en la leyenda de cada panel, cuantifican la precisión predictiva en cada paso.

\begin{figure}[p]
    \centering
    \includegraphics[width=0.7\textwidth]{Imagenes/traffic_TypeA_Top3_Mejores.png}
    \caption{Evolución de las distribuciones predictivas para los tres mejores modelos en Traffic durante los primeros 6 pasos de pronóstico.}
    \label{fig:traffic_top3_evolucion}
\end{figure}

Los paneles revelan consistencia notable en la calidad predictiva de los tres métodos superiores. En los pasos 1-3, las distribuciones predictivas de Sieve Bootstrap (amarillo) y AV-MCPS (naranja) se concentran estrechamente alrededor del valor real, con valores CRPS consistentemente inferiores a 0.004. MCPS (gris) exhibe dispersiones ligeramente mayores pero mantiene centrado adecuado. En los pasos 4-6, se observa incremento moderado en la dispersión para todos los modelos, reflejando el aumento natural de incertidumbre predictiva con el horizonte, aunque los tres métodos mantienen capacidad de concentrar masa probabilística cerca del valor observado.

Esta visualización confirma que la superioridad de Sieve Bootstrap y AV-MCPS no es meramente un artefacto del promedio global de CRPS, sino que se manifiesta consistentemente paso a paso. La habilidad de estos modelos para generar distribuciones predictivas concentradas indica que capturan efectivamente la estructura de dependencia temporal del tráfico vehicular, incluso ante la mayor estocasticidad inherente a este dominio.

\subsubsection{Comparación Estadística Formal}

Para evaluar si las diferencias observadas en desempeño predictivo resultan estadísticamente significativas, se aplicó el test de Diebold-Mariano modificado con corrección de Bonferroni entre todos los modelos evaluados. Este test, equipado con asintótica de suavizado fijo (fixed-smoothing asymptotics), resulta más robusto en muestras pequeñas que el test DM estándar, manteniendo buen desempeño asintótico.

La Figura~\ref{fig:traffic_hln_dm_pvalues} presenta la matriz completa de p-valores para las 36 comparaciones pareadas realizadas. Dado el número de comparaciones múltiples, se aplicó corrección de Bonferroni ($\alpha_{\text{Bonf}} = 0.05/36 = 0.00139$), resultando en un umbral de significancia altamente conservador. Las celdas en tonos verdosos indican p-valores bajos (evidencia de diferencia significativa), mientras que tonos rojizos señalan p-valores altos (modelos estadísticamente indistinguibles). Los asteriscos denotan significancia: *** para $p < \alpha_{\text{Bonf}}$ y * para $p < 0.05$.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{Imagenes/Cap5_traffic_HLN_DM_Pvalues_Matrix.png}
    \caption{Matriz de p-valores del test Diebold-Mariano modificado (HLN) para el dataset Traffic.}
    \label{fig:traffic_hln_dm_pvalues}
\end{figure}

El análisis de significancia revela patrones importantes que contrastan con los observados en Electricity. En Electricity, los tres mejores modelos (LSPM, MCPS, Sieve Bootstrap) exhibieron desempeño estadísticamente indistinguible con valores p superiores a 0.30 en todas las comparaciones pareadas. En Traffic, el panorama es más heterogéneo y revela diferenciación estadística más pronunciada.

Sieve Bootstrap supera significativamente ($p < 0.05$) a LSPM ($p = 0.030$), LSPMW ($p = 0.124$, tendencia), AREPD ($p = 0.001$***) y EnCQR-LSTM ($p = 0.018$*), consolidando su ventaja como método superior. Sin embargo, no muestra diferencias significativas contra MCPS ($p = 0.253$), AV-MCPS ($p = 0.371$) y DeepAR ($p = 0.223$), confirmando que estos cuatro métodos poseen capacidad predictiva estadísticamente equivalente a nivel $\alpha = 0.05$.

AV-MCPS, a pesar de su excelente mediana de CRPS (0.00170), no supera significativamente a ningún otro modelo salvo los tres peores (Block Bootstrapping: $p = 0.004$*, AREPD: $p = 0.002$*, LSPMW: $p = 0.029$*). Sus comparaciones contra Sieve Bootstrap ($p = 0.371$), MCPS ($p = 0.389$), DeepAR ($p = 0.381$) y EnCQR-LSTM ($p = 0.259$) revelan equivalencia estadística, sugiriendo que varios métodos de complejidad comparable capturan adecuadamente la estructura del tráfico.

LSPM muestra diferencias significativas contra Sieve Bootstrap ($p = 0.030$*), LSPMW ($p = 0.389$, no significativo) y AREPD ($p = 0.002$*), confirmando su deterioro relativo. Particularmente revelador es que LSPM no muestra diferencias significativas contra MCPS ($p = 0.115$), AV-MCPS ($p = 0.084$) ni contra los modelos de aprendizaje profundo (DeepAR: $p = 0.350$, EnCQR-LSTM: $p = 0.131$). Este patrón indica que LSPM sufre específicamente por su simplicidad estructural pero no es significativamente peor que otros enfoques cuando estos tampoco logran capturar completamente la complejidad.

Los tres modelos en las posiciones inferiores (LSPMW, Block Bootstrapping, AREPD) exhiben diferencias significativas contra la mayoría de métodos superiores, validando estadísticamente su peor desempeño. Particularmente notable es que AREPD muestra valores p menores a 0.003*** contra todos los modelos excepto LSPMW ($p = 0.003$*) y Block Bootstrapping ($p = 0.892$), confirmando su inadecuación severa para esta serie. El parámetro de descuento estimado $\hat{\rho} = 0.95$ en AREPD resulta excesivamente conservador para la mayor volatilidad del tráfico, causando suavizado excesivo que elimina variabilidad predictiva informativa.

La ausencia de diferencias significativas entre los cuatro métodos superiores (Sieve Bootstrap, AV-MCPS, MCPS, DeepAR) con p-valores consistentemente superiores a 0.22 sugiere que, para series complejas como Traffic, múltiples enfoques metodológicos distintos alcanzan niveles comparables de efectividad siempre que incorporen suficiente flexibilidad estructural. Este hallazgo contrasta con Electricity, donde la homogeneidad se concentraba en tres métodos específicos (LSPM, MCPS, Sieve Bootstrap), evidenciando que la complejidad del dominio amplía el conjunto de métodos viables.

\subsubsection{Análisis de Calibración Distribucional}

La calibración de las distribuciones predictivas se evaluó mediante histogramas de transformación PIT y curvas de confiabilidad. La Figura~\ref{fig:traffic_pit} presenta los histogramas PIT para todos los modelos evaluados. Los patrones de calibración en Traffic difieren notablemente de aquellos observados en Electricity, reflejando la mayor dificultad intrínseca de cuantificar incertidumbre en series con alta variabilidad temporal.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.95\textwidth]{Imagenes/Cap5_traffic_pit_histograms.png}
    \caption{Histogramas de transformación PIT para todos los modelos en el dataset Traffic.}
    \label{fig:traffic_pit}
\end{figure}

Sieve Bootstrap y AV-MCPS produjeron distribuciones PIT aproximadamente uniformes, confirmando buena calibración. Este resultado es consistente con su desempeño superior en términos de CRPS y valida que ambos métodos no solo generan predicciones precisas sino también correctamente calibradas. DeepAR y EnCQR-LSTM mostraron ligera forma de U, indicando sobreconfianza leve pero no severa. Esta tendencia fue menos pronunciada que en Electricity, sugiriendo que la mayor complejidad de Traffic obliga a estos modelos a generar distribuciones predictivas más conservadoras.

LSPM exhibió desviaciones más pronunciadas de uniformidad, con forma de U invertida indicando sobredispersión. Este patrón contrasta con su calibración adecuada en Electricity, evidenciando que cuando el modelo subyacente es inadecuado (estructura lineal simple ante dinámica compleja), los intervalos predictivos resultantes tienden a sobreestimar la incertidumbre real. Los modelos en posiciones inferiores (LSPMW con $\hat{\rho} = 0.95$, Block Bootstrapping, AREPD con $\hat{\rho} = 0.95$) mostraron patrones erráticos sin forma definida, consistente con su incapacidad para capturar la estructura de dependencia temporal.

La Figura~\ref{fig:traffic_reliability} presenta las curvas de confiabilidad, comparando frecuencias empíricas de cobertura contra niveles nominales para el rango 10\%-90\%. Los patrones observados corroboran y amplían los hallazgos de los histogramas PIT.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.95\textwidth]{Imagenes/Cap5_traffic_reliability.png}
    \caption{Curvas de confiabilidad para los modelos evaluados en el dataset Traffic.}
    \label{fig:traffic_reliability}
\end{figure}

Los tres modelos superiores (Sieve Bootstrap, DeepAR, EnCQR-LSTM) mantuvieron coberturas empíricas cercanas a los niveles nominales, aunque con mayor desviación de la diagonal perfecta que en Electricity. Este resultado refleja la mayor dificultad intrínseca de cuantificar incertidumbre en series de tráfico con interrupciones impredecibles como accidentes o condiciones climáticas adversas. AV-MCPS mostró curva particularmente cercana a la diagonal en niveles de confianza intermedios (30\%-70\%), validando su capacidad para adaptar estimaciones de volatilidad local.

LSPM y los modelos inferiores exhibieron desviaciones sustanciales, especialmente en las colas (niveles 10\% y 90\%). Este patrón indica que estos modelos fallan en capturar correctamente la incertidumbre asociada con eventos extremos, limitación crítica para aplicaciones operativas donde las decisiones más importantes frecuentemente involucran escenarios de tráfico inusualmente bajo o alto.

\subsection{Síntesis del Estudio del Dataset Traffic}
\label{subsec:traffic_sintesis}

El análisis del dataset Traffic produjo conclusiones contrastantes con Electricity, revelando la importancia crítica de adaptar la selección de modelos a las características específicas de cada serie. El reordenamiento dramático del ranking, donde Sieve Bootstrap y métodos adaptativos superan a LSPM (que dominaba en Electricity), valida que no existe un modelo universalmente superior. La efectividad depende crucialmente de la regularidad estructural, nivel de aleatoriedad y estabilidad temporal de los patrones.

La naturaleza más errática del tráfico vehicular, con eventos impredecibles como accidentes o condiciones climáticas adversas, favorece métodos flexibles capaces de adaptar su complejidad automáticamente (Sieve Bootstrap) o de ajustarse a cambios distribucionales locales (AV-MCPS). En contraste, modelos con especificaciones rígidas (LSPM) o que asumen estabilidad estructural (Block Bootstrapping estándar) sufren degradación de desempeño marcada, tanto en precisión como en calibración.

El análisis exhaustivo de significancia estadística mediante el test de Diebold-Mariano reveló que, aunque existen diferencias significativas entre métodos superiores e inferiores, varios modelos en el rango superior (Sieve Bootstrap, AV-MCPS, MCPS, DeepAR, EnCQR-LSTM) exhiben desempeño estadísticamente comparable. Este resultado sugiere que, para series complejas como Traffic, múltiples enfoques metodológicos distintos pueden alcanzar niveles de efectividad similares siempre que incorporen suficiente flexibilidad estructural.

La evaluación de calibración reveló que el desempeño superior en términos de CRPS se acompaña generalmente de mejor calibración distribucional, pero la relación no es perfecta. AV-MCPS, con la segunda mejor mediana de CRPS, exhibió calibración particularmente robusta, validando que la adaptatividad no solo mejora precisión puntual sino también confiabilidad de intervalos predictivos. Este hallazgo tiene implicaciones prácticas importantes, sugiriendo que métodos adaptativos merecen consideración prioritaria en aplicaciones donde la correcta cuantificación de incertidumbre es crítica.

\subsubsection{Recomendaciones para la Práctica}

Para series de tráfico vehicular o contextos similares con alta variabilidad temporal e interrupciones impredecibles, se recomiendan las siguientes estrategias. En primer lugar, debe priorizarse Sieve Bootstrap como método predeterminado debido a su robustez, flexibilidad y capacidad para adaptar automáticamente la complejidad del modelo a los datos observados mediante criterios de información. Su desempeño consistentemente superior y buena calibración lo tornan particularmente atractivo para implementaciones operativas.

En segundo lugar, considerar AV-MCPS como alternativa especialmente cuando existe evidencia de cambios distribucionales temporales o heterogeneidad de varianza. Su capacidad para adaptarse localmente a cambios en volatilidad, evidenciada por su mediana de CRPS comparable a Sieve Bootstrap y calibración robusta, lo torna particularmente valioso en aplicaciones donde la incertidumbre varía sistemáticamente en el tiempo.

En tercer lugar, los métodos de aprendizaje profundo (DeepAR, EnCQR-LSTM) merecen consideración cuando el tamaño de muestra es suficientemente grande y existe capacidad computacional adecuada. Aunque no dominaron en este experimento con aproximadamente 1800 observaciones, su mejora relativa respecto a Electricity sugiere que pueden explotar efectivamente la complejidad adicional en datos de tráfico. Con muestras mayores (decenas de miles de observaciones), estos métodos podrían superar a alternativas más parsimoniosas.

Finalmente, evitar la aplicación acrítica de modelos lineales simples (LSPM) en series con estructura compleja o patrones irregulares. El deterioro pronunciado de LSPM en Traffic, tanto en precisión como en calibración, demuestra que simplicidad y parsimonia no garantizan efectividad cuando la realidad subyacente excede las capacidades representacionales del modelo. La selección de modelos debe guiarse primordialmente por las características identificadas en el análisis exploratorio, no por consideraciones de simplicidad algorítmica.
\section{Serie de Tipo de Cambio: Dataset Exchange Rate}
\label{sec:aplicacion_exchange}

\subsection{Descripción del Problema y Contexto}
\label{subsec:exchange_contexto}

El pronóstico de tipos de cambio constituye un problema fundamental en economía financiera y gestión de riesgos cambiarios. La predicción precisa de fluctuaciones en tasas de cambio permite a instituciones financieras, corporaciones multinacionales e inversionistas tomar decisiones informadas sobre cobertura de riesgo cambiario, arbitraje y estrategias de inversión internacional.

El dataset \textit{Exchange Rate} contiene observaciones diarias de tasas de cambio entre pares de divisas. Para este estudio se utilizó una serie temporal de 1825 observaciones diarias, equivalente a aproximadamente 5 años de operación continua en mercados de divisas. Esta ventana temporal proporciona cobertura suficiente para capturar la dinámica característica de los mercados cambiarios, incluyendo ciclos económicos, efectos de noticias macroeconómicas y cambios de régimen asociados a intervenciones de bancos centrales.

\subsection{Resultados del Análisis Exploratorio}
\label{subsec:exchange_eda_resultados}

La aplicación del protocolo de análisis exploratorio reveló características estructurales que contrastan marcadamente con los datasets Electricity y Traffic, evidenciando propiedades únicas de series financieras.

\subsubsection{Transformación de Estabilización de Varianza}

El parámetro óptimo de la transformación Box-Cox, estimado mediante el método de Guerrero, resultó en $\hat{\lambda} = 1.9999$. Este valor extraordinariamente cercano a 2 indica que prácticamente no se requiere transformación para estabilizar la varianza. A diferencia de Electricity ($\hat{\lambda} = 0.4821$) y Traffic ($\hat{\lambda} = 0.0512$), que exhibían relaciones no lineales sustanciales entre media y varianza, Exchange Rate muestra homocedasticidad relativa en su estructura de primer orden.

La Figura~\ref{fig:transformaciones_exchange} presenta la evolución de la serie a través de las etapas de transformación. El panel superior muestra la serie original de tipo de cambio con fluctuaciones características de mercados financieros. El panel central exhibe la serie tras la aplicación de la transformación Box-Cox, donde la similitud con la serie original confirma la ausencia de necesidad de transformación no lineal fuerte. El panel inferior presenta la serie transformada tras la eliminación de tendencia mediante LOWESS, revelando la componente estocástica con sus propiedades de memoria larga.

\begin{figure}[p]
    \centering
    
    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[height=0.3\textheight, width=0.85\textwidth, keepaspectratio]{Imagenes/Cap5_exchange_serie_original.png}
        \caption{Serie original.}
        \label{fig:exchange_original}
    \end{subfigure}
    \vfill
        
    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[height=0.3\textheight, width=0.85\textwidth, keepaspectratio]{Imagenes/Cap5_exchange_serie_box_cox.png}
        \caption{Serie con transformación Box-Cox ($\lambda = 1.9999$).}
        \label{fig:exchange_boxcox}
    \end{subfigure}
    \vfill
    
    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[height=0.3\textheight, width=0.85\textwidth, keepaspectratio]{Imagenes/Cap5_exchange_serie_trend.png}
        \caption{Serie transformada sin componente de tendencia.}
        \label{fig:exchange_detrended}
    \end{subfigure}

    \caption{Proceso de transformación de la serie de tipo de cambio.}
    \label{fig:transformaciones_exchange}
\end{figure}

\subsubsection{Eliminación de Tendencia y Validación de Estacionariedad}

Se aplicó suavizado LOWESS con parámetro de ancho de banda $f = 0.05$ para remover la componente de tendencia suave. Las pruebas estadísticas confirmaron el logro de estacionariedad tras las transformaciones aplicadas. El test aumentado de Dickey-Fuller arrojó un valor p de 0.01, rechazando la presencia de raíz unitaria. El test KPSS produjo un valor p de 0.10, consistente con la hipótesis de estacionariedad.

El análisis de la función de autocorrelación reveló una estructura de dependencia temporal radicalmente diferente a las observadas en Electricity y Traffic, como se aprecia en la Figura~\ref{fig:exchange_acf_pacf}. La autocorrelación en el primer lag alcanzó $\hat{\rho}_1 = 0.890$, valor extraordinariamente alto que evidencia persistencia extrema característica de series financieras con memoria larga. Las autocorrelaciones decayeron gradualmente pero permanecieron significativas hasta lags muy distantes: $\hat{\rho}_2 = 0.797$, $\hat{\rho}_3 = 0.695$, $\hat{\rho}_4 = 0.604$, $\hat{\rho}_5 = 0.515$. Este patrón de decaimiento hiperbólico contrasta con el decaimiento geométrico típico de procesos autorregresivos estacionarios de orden bajo.

Notablemente, emergieron picos negativos significativos en lags correspondientes a ciclos de aproximadamente 30, 90, 180 y 360 días (marcados con líneas verticales naranjas), reflejando estacionalidad mensual, trimestral, semestral y anual característica de series macroeconómicas. Esta estructura sugiere reversión a la media con periodicidades múltiples asociadas a ciclos económicos y eventos recurrentes en mercados financieros globales.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.95\textwidth]{Imagenes/Cap5_exchange_acf_pacf.png}
    \caption{Funciones de autocorrelación (ACF) y autocorrelación parcial (PACF) para la serie de tipo de cambio transformada.}
    \label{fig:exchange_acf_pacf}
\end{figure}

La función de autocorrelación parcial mostró un pico dominante en lag 1 ($\hat{\phi}_{11} = 0.890$) seguido de coeficientes parciales pequeños y dispersos en lags superiores. Este patrón sugiere que, aunque la autocorrelación simple exhibe persistencia larga, gran parte de esta dependencia se captura mediante un proceso autorregresivo de orden relativamente bajo, con efectos residuales de memoria larga.

\subsubsection{Evaluación de No Linealidad y Distribución}

La batería de tests de no linealidad produjo resultados mixtos que distinguen Exchange Rate de los datasets previos. El test BDS rechazó la hipótesis nula de independencia con $p < 0.00001$, evidenciando dependencia no lineal significativa. El test de McLeod-Li rechazó fuertemente la hipótesis de homocedasticidad condicional ($p < 0.00001$), confirmando presencia de efectos ARCH/GARCH característicos de series financieras. Sin embargo, el test de Tsay \textit{no} rechazó la hipótesis de estructura lineal ($p = 0.966$), sugiriendo que la no linealidad se concentra primordialmente en la varianza condicional más que en la media condicional.

El test ARCH-LM confirmó heterocedasticidad condicional ($p < 0.00001$), validando la necesidad de métodos que capturen volatilidad cambiante en el tiempo. Esta combinación de hallazgos (linealidad en media, no linealidad en varianza) es característica de mercados financieros eficientes donde la predicción del nivel es difícil pero la predicción de volatilidad es tractable.

El exponente de Hurst estimado fue $\hat{H} = 0.933$, valor extraordinariamente elevado que indica memoria larga extrema. Este $\hat{H}$ sustancialmente mayor que los observados en Electricity ($\hat{H} = 0.62$) y Traffic ($\hat{H} = 0.58$) evidencia que shocks en el tipo de cambio tienen efectos persistentes que decaen muy lentamente. La interpretación financiera es que tendencias cambiarias tienden a mantenerse por períodos prolongados, fenómeno documentado extensamente en la literatura de finanzas bajo el término \textit{momentum} o persistencia de tendencias.

El test de Jarque-Bera rechazó normalidad de residuos ($p < 0.001$), evidenciando leptocurtosis característica de retornos financieros. Las colas pesadas reflejan la mayor frecuencia de eventos extremos (movimientos bruscos) comparado con una distribución gaussiana, justificando el uso de CRPS como métrica robusta que penaliza adecuadamente errores en las colas de la distribución predictiva.

\subsection{Configuración Experimental}
\label{subsec:exchange_configuracion}

La partición de datos siguió el mismo esquema que en Electricity y Traffic. El conjunto de prueba se fijó en 30 observaciones (30 días de operación), mientras que del resto de datos (1795 observaciones), el 15\% se asignó a validación ($\approx$269 observaciones) y el 85\% a entrenamiento ($\approx$1526 observaciones). El horizonte de predicción se mantuvo en $h = 1$ paso adelante (un día futuro), permitiendo comparaciones directas entre los tres datasets.

\subsection{Resultados}
\label{subsec:exchange_resultados}

\subsubsection{Desempeño Predictivo Global}

El Cuadro~\ref{tab:exchange_ranking} presenta el ranking de modelos según desempeño en el conjunto de prueba. Los resultados revelan un patrón de desempeño marcadamente diferente a los observados en Electricity y Traffic, con un grupo de seis modelos exhibiendo efectividad estadísticamente indistinguible en las posiciones superiores.

\begin{table}[htbp]
\centering
\caption{Ranking de modelos según desempeño en dataset Exchange Rate.}
\label{tab:exchange_ranking}
\small
\begin{tabular}{clcccccc}
\toprule
\textbf{Rango} & \textbf{Modelo} & \textbf{Victorias} & \textbf{Derrotas} & \textbf{Empates} & \textbf{CRPS Media} & \textbf{CRPS Mediana} \\
\midrule
1 & Sieve Bootstrap & 3 & 0 & 5 & 0.00322 & 0.00288 \\
2 & DeepAR & 3 & 0 & 5 & 0.00374 & 0.00263 \\
3 & LSPM & 3 & 0 & 5 & 0.00416 & 0.00262 \\
4 & LSPMW & 3 & 0 & 5 & 0.00439 & 0.00254 \\
5 & MCPS & 3 & 0 & 5 & 0.01256 & 0.00968 \\
6 & AV-MCPS & 3 & 0 & 5 & 0.01174 & 0.00934 \\
7 & AREPD & 1 & 6 & 1 & 0.06437 & 0.06564 \\
8 & EnCQR-LSTM & 0 & 6 & 2 & 0.06658 & 0.06764 \\
9 & Block Bootstrapping & 0 & 7 & 1 & 0.07180 & 0.07225 \\
\bottomrule
\end{tabular}
\end{table}

El hallazgo más notable es la ausencia de un ganador claro en las posiciones superiores. Los seis primeros modelos obtuvieron idénticos registros de victorias (3), derrotas (0) y empates (5), indicando desempeño prácticamente indistinguible en términos de comparaciones pareadas directas. LSPMW (con $\hat{\rho} = 0.95$) exhibió la mejor mediana de CRPS (0.00254), seguido cercanamente por LSPM (0.00262), DeepAR (0.00263) y Sieve Bootstrap (0.00288). Esta compresión de medianas en un rango estrecho ($\Delta = 0.00034$) contrasta marcadamente con la dispersión observada en Traffic.

La Figura~\ref{fig:exchange_boxplot_crps} presenta la distribución completa de valores CRPS para cada modelo a lo largo de las 30 predicciones diarias. La visualización revela dos grupos claramente diferenciados: un cluster superior de seis modelos con dispersiones compactas y medianas bajas, y un grupo inferior de tres modelos (AREPD con $\hat{\rho} = 0.95$, EnCQR-LSTM, Block Bootstrapping) con valores CRPS superiores en un orden de magnitud.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{Imagenes/Cap5_exchange_boxplot_crps.png}
    \caption{Distribución de valores CRPS por modelo en el conjunto de prueba del dataset Exchange Rate.}
    \label{fig:exchange_boxplot_crps}
\end{figure}

El desempeño competitivo de LSPM y LSPMW en Exchange Rate, contrastando con su deterioro en Traffic, valida la hipótesis de que estos métodos lineales son apropiados cuando la media condicional exhibe estructura autorregresiva dominante. El test de Tsay, que no rechazó linealidad en media ($p = 0.966$), anticipó correctamente este resultado. La capacidad de LSPMW para adaptarse a heterocedasticidad mediante ponderación temporal con parámetro $\hat{\rho} = 0.95$ explica su ligera ventaja sobre LSPM estándar.

Sieve Bootstrap mantuvo desempeño robusto, ocupando el primer lugar por victorias totales aunque con mediana ligeramente superior a LSPMW. Su capacidad para seleccionar automáticamente el orden autorregresivo óptimo mediante AIC resultó valiosa en este contexto de memoria larga donde el orden efectivo del proceso puede ser sustancial.

Los métodos de predicción conformal (MCPS y AV-MCPS) exhibieron medianas significativamente mayores que los cuatro métodos superiores, pero permanecieron en el cluster superior de seis modelos. Este desempeño relativamente modesto puede atribuirse a la naturaleza de series financieras, donde la hipótesis de intercambiabilidad subyacente en predicción conformal es particularmente débil debido a regímenes cambiantes de volatilidad.

DeepAR mostró mejora sustancial comparado con su desempeño en Electricity, alcanzando mediana comparable a LSPM. Este resultado sugiere que la estructura de memoria larga y dependencia no lineal en varianza proporciona señales que arquitecturas recurrentes pueden explotar efectivamente.

El colapso de tres modelos (AREPD con $\hat{\rho} = 0.95$, EnCQR-LSTM, Block Bootstrapping) con valores CRPS en el rango 0.064-0.072 representa el hallazgo más revelador. Estos métodos, que mostraron desempeño variable pero generalmente competitivo en datasets previos, fracasan completamente en Exchange Rate. AREPD, diseñado para capturar dinámicas multivariadas, no puede explotar esta capacidad en el contexto univariado del experimento. EnCQR-LSTM exhibe el peor desempeño entre los métodos de aprendizaje profundo, sugiriendo que su arquitectura de cuantiles conformales introduce rigidez inadecuada para la heterocedasticidad extrema de series cambiarias. Block Bootstrapping estándar, sin mecanismos adaptativos, no captura adecuadamente la estructura de dependencia de largo alcance.

La Figura~\ref{fig:exchange_top3_evolucion} ilustra la evolución paso a paso de las distribuciones predictivas para los tres mejores modelos (LSPMW, LSPM, DeepAR) durante los primeros seis pasos de pronóstico. Cada panel muestra las densidades predictivas superpuestas junto con el valor real observado (línea vertical discontinua negra). Los valores de CRPS, presentados mediante parches de color en la leyenda de cada panel, cuantifican la precisión predictiva en cada paso.

\begin{figure}[p]
    \centering
    \includegraphics[width=0.7\textwidth]{Imagenes/Exchange_Series_0_TypeA_Top3_Mejores.png}
    \caption{Evolución de las distribuciones predictivas para los tres mejores modelos en Exchange Rate durante los primeros 6 pasos de pronóstico.}
    \label{fig:exchange_top3_evolucion}
\end{figure}

Los paneles revelan convergencia notable de los tres métodos superiores en términos de ubicación y dispersión de las distribuciones predictivas. En los pasos 1-3, LSPMW (rosa), LSPM (gris) y DeepAR (rojo) generan densidades prácticamente superpuestas, todas concentradas estrechamente alrededor del valor real. Los valores CRPS en estos pasos iniciales permanecen en el rango 0.0037-0.0178, confirmando precisión predictiva comparable.

En los pasos 4-6, se observa ligero incremento en la dispersión predictiva para los tres modelos, reflejando acumulación natural de incertidumbre con el horizonte de pronóstico. Sin embargo, las distribuciones mantienen centrado adecuado y continúan capturando el valor observado dentro de sus regiones de alta densidad. LSPMW exhibe valores CRPS ligeramente menores en los pasos 4-6 (0.0066-0.0068) comparado con LSPM (0.0066-0.0068) y DeepAR (0.0040-0.0088), validando la ventaja marginal de la ponderación temporal adaptativa en horizontes más distantes.

Esta visualización confirma que la convergencia de métodos metodológicamente dispares (regresión lineal ponderada, bootstrap no paramétrico, redes neuronales recurrentes) hacia desempeño prácticamente idéntico no es artefacto estadístico sino reflejo genuino de estructura subyacente con dominancia autorregresiva lineal. La memoria larga extrema ($\hat{H} = 0.933$) combinada con linealidad en media ($p_{\text{Tsay}} = 0.966$) define un régimen donde múltiples enfoques competentes convergen hacia soluciones óptimas similares.


\subsubsection{Comparación Estadística Formal}

Para evaluar si las diferencias observadas en desempeño predictivo resultan estadísticamente significativas, se aplicó el test de Diebold-Mariano modificado con corrección de Bonferroni entre todos los modelos evaluados. Este test, equipado con asintótica de suavizado fijo (fixed-smoothing asymptotics), resulta más robusto en muestras pequeñas que el test DM estándar, manteniendo buen desempeño asintótico.

La Figura~\ref{fig:exchange_hln_dm_pvalues} presenta la matriz completa de p-valores para las 36 comparaciones pareadas realizadas. Dado el número de comparaciones múltiples, se aplicó corrección de Bonferroni ($\alpha_{\text{Bonf}} = 0.05/36 = 0.00139$), resultando en un umbral de significancia altamente conservador. Las celdas en tonos verdosos indican p-valores bajos (evidencia de diferencia significativa), mientras que tonos rojizos señalan p-valores altos (modelos estadísticamente indistinguibles). Los asteriscos denotan significancia: *** para $p < \alpha_{\text{Bonf}}$ y * para $p < 0.05$.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{Imagenes/Cap5_exchange_HLN_DM_Pvalues_Matrix.png}
    \caption{Matriz de p-valores del test Diebold-Mariano modificado (HLN) para el dataset Exchange Rate.}
    \label{fig:exchange_hln_dm_pvalues}
\end{figure}

El análisis de significancia revela un patrón notable: los cuatro modelos superiores (Sieve Bootstrap, DeepAR, LSPM, LSPMW) no exhiben diferencias estadísticamente significativas entre sí al nivel $\alpha = 0.05$. Las comparaciones pareadas arrojan valores p sustancialmente superiores al umbral convencional: Sieve Bootstrap vs. LSPM ($p = 0.139$), Sieve Bootstrap vs. LSPMW ($p = 0.096$), Sieve Bootstrap vs. DeepAR ($p = 0.303$), LSPM vs. DeepAR ($p = 0.502$), LSPMW vs. DeepAR ($p = 0.314$). La única excepción es LSPM vs. LSPMW ($p = 0.020$*), donde la adaptatividad del segundo genera ventaja estadísticamente significativa pero de magnitud práctica modesta ($\Delta_{\text{mediana}} = 0.00008$).

Este patrón contrasta con Electricity, donde los tres mejores modelos exhibieron indistinguibilidad estadística pero con mayor dispersión de valores p (rango 0.30-0.99), y con Traffic, donde Sieve Bootstrap mostró superioridad significativa sobre varios competidores. En Exchange Rate, la convergencia de múltiples metodologías dispares (bootstrap no paramétrico, aprendizaje profundo, predicción conformal lineal) hacia desempeño estadísticamente equivalente sugiere que todos capturan exitosamente la estructura autorregresiva lineal dominante identificada en el análisis exploratorio.

MCPS y AV-MCPS, aunque estadísticamente indistinguibles entre sí ($p = 0.600$), son significativamente inferiores a los cuatro métodos superiores. Las comparaciones contra Sieve Bootstrap arrojan $p = 0.007$** (MCPS) y $p = 0.010$* (AV-MCPS). Contra LSPM: $p = 0.011$* (MCPS) y $p = 0.021$* (AV-MCPS). Este resultado valida que, aunque ambos métodos conformales permanecen en el cluster superior de seis modelos, su desempeño es detectablemente inferior cuando se controla apropiadamente por autocorrelación temporal en el test de Diebold-Mariano.

Los tres modelos en las posiciones inferiores exhiben diferencias altamente significativas contra todos los métodos superiores, con valores p típicamente menores a 0.001***. EnCQR-LSTM muestra valores p extremadamente bajos ($p < 0.000001$***) contra los cuatro mejores modelos, confirmando su inadecuación severa para esta serie. Notablemente, AREPD y EnCQR-LSTM no muestran diferencias significativas entre sí ($p = 0.207$), indicando que ambos fallan de manera similar ante la estructura de memoria larga y heterocedasticidad condicional.

Block Bootstrapping, con valores p menores a $10^{-6}$*** contra todos los modelos superiores, representa el peor desempeño. Este resultado evidencia que el bootstrap en bloques estándar, sin selección adaptativa de longitud de bloque ni mecanismos para capturar memoria larga, es completamente inadecuado para series con $\hat{H} = 0.933$. El contraste con Sieve Bootstrap, que adaptivamente selecciona el orden autorregresivo óptimo, valida la importancia crítica de la adaptatividad en series financieras.

\subsubsection{Análisis de Calibración Distribucional}

La calibración de las distribuciones predictivas se evaluó mediante histogramas de transformación PIT y curvas de confiabilidad. La Figura~\ref{fig:exchange_pit} presenta los histogramas PIT para todos los modelos evaluados. Los patrones de calibración en Exchange Rate revelan desafíos únicos asociados con la predicción de series financieras con heterocedasticidad condicional extrema.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.95\textwidth]{Imagenes/Cap5_exchange_pit_histograms.png}
    \caption{Histogramas de transformación PIT para todos los modelos en el dataset Exchange Rate.}
    \label{fig:exchange_pit}
\end{figure}

Los cuatro modelos superiores (Sieve Bootstrap, DeepAR, LSPM, LSPMW) exhibieron patrones PIT relativamente uniformes, aunque con desviaciones más pronunciadas que las observadas en Electricity. Sieve Bootstrap y LSPM mostraron distribuciones con ligera forma de U, indicando sobreconfianza leve en predicciones centrales pero captura razonable de eventos en las colas. LSPMW (con $\hat{\rho} = 0.95$) exhibió uniformidad mejorada comparado con LSPM, validando que la ponderación temporal adaptativa no solo mejora precisión sino también calibración. DeepAR produjo la distribución PIT más uniforme entre los métodos de aprendizaje profundo, consistente con su diseño explícito para modelar distribuciones predictivas completas.

MCPS y AV-MCPS mostraron patrones PIT con mayor concentración en valores extremos (cercanos a 0 y 1), indicando tendencia a generar distribuciones predictivas demasiado conservadoras. Este fenómeno es consistente con la naturaleza de predicción conformal, que construye intervalos con garantías de cobertura marginal pero puede producir regiones excesivamente amplias cuando la hipótesis de intercambiabilidad es fuertemente violada.

Los tres modelos en posiciones inferiores exhibieron colapso de calibración severo. EnCQR-LSTM mostró concentración extrema de masa PIT en el rango 0.9-1.0, con densidad superior a 40 en este intervalo. Este patrón indica subestimación sistemática y severa del verdadero valor, generando distribuciones predictivas desplazadas hacia valores menores que las observaciones reales. AREPD (con $\hat{\rho} = 0.95$) mostró concentración bilateral en las colas (0-0.1 y 0.9-1.0), reflejando inestabilidad en la ubicación de la distribución predictiva. Block Bootstrapping exhibió concentración extrema en la cola derecha, evidenciando sesgo sistemático hacia valores predichos menores que las observaciones.

La Figura~\ref{fig:exchange_reliability} presenta las curvas de confiabilidad, comparando frecuencias empíricas de cobertura contra niveles nominales para el rango 10\%-90\%. Los patrones observados corroboran los hallazgos de los histogramas PIT pero revelan información adicional sobre el comportamiento en diferentes niveles de confianza.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.95\textwidth]{Imagenes/Cap5_exchange_reliability.png}
    \caption{Curvas de confiabilidad para los modelos evaluados en el dataset Exchange Rate.}
    \label{fig:exchange_reliability}
\end{figure}

Los cuatro modelos superiores mantuvieron trayectorias relativamente cercanas a la diagonal de calibración perfecta, aunque con mayor variabilidad que en datasets previos debido al tamaño reducido del conjunto de prueba (30 observaciones). Sieve Bootstrap y LSPMW mostraron las curvas más próximas a la diagonal en niveles de confianza intermedios (30\%-70\%), validando su capacidad para generar intervalos predictivos con coberturas empíricas consistentes con las nominales. DeepAR exhibió ligera sobrecobertura en niveles bajos (10\%-30\%) pero convergió hacia la diagonal en niveles altos, patrón consistente con su ligera sobreconfianza observada en el histograma PIT.

MCPS y AV-MCPS mostraron curvas que permanecieron por encima de la diagonal en la mayoría de niveles, confirmando su tendencia a generar intervalos excesivamente conservadores. Sin embargo, en niveles de confianza muy altos (>80\%), estas curvas se acercaron a la diagonal, indicando que las regiones predictivas conformales capturan adecuadamente eventos extremos incluso cuando son subóptimas para predicciones centrales.

Los tres modelos inferiores exhibieron colapso completo de calibración. EnCQR-LSTM mostró cobertura empírica cercana a cero para todos los niveles de confianza hasta el 90\%, manifestando el sesgo sistemático identificado en el histograma PIT. Block Bootstrapping y AREPD mostraron curvas que permanecieron cerca del eje horizontal hasta niveles de confianza muy altos, evidenciando que sus distribuciones predictivas no contienen las observaciones verdaderas dentro de sus regiones centrales. Este comportamiento es indicativo de desajuste estructural severo entre el modelo estadístico y la dinámica subyacente de la serie.

\subsection{Síntesis del Estudio del Dataset Exchange Rate}
\label{subsec:exchange_sintesis}

El análisis del dataset Exchange Rate reveló un panorama competitivo radicalmente diferente a los observados en Electricity y Traffic, validando la importancia crítica de alinear metodología con características estructurales de cada serie. El hallazgo central es la convergencia de múltiples enfoques metodológicos dispares hacia desempeño estadísticamente equivalente cuando la serie subyacente exhibe estructura autorregresiva lineal dominante con memoria larga.

La combinación de características—linealidad en media condicional ($p_{\text{Tsay}} = 0.966$), heterocedasticidad en varianza condicional ($p_{\text{McLeod-Li}} < 0.00001$), memoria larga extrema ($\hat{H} = 0.933$)—define un régimen donde métodos con capacidades complementarias alcanzan efectividad comparable. LSPM y LSPMW capitalizan la estructura lineal mediante regresión autorregresiva eficiente. Sieve Bootstrap adapta flexiblemente el orden del modelo sin imponer restricciones paramétricas. DeepAR explota la heterocedasticidad mediante su arquitectura recurrente con distribuciones de salida parametrizadas.

El deterioro pronunciado de EnCQR-LSTM, AREPD (con $\hat{\rho} = 0.95$) y Block Bootstrapping evidencia que ciertas arquitecturas son fundamentalmente inadecuadas para series financieras. EnCQR-LSTM, que combina cuantiles conformales con redes LSTM, introduce rigidez en la estimación de distribuciones predictivas que resulta contraproducente cuando la volatilidad condicional cambia drásticamente. AREPD, diseñado para contextos multivariados, no puede explotar su capacidad en el contexto univariado experimental. Block Bootstrapping estándar, sin mecanismos adaptativos para seleccionar longitud de bloque en presencia de memoria larga, genera muestras bootstrap que no preservan adecuadamente la estructura de dependencia temporal.

La naturaleza de series financieras, caracterizada por eficiencia informacional que dificulta predicción de niveles pero permite modelado de volatilidad, se refleja en los valores absolutos de CRPS. Las medianas del cluster superior (0.00254-0.00288) son comparables a las observadas en Electricity (1.497-1.791) y Traffic (0.00170-0.00288) cuando se normalizan por la escala de cada serie, indicando que la dificultad intrínseca de predicción probabilística es similar una vez controladas las características estructurales específicas.

El análisis exhaustivo de significancia estadística reveló que el poder discriminatorio del test de Diebold-Mariano es suficiente para detectar diferencias sutiles (LSPM vs. LSPMW: $p = 0.020$*, $\Delta_{\text{mediana}} = 0.00008$) mientras confirma equivalencia cuando las diferencias son aleatorias (Sieve Bootstrap vs. DeepAR: $p = 0.303$, $\Delta_{\text{mediana}} = 0.00025$). Este balance valida la robustez del protocolo de evaluación comparativa implementado.

La evaluación de calibración distribucional reveló que desempeño superior en CRPS generalmente se acompaña de mejor calibración, aunque la relación presenta excepciones importantes. LSPMW exhibió tanto la mejor mediana de CRPS como calibración PIT particularmente uniforme, validando que adaptatividad temporal mejora simultáneamente precisión y confiabilidad. MCPS y AV-MCPS, con CRPS significativamente peores que los cuatro métodos superiores, mantuvieron calibración razonable aunque conservadora, demostrando que las garantías teóricas de predicción conformal se traducen en cobertura empírica adecuada incluso cuando la precisión puntual es subóptima.

El colapso de calibración en los tres modelos inferiores tiene implicaciones prácticas severas. Distribuciones predictivas que sistemáticamente no contienen el valor observado dentro de sus regiones centrales son inútiles para gestión de riesgo, pricing de derivados o decisiones de cobertura cambiaria. Este hallazgo enfatiza que, en aplicaciones financieras, calibración distribucional correcta es tan crítica como precisión puntual.

\subsubsection{Recomendaciones para la Práctica}

Para series de tipo de cambio o contextos similares con memoria larga, heterocedasticidad condicional y estructura lineal en media, se recomiendan las siguientes estrategias metodológicas.

En primer lugar, considerar LSPMW (con parámetro $\hat{\rho}$ típicamente en rango 0.90-0.99) como método predeterminado cuando existe evidencia de memoria larga ($\hat{H} > 0.8$) y heterocedasticidad condicional confirmada mediante tests ARCH-LM. Su capacidad para adaptar ponderación temporal a cambios en volatilidad, combinada con simplicidad computacional y calibración robusta, lo torna particularmente atractivo para implementaciones en tiempo real donde la latencia computacional es crítica. La ventaja estadísticamente significativa sobre LSPM estándar ($p = 0.020$*) justifica la complejidad adicional mínima de mantener pesos exponenciales.

En segundo lugar, cuando el tamaño de muestra es suficientemente grande ($n > 1000$) y existe capacidad computacional adecuada, DeepAR merece consideración seria. Su desempeño estadísticamente indistinguible de LSPMW ($p = 0.314$) pero con CRPS media ligeramente mayor sugiere que, con más datos de entrenamiento, podría superar a métodos más parsimoniosos mediante explotación de patrones sutiles en heterocedasticidad condicional. Para instituciones financieras con infraestructura de aprendizaje profundo establecida, la inversión en desarrollo de modelos DeepAR puede justificarse por su escalabilidad a contextos multivariados.

En tercer lugar, Sieve Bootstrap constituye una opción robusta cuando se prioriza estabilidad de desempeño sobre múltiples regímenes de mercado. Su selección automática del orden autorregresivo mediante AIC proporciona adaptabilidad estructural sin requerir especificación manual de hiperparámetros. En aplicaciones donde la serie puede transitar entre regímenes de alta y baja memoria, la flexibilidad de Sieve Bootstrap confiere ventajas sobre métodos con orden fijo.

En cuarto lugar, evitar categóricamente modelos que exhibieron colapso de calibración (EnCQR-LSTM, Block Bootstrapping estándar, AREPD en contexto univariado). El deterioro de dos órdenes de magnitud en CRPS comparado con métodos superiores, combinado con distribuciones predictivas sistemáticamente mal calibradas, los torna inadecuados para cualquier aplicación práctica en mercados financieros. Instituciones que utilicen estos métodos en otros contextos deben validar exhaustivamente su desempeño antes de aplicarlos a series cambiarias.

Finalmente, reconocer que la estructura de series financieras—caracterizada por eficiencia informacional, heterocedasticidad condicional y memoria larga—favorece enfoques que balancean simplicidad estructural (linealidad en media) con flexibilidad en captura de volatilidad (ponderación adaptativa o modelado paramétrico de varianza condicional). Métodos excesivamente complejos que intentan capturar no linealidad en media (donde no existe) o excesivamente simples que ignoran heterocedasticidad (que sí existe) fallarán consistentemente. La selección de modelos debe guiarse por diagnósticos exploratorios específicos—particularmente tests de Tsay (linealidad en media), McLeod-Li (heterocedasticidad) y estimación del exponente de Hurst (memoria larga)—más que por consideraciones genéricas de complejidad algorítmica o preferencias metodológicas a priori.

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aee1784b",
   "metadata": {},
   "source": [
    "# Pre analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f559ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores √∫nicos encontrados en 'Tipo de Modelo':\n",
      "['AR(1)' 'AR(2)' 'MA(1)' 'MA(2)' 'ARMA(1,1)' 'ARMA(2,2)']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paso</th>\n",
       "      <th>Tipo de Modelo</th>\n",
       "      <th>Distribuci√≥n</th>\n",
       "      <th>Varianza error</th>\n",
       "      <th>AREPD</th>\n",
       "      <th>AV-MCPS</th>\n",
       "      <th>Block Bootstrapping</th>\n",
       "      <th>DeepAR</th>\n",
       "      <th>EnCQR-LSTM</th>\n",
       "      <th>LSPM</th>\n",
       "      <th>LSPMW</th>\n",
       "      <th>MCPS</th>\n",
       "      <th>Sieve Bootstrap</th>\n",
       "      <th>Mejor Modelo</th>\n",
       "      <th>Escenario</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AR(1)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.294667</td>\n",
       "      <td>0.289047</td>\n",
       "      <td>0.248447</td>\n",
       "      <td>0.263419</td>\n",
       "      <td>0.306622</td>\n",
       "      <td>0.440706</td>\n",
       "      <td>0.431452</td>\n",
       "      <td>0.280221</td>\n",
       "      <td>0.248691</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AR(1)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.294667</td>\n",
       "      <td>0.255505</td>\n",
       "      <td>0.248447</td>\n",
       "      <td>0.263419</td>\n",
       "      <td>0.306622</td>\n",
       "      <td>0.440706</td>\n",
       "      <td>0.431452</td>\n",
       "      <td>0.261006</td>\n",
       "      <td>0.248691</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AR(1)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.604540</td>\n",
       "      <td>0.257948</td>\n",
       "      <td>0.254264</td>\n",
       "      <td>0.273001</td>\n",
       "      <td>0.565522</td>\n",
       "      <td>0.470424</td>\n",
       "      <td>0.474111</td>\n",
       "      <td>0.259356</td>\n",
       "      <td>0.254193</td>\n",
       "      <td>Sieve Bootstrap</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>AR(1)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.604540</td>\n",
       "      <td>0.257097</td>\n",
       "      <td>0.254264</td>\n",
       "      <td>0.273001</td>\n",
       "      <td>0.565522</td>\n",
       "      <td>0.470424</td>\n",
       "      <td>0.474111</td>\n",
       "      <td>0.279181</td>\n",
       "      <td>0.254193</td>\n",
       "      <td>Sieve Bootstrap</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>AR(1)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.273622</td>\n",
       "      <td>0.346536</td>\n",
       "      <td>0.258388</td>\n",
       "      <td>0.315765</td>\n",
       "      <td>0.269452</td>\n",
       "      <td>0.520070</td>\n",
       "      <td>0.517876</td>\n",
       "      <td>0.310647</td>\n",
       "      <td>0.258039</td>\n",
       "      <td>Sieve Bootstrap</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>1</td>\n",
       "      <td>ARMA(2,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.082513</td>\n",
       "      <td>0.999066</td>\n",
       "      <td>0.953857</td>\n",
       "      <td>1.116455</td>\n",
       "      <td>1.053269</td>\n",
       "      <td>2.030504</td>\n",
       "      <td>2.165650</td>\n",
       "      <td>0.990087</td>\n",
       "      <td>0.954156</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>2</td>\n",
       "      <td>ARMA(2,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.903173</td>\n",
       "      <td>0.971148</td>\n",
       "      <td>0.954440</td>\n",
       "      <td>1.005615</td>\n",
       "      <td>1.518301</td>\n",
       "      <td>1.431610</td>\n",
       "      <td>1.522051</td>\n",
       "      <td>1.141614</td>\n",
       "      <td>0.954065</td>\n",
       "      <td>Sieve Bootstrap</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>3</td>\n",
       "      <td>ARMA(2,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.310542</td>\n",
       "      <td>1.021845</td>\n",
       "      <td>0.976235</td>\n",
       "      <td>1.002865</td>\n",
       "      <td>1.615073</td>\n",
       "      <td>1.026140</td>\n",
       "      <td>1.036051</td>\n",
       "      <td>1.484601</td>\n",
       "      <td>0.962417</td>\n",
       "      <td>Sieve Bootstrap</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>4</td>\n",
       "      <td>ARMA(2,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.324103</td>\n",
       "      <td>0.968827</td>\n",
       "      <td>0.961514</td>\n",
       "      <td>0.977739</td>\n",
       "      <td>1.072897</td>\n",
       "      <td>1.453428</td>\n",
       "      <td>1.530595</td>\n",
       "      <td>1.125230</td>\n",
       "      <td>0.960919</td>\n",
       "      <td>Sieve Bootstrap</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>5</td>\n",
       "      <td>ARMA(2,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.522689</td>\n",
       "      <td>1.011090</td>\n",
       "      <td>0.960863</td>\n",
       "      <td>1.001003</td>\n",
       "      <td>1.123328</td>\n",
       "      <td>1.061991</td>\n",
       "      <td>1.038016</td>\n",
       "      <td>1.179879</td>\n",
       "      <td>0.962942</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>928 rows √ó 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Paso Tipo de Modelo Distribuci√≥n  Varianza error     AREPD   AV-MCPS  \\\n",
       "0       1          AR(1)       normal             0.2  0.294667  0.289047   \n",
       "1       1          AR(1)       normal             0.2  0.294667  0.255505   \n",
       "2       2          AR(1)       normal             0.2  0.604540  0.257948   \n",
       "3       2          AR(1)       normal             0.2  0.604540  0.257097   \n",
       "4       3          AR(1)       normal             0.2  0.273622  0.346536   \n",
       "...   ...            ...          ...             ...       ...       ...   \n",
       "1309    1      ARMA(2,2)      mixture             3.0  1.082513  0.999066   \n",
       "1311    2      ARMA(2,2)      mixture             3.0  1.903173  0.971148   \n",
       "1313    3      ARMA(2,2)      mixture             3.0  2.310542  1.021845   \n",
       "1315    4      ARMA(2,2)      mixture             3.0  1.324103  0.968827   \n",
       "1317    5      ARMA(2,2)      mixture             3.0  1.522689  1.011090   \n",
       "\n",
       "      Block Bootstrapping    DeepAR  EnCQR-LSTM      LSPM     LSPMW      MCPS  \\\n",
       "0                0.248447  0.263419    0.306622  0.440706  0.431452  0.280221   \n",
       "1                0.248447  0.263419    0.306622  0.440706  0.431452  0.261006   \n",
       "2                0.254264  0.273001    0.565522  0.470424  0.474111  0.259356   \n",
       "3                0.254264  0.273001    0.565522  0.470424  0.474111  0.279181   \n",
       "4                0.258388  0.315765    0.269452  0.520070  0.517876  0.310647   \n",
       "...                   ...       ...         ...       ...       ...       ...   \n",
       "1309             0.953857  1.116455    1.053269  2.030504  2.165650  0.990087   \n",
       "1311             0.954440  1.005615    1.518301  1.431610  1.522051  1.141614   \n",
       "1313             0.976235  1.002865    1.615073  1.026140  1.036051  1.484601   \n",
       "1315             0.961514  0.977739    1.072897  1.453428  1.530595  1.125230   \n",
       "1317             0.960863  1.001003    1.123328  1.061991  1.038016  1.179879   \n",
       "\n",
       "      Sieve Bootstrap         Mejor Modelo            Escenario  \n",
       "0            0.248691  Block Bootstrapping  Estacionario_Lineal  \n",
       "1            0.248691  Block Bootstrapping  Estacionario_Lineal  \n",
       "2            0.254193      Sieve Bootstrap  Estacionario_Lineal  \n",
       "3            0.254193      Sieve Bootstrap  Estacionario_Lineal  \n",
       "4            0.258039      Sieve Bootstrap  Estacionario_Lineal  \n",
       "...               ...                  ...                  ...  \n",
       "1309         0.954156  Block Bootstrapping  Estacionario_Lineal  \n",
       "1311         0.954065      Sieve Bootstrap  Estacionario_Lineal  \n",
       "1313         0.962417      Sieve Bootstrap  Estacionario_Lineal  \n",
       "1315         0.960919      Sieve Bootstrap  Estacionario_Lineal  \n",
       "1317         0.962942  Block Bootstrapping  Estacionario_Lineal  \n",
       "\n",
       "[928 rows x 15 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "    \n",
    "estacionario = pd.read_excel(\"./Datos/estacionario.xlsx\")\n",
    "\n",
    "estacionario = estacionario.drop_duplicates()\n",
    "estacionario = estacionario[estacionario[\"Paso\"] != \"Promedio\"]\n",
    "\n",
    "def determinar_tipo_modelo_mejorado(row):\n",
    "    \"\"\"\n",
    "    Determina el tipo de modelo (AR, MA, ARMA) y su orden a partir de los valores\n",
    "    en las columnas 'Valores de AR' y 'Valores MA'.\n",
    "    \"\"\"\n",
    "    ar_str = str(row['Valores de AR'])\n",
    "    ma_str = str(row['Valores MA'])\n",
    "    \n",
    "    # Expresi√≥n regular para encontrar n√∫meros (enteros o decimales, positivos o negativos)\n",
    "    regex_numeros = r'-?\\d+\\.?\\d*'\n",
    "    \n",
    "    # Cuenta cu√°ntos n√∫meros v√°lidos hay en cada string\n",
    "    p = len(re.findall(regex_numeros, ar_str))\n",
    "    q = len(re.findall(regex_numeros, ma_str))\n",
    "    \n",
    "    if p > 0 and q == 0:\n",
    "        return f\"AR({p})\"\n",
    "    elif p == 0 and q > 0:\n",
    "        return f\"MA({q})\"\n",
    "    elif p > 0 and q > 0:\n",
    "        return f\"ARMA({p},{q})\"\n",
    "    else:\n",
    "        return None # O \"Ruido Blanco\" si p=0 y q=0\n",
    "\n",
    "# Aplica la funci√≥n mejorada para crear la columna \"Tipo de Modelo\"\n",
    "estacionario['Tipo de Modelo'] = estacionario.apply(determinar_tipo_modelo_mejorado, axis=1)\n",
    "\n",
    "# Imprime los valores √∫nicos de la columna Tipo de modelo para verificar\n",
    "print(\"Valores √∫nicos encontrados en 'Tipo de Modelo':\")\n",
    "print(estacionario['Tipo de Modelo'].unique())\n",
    "\n",
    "# Ordena las columnas 'Paso' y 'Tipo de modelo' al inicio\n",
    "cols = estacionario.columns.tolist()\n",
    "# Aseguramos que las columnas existan antes de moverlas\n",
    "if 'Paso' in cols:\n",
    "    cols.insert(0, cols.pop(cols.index('Paso')))\n",
    "if 'Tipo de Modelo' in cols:\n",
    "    cols.insert(1, cols.pop(cols.index('Tipo de Modelo')))\n",
    "\n",
    "estacionario = estacionario.reindex(columns=cols)\n",
    "\n",
    "\n",
    "# Borra las columnas originales 'Valores de AR' y 'Valores MA'\n",
    "estacionario = estacionario.drop(columns=['Valores de AR', 'Valores MA'])\n",
    "estacionario[\"Escenario\"] = \"Estacionario_Lineal\"\n",
    "\n",
    "# Muestra el DataFrame resultante\n",
    "estacionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba423eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paso</th>\n",
       "      <th>Tipo de Modelo</th>\n",
       "      <th>Distribuci√≥n</th>\n",
       "      <th>Varianza error</th>\n",
       "      <th>AREPD</th>\n",
       "      <th>AV-MCPS</th>\n",
       "      <th>Block Bootstrapping</th>\n",
       "      <th>DeepAR</th>\n",
       "      <th>EnCQR-LSTM</th>\n",
       "      <th>LSPM</th>\n",
       "      <th>LSPMW</th>\n",
       "      <th>MCPS</th>\n",
       "      <th>Sieve Bootstrap</th>\n",
       "      <th>Mejor Modelo</th>\n",
       "      <th>Escenario</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ARIMA(0,1,0)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.860823</td>\n",
       "      <td>0.265008</td>\n",
       "      <td>0.253635</td>\n",
       "      <td>0.319481</td>\n",
       "      <td>0.488711</td>\n",
       "      <td>0.367279</td>\n",
       "      <td>0.360494</td>\n",
       "      <td>0.271048</td>\n",
       "      <td>0.273828</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ARIMA(0,1,0)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.244128</td>\n",
       "      <td>0.473415</td>\n",
       "      <td>0.275061</td>\n",
       "      <td>0.438099</td>\n",
       "      <td>0.322919</td>\n",
       "      <td>0.426187</td>\n",
       "      <td>0.430296</td>\n",
       "      <td>0.348663</td>\n",
       "      <td>0.272952</td>\n",
       "      <td>Sieve Bootstrap</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ARIMA(0,1,0)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.799818</td>\n",
       "      <td>0.549386</td>\n",
       "      <td>0.272406</td>\n",
       "      <td>0.291500</td>\n",
       "      <td>0.396481</td>\n",
       "      <td>0.642530</td>\n",
       "      <td>0.639134</td>\n",
       "      <td>0.269410</td>\n",
       "      <td>0.275661</td>\n",
       "      <td>MCPS</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ARIMA(0,1,0)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.912421</td>\n",
       "      <td>0.268028</td>\n",
       "      <td>0.255186</td>\n",
       "      <td>0.291577</td>\n",
       "      <td>0.495882</td>\n",
       "      <td>0.341570</td>\n",
       "      <td>0.341227</td>\n",
       "      <td>0.268167</td>\n",
       "      <td>0.275948</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ARIMA(0,1,0)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.822771</td>\n",
       "      <td>1.363146</td>\n",
       "      <td>0.257461</td>\n",
       "      <td>0.658698</td>\n",
       "      <td>1.291283</td>\n",
       "      <td>0.981902</td>\n",
       "      <td>0.969842</td>\n",
       "      <td>1.442151</td>\n",
       "      <td>0.338116</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>1</td>\n",
       "      <td>ARIMA(2,1,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>76.766114</td>\n",
       "      <td>5.401405</td>\n",
       "      <td>0.965836</td>\n",
       "      <td>7.254422</td>\n",
       "      <td>13.176312</td>\n",
       "      <td>4.421885</td>\n",
       "      <td>4.173484</td>\n",
       "      <td>10.061494</td>\n",
       "      <td>2.612414</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>2</td>\n",
       "      <td>ARIMA(2,1,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>80.630681</td>\n",
       "      <td>6.208989</td>\n",
       "      <td>0.974398</td>\n",
       "      <td>8.767931</td>\n",
       "      <td>9.287902</td>\n",
       "      <td>1.733689</td>\n",
       "      <td>1.596168</td>\n",
       "      <td>21.549436</td>\n",
       "      <td>1.956761</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>3</td>\n",
       "      <td>ARIMA(2,1,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>86.539087</td>\n",
       "      <td>9.466479</td>\n",
       "      <td>0.982561</td>\n",
       "      <td>24.631292</td>\n",
       "      <td>18.639842</td>\n",
       "      <td>6.195609</td>\n",
       "      <td>5.953120</td>\n",
       "      <td>20.950880</td>\n",
       "      <td>3.623684</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>4</td>\n",
       "      <td>ARIMA(2,1,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>93.057798</td>\n",
       "      <td>12.374480</td>\n",
       "      <td>0.958507</td>\n",
       "      <td>27.567728</td>\n",
       "      <td>17.852720</td>\n",
       "      <td>7.288522</td>\n",
       "      <td>6.952830</td>\n",
       "      <td>28.040032</td>\n",
       "      <td>4.681807</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>5</td>\n",
       "      <td>ARIMA(2,1,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>99.120410</td>\n",
       "      <td>12.714708</td>\n",
       "      <td>0.955009</td>\n",
       "      <td>17.064311</td>\n",
       "      <td>8.945594</td>\n",
       "      <td>4.716275</td>\n",
       "      <td>4.320090</td>\n",
       "      <td>34.209230</td>\n",
       "      <td>4.177879</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows √ó 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Paso Tipo de Modelo Distribuci√≥n  Varianza error      AREPD    AV-MCPS  \\\n",
       "0      1   ARIMA(0,1,0)       normal             0.2   1.860823   0.265008   \n",
       "1      2   ARIMA(0,1,0)       normal             0.2   1.244128   0.473415   \n",
       "2      3   ARIMA(0,1,0)       normal             0.2   1.799818   0.549386   \n",
       "3      4   ARIMA(0,1,0)       normal             0.2   1.912421   0.268028   \n",
       "4      5   ARIMA(0,1,0)       normal             0.2   2.822771   1.363146   \n",
       "..   ...            ...          ...             ...        ...        ...   \n",
       "834    1   ARIMA(2,1,2)      mixture             3.0  76.766114   5.401405   \n",
       "835    2   ARIMA(2,1,2)      mixture             3.0  80.630681   6.208989   \n",
       "836    3   ARIMA(2,1,2)      mixture             3.0  86.539087   9.466479   \n",
       "837    4   ARIMA(2,1,2)      mixture             3.0  93.057798  12.374480   \n",
       "838    5   ARIMA(2,1,2)      mixture             3.0  99.120410  12.714708   \n",
       "\n",
       "     Block Bootstrapping     DeepAR  EnCQR-LSTM      LSPM     LSPMW  \\\n",
       "0               0.253635   0.319481    0.488711  0.367279  0.360494   \n",
       "1               0.275061   0.438099    0.322919  0.426187  0.430296   \n",
       "2               0.272406   0.291500    0.396481  0.642530  0.639134   \n",
       "3               0.255186   0.291577    0.495882  0.341570  0.341227   \n",
       "4               0.257461   0.658698    1.291283  0.981902  0.969842   \n",
       "..                   ...        ...         ...       ...       ...   \n",
       "834             0.965836   7.254422   13.176312  4.421885  4.173484   \n",
       "835             0.974398   8.767931    9.287902  1.733689  1.596168   \n",
       "836             0.982561  24.631292   18.639842  6.195609  5.953120   \n",
       "837             0.958507  27.567728   17.852720  7.288522  6.952830   \n",
       "838             0.955009  17.064311    8.945594  4.716275  4.320090   \n",
       "\n",
       "          MCPS  Sieve Bootstrap         Mejor Modelo               Escenario  \n",
       "0     0.271048         0.273828  Block Bootstrapping  No_Estacionario_Lineal  \n",
       "1     0.348663         0.272952      Sieve Bootstrap  No_Estacionario_Lineal  \n",
       "2     0.269410         0.275661                 MCPS  No_Estacionario_Lineal  \n",
       "3     0.268167         0.275948  Block Bootstrapping  No_Estacionario_Lineal  \n",
       "4     1.442151         0.338116  Block Bootstrapping  No_Estacionario_Lineal  \n",
       "..         ...              ...                  ...                     ...  \n",
       "834  10.061494         2.612414  Block Bootstrapping  No_Estacionario_Lineal  \n",
       "835  21.549436         1.956761  Block Bootstrapping  No_Estacionario_Lineal  \n",
       "836  20.950880         3.623684  Block Bootstrapping  No_Estacionario_Lineal  \n",
       "837  28.040032         4.681807  Block Bootstrapping  No_Estacionario_Lineal  \n",
       "838  34.209230         4.177879  Block Bootstrapping  No_Estacionario_Lineal  \n",
       "\n",
       "[700 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_estacionario = pd.read_excel(\"./Datos/no_estacionario.xlsx\")\n",
    "no_estacionario.drop(columns=['Valores de AR', 'Valores MA'], inplace=True)\n",
    "no_estacionario[\"Escenario\"] = \"No_Estacionario_Lineal\"\n",
    "no_estacionario = no_estacionario[no_estacionario[\"Paso\"] != \"Promedio\"]\n",
    "no_estacionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e7ce88d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paso</th>\n",
       "      <th>Tipo de Modelo</th>\n",
       "      <th>Distribuci√≥n</th>\n",
       "      <th>Varianza error</th>\n",
       "      <th>AREPD</th>\n",
       "      <th>AV-MCPS</th>\n",
       "      <th>Block Bootstrapping</th>\n",
       "      <th>DeepAR</th>\n",
       "      <th>EnCQR-LSTM</th>\n",
       "      <th>LSPM</th>\n",
       "      <th>LSPMW</th>\n",
       "      <th>MCPS</th>\n",
       "      <th>Sieve Bootstrap</th>\n",
       "      <th>Mejor Modelo</th>\n",
       "      <th>Escenario</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>SETAR-1</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.257043</td>\n",
       "      <td>0.256918</td>\n",
       "      <td>0.251524</td>\n",
       "      <td>0.263274</td>\n",
       "      <td>0.257984</td>\n",
       "      <td>0.285655</td>\n",
       "      <td>0.282110</td>\n",
       "      <td>0.257497</td>\n",
       "      <td>0.251188</td>\n",
       "      <td>Sieve Bootstrap</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>SETAR-1</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.305723</td>\n",
       "      <td>0.737200</td>\n",
       "      <td>0.288529</td>\n",
       "      <td>0.297164</td>\n",
       "      <td>0.324101</td>\n",
       "      <td>0.316846</td>\n",
       "      <td>0.319675</td>\n",
       "      <td>0.350625</td>\n",
       "      <td>0.290022</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>SETAR-1</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.292055</td>\n",
       "      <td>0.284794</td>\n",
       "      <td>0.287265</td>\n",
       "      <td>0.275374</td>\n",
       "      <td>0.278881</td>\n",
       "      <td>0.320347</td>\n",
       "      <td>0.320181</td>\n",
       "      <td>0.280633</td>\n",
       "      <td>0.262183</td>\n",
       "      <td>AV-MCPS</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>SETAR-1</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.298469</td>\n",
       "      <td>0.322090</td>\n",
       "      <td>0.263802</td>\n",
       "      <td>0.255605</td>\n",
       "      <td>0.270449</td>\n",
       "      <td>0.290893</td>\n",
       "      <td>0.290581</td>\n",
       "      <td>0.320509</td>\n",
       "      <td>0.258734</td>\n",
       "      <td>DeepAR</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>SETAR-1</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.298007</td>\n",
       "      <td>0.330242</td>\n",
       "      <td>0.501202</td>\n",
       "      <td>0.323900</td>\n",
       "      <td>0.348571</td>\n",
       "      <td>0.326254</td>\n",
       "      <td>0.329508</td>\n",
       "      <td>0.401144</td>\n",
       "      <td>0.442319</td>\n",
       "      <td>AREPD</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>1</td>\n",
       "      <td>SETAR-3</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.164445</td>\n",
       "      <td>1.034125</td>\n",
       "      <td>0.962026</td>\n",
       "      <td>0.989297</td>\n",
       "      <td>1.046459</td>\n",
       "      <td>0.971555</td>\n",
       "      <td>1.076860</td>\n",
       "      <td>1.003977</td>\n",
       "      <td>0.961513</td>\n",
       "      <td>Sieve Bootstrap</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>2</td>\n",
       "      <td>SETAR-3</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.191648</td>\n",
       "      <td>1.050684</td>\n",
       "      <td>0.986347</td>\n",
       "      <td>1.077081</td>\n",
       "      <td>0.972263</td>\n",
       "      <td>0.957417</td>\n",
       "      <td>0.986525</td>\n",
       "      <td>0.970809</td>\n",
       "      <td>0.984072</td>\n",
       "      <td>LSPM</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>3</td>\n",
       "      <td>SETAR-3</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.193252</td>\n",
       "      <td>1.010777</td>\n",
       "      <td>1.012627</td>\n",
       "      <td>0.981861</td>\n",
       "      <td>0.955903</td>\n",
       "      <td>0.987603</td>\n",
       "      <td>0.977201</td>\n",
       "      <td>1.124558</td>\n",
       "      <td>1.009812</td>\n",
       "      <td>EnCQR-LSTM</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>4</td>\n",
       "      <td>SETAR-3</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.229893</td>\n",
       "      <td>1.109528</td>\n",
       "      <td>1.124342</td>\n",
       "      <td>0.983326</td>\n",
       "      <td>0.960088</td>\n",
       "      <td>1.036372</td>\n",
       "      <td>0.978720</td>\n",
       "      <td>1.028709</td>\n",
       "      <td>1.103310</td>\n",
       "      <td>EnCQR-LSTM</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>5</td>\n",
       "      <td>SETAR-3</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.149135</td>\n",
       "      <td>1.113084</td>\n",
       "      <td>1.046778</td>\n",
       "      <td>0.999776</td>\n",
       "      <td>0.961731</td>\n",
       "      <td>0.961208</td>\n",
       "      <td>0.977492</td>\n",
       "      <td>1.082153</td>\n",
       "      <td>1.059325</td>\n",
       "      <td>LSPM</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows √ó 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Paso Tipo de Modelo Distribuci√≥n  Varianza error     AREPD   AV-MCPS  \\\n",
       "0      1        SETAR-1       normal             0.2  0.257043  0.256918   \n",
       "1      2        SETAR-1       normal             0.2  0.305723  0.737200   \n",
       "2      3        SETAR-1       normal             0.2  0.292055  0.284794   \n",
       "3      4        SETAR-1       normal             0.2  0.298469  0.322090   \n",
       "4      5        SETAR-1       normal             0.2  0.298007  0.330242   \n",
       "..   ...            ...          ...             ...       ...       ...   \n",
       "834    1        SETAR-3      mixture             3.0  1.164445  1.034125   \n",
       "835    2        SETAR-3      mixture             3.0  1.191648  1.050684   \n",
       "836    3        SETAR-3      mixture             3.0  1.193252  1.010777   \n",
       "837    4        SETAR-3      mixture             3.0  1.229893  1.109528   \n",
       "838    5        SETAR-3      mixture             3.0  1.149135  1.113084   \n",
       "\n",
       "     Block Bootstrapping    DeepAR  EnCQR-LSTM      LSPM     LSPMW      MCPS  \\\n",
       "0               0.251524  0.263274    0.257984  0.285655  0.282110  0.257497   \n",
       "1               0.288529  0.297164    0.324101  0.316846  0.319675  0.350625   \n",
       "2               0.287265  0.275374    0.278881  0.320347  0.320181  0.280633   \n",
       "3               0.263802  0.255605    0.270449  0.290893  0.290581  0.320509   \n",
       "4               0.501202  0.323900    0.348571  0.326254  0.329508  0.401144   \n",
       "..                   ...       ...         ...       ...       ...       ...   \n",
       "834             0.962026  0.989297    1.046459  0.971555  1.076860  1.003977   \n",
       "835             0.986347  1.077081    0.972263  0.957417  0.986525  0.970809   \n",
       "836             1.012627  0.981861    0.955903  0.987603  0.977201  1.124558   \n",
       "837             1.124342  0.983326    0.960088  1.036372  0.978720  1.028709   \n",
       "838             1.046778  0.999776    0.961731  0.961208  0.977492  1.082153   \n",
       "\n",
       "     Sieve Bootstrap         Mejor Modelo               Escenario  \n",
       "0           0.251188      Sieve Bootstrap  No_Lineal_Estacionario  \n",
       "1           0.290022  Block Bootstrapping  No_Lineal_Estacionario  \n",
       "2           0.262183              AV-MCPS  No_Lineal_Estacionario  \n",
       "3           0.258734               DeepAR  No_Lineal_Estacionario  \n",
       "4           0.442319                AREPD  No_Lineal_Estacionario  \n",
       "..               ...                  ...                     ...  \n",
       "834         0.961513      Sieve Bootstrap  No_Lineal_Estacionario  \n",
       "835         0.984072                 LSPM  No_Lineal_Estacionario  \n",
       "836         1.009812           EnCQR-LSTM  No_Lineal_Estacionario  \n",
       "837         1.103310           EnCQR-LSTM  No_Lineal_Estacionario  \n",
       "838         1.059325                 LSPM  No_Lineal_Estacionario  \n",
       "\n",
       "[700 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_lineal = pd.read_excel(\"./Datos/no_lineal.xlsx\")\n",
    "no_lineal = no_lineal[no_lineal[\"Paso\"] != \"Promedio\"]\n",
    "no_lineal[\"Escenario\"] = \"No_Lineal_Estacionario\"\n",
    "# 1. Definir el diccionario de mapeo basado en nuestro an√°lisis\n",
    "mapeo_nombres_exacto = {\n",
    "    'SETAR(2,1)': 'SETAR-1',\n",
    "    'SETAR(2,2)': 'SETAR-2',\n",
    "    'SETAR(2,3)': 'SETAR-3',\n",
    "    'TAR(2,1)': 'SETAR-4',\n",
    "    'TAR(2,2)': 'SETAR-5',\n",
    "    'EXPAR(2,1)': 'SETAR Estoc√°stico',\n",
    "    'BILINEAR(1)': 'SETAR Bilinear'\n",
    "}\n",
    "\n",
    "# 2. Aplicar el reemplazo en la columna \"Tipo de Modelo\"\n",
    "no_lineal['Tipo de Modelo'] = no_lineal['Tipo de Modelo'].replace(mapeo_nombres_exacto)\n",
    "\n",
    "no_lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f2c36b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Une los tres DataFrames en uno solo uno debajo de otro\n",
    "df_all = pd.concat([estacionario, no_estacionario, no_lineal], ignore_index=True)\n",
    "# Guarda el DataFrame combinado en un archivo Excel\n",
    "df_all.to_excel(\"./Datos/datos_combinados.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a1dff2",
   "metadata": {},
   "source": [
    "# Analisis Escalonado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6662db",
   "metadata": {},
   "source": [
    "## Analisis General Corregido*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7ce1242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "‚ñà                                                                              ‚ñà\n",
      "‚ñà          AN√ÅLISIS COMPLETO DE BASE DE DATOS - VERSI√ìN MEJORADA         ‚ñà\n",
      "‚ñà                                                                              ‚ñà\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "\n",
      "================================================================================\n",
      "INICIANDO AN√ÅLISIS COMPLETO DE BASE DE DATOS - VERSI√ìN MEJORADA\n",
      "================================================================================\n",
      "\n",
      "‚úì Caracter√≠sticas extra√≠das:\n",
      "  - Estacionariedad: ['Estacionario' 'No Estacionario']\n",
      "  - Linealidad: ['Lineal' 'No Lineal']\n",
      "  - Tipos de Modelo: ['AR(1)' 'AR(2)' 'MA(1)' 'MA(2)' 'ARMA(1,1)' 'ARMA(2,2)' 'ARIMA(0,1,0)'\n",
      " 'ARIMA(1,1,0)' 'ARIMA(2,1,0)' 'ARIMA(0,1,1)' 'ARIMA(0,1,2)'\n",
      " 'ARIMA(1,1,1)' 'ARIMA(2,1,2)' 'SETAR-1' 'SETAR-4' 'SETAR Estoc√°stico'\n",
      " 'SETAR Bilinear' 'SETAR-2' 'SETAR-5' 'SETAR-3']\n",
      "  - Distribuciones: ['normal' 'uniform' 'exponential' 't-student' 'mixture']\n",
      "  - Varianzas: [np.float64(0.2), np.float64(0.5), np.float64(1.0), np.float64(3.0)]\n",
      "  - Pasos: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5)]\n",
      "‚úì Datos cargados: 2328 filas, 17 columnas\n",
      "‚úì Modelos a analizar: 9\n",
      "‚úì Directorio de salida: resultados_base_completa_mejorado\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨\n",
      "\n",
      "1Ô∏è‚É£  Analizando impacto de Escenarios (Estacionariedad y Linealidad)...\n",
      "   ‚úì 2 figuras generadas para an√°lisis de escenarios consolidado\n",
      "\n",
      "2Ô∏è‚É£  Analizando impacto de Linealidad...\n",
      "   ‚ÑπÔ∏è  An√°lisis de linealidad integrado en an√°lisis de escenarios\n",
      "\n",
      "3Ô∏è‚É£  Analizando efecto del Modelo Generador...\n",
      "   ‚úì 2 figuras generadas para modelo generador\n",
      "\n",
      "4Ô∏è‚É£  Analizando influencia de Distribuci√≥n...\n",
      "   ‚úì 2 figuras generadas para distribuci√≥n\n",
      "\n",
      "5Ô∏è‚É£  Analizando impacto de Varianza...\n",
      "   ‚úì 6 figuras generadas para varianza (2 por cada uno de los 3 escenarios)\n",
      "\n",
      "6Ô∏è‚É£  Analizando deterioro por Horizonte...\n",
      "   ‚úì 6 figuras generadas para horizonte (2 por cada uno de los 3 escenarios)\n",
      "\n",
      "7Ô∏è‚É£  Analizando Robustez y Estabilidad...\n",
      "   ‚úì 1 figura generada para robustez\n",
      "\n",
      "8Ô∏è‚É£  Analizando Diferencias Estad√≠sticamente Significativas...\n",
      "\n",
      "================================================================================\n",
      "REALIZANDO TEST DE DIEBOLD-MARIANO\n",
      "================================================================================\n",
      "\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "   Comparaciones significativas: 35\n",
      "\n",
      "   ‚úì Ranking guardado: Top 3\n",
      "      1. Block Bootstrapping - Score: 8 (V:8, D:0, E:0)\n",
      "      2. Sieve Bootstrap - Score: 6 (V:7, D:1, E:0)\n",
      "      3. LSPM - Score: 4 (V:6, D:2, E:0)\n",
      "\n",
      "   ‚úì 1 figura generada para significancia\n",
      "\n",
      "\n",
      "9Ô∏è‚É£  An√°lisis de Impacto de Caracter√≠sticas (PFI) OMITIDO.\n",
      "\n",
      "üîü An√°lisis de Variabilidad (PDP e ICE) OMITIDO.\n",
      "\n",
      "‚ú® Resumen Ejecutivo OMITIDO.\n",
      "\n",
      "================================================================================\n",
      "‚úÖ AN√ÅLISIS COMPLETO FINALIZADO\n",
      "üìÅ Resultados guardados en: resultados_base_completa_mejorado\n",
      "================================================================================\n",
      "\n",
      "\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "‚ñà                                                                              ‚ñà\n",
      "‚ñà                    ‚úÖ AN√ÅLISIS COMPLETADO EXITOSAMENTE                       ‚ñà\n",
      "‚ñà                                                                              ‚ñà\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "üìä TOTAL DE FIGURAS GENERADAS APROXIMADAMENTE: 23 im√°genes PNG\n",
      "\n",
      "üìÅ ESTRUCTURA DE RESULTADOS:\n",
      "   ./resultados_base_completa_mejorado/\n",
      "   ‚îú‚îÄ‚îÄ 1.1: Escenarios - Rendimiento Completo\n",
      "   ‚îú‚îÄ‚îÄ 1.2: Escenarios - Cambio Relativo\n",
      "   ‚îú‚îÄ‚îÄ 3.2: Modelo Generador - Z-Score\n",
      "   ‚îú‚îÄ‚îÄ 3.3: Modelo Generador - Variabilidad\n",
      "   ‚îú‚îÄ‚îÄ 4.1: Distribuci√≥n - Heatmap ECRPS\n",
      "   ‚îú‚îÄ‚îÄ 4.2: Distribuci√≥n - Heatmap Variabilidad\n",
      "   ‚îú‚îÄ‚îÄ 5.1: Varianza - Tendencias (x4 escenarios) (MODIFICADO)\n",
      "   ‚îú‚îÄ‚îÄ 5.2: Varianza - Tasa de Crecimiento (x4 escenarios) (MODIFICADO)\n",
      "   ‚îú‚îÄ‚îÄ 6.1: Horizonte - Evoluci√≥n (x4 escenarios) (MODIFICADO)\n",
      "   ‚îú‚îÄ‚îÄ 6.2: Horizonte - Tasa de Deterioro (x4 escenarios) (MODIFICADO)\n",
      "   ‚îú‚îÄ‚îÄ 7.2: Robustez - Coeficiente de Variaci√≥n\n",
      "   ‚îú‚îÄ‚îÄ 8.2: Significancia - Matriz de Superioridad\n",
      "   ‚îî‚îÄ‚îÄ (An√°lisis 9 y 10 OMITIDOS)\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from itertools import combinations\n",
    "import warnings\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance, PartialDependenceDisplay\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuraci√≥n de estilo\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURACI√ìN GLOBAL\n",
    "# ============================================================================\n",
    "\n",
    "RUTA_DATOS = \"./Datos/datos_combinados.xlsx\"\n",
    "DIR_SALIDA = \"./resultados_base_completa_mejorado\"\n",
    "\n",
    "MODELOS = ['AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR',\n",
    "           'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
    "\n",
    "# Colores √∫nicos para 9 modelos\n",
    "COLORES_MODELOS = {\n",
    "    'AREPD': '#e41a1c',\n",
    "    'AV-MCPS': '#377eb8',\n",
    "    'Block Bootstrapping': '#4daf4a',\n",
    "    'DeepAR': '#984ea3',\n",
    "    'EnCQR-LSTM': '#ff7f00',\n",
    "    'LSPM': '#ffff33',\n",
    "    'LSPMW': '#a65628',\n",
    "    'MCPS': '#f781bf',\n",
    "    'Sieve Bootstrap': '#999999'\n",
    "}\n",
    "\n",
    "# Caracter√≠sticas para el meta-modelo\n",
    "CARACTERISTICAS_META_MODELO = [\n",
    "    'Estacionario', 'Lineal', 'Tipo de Modelo',\n",
    "    'Distribuci√≥n', 'Varianza error', 'Paso'\n",
    "]\n",
    "CARACTERISTICAS_NUMERICAS_META_MODELO = ['Varianza error', 'Paso']\n",
    "CARACTERISTICAS_CATEGORICAS_META_MODELO = [\n",
    "    'Estacionario', 'Lineal', 'Tipo de Modelo', 'Distribuci√≥n'\n",
    "]\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# FUNCIONES AUXILIARES - TEST DIEBOLD-MARIANO (Sin cambios)\n",
    "# ============================================================================\n",
    "\n",
    "def diebold_mariano_test(errores1, errores2, h=1, alternative='two-sided'):\n",
    "    \"\"\"Test de Diebold-Mariano para comparar precisi√≥n de pron√≥sticos\"\"\"\n",
    "    e1 = np.asarray(errores1)\n",
    "    e2 = np.asarray(errores2)\n",
    "\n",
    "    if len(e1) != len(e2):\n",
    "        raise ValueError(\"Los vectores de errores deben tener la misma longitud\")\n",
    "\n",
    "    n = len(e1)\n",
    "    d = e1 - e2\n",
    "    d_mean = np.mean(d)\n",
    "\n",
    "    # Varianza con correcci√≥n de autocorrelaci√≥n\n",
    "    gamma_0 = np.var(d, ddof=1)\n",
    "    gamma_sum = 0\n",
    "    for k in range(1, h):\n",
    "        if k < n:\n",
    "            gamma_k = np.mean((d[:-k] - d_mean) * (d[k:] - d_mean))\n",
    "            gamma_sum += 2 * gamma_k\n",
    "\n",
    "    var_d = (gamma_0 + gamma_sum) / n\n",
    "\n",
    "    # Correcci√≥n de Harvey-Leybourne-Newbold\n",
    "    hlnc = np.sqrt((n + 1 - 2 * h + h * (h - 1) / n) / n)\n",
    "\n",
    "    if var_d > 0:\n",
    "        dm_stat = d_mean / np.sqrt(var_d)\n",
    "        dm_stat_corrected = dm_stat * hlnc\n",
    "    else:\n",
    "        dm_stat = 0\n",
    "        dm_stat_corrected = 0\n",
    "\n",
    "    # P-valor\n",
    "    if alternative == 'two-sided':\n",
    "        p_value = 2 * (1 - stats.t.cdf(abs(dm_stat_corrected), df=n - 1))\n",
    "    elif alternative == 'less':\n",
    "        p_value = stats.t.cdf(dm_stat_corrected, df=n - 1)\n",
    "    elif alternative == 'greater':\n",
    "        p_value = 1 - stats.t.cdf(dm_stat_corrected, df=n - 1)\n",
    "    else:\n",
    "        raise ValueError(\"alternative debe ser 'two-sided', 'less' o 'greater'\")\n",
    "\n",
    "    return {\n",
    "        'dm_statistic': dm_stat,\n",
    "        'dm_statistic_corrected': dm_stat_corrected,\n",
    "        'p_value': p_value,\n",
    "        'mean_diff': d_mean,\n",
    "        'modelo1_mejor': d_mean < 0,\n",
    "        'n': n\n",
    "    }\n",
    "\n",
    "\n",
    "def comparaciones_multiples_dm(df, modelos, alpha=0.05):\n",
    "    \"\"\"Comparaciones m√∫ltiples con correcci√≥n de Bonferroni\"\"\"\n",
    "    n_comparaciones = len(list(combinations(modelos, 2)))\n",
    "    alpha_bonferroni = alpha / n_comparaciones\n",
    "\n",
    "    resultados = []\n",
    "\n",
    "    for modelo1, modelo2 in combinations(modelos, 2):\n",
    "        try:\n",
    "            dm_result = diebold_mariano_test(\n",
    "                df[modelo1].values,\n",
    "                df[modelo2].values,\n",
    "                h=1,\n",
    "                alternative='two-sided'\n",
    "            )\n",
    "\n",
    "            significativo = dm_result['p_value'] < alpha_bonferroni\n",
    "\n",
    "            if significativo:\n",
    "                if dm_result['mean_diff'] < 0:\n",
    "                    ganador = modelo1\n",
    "                else:\n",
    "                    ganador = modelo2\n",
    "            else:\n",
    "                ganador = \"No hay diferencia\"\n",
    "\n",
    "            resultados.append({\n",
    "                'Modelo_1': modelo1,\n",
    "                'Modelo_2': modelo2,\n",
    "                'DM_Statistic': dm_result['dm_statistic_corrected'],\n",
    "                'p_value': dm_result['p_value'],\n",
    "                'p_value_bonferroni': alpha_bonferroni,\n",
    "                'Significativo': significativo,\n",
    "                'Ganador': ganador,\n",
    "                'Diff_Media': dm_result['mean_diff']\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            # print(f\"Error en DM test entre {modelo1} y {modelo2}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(resultados), alpha_bonferroni\n",
    "\n",
    "\n",
    "def calcular_ranking_dm(df_comparaciones, modelos):\n",
    "    \"\"\"Calcula ranking basado en resultados DM\"\"\"\n",
    "    n = len(modelos)\n",
    "    matriz = pd.DataFrame(np.zeros((n, n)), index=modelos, columns=modelos)\n",
    "\n",
    "    for _, row in df_comparaciones.iterrows():\n",
    "        m1, m2 = row['Modelo_1'], row['Modelo_2']\n",
    "        if row['Significativo']:\n",
    "            if row['Ganador'] == m1:\n",
    "                matriz.loc[m1, m2] = 1\n",
    "                matriz.loc[m2, m1] = -1\n",
    "            elif row['Ganador'] == m2:\n",
    "                matriz.loc[m2, m1] = 1\n",
    "                matriz.loc[m1, m2] = -1\n",
    "\n",
    "    ranking_data = []\n",
    "    for modelo in modelos:\n",
    "        victorias = (matriz.loc[modelo] == 1).sum()\n",
    "        derrotas = (matriz.loc[modelo] == -1).sum()\n",
    "        empates = (matriz.loc[modelo] == 0).sum() - 1 # Excluir la comparaci√≥n consigo mismo\n",
    "        score = victorias - derrotas\n",
    "        total_comparaciones = victorias + derrotas + empates if (victorias + derrotas + empates) > 0 else 1 # Evitar division by zero\n",
    "        pct_victorias = (victorias / total_comparaciones * 100) if total_comparaciones > 0 else 0\n",
    "\n",
    "\n",
    "        ranking_data.append({\n",
    "            'Modelo': modelo,\n",
    "            'Victorias': int(victorias),\n",
    "            'Derrotas': int(derrotas),\n",
    "            'Empates': int(empates),\n",
    "            'Score': int(score),\n",
    "            'Pct_Victorias': round(pct_victorias, 2)\n",
    "        })\n",
    "\n",
    "    df_ranking = pd.DataFrame(ranking_data)\n",
    "    df_ranking = df_ranking.sort_values('Score', ascending=False).reset_index(drop=True)\n",
    "    df_ranking['Rank'] = range(1, len(df_ranking) + 1)\n",
    "\n",
    "    return df_ranking, matriz\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CLASE PRINCIPAL DE AN√ÅLISIS - MEJORADA\n",
    "# ============================================================================\n",
    "\n",
    "class AnalizadorBaseCompleta:\n",
    "    \"\"\"An√°lisis completo de la base de datos en 8 dimensiones + PFI/PDP/ICE\"\"\"\n",
    "\n",
    "    def __init__(self, ruta_datos):\n",
    "        \"\"\"Inicializa el analizador\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"INICIANDO AN√ÅLISIS COMPLETO DE BASE DE DATOS - VERSI√ìN MEJORADA\")\n",
    "        print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "        self.df = pd.read_excel(ruta_datos)\n",
    "        self.modelos = MODELOS\n",
    "        self.dir_salida = Path(DIR_SALIDA)\n",
    "        self.dir_salida.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Extraer caracter√≠sticas del escenario\n",
    "        self._extraer_caracteristicas()\n",
    "\n",
    "        # Preprocesar datos para meta-modelo\n",
    "        self.preprocessor, self.X_processed = self._preprocess_meta_features()\n",
    "        self.meta_models = {} # Almacenar meta-modelos entrenados\n",
    "        self.pfi_results = {} # Almacenar resultados de PFI\n",
    "\n",
    "        print(f\"‚úì Datos cargados: {self.df.shape[0]} filas, {self.df.shape[1]} columnas\")\n",
    "        print(f\"‚úì Modelos a analizar: {len(self.modelos)}\")\n",
    "        print(f\"‚úì Directorio de salida: {self.dir_salida}\")\n",
    "        print(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
    "\n",
    "    def _extraer_caracteristicas(self):\n",
    "        \"\"\"Extrae caracter√≠sticas individuales del escenario (sin cambios)\"\"\"\n",
    "        self.df['Estacionario'] = self.df['Escenario'].apply(\n",
    "            lambda x: 'Estacionario' if 'Estacionario' in x and 'No_Estacionario' not in x else 'No Estacionario'\n",
    "        )\n",
    "\n",
    "        self.df['Lineal'] = self.df['Escenario'].apply(\n",
    "            lambda x: 'Lineal' if 'Lineal' in x and 'No_Lineal' not in x else 'No Lineal'\n",
    "        )\n",
    "\n",
    "        print(\"‚úì Caracter√≠sticas extra√≠das:\")\n",
    "        print(f\"  - Estacionariedad: {self.df['Estacionario'].unique()}\")\n",
    "        print(f\"  - Linealidad: {self.df['Lineal'].unique()}\")\n",
    "        print(f\"  - Tipos de Modelo: {self.df['Tipo de Modelo'].unique()}\")\n",
    "        print(f\"  - Distribuciones: {self.df['Distribuci√≥n'].unique()}\")\n",
    "        print(f\"  - Varianzas: {sorted(self.df['Varianza error'].unique())}\")\n",
    "        print(f\"  - Pasos: {sorted(self.df['Paso'].unique())}\")\n",
    "\n",
    "    def _preprocess_meta_features(self):\n",
    "        \"\"\"\n",
    "        Preprocesa las caracter√≠sticas para el meta-modelo (OneHotEncoding para categ√≥ricas).\n",
    "        \"\"\"\n",
    "        numeric_features = CARACTERISTICAS_NUMERICAS_META_MODELO\n",
    "        categorical_features = CARACTERISTICAS_CATEGORICAS_META_MODELO\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', 'passthrough', numeric_features),\n",
    "                # A√ëADIR sparse_output=False AQU√ç PARA SOLUCIONAR EL ERROR\n",
    "                ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
    "            ],\n",
    "            remainder='drop'\n",
    "        )\n",
    "        \n",
    "        # Ajustar y transformar X\n",
    "        X = self.df[CARACTERISTICAS_META_MODELO]\n",
    "        X_processed_array = preprocessor.fit_transform(X)\n",
    "        \n",
    "        # Obtener nombres de las caracter√≠sticas preprocesadas para PFI/PDP\n",
    "        # Se debe usar get_feature_names_out para versiones recientes de sklearn\n",
    "        try:\n",
    "            ohe_feature_names = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features)\n",
    "        except AttributeError:\n",
    "             # Fallback para versiones m√°s antiguas\n",
    "            ohe_feature_names = preprocessor.named_transformers_['cat'].get_feature_names(categorical_features)\n",
    "            \n",
    "        feature_names = numeric_features + list(ohe_feature_names)\n",
    "\n",
    "        # Ahora la creaci√≥n del DataFrame funcionar√°\n",
    "        return preprocessor, pd.DataFrame(X_processed_array, columns=feature_names)\n",
    "\n",
    "\n",
    "    def _train_meta_model(self, target_model_name):\n",
    "        \"\"\"\n",
    "        Entrena un RandomForestRegressor para predecir el error de un modelo de pron√≥stico\n",
    "        basado en las caracter√≠sticas de la simulaci√≥n.\n",
    "        \"\"\"\n",
    "        if target_model_name in self.meta_models:\n",
    "            return self.meta_models[target_model_name]\n",
    "\n",
    "        print(f\"   Entrenando meta-modelo para {target_model_name}...\")\n",
    "        y = self.df[target_model_name]\n",
    "        \n",
    "        # Usamos un pipeline simplificado para que PFI/PDP puedan trabajar con el preprocesador\n",
    "        # directamente si fuera necesario, aunque aqu√≠ ya pasamos X_processed.\n",
    "        # En este caso, el preprocessor ya se us√≥ para obtener X_processed.\n",
    "        # Creamos solo el modelo RandomForestRegressor.\n",
    "        \n",
    "        meta_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "        meta_model.fit(self.X_processed, y)\n",
    "        self.meta_models[target_model_name] = meta_model\n",
    "        print(f\"   ‚úì Meta-modelo entrenado para {target_model_name}.\")\n",
    "        return meta_model\n",
    "\n",
    "    def ejecutar_analisis_completo(self):\n",
    "        \"\"\"Ejecuta todos los an√°lisis, incluyendo los nuevos\"\"\"\n",
    "        print(\"\\n\" + \"üî¨\" * 40 + \"\\n\")\n",
    "\n",
    "        # 1. Impacto de Estacionariedad\n",
    "        print(\"1Ô∏è‚É£  Analizando impacto de Escenarios (Estacionariedad y Linealidad)...\")\n",
    "        self._analisis_estacionariedad()\n",
    "\n",
    "        # 2. Impacto de Linealidad\n",
    "        print(\"2Ô∏è‚É£  Analizando impacto de Linealidad...\")\n",
    "        self._analisis_linealidad()\n",
    "\n",
    "        # 3. Efecto del Modelo Generador\n",
    "        print(\"3Ô∏è‚É£  Analizando efecto del Modelo Generador...\")\n",
    "        self._analisis_modelo_generador()\n",
    "\n",
    "        # 4. Influencia de Distribuci√≥n\n",
    "        print(\"4Ô∏è‚É£  Analizando influencia de Distribuci√≥n...\")\n",
    "        self._analisis_distribucion()\n",
    "\n",
    "        # 5. Impacto de Varianza\n",
    "        print(\"5Ô∏è‚É£  Analizando impacto de Varianza...\")\n",
    "        self._analisis_varianza()\n",
    "\n",
    "        # 6. Deterioro por Horizonte\n",
    "        print(\"6Ô∏è‚É£  Analizando deterioro por Horizonte...\")\n",
    "        self._analisis_horizonte()\n",
    "\n",
    "        # 7. Robustez y Estabilidad\n",
    "        print(\"7Ô∏è‚É£  Analizando Robustez y Estabilidad...\")\n",
    "        self._analisis_robustez()\n",
    "\n",
    "        # 8. Diferencias Estad√≠sticamente Significativas\n",
    "        print(\"8Ô∏è‚É£  Analizando Diferencias Estad√≠sticamente Significativas...\")\n",
    "        self._analisis_significancia()\n",
    "\n",
    "        # AN√ÅLISIS 9 Y 10 DESHABILITADOS POR SOLICITUD\n",
    "        print(\"\\n9Ô∏è‚É£  An√°lisis de Impacto de Caracter√≠sticas (PFI) OMITIDO.\")\n",
    "        print(\"\\nüîü An√°lisis de Variabilidad (PDP e ICE) OMITIDO.\")\n",
    "        print(\"\\n‚ú® Resumen Ejecutivo OMITIDO.\")\n",
    "        # self._analisis_impacto_pfi()\n",
    "        # self._analisis_variabilidad_pdp_ice()\n",
    "        # self._generar_resumen_ejecutivo()\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"‚úÖ AN√ÅLISIS COMPLETO FINALIZADO\")\n",
    "        print(f\"üìÅ Resultados guardados en: {self.dir_salida}\")\n",
    "        print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # 1 y 2. IMPACTO DE ESCENARIOS (CONSOLIDADO)\n",
    "    # ========================================================================\n",
    "\n",
    "    def _analisis_estacionariedad(self):\n",
    "        \"\"\"Analiza el impacto de los 4 escenarios combinados\"\"\"\n",
    "        \n",
    "        # Crear columna con combinaci√≥n de Estacionariedad y Linealidad\n",
    "        self.df['Escenario_Combinado'] = self.df['Estacionario'] + ' - ' + self.df['Lineal']\n",
    "        \n",
    "        escenarios_orden = [\n",
    "            'Estacionario - Lineal',\n",
    "            'Estacionario - No Lineal', \n",
    "            'No Estacionario - Lineal'\n",
    "        ]\n",
    "        \n",
    "        # Calcular estad√≠sticas por escenario combinado\n",
    "        stats_esc = []\n",
    "        for modelo in self.modelos:\n",
    "            for esc in escenarios_orden:\n",
    "                df_subset = self.df[self.df['Escenario_Combinado'] == esc]\n",
    "                stats_esc.append({\n",
    "                    'Modelo': modelo,\n",
    "                    'Escenario': esc,\n",
    "                    'Media': df_subset[modelo].mean(),\n",
    "                    'Std': df_subset[modelo].std()\n",
    "                })\n",
    "        \n",
    "        df_stats = pd.DataFrame(stats_esc)\n",
    "        \n",
    "        # FIGURA 1.1: Rendimiento por escenario (barras agrupadas verticales)\n",
    "        fig, ax = plt.subplots(figsize=(16, 9))\n",
    "        pivot_media = df_stats.pivot(index='Modelo', columns='Escenario', values='Media')\n",
    "        pivot_media = pivot_media[escenarios_orden]  # Ordenar columnas\n",
    "        pivot_media = pivot_media.sort_values(escenarios_orden[0])  # Ordenar por baseline\n",
    "        \n",
    "        x = np.arange(len(pivot_media))\n",
    "        width = 0.2\n",
    "        \n",
    "        colores_escenarios = {\n",
    "            'Estacionario - Lineal': '#2E7D32',  # Verde oscuro\n",
    "            'Estacionario - No Lineal': '#66BB6A',  # Verde claro\n",
    "            'No Estacionario - Lineal': '#F57C00',  # Naranja\n",
    "            'No Estacionario - No Lineal': '#D32F2F'  # Rojo\n",
    "        }\n",
    "        \n",
    "        for i, esc in enumerate(escenarios_orden):\n",
    "            offset = width * (i - 1.5)\n",
    "            ax.bar(x + offset, pivot_media[esc], width,\n",
    "                   label=esc, color=colores_escenarios[esc], \n",
    "                   edgecolor='black', linewidth=1.2, alpha=0.85)\n",
    "        \n",
    "        ax.set_xlabel('Modelos Predictores', fontweight='bold', fontsize=13)\n",
    "        ax.set_ylabel('ECRPS Promedio', fontweight='bold', fontsize=13)\n",
    "        ax.set_title('Rendimiento por Escenario: Comparaci√≥n Completa',\n",
    "                     fontweight='bold', fontsize=15, pad=20)\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(pivot_media.index, rotation=45, ha='right', fontsize=11)\n",
    "        ax.legend(title='Escenario', fontsize=10, title_fontsize=11, loc='best')\n",
    "        ax.grid(True, alpha=0.3, axis='y', linestyle='--')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '1_1_escenarios_rendimiento_completo.png',\n",
    "                    dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # FIGURA 1.2: Cambio relativo respecto al baseline (Estacionario-Lineal)\n",
    "        fig, ax = plt.subplots(figsize=(14, 10))\n",
    "        \n",
    "        baseline = pivot_media[escenarios_orden[0]]\n",
    "        cambios_relativos = {}\n",
    "        \n",
    "        for esc in escenarios_orden[1:]:  # Excluir baseline\n",
    "            cambio = ((pivot_media[esc] - baseline) / baseline * 100)\n",
    "            cambios_relativos[esc] = cambio\n",
    "        \n",
    "        df_cambios = pd.DataFrame(cambios_relativos)\n",
    "        df_cambios = df_cambios.sort_values(escenarios_orden[1])  # Ordenar por primer escenario no-baseline\n",
    "        \n",
    "        x_models = np.arange(len(df_cambios))\n",
    "        width = 0.25\n",
    "        \n",
    "        for i, esc in enumerate(escenarios_orden[1:]):\n",
    "            offset = width * (i - 1)\n",
    "            colors = ['green' if val < 0 else 'red' for val in df_cambios[esc].values]\n",
    "            ax.barh(x_models + offset, df_cambios[esc].values, width,\n",
    "                   label=esc, color=colores_escenarios[esc], \n",
    "                   alpha=0.75, edgecolor='black', linewidth=1.2)\n",
    "        \n",
    "        ax.axvline(0, color='black', linestyle='-', linewidth=2.5)\n",
    "        ax.set_yticks(x_models)\n",
    "        ax.set_yticklabels(df_cambios.index, fontsize=11)\n",
    "        ax.set_xlabel('Cambio Relativo vs Estacionario-Lineal (%)', fontweight='bold', fontsize=13)\n",
    "        ax.set_ylabel('Modelos Predictores', fontweight='bold', fontsize=13)\n",
    "        ax.set_title('Deterioro Relativo por Escenario\\n(Baseline: Estacionario-Lineal)',\n",
    "                     fontweight='bold', fontsize=15, pad=20)\n",
    "        ax.legend(title='Escenario', fontsize=10, title_fontsize=11, loc='best')\n",
    "        ax.grid(True, alpha=0.3, axis='x', linestyle='--')\n",
    "        \n",
    "        # A√±adir valores en las barras\n",
    "        for i, esc in enumerate(escenarios_orden[1:]):\n",
    "            offset = width * (i - 1)\n",
    "            for j, val in enumerate(df_cambios[esc].values):\n",
    "                x_pos = val + (2 if val > 0 else -2)\n",
    "                ha = 'left' if val > 0 else 'right'\n",
    "                ax.text(x_pos, j + offset, f'{val:.1f}%',\n",
    "                       va='center', ha=ha, fontweight='bold', fontsize=8)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '1_2_escenarios_cambio_relativo.png',\n",
    "                    dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(\"   ‚úì 2 figuras generadas para an√°lisis de escenarios consolidado\\n\")\n",
    "\n",
    "    def _analisis_linealidad(self):\n",
    "        \"\"\"Esta funci√≥n ya no genera figuras separadas - integrada en _analisis_estacionariedad\"\"\"\n",
    "        print(\"   ‚ÑπÔ∏è  An√°lisis de linealidad integrado en an√°lisis de escenarios\\n\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # 3. EFECTO DEL MODELO GENERADOR (Sin cambios funcionales, solo prints)\n",
    "    # ========================================================================\n",
    "\n",
    "    def _analisis_modelo_generador(self):\n",
    "        \"\"\"Analiza el efecto del modelo generador de datos\"\"\"\n",
    "\n",
    "        pivot_media = self.df.groupby('Tipo de Modelo')[self.modelos].mean()\n",
    "        tipos = self.df['Tipo de Modelo'].unique()\n",
    "\n",
    "        # FIGURA 3.2: Heatmap normalizado (Z-scores)\n",
    "        fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "        pivot_norm = pivot_media.T.sub(pivot_media.T.mean(axis=1), axis=0).div(pivot_media.T.std(axis=1), axis=0)\n",
    "\n",
    "        sns.heatmap(pivot_norm, annot=True, fmt='.2f', cmap='RdBu_r', center=0,\n",
    "                    ax=ax, cbar_kws={'label': 'Z-Score'},\n",
    "                    linewidths=0.5, linecolor='gray', vmin=-2, vmax=2,\n",
    "                    annot_kws={'fontsize': 8})\n",
    "        ax.set_xlabel('Tipo de Modelo Generador', fontweight='bold', fontsize=13, labelpad=15)\n",
    "        ax.set_ylabel('Modelo de Predicci√≥n', fontweight='bold', fontsize=13, labelpad=10)\n",
    "        ax.set_title('ECRPS Relativo (Z-Score por Modelo)',\n",
    "                     fontweight='bold', fontsize=15, pad=20)\n",
    "        \n",
    "        # Ajustar etiquetas del eje X para evitar superposici√≥n\n",
    "        ax.tick_params(axis='x', rotation=45, labelsize=9)\n",
    "        ax.tick_params(axis='y', rotation=0, labelsize=11)\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45, ha='right', va='top')\n",
    "        plt.setp(ax.get_yticklabels(), rotation=0, ha='right', va='center')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '3_2_modelo_generador_zscore.png',\n",
    "                    dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        # FIGURA 3.3: Variabilidad por tipo\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "        rankings = []\n",
    "        for tipo in tipos:\n",
    "            df_tipo = self.df[self.df['Tipo de Modelo'] == tipo]\n",
    "            medias = df_tipo[self.modelos].mean().sort_values()\n",
    "            rankings.append({\n",
    "                'Tipo': tipo,\n",
    "                'Mejor_Modelo': medias.index[0],\n",
    "                'Mejor_ECRPS': medias.values[0],\n",
    "                'Peor_Modelo': medias.index[-1],\n",
    "                'Peor_ECRPS': medias.values[-1],\n",
    "                'Rango': medias.values[-1] - medias.values[0]\n",
    "            })\n",
    "\n",
    "        df_rankings = pd.DataFrame(rankings).sort_values('Rango', ascending=False)\n",
    "\n",
    "        y_pos = np.arange(len(df_rankings))\n",
    "        bars = ax.barh(y_pos, df_rankings['Rango'].values,\n",
    "                       color='steelblue', alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "        ax.set_yticks(y_pos)\n",
    "        ax.set_yticklabels(df_rankings['Tipo'].values, fontsize=10)\n",
    "        ax.set_xlabel('Rango de ECRPS (Max - Min)', fontweight='bold', fontsize=12)\n",
    "        ax.set_title('Variabilidad por Tipo de Generador',\n",
    "                     fontweight='bold', fontsize=14, pad=20)\n",
    "        ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "        for i, (bar, val) in enumerate(zip(bars, df_rankings['Rango'].values)):\n",
    "            ax.text(val + 0.001, i, f'{val:.3f}', va='center', fontweight='bold', fontsize=10)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '3_3_modelo_generador_variabilidad.png',\n",
    "                    dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        print(\"   ‚úì 2 figuras generadas para modelo generador\\n\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # 4. INFLUENCIA DE LA DISTRIBUCI√ìN (Sin cambios funcionales, solo prints)\n",
    "    # ========================================================================\n",
    "\n",
    "    def _analisis_distribucion(self):\n",
    "        \"\"\"Analiza la influencia de la distribuci√≥n de errores\"\"\"\n",
    "\n",
    "        pivot_media = self.df.groupby('Distribuci√≥n')[self.modelos].mean()\n",
    "        pivot_std = self.df.groupby('Distribuci√≥n')[self.modelos].std()\n",
    "\n",
    "        # FIGURA 4.1: Heatmap de rendimiento\n",
    "        fig, ax = plt.subplots(figsize=(14, 10))\n",
    "\n",
    "        sns.heatmap(pivot_media.T, annot=True, fmt='.3f', cmap='RdYlGn_r',\n",
    "                    ax=ax, cbar_kws={'label': 'ECRPS Promedio'},\n",
    "                    linewidths=0.5, linecolor='gray')\n",
    "        ax.set_xlabel('Distribuci√≥n de Errores', fontweight='bold', fontsize=12)\n",
    "        ax.set_ylabel('Modelo de Predicci√≥n', fontweight='bold', fontsize=12)\n",
    "        ax.set_title('ECRPS por Distribuci√≥n de Errores',\n",
    "                     fontweight='bold', fontsize=14, pad=20)\n",
    "        ax.tick_params(axis='x', rotation=45, labelsize=10)\n",
    "        ax.tick_params(axis='y', rotation=0, labelsize=10)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '4_1_distribucion_heatmap_rendimiento.png',\n",
    "                    dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        # FIGURA 4.2: Heatmap de variabilidad\n",
    "        fig, ax = plt.subplots(figsize=(14, 10))\n",
    "\n",
    "        sns.heatmap(pivot_std.T, annot=True, fmt='.3f', cmap='YlOrRd',\n",
    "                    ax=ax, cbar_kws={'label': 'Desviaci√≥n Est√°ndar'},\n",
    "                    linewidths=0.5, linecolor='gray')\n",
    "        ax.set_xlabel('Distribuci√≥n de Errores', fontweight='bold', fontsize=12)\n",
    "        ax.set_ylabel('Modelo de Predicci√≥n', fontweight='bold', fontsize=12)\n",
    "        ax.set_title('Variabilidad por Distribuci√≥n de Errores',\n",
    "                     fontweight='bold', fontsize=14, pad=20)\n",
    "        ax.tick_params(axis='x', rotation=45, labelsize=10)\n",
    "        ax.tick_params(axis='y', rotation=0, labelsize=10)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '4_2_distribucion_heatmap_variabilidad.png',\n",
    "                    dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        print(\"   ‚úì 2 figuras generadas para distribuci√≥n\\n\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # 5. IMPACTO DE VARIANZA (MODIFICADO PARA AGRUPAR POR ESCENARIO)\n",
    "    # ========================================================================\n",
    "\n",
    "    def _analisis_varianza(self):\n",
    "        \"\"\"Analiza el impacto del nivel de varianza (ruido) POR ESCENARIO\"\"\"\n",
    "        \n",
    "        # Asegurarse de que la columna del escenario combinado exista\n",
    "        if 'Escenario_Combinado' not in self.df.columns:\n",
    "            self.df['Escenario_Combinado'] = self.df['Estacionario'] + ' - ' + self.df['Lineal']\n",
    "        \n",
    "        escenarios = self.df['Escenario_Combinado'].unique()\n",
    "        varianzas = sorted(self.df['Varianza error'].unique())\n",
    "\n",
    "        for escenario in escenarios:\n",
    "            df_escenario = self.df[self.df['Escenario_Combinado'] == escenario]\n",
    "            escenario_filename = escenario.replace(' ', '_').replace('-', '')\n",
    "\n",
    "            # FIGURA 5.1: L√≠neas de tendencia por escenario\n",
    "            fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "            for modelo in self.modelos:\n",
    "                medias = [df_escenario[df_escenario['Varianza error'] == v][modelo].mean()\n",
    "                          for v in varianzas]\n",
    "                ax.plot(varianzas, medias, marker='o', label=modelo,\n",
    "                        linewidth=2.5, markersize=8, color=COLORES_MODELOS[modelo])\n",
    "\n",
    "            ax.set_xlabel('Nivel de Varianza', fontweight='bold', fontsize=12)\n",
    "            ax.set_ylabel('ECRPS Promedio', fontweight='bold', fontsize=12)\n",
    "            ax.set_title(f'Deterioro con Aumento de Varianza\\nEscenario: {escenario}',\n",
    "                         fontweight='bold', fontsize=14, pad=20)\n",
    "            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            ax.set_xticks(varianzas)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(self.dir_salida / f'5_1_varianza_tendencias_{escenario_filename}.png',\n",
    "                        dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "            # FIGURA 5.2: Tasa de crecimiento por escenario\n",
    "            fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "            tasas_crecimiento = {}\n",
    "            for modelo in self.modelos:\n",
    "                medias = [df_escenario[df_escenario['Varianza error'] == v][modelo].mean()\n",
    "                          for v in varianzas]\n",
    "                if len(medias) > 1 and all(pd.notna(m) for m in medias):\n",
    "                    pendiente = (medias[-1] - medias[0]) / (varianzas[-1] - varianzas[0])\n",
    "                    tasas_crecimiento[modelo] = pendiente\n",
    "\n",
    "            if not tasas_crecimiento:\n",
    "                print(f\"      No hay datos suficientes para calcular tasas de crecimiento en el escenario: {escenario}\")\n",
    "                continue\n",
    "\n",
    "            tc_sorted = dict(sorted(tasas_crecimiento.items(), key=lambda x: x[1]))\n",
    "            median_val = np.median(list(tc_sorted.values()))\n",
    "\n",
    "            colors_tc = ['green' if v < median_val else 'red'\n",
    "                         for v in tc_sorted.values()]\n",
    "            bars = ax.barh(range(len(tc_sorted)), list(tc_sorted.values()),\n",
    "                           color=colors_tc, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "            ax.set_yticks(range(len(tc_sorted)))\n",
    "            ax.set_yticklabels(list(tc_sorted.keys()), fontsize=10)\n",
    "            ax.set_xlabel('Tasa de Crecimiento del Error', fontweight='bold', fontsize=12)\n",
    "            ax.set_title(f'Sensibilidad al Ruido\\nEscenario: {escenario} (Menor = M√°s Robusto)',\n",
    "                         fontweight='bold', fontsize=14, pad=20)\n",
    "            ax.axvline(median_val, color='black',\n",
    "                       linestyle='--', linewidth=2, label='Mediana')\n",
    "            ax.grid(True, alpha=0.3, axis='x')\n",
    "            ax.legend(fontsize=11)\n",
    "\n",
    "            for i, (bar, val) in enumerate(zip(bars, tc_sorted.values())):\n",
    "                ax.text(val + (0.0001 if val > 0 else -0.0001), i, f'{val:.4f}',\n",
    "                        va='center', ha='left' if val > 0 else 'right',\n",
    "                        fontweight='bold', fontsize=9)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(self.dir_salida / f'5_2_varianza_tasa_crecimiento_{escenario_filename}.png',\n",
    "                        dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "        print(f\"   ‚úì {2 * len(escenarios)} figuras generadas para varianza (2 por cada uno de los {len(escenarios)} escenarios)\\n\")\n",
    "\n",
    "\n",
    "    # ========================================================================\n",
    "    # 6. DETERIORO POR HORIZONTE (MODIFICADO PARA AGRUPAR POR ESCENARIO)\n",
    "    # ========================================================================\n",
    "\n",
    "    def _analisis_horizonte(self):\n",
    "        \"\"\"Analiza el deterioro del rendimiento con el horizonte de predicci√≥n POR ESCENARIO\"\"\"\n",
    "\n",
    "        # Asegurarse de que la columna del escenario combinado exista\n",
    "        if 'Escenario_Combinado' not in self.df.columns:\n",
    "            self.df['Escenario_Combinado'] = self.df['Estacionario'] + ' - ' + self.df['Lineal']\n",
    "        \n",
    "        escenarios = self.df['Escenario_Combinado'].unique()\n",
    "        pasos = sorted(self.df['Paso'].unique())\n",
    "\n",
    "        for escenario in escenarios:\n",
    "            df_escenario = self.df[self.df['Escenario_Combinado'] == escenario]\n",
    "            escenario_filename = escenario.replace(' ', '_').replace('-', '')\n",
    "\n",
    "            # FIGURA 6.1: Evoluci√≥n paso a paso por escenario\n",
    "            fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "            for modelo in self.modelos:\n",
    "                medias = [df_escenario[df_escenario['Paso'] == p][modelo].mean() for p in pasos]\n",
    "                ax.plot(pasos, medias, marker='o', label=modelo,\n",
    "                        linewidth=2.5, markersize=8, color=COLORES_MODELOS[modelo])\n",
    "\n",
    "            ax.set_xlabel('Horizonte de Predicci√≥n (Paso)', fontweight='bold', fontsize=12)\n",
    "            ax.set_ylabel('ECRPS Promedio', fontweight='bold', fontsize=12)\n",
    "            ax.set_title(f'Evoluci√≥n del ECRPS por Horizonte\\nEscenario: {escenario}',\n",
    "                         fontweight='bold', fontsize=14, pad=20)\n",
    "            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            ax.set_xticks(pasos)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(self.dir_salida / f'6_1_horizonte_evolucion_{escenario_filename}.png',\n",
    "                        dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "            # FIGURA 6.2: Tasa de deterioro por escenario\n",
    "            fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "            tasas_deterioro = {}\n",
    "            for modelo in self.modelos:\n",
    "                medias = [df_escenario[df_escenario['Paso'] == p][modelo].mean() for p in pasos]\n",
    "                if len(medias) > 1 and all(pd.notna(m) for m in medias):\n",
    "                    pendiente = (medias[-1] - medias[0]) / (pasos[-1] - pasos[0])\n",
    "                    tasas_deterioro[modelo] = pendiente\n",
    "\n",
    "            if not tasas_deterioro:\n",
    "                print(f\"      No hay datos suficientes para calcular tasas de deterioro en el escenario: {escenario}\")\n",
    "                continue\n",
    "            \n",
    "            td_sorted = dict(sorted(tasas_deterioro.items(), key=lambda x: x[1]))\n",
    "            median_val = np.median(list(td_sorted.values()))\n",
    "            \n",
    "            colors_td = ['green' if v < median_val else 'red'\n",
    "                         for v in td_sorted.values()]\n",
    "            bars = ax.barh(range(len(td_sorted)), list(td_sorted.values()),\n",
    "                           color=colors_td, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "            ax.set_yticks(range(len(td_sorted)))\n",
    "            ax.set_yticklabels(list(td_sorted.keys()), fontsize=10)\n",
    "            ax.set_xlabel('Tasa de Deterioro por Paso', fontweight='bold', fontsize=12)\n",
    "            ax.set_title(f'Velocidad de Deterioro\\nEscenario: {escenario} (Menor = M√°s Estable)',\n",
    "                         fontweight='bold', fontsize=14, pad=20)\n",
    "            ax.axvline(0, color='black', linestyle='-', linewidth=2)\n",
    "            ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "            for i, (bar, val) in enumerate(zip(bars, td_sorted.values())):\n",
    "                ax.text(val + (0.0001 if val > 0 else -0.0001), i, f'{val:.4f}',\n",
    "                        va='center', ha='left' if val > 0 else 'right',\n",
    "                        fontweight='bold', fontsize=9)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(self.dir_salida / f'6_2_horizonte_tasa_deterioro_{escenario_filename}.png',\n",
    "                        dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "        print(f\"   ‚úì {2 * len(escenarios)} figuras generadas para horizonte (2 por cada uno de los {len(escenarios)} escenarios)\\n\")\n",
    "\n",
    "\n",
    "    # ========================================================================\n",
    "    # 7. ROBUSTEZ Y ESTABILIDAD (Sin cambios funcionales, solo prints)\n",
    "    # ========================================================================\n",
    "\n",
    "    def _analisis_robustez(self):\n",
    "        \"\"\"Analiza la robustez y estabilidad de los modelos\"\"\"\n",
    "\n",
    "        # Calcular m√©tricas de robustez\n",
    "        metricas_robustez = []\n",
    "\n",
    "        for modelo in self.modelos:\n",
    "            std_global = self.df[modelo].std()\n",
    "            cv = (self.df[modelo].std() / self.df[modelo].mean()) * 100\n",
    "            q75, q25 = self.df[modelo].quantile([0.75, 0.25])\n",
    "            iqr = q75 - q25\n",
    "            std_entre_escenarios = self.df.groupby('Escenario')[modelo].mean().std()\n",
    "            std_entre_dist = self.df.groupby('Distribuci√≥n')[modelo].mean().std()\n",
    "            std_entre_var = self.df.groupby('Varianza error')[modelo].mean().std()\n",
    "\n",
    "            metricas_robustez.append({\n",
    "                'Modelo': modelo,\n",
    "                'Std_Global': std_global,\n",
    "                'CV': cv,\n",
    "                'IQR': iqr,\n",
    "                'Std_Escenarios': std_entre_escenarios,\n",
    "                'Std_Distribuciones': std_entre_dist,\n",
    "                'Std_Varianzas': std_entre_var\n",
    "            })\n",
    "\n",
    "        df_robustez = pd.DataFrame(metricas_robustez)\n",
    "\n",
    "        # FIGURA 7.2: Coeficiente de variaci√≥n\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "        df_sorted = df_robustez.sort_values('CV')\n",
    "        colors = plt.cm.RdYlGn(np.linspace(0.8, 0.2, len(df_sorted)))\n",
    "        bars = ax.barh(df_sorted['Modelo'], df_sorted['CV'],\n",
    "                       color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "        ax.set_xlabel('Coeficiente de Variaci√≥n (%)', fontweight='bold', fontsize=12)\n",
    "        ax.set_title('Variabilidad Relativa\\n(Menor = M√°s Consistente)',\n",
    "                     fontweight='bold', fontsize=14, pad=20)\n",
    "        ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "        for i, (bar, val) in enumerate(zip(bars, df_sorted['CV'].values)):\n",
    "            ax.text(val + 1, i, f'{val:.1f}%', va='center', fontweight='bold', fontsize=9)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '7_2_robustez_coef_variacion.png',\n",
    "                    dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        # Guardar para usar despu√©s\n",
    "        self.df_robustez = df_robustez\n",
    "\n",
    "        print(\"   ‚úì 1 figura generada para robustez\\n\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # 8. DIFERENCIAS ESTAD√çSTICAMENTE SIGNIFICATIVAS (Sin cambios funcionales, solo prints)\n",
    "    # ========================================================================\n",
    "\n",
    "    def _analisis_significancia(self):\n",
    "        \"\"\"An√°lisis de diferencias estad√≠sticamente significativas con Test DM\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"REALIZANDO TEST DE DIEBOLD-MARIANO\")\n",
    "        print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "        # Realizar comparaciones m√∫ltiples\n",
    "        df_comparaciones, alpha_bonf = comparaciones_multiples_dm(\n",
    "            self.df, self.modelos, alpha=0.05\n",
    "        )\n",
    "\n",
    "        print(f\"   N√∫mero de comparaciones: {len(df_comparaciones)}\")\n",
    "        print(f\"   Alpha corregido (Bonferroni): {alpha_bonf:.6f}\")\n",
    "        print(f\"   Comparaciones significativas: {df_comparaciones['Significativo'].sum()}\")\n",
    "\n",
    "        # Calcular ranking\n",
    "        df_ranking, matriz_sup = calcular_ranking_dm(df_comparaciones, self.modelos)\n",
    "\n",
    "        # FIGURA 8.2: Matriz de superioridad\n",
    "        fig, ax = plt.subplots(figsize=(14, 12))\n",
    "\n",
    "        sns.heatmap(matriz_sup, annot=True, fmt='.0f', cmap='RdYlGn',\n",
    "                    center=0, ax=ax, cbar_kws={'label': 'Superioridad'},\n",
    "                    vmin=-1, vmax=1, linewidths=1, linecolor='gray',\n",
    "                    annot_kws={'fontsize': 10, 'fontweight': 'bold'})\n",
    "        ax.set_title('Matriz de Superioridad\\n(1=Superior, -1=Inferior, 0=Sin diferencia)',\n",
    "                     fontweight='bold', fontsize=14, pad=20)\n",
    "        ax.set_xlabel('Modelo Comparado', fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel('Modelo', fontsize=12, fontweight='bold')\n",
    "        ax.tick_params(labelsize=10)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '8_2_significancia_matriz_superioridad.png',\n",
    "                    dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        # Guardar para usar despu√©s\n",
    "        self.df_ranking = df_ranking\n",
    "        self.df_comparaciones = df_comparaciones\n",
    "\n",
    "        print(f\"\\n   ‚úì Ranking guardado: Top 3\")\n",
    "        for i, row in df_ranking.head(3).iterrows():\n",
    "            print(f\"      {row['Rank']}. {row['Modelo']} - Score: {row['Score']} \"\n",
    "                  f\"(V:{row['Victorias']}, D:{row['Derrotas']}, E:{row['Empates']})\")\n",
    "\n",
    "        print(\"\\n   ‚úì 1 figura generada para significancia\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# FUNCI√ìN PRINCIPAL\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Funci√≥n principal de ejecuci√≥n\"\"\"\n",
    "    print(\"\\n\" + \"‚ñà\" * 80)\n",
    "    print(\"‚ñà\" + \" \" * 78 + \"‚ñà\")\n",
    "    print(\"‚ñà\" + \" \" * 10 + \"AN√ÅLISIS COMPLETO DE BASE DE DATOS - VERSI√ìN MEJORADA\" + \" \" * 9 + \"‚ñà\")\n",
    "    print(\"‚ñà\" + \" \" * 78 + \"‚ñà\")\n",
    "    print(\"‚ñà\" * 80 + \"\\n\")\n",
    "\n",
    "    try:\n",
    "        # Crear instancia del analizador\n",
    "        analizador = AnalizadorBaseCompleta(RUTA_DATOS)\n",
    "\n",
    "        # Ejecutar an√°lisis completo\n",
    "        analizador.ejecutar_analisis_completo()\n",
    "\n",
    "        print(\"\\n\" + \"‚ñà\" * 80)\n",
    "        print(\"‚ñà\" + \" \" * 78 + \"‚ñà\")\n",
    "        print(\"‚ñà\" + \" \" * 20 + \"‚úÖ AN√ÅLISIS COMPLETADO EXITOSAMENTE\" + \" \" * 23 + \"‚ñà\")\n",
    "        print(\"‚ñà\" + \" \" * 78 + \"‚ñà\")\n",
    "        print(\"‚ñà\" * 80 + \"\\n\")\n",
    "        \n",
    "        print(f\"üìä TOTAL DE FIGURAS GENERADAS APROXIMADAMENTE: 23 im√°genes PNG\")\n",
    "        print(\"\\nüìÅ ESTRUCTURA DE RESULTADOS:\")\n",
    "        print(f\"   {DIR_SALIDA}/\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ 1.1: Escenarios - Rendimiento Completo\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ 1.2: Escenarios - Cambio Relativo\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ 3.2: Modelo Generador - Z-Score\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ 3.3: Modelo Generador - Variabilidad\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ 4.1: Distribuci√≥n - Heatmap ECRPS\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ 4.2: Distribuci√≥n - Heatmap Variabilidad\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ 5.1: Varianza - Tendencias (x4 escenarios) (MODIFICADO)\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ 5.2: Varianza - Tasa de Crecimiento (x4 escenarios) (MODIFICADO)\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ 6.1: Horizonte - Evoluci√≥n (x4 escenarios) (MODIFICADO)\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ 6.2: Horizonte - Tasa de Deterioro (x4 escenarios) (MODIFICADO)\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ 7.2: Robustez - Coeficiente de Variaci√≥n\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ 8.2: Significancia - Matriz de Superioridad\")\n",
    "        print(\"   ‚îî‚îÄ‚îÄ (An√°lisis 9 y 10 OMITIDOS)\")\n",
    "        print(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"\\n‚ùå ERROR: No se encontr√≥ el archivo {RUTA_DATOS}\")\n",
    "        print(\"   Por favor, verifica que el archivo existe y la ruta es correcta.\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå ERROR INESPERADO: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f818263",
   "metadata": {},
   "source": [
    "# Preguntas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "648b4035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "‚ñà                                                                              ‚ñà\n",
      "‚ñà               AN√ÅLISIS DE PREGUNTAS DE PROFUNDIZACI√ìN                       ‚ñà\n",
      "‚ñà                                                                              ‚ñà\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS DE PREGUNTAS DE PROFUNDIZACI√ìN\n",
      "================================================================================\n",
      "\n",
      "‚úì Datos cargados: 2328 filas, 17 columnas\n",
      "‚úì Modelos a analizar: 9\n",
      "‚úì Directorio de salida: resultados_preguntas_profundizacion\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨\n",
      "\n",
      "1Ô∏è‚É£  Pregunta 1: Punto de quiebre de AREPD...\n",
      "--- An√°lisis de Punto de Quiebre para AREPD ---\n",
      "   ‚úì Punto de quiebre AREPD (Normal): Varianza ‚âà 0.350\n",
      "   ‚úì Punto de quiebre AREPD (Uniform): Varianza ‚âà 0.750\n",
      "   ‚úì Punto de quiebre AREPD (Exponential): Varianza ‚âà 0.350\n",
      "   ‚úì Punto de quiebre AREPD (T-student): Varianza ‚âà 0.750\n",
      "   ‚úì Punto de quiebre AREPD (Mixture): Varianza ‚âà 0.350\n",
      "   ‚úì 2 figuras generadas\n",
      "\n",
      "\n",
      "2Ô∏è‚É£  Pregunta 2: Zona de dominio Block Bootstrapping...\n",
      "   ‚úì BB domina en: 1446 / 2328 casos (62.1%)\n",
      "   ‚úì 2 figuras generadas\n",
      "\n",
      "\n",
      "3Ô∏è‚É£  Pregunta 3: Deterioro de AV-MCPS por horizonte...\n",
      "   ‚úì Tipo de deterioro predominante: Cuadr√°tico\n",
      "   ‚úì 2 figuras generadas\n",
      "\n",
      "\n",
      "4Ô∏è‚É£  Pregunta 4: Efecto multiplicativo distribuci√≥n Normal...\n",
      "   ‚úì Modelos con efecto multiplicativo: ['MCPS']\n",
      "   ‚úì 2 figuras generadas\n",
      "\n",
      "\n",
      "5Ô∏è‚É£  Pregunta 5: Frontera de colapso Deep Learning...\n",
      "   ‚úì Escenarios cr√≠ticos identificados: 1\n",
      "   ‚úì 2 figuras generadas\n",
      "\n",
      "\n",
      "6Ô∏è‚É£  Pregunta 6: Validaci√≥n de 'Mejor Modelo'...\n",
      "   ‚úì Tasa de coincidencia global: 83.8%\n",
      "   ‚úì Distribuci√≥n con mayor consistencia: exponential (85.7%)\n",
      "   ‚úì 2 figuras generadas\n",
      "\n",
      "\n",
      "7Ô∏è‚É£  Pregunta 7: Aceleraci√≥n del deterioro...\n",
      "   ‚úì Modelos con deterioro acelerado: 1\n",
      "   ‚úì Modelos con deterioro desacelerado: 8\n",
      "   ‚úì 2 figuras generadas\n",
      "\n",
      "\n",
      "8Ô∏è‚É£  Pregunta 8: Colapso LSPM con varianza alta...\n",
      "   ‚úì Cambio de ranking LSPM: +0.0 posiciones\n",
      "   ‚úì Cambio de ranking LSPMW: +0.0 posiciones\n",
      "   ‚úì LSPM/LSPMW mantienen ventaja incluso con alta varianza\n",
      "   ‚úì 2 figuras generadas\n",
      "\n",
      "\n",
      "9Ô∏è‚É£  Pregunta 9: Mapa de decisi√≥n operacional...\n",
      "   ‚úì Modelo m√°s robusto: Block Bootstrapping\n",
      "   ‚úì Reglas de alta confianza (>70%): 3\n",
      "   ‚úì Archivo CSV generado: reglas_decision.csv\n",
      "   ‚úì 3 figuras generadas\n",
      "\n",
      "\n",
      "================================================================================\n",
      "‚úÖ AN√ÅLISIS DE PREGUNTAS COMPLETO\n",
      "üìÅ Resultados guardados en: resultados_preguntas_profundizacion\n",
      "================================================================================\n",
      "\n",
      "\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "‚ñà                                                                              ‚ñà\n",
      "‚ñà                    ‚úÖ AN√ÅLISIS COMPLETADO EXITOSAMENTE                       ‚ñà\n",
      "‚ñà                                                                              ‚ñà\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "üìä RESUMEN DE FIGURAS GENERADAS POR PREGUNTA:\n",
      "\n",
      "   Pregunta 1 (Punto de quiebre AREPD): 2 figuras\n",
      "   Pregunta 2 (Zona de dominio BB): 2 figuras\n",
      "   Pregunta 3 (Deterioro AV-MCPS): 2 figuras\n",
      "   Pregunta 4 (Penalizaci√≥n Normal): 2 figuras\n",
      "   Pregunta 5 (Frontera DL): 2 figuras\n",
      "   Pregunta 6 (Consistencia Mejor Modelo): 2 figuras\n",
      "   Pregunta 7 (Segunda derivada): 2 figuras\n",
      "   Pregunta 8 (Interacci√≥n No-Lineal √ó Varianza): 2 figuras\n",
      "   Pregunta 9 (Mapa de decisi√≥n): 3 figuras\n",
      "\n",
      "   üìÅ TOTAL: 19 figuras PNG + 1 archivo CSV (reglas_decision.csv)\n",
      "\n",
      "üìÅ ESTRUCTURA DE RESULTADOS:\n",
      "   ./resultados_preguntas_profundizacion/\n",
      "   ‚îú‚îÄ‚îÄ P1_1: Punto de quiebre AREPD - Comparativo\n",
      "   ‚îú‚îÄ‚îÄ P1_2: Tasa de deterioro AREPD\n",
      "   ‚îú‚îÄ‚îÄ P2_1: Zona de dominio BB - Heatmap\n",
      "   ‚îú‚îÄ‚îÄ P2_2: Frecuencia de dominio BB\n",
      "   ‚îú‚îÄ‚îÄ P3_1: Deterioro AV-MCPS - Curvas\n",
      "   ‚îú‚îÄ‚îÄ P3_2: Tipo de deterioro AV-MCPS\n",
      "   ‚îú‚îÄ‚îÄ P4_1: Penalizaci√≥n Normal - Interacci√≥n\n",
      "   ‚îú‚îÄ‚îÄ P4_2: Clasificaci√≥n de interacci√≥n\n",
      "   ‚îú‚îÄ‚îÄ P5_1: Frontera de colapso DL\n",
      "   ‚îú‚îÄ‚îÄ P5_2: Brecha DL por escenario\n",
      "   ‚îú‚îÄ‚îÄ P6_1: Consistencia Mejor Modelo - Global\n",
      "   ‚îú‚îÄ‚îÄ P6_2: Consistencia por condiciones\n",
      "   ‚îú‚îÄ‚îÄ P7_1: Segunda derivada - Aceleraci√≥n\n",
      "   ‚îú‚îÄ‚îÄ P7_2: Comparaci√≥n de derivadas\n",
      "   ‚îú‚îÄ‚îÄ P8_1: Interacci√≥n No-Lineal √ó Varianza - Ranking\n",
      "   ‚îú‚îÄ‚îÄ P8_2: Cambio de ranking LSPM\n",
      "   ‚îú‚îÄ‚îÄ P9_1: Mapa de decisi√≥n operacional\n",
      "   ‚îú‚îÄ‚îÄ P9_2: Confiabilidad de reglas\n",
      "   ‚îú‚îÄ‚îÄ P9_3: √Årbol de decisi√≥n textual\n",
      "   ‚îî‚îÄ‚îÄ reglas_decision.csv\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from itertools import combinations\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuraci√≥n de estilo\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURACI√ìN GLOBAL\n",
    "# ============================================================================\n",
    "\n",
    "RUTA_DATOS = \"./Datos/datos_combinados.xlsx\"\n",
    "DIR_SALIDA = \"./resultados_preguntas_profundizacion\"\n",
    "\n",
    "MODELOS = ['AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR',\n",
    "           'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
    "\n",
    "COLORES_MODELOS = {\n",
    "    'AREPD': '#e41a1c',\n",
    "    'AV-MCPS': '#377eb8',\n",
    "    'Block Bootstrapping': '#4daf4a',\n",
    "    'DeepAR': '#984ea3',\n",
    "    'EnCQR-LSTM': '#ff7f00',\n",
    "    'LSPM': '#ffff33',\n",
    "    'LSPMW': '#a65628',\n",
    "    'MCPS': '#f781bf',\n",
    "    'Sieve Bootstrap': '#999999'\n",
    "}\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CLASE PRINCIPAL DE AN√ÅLISIS - PREGUNTAS DE PROFUNDIZACI√ìN\n",
    "# ============================================================================\n",
    "\n",
    "class AnalizadorPreguntasProfundizacion:\n",
    "    \"\"\"An√°lisis espec√≠fico para responder preguntas de profundizaci√≥n\"\"\"\n",
    "\n",
    "    def __init__(self, ruta_datos):\n",
    "        \"\"\"Inicializa el analizador\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"AN√ÅLISIS DE PREGUNTAS DE PROFUNDIZACI√ìN\")\n",
    "        print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "        self.df = pd.read_excel(ruta_datos)\n",
    "        self.modelos = MODELOS\n",
    "        self.COLORES_MODELOS = COLORES_MODELOS\n",
    "        self.dir_salida = Path(DIR_SALIDA)\n",
    "        self.dir_salida.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Extraer caracter√≠sticas del escenario\n",
    "        self._extraer_caracteristicas()\n",
    "\n",
    "        print(f\"‚úì Datos cargados: {self.df.shape[0]} filas, {self.df.shape[1]} columnas\")\n",
    "        print(f\"‚úì Modelos a analizar: {len(self.modelos)}\")\n",
    "        print(f\"‚úì Directorio de salida: {self.dir_salida}\")\n",
    "        print(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
    "\n",
    "    def _extraer_caracteristicas(self):\n",
    "        \"\"\"Extrae caracter√≠sticas individuales del escenario\"\"\"\n",
    "        self.df['Estacionario'] = self.df['Escenario'].apply(\n",
    "            lambda x: 'Estacionario' if 'Estacionario' in x and 'No_Estacionario' not in x else 'No Estacionario'\n",
    "        )\n",
    "\n",
    "        self.df['Lineal'] = self.df['Escenario'].apply(\n",
    "            lambda x: 'Lineal' if 'Lineal' in x and 'No_Lineal' not in x else 'No Lineal'\n",
    "        )\n",
    "\n",
    "    def ejecutar_analisis_completo(self):\n",
    "        \"\"\"Ejecuta todos los an√°lisis para las preguntas\"\"\"\n",
    "        print(\"\\n\" + \"üî¨\" * 40 + \"\\n\")\n",
    "\n",
    "        # Pregunta 1: Punto de quiebre de AREPD\n",
    "        print(\"1Ô∏è‚É£  Pregunta 1: Punto de quiebre de AREPD...\")\n",
    "        self._pregunta_1_punto_quiebre_arepd()\n",
    "\n",
    "        # Pregunta 2: Robustez de Block Bootstrapping vs Sieve Bootstrap\n",
    "        print(\"\\n2Ô∏è‚É£  Pregunta 2: Zona de dominio Block Bootstrapping...\")\n",
    "        self._pregunta_2_zona_dominio_bb()\n",
    "\n",
    "        # Pregunta 3: Deterioro acelerado AV-MCPS\n",
    "        print(\"\\n3Ô∏è‚É£  Pregunta 3: Deterioro de AV-MCPS por horizonte...\")\n",
    "        self._pregunta_3_deterioro_av_mcps()\n",
    "\n",
    "        # Pregunta 4: Penalizaci√≥n Normal multiplicativa\n",
    "        print(\"\\n4Ô∏è‚É£  Pregunta 4: Efecto multiplicativo distribuci√≥n Normal...\")\n",
    "        self._pregunta_4_penalizacion_normal()\n",
    "\n",
    "        # Pregunta 5: Frontera de colapso Deep Learning\n",
    "        print(\"\\n5Ô∏è‚É£  Pregunta 5: Frontera de colapso Deep Learning...\")\n",
    "        self._pregunta_5_frontera_dl()\n",
    "\n",
    "        # Pregunta 6: Consistencia \"Mejor Modelo\"\n",
    "        print(\"\\n6Ô∏è‚É£  Pregunta 6: Validaci√≥n de 'Mejor Modelo'...\")\n",
    "        self._pregunta_6_consistencia_mejor_modelo()\n",
    "\n",
    "        # Pregunta 7: An√°lisis de segunda derivada\n",
    "        print(\"\\n7Ô∏è‚É£  Pregunta 7: Aceleraci√≥n del deterioro...\")\n",
    "        self._pregunta_7_segunda_derivada()\n",
    "\n",
    "        # Pregunta 8: Interacci√≥n No Linealidad √ó Varianza\n",
    "        print(\"\\n8Ô∏è‚É£  Pregunta 8: Colapso LSPM con varianza alta...\")\n",
    "        self._pregunta_8_interaccion_nolineal_varianza()\n",
    "\n",
    "        # Pregunta 9: Mapa de decisi√≥n operacional\n",
    "        print(\"\\n9Ô∏è‚É£  Pregunta 9: Mapa de decisi√≥n operacional...\")\n",
    "        self._pregunta_9_mapa_decision()\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"‚úÖ AN√ÅLISIS DE PREGUNTAS COMPLETO\")\n",
    "        print(f\"üìÅ Resultados guardados en: {self.dir_salida}\")\n",
    "        print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # PREGUNTA 1: PUNTO DE QUIEBRE DE AREPD\n",
    "    # ========================================================================\n",
    "\n",
    "    def _pregunta_1_punto_quiebre_arepd(self):\n",
    "        \"\"\"\n",
    "        ¬øExiste un punto de quiebre en la varianza del error donde AREPD se deteriora?\n",
    "        ¬øEste punto es consistente entre todas las distribuciones presentes?\n",
    "        \"\"\"\n",
    "        \n",
    "        # --- MODIFICACI√ìN: Detectar todas las distribuciones √∫nicas autom√°ticamente ---\n",
    "        distribuciones = self.df['Distribuci√≥n'].unique()\n",
    "        varianzas = sorted(self.df['Varianza error'].unique())\n",
    "        \n",
    "        # Diccionario para almacenar los resultados de cada distribuci√≥n\n",
    "        resultados_por_dist = {dist: {'arepd': [], 'otros_robustos': []} for dist in distribuciones}\n",
    "        \n",
    "        # Modelos robustos para comparaci√≥n\n",
    "        otros_modelos = ['Block Bootstrapping', 'Sieve Bootstrap', 'LSPM']\n",
    "        \n",
    "        # Calcular el rendimiento promedio para cada distribuci√≥n y varianza\n",
    "        for dist in distribuciones:\n",
    "            df_dist = self.df[self.df['Distribuci√≥n'] == dist]\n",
    "            for var in varianzas:\n",
    "                df_var = df_dist[df_dist['Varianza error'] == var]\n",
    "                \n",
    "                # Rendimiento de AREPD\n",
    "                resultados_por_dist[dist]['arepd'].append(df_var['AREPD'].mean())\n",
    "                \n",
    "                # Rendimiento promedio de otros modelos robustos\n",
    "                resultados_por_dist[dist]['otros_robustos'].append(df_var[otros_modelos].mean().mean())\n",
    "\n",
    "        # --- MODIFICACI√ìN: Gr√°fico din√°mico para N distribuciones ---\n",
    "        # FIGURA 1.1: Evoluci√≥n de AREPD vs modelos robustos por distribuci√≥n\n",
    "        n_dist = len(distribuciones)\n",
    "        n_cols = 2\n",
    "        n_rows = math.ceil(n_dist / n_cols)\n",
    "        \n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(8 * n_cols, 6 * n_rows), squeeze=False)\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        for idx, dist in enumerate(distribuciones):\n",
    "            ax = axes[idx]\n",
    "            arepd_perf = resultados_por_dist[dist]['arepd']\n",
    "            otros_perf = resultados_por_dist[dist]['otros_robustos']\n",
    "            \n",
    "            ax.plot(varianzas, arepd_perf, 'o-', label='AREPD', \n",
    "                    color=self.COLORES_MODELOS.get('AREPD', 'blue'), linewidth=3, markersize=8)\n",
    "            ax.plot(varianzas, otros_perf, 's--', label='Promedio Modelos Robustos',\n",
    "                    color='green', linewidth=2, markersize=7, alpha=0.7)\n",
    "            \n",
    "            ax.set_xlabel('Varianza del Error', fontweight='bold', fontsize=12)\n",
    "            ax.set_ylabel('ECRPS Promedio', fontweight='bold', fontsize=12)\n",
    "            ax.set_title(f'Distribuci√≥n {dist.capitalize()}: Punto de Quiebre AREPD', \n",
    "                         fontweight='bold', fontsize=13)\n",
    "            ax.legend(fontsize=11)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Ocultar ejes no utilizados si el n√∫mero de distribuciones es impar\n",
    "        for idx in range(n_dist, len(axes)):\n",
    "            axes[idx].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / 'P1_1_punto_quiebre_arepd_comparativo.png',\n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # --- MODIFICACI√ìN: Gr√°fico de comparaci√≥n de tasas con N distribuciones ---\n",
    "        # FIGURA 1.2: Tasa de deterioro incremental\n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        \n",
    "        # Usar un ciclo de colores de Matplotlib para distinguir las l√≠neas\n",
    "        colors = plt.cm.viridis(np.linspace(0, 1, n_dist))\n",
    "        var_medias = [(varianzas[i] + varianzas[i+1]) / 2 for i in range(len(varianzas) - 1)]\n",
    "        \n",
    "        puntos_quiebre = {}\n",
    "\n",
    "        for idx, dist in enumerate(distribuciones):\n",
    "            arepd_perf = resultados_por_dist[dist]['arepd']\n",
    "            \n",
    "            # Calcular tasas de cambio (derivada num√©rica)\n",
    "            if len(varianzas) > 1 and np.diff(varianzas).any():\n",
    "                tasas = np.diff(arepd_perf) / np.diff(varianzas)\n",
    "            else:\n",
    "                tasas = []\n",
    "\n",
    "            if len(tasas) > 0:\n",
    "                ax.plot(var_medias, tasas, 'o-', label=f'{dist.capitalize()}', \n",
    "                       color=colors[idx], linewidth=2.5, markersize=8)\n",
    "                \n",
    "                # Identificar y almacenar el punto de m√°xima aceleraci√≥n del deterioro\n",
    "                max_accel_idx = np.argmax(tasas)\n",
    "                puntos_quiebre[dist] = var_medias[max_accel_idx]\n",
    "            else:\n",
    "                puntos_quiebre[dist] = None\n",
    "\n",
    "\n",
    "        ax.axhline(y=0, color='black', linestyle='--', linewidth=1.5, alpha=0.5)\n",
    "        ax.set_xlabel('Varianza del Error (punto medio)', fontweight='bold', fontsize=12)\n",
    "        ax.set_ylabel('Tasa de Deterioro (ŒîECRPS/ŒîVarianza)', fontweight='bold', fontsize=12)\n",
    "        ax.set_title('AREPD: Aceleraci√≥n del Deterioro por Distribuci√≥n\\n(Mayor pendiente = Colapso m√°s r√°pido)',\n",
    "                    fontweight='bold', fontsize=14, pad=20)\n",
    "        ax.legend(fontsize=12, loc='upper left', title='Distribuciones')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / 'P1_2_tasa_deterioro_arepd.png',\n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # --- MODIFICACI√ìN: Imprimir resultados para todas las distribuciones ---\n",
    "        print(\"--- An√°lisis de Punto de Quiebre para AREPD ---\")\n",
    "        for dist, umbral in puntos_quiebre.items():\n",
    "            if umbral is not None:\n",
    "                print(f\"   ‚úì Punto de quiebre AREPD ({dist.capitalize()}): Varianza ‚âà {umbral:.3f}\")\n",
    "            else:\n",
    "                print(f\"   ! No se pudo calcular el punto de quiebre para {dist.capitalize()}.\")\n",
    "        \n",
    "        print(\"   ‚úì 2 figuras generadas\\n\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # PREGUNTA 2: ZONA DE DOMINIO BLOCK BOOTSTRAPPING\n",
    "    # ========================================================================\n",
    "\n",
    "    def _pregunta_2_zona_dominio_bb(self):\n",
    "        \"\"\"\n",
    "        ¬øEn qu√© condiciones EXACTAS Block Bootstrapping supera a Sieve Bootstrap?\n",
    "        \"\"\"\n",
    "        \n",
    "        # Crear DataFrame de comparaci√≥n directa\n",
    "        df_comp = self.df.copy()\n",
    "        df_comp['BB_mejor'] = df_comp['Block Bootstrapping'] < df_comp['Sieve Bootstrap']\n",
    "        df_comp['Diferencia'] = df_comp['Sieve Bootstrap'] - df_comp['Block Bootstrapping']\n",
    "        \n",
    "        # FIGURA 2.1: Mapa de calor de superioridad\n",
    "        # >>> INICIO DE MODIFICACI√ìN 1 <<<\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(24, 7))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        escenarios_principales = [\n",
    "            ('Estacionario', 'Lineal'),\n",
    "            ('Estacionario', 'No Lineal'),\n",
    "            ('No Estacionario', 'Lineal')\n",
    "        ]\n",
    "        # >>> FIN DE MODIFICACI√ìN 1 <<<\n",
    "        \n",
    "        for idx, (est, lin) in enumerate(escenarios_principales):\n",
    "            ax = axes[idx]\n",
    "            df_esc = df_comp[(df_comp['Estacionario'] == est) & (df_comp['Lineal'] == lin)]\n",
    "            \n",
    "            # Crear matriz de diferencias\n",
    "            pivot = df_esc.pivot_table(\n",
    "                values='Diferencia',\n",
    "                index='Distribuci√≥n',\n",
    "                columns='Varianza error',\n",
    "                aggfunc='mean'\n",
    "            )\n",
    "            \n",
    "            sns.heatmap(pivot, annot=True, fmt='.4f', cmap='RdYlGn', center=0,\n",
    "                       ax=ax, cbar_kws={'label': 'SB - BB (>0 = BB mejor)'},\n",
    "                       linewidths=1, linecolor='gray', vmin=-0.02, vmax=0.02)\n",
    "            ax.set_title(f'{est} + {lin}', fontweight='bold', fontsize=12)\n",
    "            ax.set_xlabel('Varianza Error', fontweight='bold')\n",
    "            ax.set_ylabel('Distribuci√≥n', fontweight='bold')\n",
    "        \n",
    "        plt.suptitle('Zona de Dominio: Block Bootstrapping vs Sieve Bootstrap\\n(Verde = BB domina, Rojo = SB domina)',\n",
    "                    fontweight='bold', fontsize=16, y=1.03)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / 'P2_1_zona_dominio_bb_heatmap.png',\n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # FIGURA 2.2: Frecuencia de dominio por condiciones\n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        \n",
    "        # Calcular % de casos donde BB es mejor\n",
    "        resultados_dominio = []\n",
    "        # >>> INICIO DE MODIFICACI√ìN 1 (cont.) <<<\n",
    "        # Se usan los mismos 3 escenarios definidos para la figura 2.1\n",
    "        for est, lin in escenarios_principales:\n",
    "            df_esc = df_comp[(df_comp['Estacionario'] == est) & (df_comp['Lineal'] == lin)]\n",
    "            pct_bb_mejor = (df_esc['BB_mejor'].sum() / len(df_esc) * 100) if len(df_esc) > 0 else 0\n",
    "            resultados_dominio.append({\n",
    "                'Escenario': f'{est[:3]}+{lin[:3]}',\n",
    "                'Completo': f'{est} + {lin}',\n",
    "                'Pct_BB_Mejor': pct_bb_mejor\n",
    "            })\n",
    "        # >>> FIN DE MODIFICACI√ìN 1 (cont.) <<<\n",
    "        \n",
    "        df_dominio = pd.DataFrame(resultados_dominio).sort_values('Pct_BB_Mejor', ascending=False)\n",
    "        \n",
    "        colors = ['green' if x > 50 else 'red' for x in df_dominio['Pct_BB_Mejor']]\n",
    "        bars = ax.barh(df_dominio['Escenario'], df_dominio['Pct_BB_Mejor'],\n",
    "                      color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "        ax.axvline(50, color='black', linestyle='--', linewidth=2, label='50% (Equilibrio)')\n",
    "        ax.set_xlabel('% de casos donde BB supera a SB', fontweight='bold', fontsize=12)\n",
    "        ax.set_title('Frecuencia de Dominio de Block Bootstrapping\\n(>50% = BB generalmente mejor)',\n",
    "                    fontweight='bold', fontsize=14, pad=20)\n",
    "        ax.legend(fontsize=11)\n",
    "        ax.grid(True, alpha=0.3, axis='x')\n",
    "        ax.set_xlim(0, 100)\n",
    "        \n",
    "        for i, (bar, val) in enumerate(zip(bars, df_dominio['Pct_BB_Mejor'])):\n",
    "            ax.text(val + 2, i, f'{val:.1f}%', va='center', fontweight='bold', fontsize=11)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / 'P2_2_frecuencia_dominio_bb.png',\n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"   ‚úì BB domina en: {df_comp['BB_mejor'].sum()} / {len(df_comp)} casos ({df_comp['BB_mejor'].sum()/len(df_comp)*100:.1f}%)\")\n",
    "        print(\"   ‚úì 2 figuras generadas\\n\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # PREGUNTA 3: DETERIORO AV-MCPS POR HORIZONTE\n",
    "    # ========================================================================\n",
    "\n",
    "    def _pregunta_3_deterioro_av_mcps(self):\n",
    "        \"\"\"\n",
    "        ¬øEl deterioro de AV-MCPS es lineal, cuadr√°tico o exponencial?\n",
    "        ¬øCambia seg√∫n el nivel de varianza?\n",
    "        \"\"\"\n",
    "        \n",
    "        pasos = sorted(self.df['Paso'].unique())\n",
    "        varianzas = sorted(self.df['Varianza error'].unique())\n",
    "        \n",
    "        # FIGURA 3.1: Ajuste de curvas de deterioro\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        # Seleccionar niveles de varianza representativos\n",
    "        if len(varianzas) >= 4:\n",
    "            var_seleccionadas = [varianzas[0], varianzas[len(varianzas)//3], \n",
    "                                varianzas[2*len(varianzas)//3], varianzas[-1]]\n",
    "        else:\n",
    "            var_seleccionadas = varianzas\n",
    "        \n",
    "        modelos_comparacion = ['AV-MCPS', 'LSPM', 'Block Bootstrapping']\n",
    "        \n",
    "        for idx, var in enumerate(var_seleccionadas[:4]):\n",
    "            ax = axes[idx]\n",
    "            df_var = self.df[self.df['Varianza error'] == var]\n",
    "            \n",
    "            for modelo in modelos_comparacion:\n",
    "                valores = [df_var[df_var['Paso'] == p][modelo].mean() for p in pasos]\n",
    "                ax.plot(pasos, valores, 'o-', label=modelo, \n",
    "                       linewidth=2.5, markersize=8, color=COLORES_MODELOS[modelo])\n",
    "            \n",
    "            ax.set_xlabel('Horizonte (Paso)', fontweight='bold', fontsize=11)\n",
    "            ax.set_ylabel('ECRPS', fontweight='bold', fontsize=11)\n",
    "            ax.set_title(f'Varianza = {var:.3f}', fontweight='bold', fontsize=12)\n",
    "            ax.legend(fontsize=10)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.suptitle('Evoluci√≥n del Deterioro por Horizonte: AV-MCPS vs Modelos Estables',\n",
    "                    fontweight='bold', fontsize=14, y=0.995)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / 'P3_1_deterioro_av_mcps_curvas.png',\n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # FIGURA 3.2: An√°lisis de tipo de crecimiento\n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        \n",
    "        # Calcular R¬≤ para diferentes tipos de ajuste\n",
    "        tipos_ajuste = []\n",
    "        \n",
    "        for var in varianzas:\n",
    "            df_var = self.df[self.df['Varianza error'] == var]\n",
    "            valores_av = [df_var[df_var['Paso'] == p]['AV-MCPS'].mean() for p in pasos]\n",
    "            \n",
    "            x = np.array(pasos)\n",
    "            y = np.array(valores_av)\n",
    "            \n",
    "            # Ajuste lineal\n",
    "            p_lin = np.polyfit(x, y, 1)\n",
    "            y_lin = np.polyval(p_lin, x)\n",
    "            r2_lin = 1 - (np.sum((y - y_lin)**2) / np.sum((y - np.mean(y))**2))\n",
    "            \n",
    "            # Ajuste cuadr√°tico\n",
    "            p_quad = np.polyfit(x, y, 2)\n",
    "            y_quad = np.polyval(p_quad, x)\n",
    "            r2_quad = 1 - (np.sum((y - y_quad)**2) / np.sum((y - np.mean(y))**2))\n",
    "            \n",
    "            # Ajuste exponencial (logar√≠tmico)\n",
    "            try:\n",
    "                z = np.polyfit(x, np.log(y + 1e-10), 1)\n",
    "                y_exp = np.exp(np.polyval(z, x))\n",
    "                r2_exp = 1 - (np.sum((y - y_exp)**2) / np.sum((y - np.mean(y))**2))\n",
    "            except:\n",
    "                r2_exp = 0\n",
    "            \n",
    "            mejor_ajuste = max([('Lineal', r2_lin), ('Cuadr√°tico', r2_quad), ('Exponencial', r2_exp)], \n",
    "                              key=lambda x: x[1])\n",
    "            \n",
    "            tipos_ajuste.append({\n",
    "                'Varianza': var,\n",
    "                'R2_Lineal': r2_lin,\n",
    "                'R2_Cuadratico': r2_quad,\n",
    "                'R2_Exponencial': r2_exp,\n",
    "                'Mejor': mejor_ajuste[0]\n",
    "            })\n",
    "        \n",
    "        df_ajustes = pd.DataFrame(tipos_ajuste)\n",
    "        \n",
    "        x_pos = np.arange(len(varianzas))\n",
    "        width = 0.25\n",
    "        \n",
    "        ax.bar(x_pos - width, df_ajustes['R2_Lineal'], width, label='Lineal', alpha=0.8)\n",
    "        ax.bar(x_pos, df_ajustes['R2_Cuadratico'], width, label='Cuadr√°tico', alpha=0.8)\n",
    "        ax.bar(x_pos + width, df_ajustes['R2_Exponencial'], width, label='Exponencial', alpha=0.8)\n",
    "        \n",
    "        ax.set_xlabel('Varianza del Error', fontweight='bold', fontsize=12)\n",
    "        ax.set_ylabel('R¬≤ (Bondad de Ajuste)', fontweight='bold', fontsize=12)\n",
    "        ax.set_title('AV-MCPS: Tipo de Deterioro por Nivel de Varianza\\n(R¬≤ m√°s alto = Mejor ajuste)',\n",
    "                    fontweight='bold', fontsize=14, pad=20)\n",
    "        ax.set_xticks(x_pos)\n",
    "        ax.set_xticklabels([f'{v:.3f}' for v in varianzas], rotation=45)\n",
    "        ax.legend(fontsize=11)\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        ax.set_ylim(0, 1.1)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / 'P3_2_tipo_deterioro_av_mcps.png',\n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"   ‚úì Tipo de deterioro predominante: {df_ajustes['Mejor'].mode()[0]}\")\n",
    "        print(\"   ‚úì 2 figuras generadas\\n\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # PREGUNTA 4: PENALIZACI√ìN NORMAL MULTIPLICATIVA\n",
    "    # ========================================================================\n",
    "    def _pregunta_4_penalizacion_normal(self):\n",
    "        \"\"\"\n",
    "        ¬øLa penalizaci√≥n de la distribuci√≥n Normal es aditiva o multiplicativa \n",
    "        con la no-estacionariedad?\n",
    "        \"\"\"\n",
    "        \n",
    "        # --- CORRECCI√ìN: Se definen los nombres reales de los escenarios del Excel ---\n",
    "        # Se usan estos nombres para filtrar el DataFrame correctamente.\n",
    "        escenario_estacionario = 'Estacionario_Lineal'\n",
    "        escenario_no_estacionario = 'No_Estacionario_Lineal'\n",
    "        \n",
    "        # Modelos a analizar\n",
    "        modelos_analisis = ['DeepAR', 'MCPS', 'LSPM', 'Block Bootstrapping']\n",
    "        \n",
    "        # FIGURA 4.1: Efecto aditivo vs multiplicativo\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        resultados_interaccion = []\n",
    "        \n",
    "        for idx, modelo in enumerate(modelos_analisis):\n",
    "            ax = axes[idx]\n",
    "            \n",
    "            # Calcular penalizaci√≥n por escenario\n",
    "            penalizaciones = []\n",
    "            \n",
    "            # --- CORRECCI√ìN: Se itera sobre los escenarios correctos y se usan etiquetas limpias para los gr√°ficos ---\n",
    "            escenarios_a_comparar = {\n",
    "                'Estacionario': escenario_estacionario,\n",
    "                'No Estacionario': escenario_no_estacionario\n",
    "            }\n",
    "            \n",
    "            for etiqueta, nombre_escenario in escenarios_a_comparar.items():\n",
    "                \n",
    "                # --- CORRECCI√ìN: Filtrar por la columna 'Escenario' con los nombres correctos ---\n",
    "                df_escenario = self.df[self.df['Escenario'] == nombre_escenario]\n",
    "                \n",
    "                # --- CORRECCI√ìN: Usar 'normal' y 'mixture' en min√∫sculas ---\n",
    "                rend_normal = df_escenario[df_escenario['Distribuci√≥n'] == 'normal'][modelo].mean()\n",
    "                rend_mixture = df_escenario[df_escenario['Distribuci√≥n'] == 'mixture'][modelo].mean()\n",
    "                \n",
    "                # Calcular el deterioro porcentual. Se a√±ade una guarda contra la divisi√≥n por cero.\n",
    "                if rend_mixture != 0:\n",
    "                    deterioro = ((rend_normal - rend_mixture) / rend_mixture) * 100\n",
    "                else:\n",
    "                    deterioro = 0.0 # O float('inf') si se prefiere, pero 0 es m√°s seguro para graficar\n",
    "                \n",
    "                penalizaciones.append({\n",
    "                    'Estacionariedad': etiqueta, # Usar la etiqueta limpia para el gr√°fico\n",
    "                    'Deterioro_pct': deterioro\n",
    "                })\n",
    "            \n",
    "            df_pen = pd.DataFrame(penalizaciones)\n",
    "            \n",
    "            # Calcular raz√≥n de efectos\n",
    "            det_estacionario = df_pen[df_pen['Estacionariedad'] == 'Estacionario']['Deterioro_pct'].values[0]\n",
    "            det_no_estacionario = df_pen[df_pen['Estacionariedad'] == 'No Estacionario']['Deterioro_pct'].values[0]\n",
    "            \n",
    "            # Evitar divisi√≥n por cero si el deterioro en el caso estacionario fue nulo\n",
    "            razon = det_no_estacionario / det_estacionario if det_estacionario != 0 else 0\n",
    "            es_multiplicativo = razon > 1.5  # Si el efecto es >50% mayor, se considera multiplicativo\n",
    "            \n",
    "            resultados_interaccion.append({\n",
    "                'Modelo': modelo,\n",
    "                'Razon': razon,\n",
    "                'Tipo': 'Multiplicativo' if es_multiplicativo else 'Aditivo'\n",
    "            })\n",
    "            \n",
    "            # Visualizaci√≥n\n",
    "            colors = ['lightblue', 'coral']\n",
    "            bars = ax.bar(df_pen['Estacionariedad'], df_pen['Deterioro_pct'], \n",
    "                         color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "            ax.set_ylabel('Deterioro por Dist. Normal (%)', fontweight='bold', fontsize=11)\n",
    "            ax.set_title(f'{modelo}\\nRaz√≥n: {razon:.2f}x ({(\"MULTIPLICATIVO\" if es_multiplicativo else \"ADITIVO\")})',\n",
    "                        fontweight='bold', fontsize=12)\n",
    "            ax.grid(True, alpha=0.3, axis='y')\n",
    "            ax.axhline(0, color='black', linestyle='-', linewidth=1)\n",
    "            \n",
    "            for bar, val in zip(bars, df_pen['Deterioro_pct']):\n",
    "                height = bar.get_height()\n",
    "                ax.text(bar.get_x() + bar.get_width() / 2., height + 1,\n",
    "                       f'{val:.1f}%', ha='center', va='bottom', fontweight='bold', fontsize=10)\n",
    "        \n",
    "        plt.suptitle('Interacci√≥n: Distribuci√≥n Normal √ó No-Estacionariedad\\n(Raz√≥n > 1.5 = Efecto Multiplicativo)',\n",
    "                    fontweight='bold', fontsize=14, y=0.995)\n",
    "        \n",
    "        # >>> INICIO DE MODIFICACI√ìN 2 <<<\n",
    "        # Se a√±ade m√°s padding para evitar que los elementos se superpongan\n",
    "        plt.tight_layout(pad=3.0)\n",
    "        # >>> FIN DE MODIFICACI√ìN 2 <<<\n",
    "        \n",
    "        plt.savefig(self.dir_salida / 'P4_1_penalizacion_normal_interaccion.png',\n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # FIGURA 4.2: Resumen de tipos de interacci√≥n\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        \n",
    "        df_interaccion = pd.DataFrame(resultados_interaccion).sort_values('Razon', ascending=False)\n",
    "        \n",
    "        colors_tipo = ['red' if x == 'Multiplicativo' else 'green' for x in df_interaccion['Tipo']]\n",
    "        bars = ax.barh(df_interaccion['Modelo'], df_interaccion['Razon'],\n",
    "                      color=colors_tipo, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "        ax.axvline(1.5, color='black', linestyle='--', linewidth=2, label='Umbral Multiplicativo (1.5x)')\n",
    "        ax.axvline(1.0, color='gray', linestyle=':', linewidth=1.5, alpha=0.5)\n",
    "        ax.set_xlabel('Raz√≥n de Efectos (No-Est / Est)', fontweight='bold', fontsize=12)\n",
    "        ax.set_title('Clasificaci√≥n del Tipo de Interacci√≥n por Modelo\\n(Rojo = Multiplicativo, Verde = Aditivo)',\n",
    "                    fontweight='bold', fontsize=14, pad=20)\n",
    "        ax.legend(fontsize=11)\n",
    "        ax.grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        for i, (bar, val, tipo) in enumerate(zip(bars, df_interaccion['Razon'], df_interaccion['Tipo'])):\n",
    "            ax.text(val + 0.05, i, f'{val:.2f}x ({tipo})', \n",
    "                   va='center', fontweight='bold', fontsize=10)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / 'P4_2_clasificacion_interaccion.png',\n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        modelos_multiplicativos = df_interaccion[df_interaccion['Tipo'] == 'Multiplicativo']['Modelo'].tolist()\n",
    "        print(f\"   ‚úì Modelos con efecto multiplicativo: {modelos_multiplicativos}\")\n",
    "        print(\"   ‚úì 2 figuras generadas\\n\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # PREGUNTA 5: FRONTERA DE COLAPSO DEEP LEARNING\n",
    "    # ========================================================================\n",
    "\n",
    "    def _pregunta_5_frontera_dl(self):\n",
    "        \"\"\"\n",
    "        ¬øExiste una 'frontera de colapso' para DeepAR y EnCQR-LSTM donde su \n",
    "        rendimiento cae por debajo de m√©todos estad√≠sticos simples?\n",
    "        \"\"\"\n",
    "        \n",
    "        modelos_dl = ['DeepAR', 'EnCQR-LSTM']\n",
    "        modelos_estadisticos = ['Block Bootstrapping', 'Sieve Bootstrap', 'LSPM']\n",
    "        \n",
    "        varianzas = sorted(self.df['Varianza error'].unique())\n",
    "        \n",
    "        # FIGURA 5.1: Evoluci√≥n comparativa con varianza\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "        \n",
    "        for idx, modelo_dl in enumerate(modelos_dl):\n",
    "            ax = axes[idx]\n",
    "            \n",
    "            # Calcular promedios por varianza\n",
    "            dl_vals = [self.df[self.df['Varianza error'] == v][modelo_dl].mean() for v in varianzas]\n",
    "            \n",
    "            # Promedio de modelos estad√≠sticos\n",
    "            est_vals = []\n",
    "            for v in varianzas:\n",
    "                df_v = self.df[self.df['Varianza error'] == v]\n",
    "                est_vals.append(df_v[modelos_estadisticos].mean().mean())\n",
    "            \n",
    "            # Plotear\n",
    "            ax.plot(varianzas, dl_vals, 'o-', label=f'{modelo_dl} (DL)',\n",
    "                   color=COLORES_MODELOS[modelo_dl], linewidth=3, markersize=10)\n",
    "            ax.plot(varianzas, est_vals, 's--', label='Promedio Estad√≠sticos',\n",
    "                   color='green', linewidth=2.5, markersize=8, alpha=0.7)\n",
    "            \n",
    "            # Identificar punto de cruce\n",
    "            diferencias = np.array(dl_vals) - np.array(est_vals)\n",
    "            if np.any(diferencias > 0):\n",
    "                idx_cruce_candidatos = np.where(diferencias > 0)[0]\n",
    "                if len(idx_cruce_candidatos) > 0:\n",
    "                    idx_cruce = idx_cruce_candidatos[0]\n",
    "                    var_cruce = varianzas[idx_cruce]\n",
    "                    ax.axvline(var_cruce, color='red', linestyle=':', linewidth=2, alpha=0.7)\n",
    "                    ax.annotate(f'Frontera de colapso\\nVarianza ‚âà {var_cruce:.3f}',\n",
    "                               xy=(var_cruce, dl_vals[idx_cruce]),\n",
    "                               xytext=(20, -30), textcoords='offset points',\n",
    "                               bbox=dict(boxstyle='round,pad=0.5', facecolor='yellow', alpha=0.8),\n",
    "                               arrowprops=dict(arrowstyle='->', color='red', lw=2),\n",
    "                               fontsize=10, fontweight='bold')\n",
    "            \n",
    "            ax.set_xlabel('Varianza del Error', fontweight='bold', fontsize=12)\n",
    "            ax.set_ylabel('ECRPS Promedio', fontweight='bold', fontsize=12)\n",
    "            ax.set_title(f'Frontera de Colapso: {modelo_dl}',\n",
    "                        fontweight='bold', fontsize=13)\n",
    "            ax.legend(fontsize=11)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.suptitle('Identificaci√≥n de Frontera donde Deep Learning < M√©todos Estad√≠sticos',\n",
    "                    fontweight='bold', fontsize=14, y=0.995)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / 'P5_1_frontera_colapso_dl.png',\n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # FIGURA 5.2: Brecha de rendimiento por escenario\n",
    "        # >>> INICIO DE MODIFICACI√ìN 3 <<<\n",
    "        fig, ax = plt.subplots(figsize=(16, 9)) # Ajustar tama√±o para mejor visualizaci√≥n\n",
    "        \n",
    "        escenarios_unicos = self.df['Escenario'].unique()\n",
    "        \n",
    "        brechas = []\n",
    "        for esc in escenarios_unicos:\n",
    "            df_esc = self.df[self.df['Escenario'] == esc]\n",
    "            \n",
    "            for modelo_dl in modelos_dl:\n",
    "                dl_mean = df_esc[modelo_dl].mean()\n",
    "                est_mean = df_esc[modelos_estadisticos].mean().mean()\n",
    "                \n",
    "                brecha_pct = ((dl_mean - est_mean) / est_mean) * 100\n",
    "                \n",
    "                brechas.append({\n",
    "                    'Escenario': esc.replace(\"_\", \" \"), # Nombres m√°s legibles\n",
    "                    'Modelo_DL': modelo_dl,\n",
    "                    'Brecha_pct': brecha_pct\n",
    "                })\n",
    "        \n",
    "        df_brechas = pd.DataFrame(brechas)\n",
    "        \n",
    "        # Pivot para visualizaci√≥n\n",
    "        pivot_brechas = df_brechas.pivot(index='Escenario', columns='Modelo_DL', values='Brecha_pct')\n",
    "        pivot_brechas = pivot_brechas.sort_values(by='DeepAR', ascending=False)\n",
    "        \n",
    "        x = np.arange(len(pivot_brechas))\n",
    "        width = 0.35\n",
    "        \n",
    "        # Se cambia barh por bar para un gr√°fico vertical\n",
    "        ax.bar(x - width/2, pivot_brechas['DeepAR'], width, \n",
    "               label='DeepAR', color=COLORES_MODELOS['DeepAR'], alpha=0.8, edgecolor='black')\n",
    "        ax.bar(x + width/2, pivot_brechas['EnCQR-LSTM'], width,\n",
    "               label='EnCQR-LSTM', color=COLORES_MODELOS['EnCQR-LSTM'], alpha=0.8, edgecolor='black')\n",
    "        \n",
    "        # Se cambia axvline por axhline\n",
    "        ax.axhline(0, color='black', linestyle='-', linewidth=2)\n",
    "        ax.axhline(50, color='red', linestyle='--', linewidth=2, alpha=0.5, label='Umbral Cr√≠tico (+50%)')\n",
    "        \n",
    "        # Se configuran los ejes para el gr√°fico vertical\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(pivot_brechas.index, rotation=45, ha='right', fontsize=9)\n",
    "        ax.set_ylabel('Brecha vs M√©todos Estad√≠sticos (%)', fontweight='bold', fontsize=12)\n",
    "        ax.set_xlabel('Escenario', fontweight='bold', fontsize=12)\n",
    "        ax.set_title('Escenarios donde Deep Learning Colapsa\\n(>0% = DL peor que Estad√≠sticos)',\n",
    "                    fontweight='bold', fontsize=14, pad=20)\n",
    "        ax.legend(fontsize=11, loc='upper right')\n",
    "        ax.grid(True, alpha=0.3, axis='y') # Grid en el eje Y\n",
    "        # >>> FIN DE MODIFICACI√ìN 3 <<<\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / 'P5_2_brecha_dl_por_escenario.png',\n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"   ‚úì Escenarios cr√≠ticos identificados: {len(pivot_brechas[pivot_brechas['DeepAR'] > 50])}\")\n",
    "        print(\"   ‚úì 2 figuras generadas\\n\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # PREGUNTA 6: CONSISTENCIA \"MEJOR MODELO\"\n",
    "    # ========================================================================\n",
    "\n",
    "    def _pregunta_6_consistencia_mejor_modelo(self):\n",
    "        \"\"\"\n",
    "        ¬øCon qu√© frecuencia el modelo marcado como 'Mejor Modelo' coincide con el \n",
    "        que REALMENTE tiene el menor error num√©rico?\n",
    "        \"\"\"\n",
    "        \n",
    "        # Verificar si existe la columna \"Mejor Modelo\"\n",
    "        if 'Mejor Modelo' not in self.df.columns:\n",
    "            print(\"   ‚ö†Ô∏è  Columna 'Mejor Modelo' no encontrada. Saltando an√°lisis.\\n\")\n",
    "            return\n",
    "        \n",
    "        # Identificar el modelo con menor error en cada fila\n",
    "        self.df['Modelo_Min_Real'] = self.df[self.modelos].idxmin(axis=1)\n",
    "        self.df['Coincide'] = self.df['Mejor Modelo'] == self.df['Modelo_Min_Real']\n",
    "        \n",
    "        # FIGURA 6.1: Tasa de coincidencia global\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        tasa_coincidencia = self.df['Coincide'].mean() * 100\n",
    "        \n",
    "        labels = ['Coincide', 'No Coincide']\n",
    "        sizes = [tasa_coincidencia, 100 - tasa_coincidencia]\n",
    "        colors = ['#4CAF50', '#F44336']\n",
    "        explode = (0.1, 0)\n",
    "        \n",
    "        ax.pie(sizes, explode=explode, labels=labels, colors=colors,\n",
    "               autopct='%1.1f%%', shadow=True, startangle=90,\n",
    "               textprops={'fontsize': 14, 'fontweight': 'bold'})\n",
    "        ax.set_title('Consistencia de \"Mejor Modelo\" con Menor Error Real\\n',\n",
    "                    fontweight='bold', fontsize=14, pad=20)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / 'P6_1_consistencia_mejor_modelo_global.png',\n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # FIGURA 6.2: Coincidencia por escenario y distribuci√≥n\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "        \n",
    "        # Por Escenario\n",
    "        ax1 = axes[0]\n",
    "        coincidencia_esc = self.df.groupby('Escenario')['Coincide'].mean() * 100\n",
    "        coincidencia_esc = coincidencia_esc.sort_values(ascending=True)\n",
    "        \n",
    "        colors_esc = ['green' if x > 70 else 'orange' if x > 50 else 'red' \n",
    "                      for x in coincidencia_esc.values]\n",
    "        bars1 = ax1.barh(range(len(coincidencia_esc)), coincidencia_esc.values,\n",
    "                        color=colors_esc, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "        ax1.set_yticks(range(len(coincidencia_esc)))\n",
    "        ax1.set_yticklabels([x[:30] + '...' if len(x) > 30 else x for x in coincidencia_esc.index], \n",
    "                           fontsize=8)\n",
    "        ax1.set_xlabel('% de Coincidencia', fontweight='bold', fontsize=11)\n",
    "        ax1.set_title('Consistencia por Escenario', fontweight='bold', fontsize=12)\n",
    "        ax1.axvline(70, color='green', linestyle='--', linewidth=1.5, alpha=0.5, label='Umbral Bueno (70%)')\n",
    "        ax1.axvline(50, color='orange', linestyle='--', linewidth=1.5, alpha=0.5, label='Umbral Aceptable (50%)')\n",
    "        ax1.legend(fontsize=9)\n",
    "        ax1.grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        # Por Distribuci√≥n\n",
    "        ax2 = axes[1]\n",
    "        coincidencia_dist = self.df.groupby('Distribuci√≥n')['Coincide'].mean() * 100\n",
    "        coincidencia_dist = coincidencia_dist.sort_values(ascending=False)\n",
    "        \n",
    "        colors_dist = ['green' if x > 70 else 'orange' if x > 50 else 'red' \n",
    "                       for x in coincidencia_dist.values]\n",
    "        bars2 = ax2.bar(range(len(coincidencia_dist)), coincidencia_dist.values,\n",
    "                       color=colors_dist, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "        ax2.set_xticks(range(len(coincidencia_dist)))\n",
    "        ax2.set_xticklabels(coincidencia_dist.index, rotation=45, ha='right')\n",
    "        ax2.set_ylabel('% de Coincidencia', fontweight='bold', fontsize=11)\n",
    "        ax2.set_title('Consistencia por Distribuci√≥n', fontweight='bold', fontsize=12)\n",
    "        ax2.axhline(70, color='green', linestyle='--', linewidth=1.5, alpha=0.5)\n",
    "        ax2.axhline(50, color='orange', linestyle='--', linewidth=1.5, alpha=0.5)\n",
    "        ax2.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        for bar, val in zip(bars2, coincidencia_dist.values):\n",
    "            height = bar.get_height()\n",
    "            ax2.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                    f'{val:.1f}%', ha='center', va='bottom', fontweight='bold', fontsize=10)\n",
    "        \n",
    "        plt.suptitle('An√°lisis de Consistencia de \"Mejor Modelo\" por Condiciones',\n",
    "                    fontweight='bold', fontsize=14, y=0.995)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / 'P6_2_consistencia_por_condiciones.png',\n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"   ‚úì Tasa de coincidencia global: {tasa_coincidencia:.1f}%\")\n",
    "        print(f\"   ‚úì Distribuci√≥n con mayor consistencia: {coincidencia_dist.idxmax()} ({coincidencia_dist.max():.1f}%)\")\n",
    "        print(\"   ‚úì 2 figuras generadas\\n\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # PREGUNTA 7: AN√ÅLISIS DE SEGUNDA DERIVADA\n",
    "    # ========================================================================\n",
    "\n",
    "    def _pregunta_7_segunda_derivada(self):\n",
    "        \"\"\"\n",
    "        ¬øQu√© modelos muestran 'deterioro acelerado' (segunda derivada positiva) \n",
    "        vs 'deterioro constante' al aumentar Pasos?\n",
    "        \"\"\"\n",
    "        \n",
    "        pasos = sorted(self.df['Paso'].unique())\n",
    "        \n",
    "        if len(pasos) < 3:\n",
    "            print(\"   ‚ö†Ô∏è  Insuficientes pasos para an√°lisis de segunda derivada. Saltando.\\n\")\n",
    "            return\n",
    "        \n",
    "        # FIGURA 7.1: Aceleraci√≥n del deterioro\n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        \n",
    "        aceleraciones = []\n",
    "        \n",
    "        for modelo in self.modelos:\n",
    "            valores = [self.df[self.df['Paso'] == p][modelo].mean() for p in pasos]\n",
    "            \n",
    "            # Primera derivada (velocidad de cambio)\n",
    "            primera_deriv = np.diff(valores)\n",
    "            \n",
    "            # Segunda derivada (aceleraci√≥n)\n",
    "            if len(primera_deriv) > 1:\n",
    "                segunda_deriv = np.diff(primera_deriv)\n",
    "                aceleracion_media = np.mean(segunda_deriv)\n",
    "                \n",
    "                # Clasificaci√≥n\n",
    "                if aceleracion_media > 0.001:\n",
    "                    tipo = 'Acelerado'\n",
    "                elif aceleracion_media < -0.001:\n",
    "                    tipo = 'Desacelerado'\n",
    "                else:\n",
    "                    tipo = 'Constante'\n",
    "                \n",
    "                aceleraciones.append({\n",
    "                    'Modelo': modelo,\n",
    "                    'Aceleracion': aceleracion_media,\n",
    "                    'Tipo': tipo\n",
    "                })\n",
    "        \n",
    "        df_aceleraciones = pd.DataFrame(aceleraciones).sort_values('Aceleracion', ascending=False)\n",
    "        \n",
    "        # Colores seg√∫n tipo\n",
    "        color_map = {'Acelerado': 'red', 'Constante': 'orange', 'Desacelerado': 'green'}\n",
    "        colors = [color_map[t] for t in df_aceleraciones['Tipo']]\n",
    "        \n",
    "        bars = ax.barh(df_aceleraciones['Modelo'], df_aceleraciones['Aceleracion'],\n",
    "                      color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "        ax.axvline(0, color='black', linestyle='-', linewidth=2)\n",
    "        ax.set_xlabel('Aceleraci√≥n del Deterioro (Segunda Derivada)', fontweight='bold', fontsize=12)\n",
    "        ax.set_title('Clasificaci√≥n de Modelos por Aceleraci√≥n del Deterioro\\n(Rojo=Acelerado, Verde=Desacelerado, Naranja=Constante)',\n",
    "                    fontweight='bold', fontsize=14, pad=20)\n",
    "        ax.grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        for i, (bar, val, tipo) in enumerate(zip(bars, df_aceleraciones['Aceleracion'], \n",
    "                                                  df_aceleraciones['Tipo'])):\n",
    "            ax.text(val + (0.0001 if val > 0 else -0.0001), i, f'{val:.4f} ({tipo})',\n",
    "                   va='center', ha='left' if val > 0 else 'right',\n",
    "                   fontweight='bold', fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / 'P7_1_segunda_derivada_aceleracion.png',\n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # FIGURA 7.2: Comparaci√≥n de primeras y segundas derivadas\n",
    "        fig, axes = plt.subplots(2, 1, figsize=(14, 12))\n",
    "        \n",
    "        # >>> INICIO DE MODIFICACI√ìN 4 <<<\n",
    "        # Mapear cada modelo a su tipo de aceleraci√≥n para el estilo de l√≠nea\n",
    "        modelo_a_tipo = df_aceleraciones.set_index('Modelo')['Tipo'].to_dict()\n",
    "        tipo_a_estilo = {'Acelerado': '-', 'Desacelerado': '--', 'Constante': ':'}\n",
    "\n",
    "        # Primera derivada\n",
    "        ax1 = axes[0]\n",
    "        for modelo in self.modelos:\n",
    "            valores = [self.df[self.df['Paso'] == p][modelo].mean() for p in pasos]\n",
    "            primera_deriv = np.diff(valores)\n",
    "            pasos_deriv = pasos[1:]\n",
    "            \n",
    "            tipo_modelo = modelo_a_tipo.get(modelo, 'Constante')\n",
    "            linestyle = tipo_a_estilo[tipo_modelo]\n",
    "            \n",
    "            ax1.plot(pasos_deriv, primera_deriv, 'o-', label=modelo,\n",
    "                    linewidth=2.5, markersize=8, color=COLORES_MODELOS[modelo],\n",
    "                    linestyle=linestyle)\n",
    "        \n",
    "        ax1.axhline(0, color='black', linestyle=':', linewidth=1.5, alpha=0.5)\n",
    "        ax1.set_xlabel('Paso', fontweight='bold', fontsize=11)\n",
    "        ax1.set_ylabel('Primera Derivada (Velocidad)', fontweight='bold', fontsize=11)\n",
    "        ax1.set_title('Velocidad de Deterioro por Paso\\n(Acelerado:‚Äî, Desacelerado:--, Constante:..)',\n",
    "                     fontweight='bold', fontsize=12)\n",
    "        ax1.legend(fontsize=9, ncol=3) # Aumentar columnas para que quepan todos\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Segunda derivada\n",
    "        ax2 = axes[1]\n",
    "        for modelo in self.modelos:\n",
    "            valores = [self.df[self.df['Paso'] == p][modelo].mean() for p in pasos]\n",
    "            primera_deriv = np.diff(valores)\n",
    "            \n",
    "            if len(primera_deriv) > 1:\n",
    "                segunda_deriv = np.diff(primera_deriv)\n",
    "                pasos_deriv2 = pasos[2:]\n",
    "                \n",
    "                tipo_modelo = modelo_a_tipo.get(modelo, 'Constante')\n",
    "                linestyle = tipo_a_estilo[tipo_modelo]\n",
    "                \n",
    "                ax2.plot(pasos_deriv2, segunda_deriv, 's-', label=modelo,\n",
    "                        linewidth=2.5, markersize=8, color=COLORES_MODELOS[modelo],\n",
    "                        linestyle=linestyle)\n",
    "        \n",
    "        ax2.axhline(0, color='black', linestyle=':', linewidth=1.5, alpha=0.5)\n",
    "        ax2.set_xlabel('Paso', fontweight='bold', fontsize=11)\n",
    "        ax2.set_ylabel('Segunda Derivada (Aceleraci√≥n)', fontweight='bold', fontsize=11)\n",
    "        ax2.set_title('Aceleraci√≥n del Deterioro por Paso\\n(Valores positivos = Deterioro acelerado)',\n",
    "                     fontweight='bold', fontsize=12)\n",
    "        ax2.legend(fontsize=9, ncol=3) # Aumentar columnas\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        # >>> FIN DE MODIFICACI√ìN 4 <<<\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / 'P7_2_comparacion_derivadas.png',\n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        modelos_vulnerables = df_aceleraciones[df_aceleraciones['Tipo'] == 'Acelerado']['Modelo'].tolist()\n",
    "        modelos_robustos = df_aceleraciones[df_aceleraciones['Tipo'] == 'Desacelerado']['Modelo'].tolist()\n",
    "        print(f\"   ‚úì Modelos con deterioro acelerado: {len(modelos_vulnerables)}\")\n",
    "        print(f\"   ‚úì Modelos con deterioro desacelerado: {len(modelos_robustos)}\")\n",
    "        print(\"   ‚úì 2 figuras generadas\\n\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # PREGUNTA 8: INTERACCI√ìN NO LINEALIDAD √ó VARIANZA\n",
    "    # ========================================================================\n",
    "\n",
    "    def _pregunta_8_interaccion_nolineal_varianza(self):\n",
    "        \"\"\"\n",
    "        ¬øLa ventaja de LSPM/LSPMW en escenarios no lineales DESAPARECE cuando \n",
    "        la varianza del error supera cierto umbral?\n",
    "        \"\"\"\n",
    "        \n",
    "        # Filtrar escenarios no lineales\n",
    "        df_nolineal = self.df[self.df['Lineal'] == 'No Lineal'].copy()\n",
    "        \n",
    "        if df_nolineal.empty:\n",
    "            print(\"   ‚ö†Ô∏è  No hay datos para escenarios no lineales. Saltando an√°lisis.\\n\")\n",
    "            return\n",
    "            \n",
    "        varianzas = sorted(df_nolineal['Varianza error'].unique())\n",
    "        \n",
    "        # >>> INICIO DE MODIFICACI√ìN 5 <<<\n",
    "        # Se redefine el c√°lculo para hacer una comparaci√≥n m√°s clara entre los extremos\n",
    "        # Se usa el primer cuartil (Q1) para \"Varianza Baja\" y el tercer cuartil (Q3) para \"Varianza Alta\"\n",
    "        if len(varianzas) > 3:\n",
    "            q1, q3 = np.percentile(varianzas, [25, 75])\n",
    "            df_baja = df_nolineal[df_nolineal['Varianza error'] <= q1]\n",
    "            df_alta = df_nolineal[df_nolineal['Varianza error'] >= q3]\n",
    "        else: # Fallback para pocos datos\n",
    "            q2 = np.percentile(varianzas, 50)\n",
    "            df_baja = df_nolineal[df_nolineal['Varianza error'] <= q2]\n",
    "            df_alta = df_nolineal[df_nolineal['Varianza error'] >= q2]\n",
    "\n",
    "        grupos_dfs = {'Varianza Baja': df_baja, 'Varianza Alta': df_alta}\n",
    "        # >>> FIN DE MODIFICACI√ìN 5 <<<\n",
    "\n",
    "        # FIGURA 8.1: Ranking por grupo de varianza\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "        \n",
    "        for idx, (grupo, df_grupo) in enumerate(grupos_dfs.items()):\n",
    "            ax = axes[idx]\n",
    "            \n",
    "            if df_grupo.empty:\n",
    "                ax.text(0.5, 0.5, 'Sin datos', ha='center', va='center', fontsize=12)\n",
    "                ax.set_title(f'Ranking en Escenarios No Lineales\\n{grupo}', fontweight='bold', fontsize=12)\n",
    "                continue\n",
    "\n",
    "            # Calcular medias y ranking\n",
    "            medias = df_grupo[self.modelos].mean().sort_values()\n",
    "            \n",
    "            colors = ['gold' if m in ['LSPM', 'LSPMW'] else 'steelblue' for m in medias.index]\n",
    "            bars = ax.barh(range(len(medias)), medias.values, color=colors,\n",
    "                          alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "            \n",
    "            ax.set_yticks(range(len(medias)))\n",
    "            ax.set_yticklabels(medias.index, fontsize=10)\n",
    "            ax.set_xlabel('ECRPS Promedio', fontweight='bold', fontsize=11)\n",
    "            ax.set_title(f'Ranking en Escenarios No Lineales\\n{grupo}',\n",
    "                        fontweight='bold', fontsize=12)\n",
    "            ax.grid(True, alpha=0.3, axis='x')\n",
    "            \n",
    "            # Destacar posici√≥n de LSPM/LSPMW\n",
    "            pos_lspm = list(medias.index).index('LSPM') + 1\n",
    "            pos_lspmw = list(medias.index).index('LSPMW') + 1\n",
    "            \n",
    "            ax.text(0.02, 0.98, f'LSPM: Rank {pos_lspm}\\nLSPMW: Rank {pos_lspmw}',\n",
    "                   transform=ax.transAxes, fontsize=11, fontweight='bold',\n",
    "                   va='top', bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n",
    "        \n",
    "        plt.suptitle('¬øLSPM/LSPMW Pierden Ventaja con Alta Varianza?',\n",
    "                    fontweight='bold', fontsize=14, y=0.995)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / 'P8_1_interaccion_nolineal_varianza_ranking.png',\n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # FIGURA 8.2: Cambio de posici√≥n en ranking\n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        \n",
    "        cambios_ranking = []\n",
    "        \n",
    "        # >>> INICIO DE MODIFICACI√ìN 5 (cont.) <<<\n",
    "        # Se usan los dataframes df_baja y df_alta definidos previamente\n",
    "        for modelo in self.modelos:\n",
    "            if df_baja.empty or df_alta.empty: continue\n",
    "            \n",
    "            ranking_baja = df_baja[self.modelos].mean().rank().loc[modelo]\n",
    "            ranking_alta = df_alta[self.modelos].mean().rank().loc[modelo]\n",
    "            \n",
    "            cambio = ranking_alta - ranking_baja  # Positivo = empeor√≥ posici√≥n\n",
    "            \n",
    "            cambios_ranking.append({\n",
    "                'Modelo': modelo,\n",
    "                'Cambio': cambio,\n",
    "                'Empeora': cambio > 0\n",
    "            })\n",
    "        # >>> FIN DE MODIFICACI√ìN 5 (cont.) <<<\n",
    "\n",
    "        if not cambios_ranking:\n",
    "            print(\"   ‚ö†Ô∏è  No se pudo generar el gr√°fico de cambio de ranking.\\n\")\n",
    "            return\n",
    "\n",
    "        df_cambios = pd.DataFrame(cambios_ranking).sort_values('Cambio', ascending=True)\n",
    "        \n",
    "        colors_cambio = ['red' if x > 2 else 'orange' if x > 0 else 'green' \n",
    "                        for x in df_cambios['Cambio']]\n",
    "        bars = ax.barh(df_cambios['Modelo'], df_cambios['Cambio'],\n",
    "                      color=colors_cambio, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "        ax.axvline(0, color='black', linestyle='-', linewidth=2)\n",
    "        ax.axvline(3, color='red', linestyle='--', linewidth=1.5, alpha=0.5, \n",
    "                  label='Cambio Cr√≠tico (>3 posiciones)')\n",
    "        ax.set_xlabel('Cambio en Ranking (Varianza Alta - Varianza Baja)', fontweight='bold', fontsize=12)\n",
    "        ax.set_title('Deterioro de Posici√≥n con Alta Varianza en Escenarios No Lineales\\n(Positivo = Pierde posiciones, Negativo = Gana posiciones)',\n",
    "                    fontweight='bold', fontsize=14, pad=20)\n",
    "        ax.legend(fontsize=11)\n",
    "        ax.grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        for i, (bar, val, modelo) in enumerate(zip(bars, df_cambios['Cambio'], df_cambios['Modelo'])):\n",
    "            label_text = f'{val:+.1f}'\n",
    "            if modelo in ['LSPM', 'LSPMW']:\n",
    "                label_text += ' ‚≠ê'\n",
    "            ax.text(val + (0.1 if val > 0 else -0.1), i, label_text,\n",
    "                   va='center', ha='left' if val > 0 else 'right',\n",
    "                   fontweight='bold', fontsize=10)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / 'P8_2_cambio_ranking_lspm.png',\n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # An√°lisis espec√≠fico de LSPM/LSPMW\n",
    "        cambio_lspm = df_cambios[df_cambios['Modelo'] == 'LSPM']['Cambio'].values[0]\n",
    "        cambio_lspmw = df_cambios[df_cambios['Modelo'] == 'LSPMW']['Cambio'].values[0]\n",
    "        \n",
    "        print(f\"   ‚úì Cambio de ranking LSPM: {cambio_lspm:+.1f} posiciones\")\n",
    "        print(f\"   ‚úì Cambio de ranking LSPMW: {cambio_lspmw:+.1f} posiciones\")\n",
    "        \n",
    "        if cambio_lspm > 3 or cambio_lspmw > 3:\n",
    "            print(\"   ‚ö†Ô∏è  ADVERTENCIA: LSPM/LSPMW pierden >3 posiciones con alta varianza\")\n",
    "        else:\n",
    "            print(\"   ‚úì LSPM/LSPMW mantienen ventaja incluso con alta varianza\")\n",
    "        \n",
    "        print(\"   ‚úì 2 figuras generadas\\n\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # PREGUNTA 9: MAPA DE DECISI√ìN OPERACIONAL\n",
    "    # ========================================================================\n",
    "\n",
    "    def _pregunta_9_mapa_decision(self):\n",
    "        \"\"\"\n",
    "        ¬øPodemos construir una 'regla de decisi√≥n' simple para elegir modelo \n",
    "        basada en 3 variables: Estacionariedad, Distribuci√≥n y Varianza?\n",
    "        \"\"\"\n",
    "        \n",
    "        # Crear categor√≠as de varianza\n",
    "        varianzas = sorted(self.df['Varianza error'].unique())\n",
    "        q33, q67 = np.percentile(varianzas, [33, 67])\n",
    "        \n",
    "        self.df['Nivel_Varianza'] = pd.cut(\n",
    "            self.df['Varianza error'],\n",
    "            bins=[-np.inf, q33, q67, np.inf],\n",
    "            labels=['Baja', 'Media', 'Alta']\n",
    "        )\n",
    "        \n",
    "        # FIGURA 9.1: √Årbol de decisi√≥n visual (heatmap 3D colapsado)\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        \n",
    "        niveles_var = ['Baja', 'Media', 'Alta']\n",
    "        estacionariedades = ['Estacionario', 'No Estacionario']\n",
    "        \n",
    "        for idx_est, est in enumerate(estacionariedades):\n",
    "            for idx_var,niv_var in enumerate(niveles_var):\n",
    "                ax = axes[idx_est, idx_var]\n",
    "                \n",
    "                # Filtrar datos\n",
    "                df_filtrado = self.df[\n",
    "                    (self.df['Estacionario'] == est) & \n",
    "                    (self.df['Nivel_Varianza'] == niv_var)\n",
    "                ]\n",
    "                \n",
    "                if len(df_filtrado) == 0:\n",
    "                    ax.text(0.5, 0.5, 'Sin datos', ha='center', va='center',\n",
    "                           transform=ax.transAxes, fontsize=12)\n",
    "                    ax.set_title(f'{est} + Varianza {niv_var}', fontweight='bold', fontsize=11)\n",
    "                    continue\n",
    "                \n",
    "                # Calcular mejor modelo por distribuci√≥n\n",
    "                mejores_por_dist = {}\n",
    "                for dist in df_filtrado['Distribuci√≥n'].unique():\n",
    "                    df_dist = df_filtrado[df_filtrado['Distribuci√≥n'] == dist]\n",
    "                    medias = df_dist[self.modelos].mean()\n",
    "                    mejor = medias.idxmin()\n",
    "                    mejores_por_dist[dist] = mejor\n",
    "                \n",
    "                # Crear matriz para heatmap\n",
    "                distribuciones = sorted(df_filtrado['Distribuci√≥n'].unique())\n",
    "                matriz_decision = pd.DataFrame(index=distribuciones, columns=['Mejor Modelo'])\n",
    "                \n",
    "                for dist in distribuciones:\n",
    "                    matriz_decision.loc[dist, 'Mejor Modelo'] = mejores_por_dist.get(dist, 'N/A')\n",
    "                \n",
    "                # Asignar colores por modelo\n",
    "                modelo_a_color = {modelo: idx for idx, modelo in enumerate(self.modelos)}\n",
    "                matriz_numerica = matriz_decision['Mejor Modelo'].map(\n",
    "                    lambda x: modelo_a_color.get(x, -1)\n",
    "                ).values.reshape(-1, 1)\n",
    "                \n",
    "                im = ax.imshow(matriz_numerica, cmap='tab10', aspect='auto', vmin=0, vmax=len(self.modelos)-1)\n",
    "                \n",
    "                # Configurar ejes\n",
    "                ax.set_yticks(range(len(distribuciones)))\n",
    "                ax.set_yticklabels(distribuciones, fontsize=9)\n",
    "                ax.set_xticks([])\n",
    "                ax.set_title(f'{est}\\nVarianza {niv_var}', fontweight='bold', fontsize=11)\n",
    "                \n",
    "                # A√±adir texto con nombre del modelo\n",
    "                for i, dist in enumerate(distribuciones):\n",
    "                    modelo = mejores_por_dist.get(dist, 'N/A')\n",
    "                    ax.text(0, i, modelo, ha='center', va='center',\n",
    "                           fontweight='bold', fontsize=9, color='white',\n",
    "                           bbox=dict(boxstyle='round', facecolor='black', alpha=0.6))\n",
    "        \n",
    "        plt.suptitle('Mapa de Decisi√≥n Operacional: Mejor Modelo por Condiciones\\n(Cada celda muestra el modelo √≥ptimo)',\n",
    "                    fontweight='bold', fontsize=14, y=0.995)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / 'P9_1_mapa_decision_operacional.png',\n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # FIGURA 9.2: Reglas de decisi√≥n simplificadas\n",
    "        fig, ax = plt.subplots(figsize=(14, 10))\n",
    "        \n",
    "        # Calcular frecuencia de \"mejor modelo\" en cada combinaci√≥n\n",
    "        reglas = []\n",
    "        \n",
    "        for est in estacionariedades:\n",
    "            for niv_var in niveles_var:\n",
    "                df_comb = self.df[\n",
    "                    (self.df['Estacionario'] == est) & \n",
    "                    (self.df['Nivel_Varianza'] == niv_var)\n",
    "                ]\n",
    "                \n",
    "                if len(df_comb) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Encontrar modelo con menor error promedio\n",
    "                medias = df_comb[self.modelos].mean()\n",
    "                mejor_modelo = medias.idxmin()\n",
    "                mejor_ecrps = medias.min()\n",
    "                \n",
    "                # Calcular % de veces que es el mejor\n",
    "                cuenta_mejor = 0\n",
    "                for idx, row in df_comb.iterrows():\n",
    "                    if row[self.modelos].idxmin() == mejor_modelo:\n",
    "                        cuenta_mejor += 1\n",
    "                \n",
    "                frecuencia = (cuenta_mejor / len(df_comb)) * 100 if len(df_comb) > 0 else 0\n",
    "                \n",
    "                reglas.append({\n",
    "                    'Condicion': f'{est[:3]}+Var_{niv_var}',\n",
    "                    'Completo': f'{est} + Varianza {niv_var}',\n",
    "                    'Mejor_Modelo': mejor_modelo,\n",
    "                    'ECRPS': mejor_ecrps,\n",
    "                    'Frecuencia': frecuencia\n",
    "                })\n",
    "        \n",
    "        df_reglas = pd.DataFrame(reglas).sort_values('Frecuencia', ascending=True)\n",
    "        \n",
    "        # Visualizaci√≥n\n",
    "        y_pos = np.arange(len(df_reglas))\n",
    "        colors_reglas = [COLORES_MODELOS.get(m, 'gray') for m in df_reglas['Mejor_Modelo']]\n",
    "        \n",
    "        bars = ax.barh(y_pos, df_reglas['Frecuencia'], color=colors_reglas,\n",
    "                      alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "        \n",
    "        ax.set_yticks(y_pos)\n",
    "        ax.set_yticklabels(df_reglas['Condicion'], fontsize=10)\n",
    "        ax.set_xlabel('Frecuencia de Optimalidad (%)', fontweight='bold', fontsize=12)\n",
    "        ax.set_title('Confiabilidad de Reglas de Decisi√≥n\\n(% de casos donde el modelo recomendado es √≥ptimo)',\n",
    "                    fontweight='bold', fontsize=14, pad=20)\n",
    "        ax.axvline(70, color='green', linestyle='--', linewidth=2, alpha=0.5, label='Umbral Alta Confianza (70%)')\n",
    "        ax.legend(fontsize=11)\n",
    "        ax.grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        # A√±adir etiquetas con modelo recomendado\n",
    "        for i, (bar, modelo, freq) in enumerate(zip(bars, df_reglas['Mejor_Modelo'], \n",
    "                                                     df_reglas['Frecuencia'])):\n",
    "            ax.text(freq + 2, i, f'{modelo} ({freq:.0f}%)',\n",
    "                   va='center', fontweight='bold', fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / 'P9_2_confiabilidad_reglas.png',\n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # FIGURA 9.3: √Årbol de decisi√≥n textual\n",
    "        fig, ax = plt.subplots(figsize=(14, 10))\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # Generar reglas textuales\n",
    "        texto_reglas = \"√ÅRBOL DE DECISI√ìN OPERACIONAL\\n\" + \"=\"*60 + \"\\n\\n\"\n",
    "        \n",
    "        for idx, row in df_reglas.iterrows():\n",
    "            confianza = \"ALTA\" if row['Frecuencia'] > 70 else \"MEDIA\" if row['Frecuencia'] > 50 else \"BAJA\"\n",
    "            texto_reglas += f\"üìå SI: {row['Completo']}\\n\"\n",
    "            texto_reglas += f\"   ‚Üí USAR: {row['Mejor_Modelo']}\\n\"\n",
    "            texto_reglas += f\"   ‚Üí Confianza: {confianza} ({row['Frecuencia']:.1f}%)\\n\"\n",
    "            texto_reglas += f\"   ‚Üí ECRPS esperado: {row['ECRPS']:.4f}\\n\\n\"\n",
    "        \n",
    "        # A√±adir reglas generales\n",
    "        texto_reglas += \"\\n\" + \"=\"*60 + \"\\n\"\n",
    "        texto_reglas += \"REGLAS GENERALES SIMPLIFICADAS:\\n\\n\"\n",
    "        \n",
    "        # Mejor modelo global\n",
    "        mejor_global = df_reglas.loc[df_reglas['ECRPS'].idxmin(), 'Mejor_Modelo']\n",
    "        texto_reglas += f\"üèÜ Modelo m√°s robusto (recomendaci√≥n por defecto): {mejor_global}\\n\\n\"\n",
    "        \n",
    "        # Modelos por caracter√≠sticas\n",
    "        mejor_no_est = df_reglas[df_reglas['Completo'].str.contains('No Estacionario')].iloc[0]['Mejor_Modelo'] if len(df_reglas[df_reglas['Completo'].str.contains('No Estacionario')]) > 0 else 'N/A'\n",
    "        mejor_alta_var = df_reglas[df_reglas['Completo'].str.contains('Alta')].iloc[0]['Mejor_Modelo'] if len(df_reglas[df_reglas['Completo'].str.contains('Alta')]) > 0 else 'N/A'\n",
    "        \n",
    "        texto_reglas += f\"üî¥ Para datos NO estacionarios: {mejor_no_est}\\n\"\n",
    "        texto_reglas += f\"üî¥ Para varianza ALTA: {mejor_alta_var}\\n\"\n",
    "        \n",
    "        ax.text(0.05, 0.95, texto_reglas, transform=ax.transAxes,\n",
    "               fontsize=10, verticalalignment='top', fontfamily='monospace',\n",
    "               bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / 'P9_3_arbol_decision_textual.png',\n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # Guardar reglas en CSV\n",
    "        df_reglas.to_csv(self.dir_salida / 'reglas_decision.csv', index=False)\n",
    "        \n",
    "        print(f\"   ‚úì Modelo m√°s robusto: {mejor_global}\")\n",
    "        print(f\"   ‚úì Reglas de alta confianza (>70%): {len(df_reglas[df_reglas['Frecuencia'] > 70])}\")\n",
    "        print(f\"   ‚úì Archivo CSV generado: reglas_decision.csv\")\n",
    "        print(\"   ‚úì 3 figuras generadas\\n\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# FUNCI√ìN PRINCIPAL\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Funci√≥n principal de ejecuci√≥n\"\"\"\n",
    "    print(\"\\n\" + \"‚ñà\" * 80)\n",
    "    print(\"‚ñà\" + \" \" * 78 + \"‚ñà\")\n",
    "    print(\"‚ñà\" + \" \" * 15 + \"AN√ÅLISIS DE PREGUNTAS DE PROFUNDIZACI√ìN\" + \" \" * 23 + \"‚ñà\")\n",
    "    print(\"‚ñà\" + \" \" * 78 + \"‚ñà\")\n",
    "    print(\"‚ñà\" * 80 + \"\\n\")\n",
    "\n",
    "    try:\n",
    "        # Crear instancia del analizador\n",
    "        analizador = AnalizadorPreguntasProfundizacion(RUTA_DATOS)\n",
    "\n",
    "        # Ejecutar an√°lisis completo\n",
    "        analizador.ejecutar_analisis_completo()\n",
    "\n",
    "        print(\"\\n\" + \"‚ñà\" * 80)\n",
    "        print(\"‚ñà\" + \" \" * 78 + \"‚ñà\")\n",
    "        print(\"‚ñà\" + \" \" * 20 + \"‚úÖ AN√ÅLISIS COMPLETADO EXITOSAMENTE\" + \" \" * 23 + \"‚ñà\")\n",
    "        print(\"‚ñà\" + \" \" * 78 + \"‚ñà\")\n",
    "        print(\"‚ñà\" * 80 + \"\\n\")\n",
    "\n",
    "        print(\"üìä RESUMEN DE FIGURAS GENERADAS POR PREGUNTA:\\n\")\n",
    "        print(\"   Pregunta 1 (Punto de quiebre AREPD): 2 figuras\")\n",
    "        print(\"   Pregunta 2 (Zona de dominio BB): 2 figuras\")\n",
    "        print(\"   Pregunta 3 (Deterioro AV-MCPS): 2 figuras\")\n",
    "        print(\"   Pregunta 4 (Penalizaci√≥n Normal): 2 figuras\")\n",
    "        print(\"   Pregunta 5 (Frontera DL): 2 figuras\")\n",
    "        print(\"   Pregunta 6 (Consistencia Mejor Modelo): 2 figuras\")\n",
    "        print(\"   Pregunta 7 (Segunda derivada): 2 figuras\")\n",
    "        print(\"   Pregunta 8 (Interacci√≥n No-Lineal √ó Varianza): 2 figuras\")\n",
    "        print(\"   Pregunta 9 (Mapa de decisi√≥n): 3 figuras\")\n",
    "        print(\"\\n   üìÅ TOTAL: 19 figuras PNG + 1 archivo CSV (reglas_decision.csv)\")\n",
    "        \n",
    "        print(\"\\nüìÅ ESTRUCTURA DE RESULTADOS:\")\n",
    "        print(f\"   {DIR_SALIDA}/\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ P1_1: Punto de quiebre AREPD - Comparativo\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ P1_2: Tasa de deterioro AREPD\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ P2_1: Zona de dominio BB - Heatmap\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ P2_2: Frecuencia de dominio BB\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ P3_1: Deterioro AV-MCPS - Curvas\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ P3_2: Tipo de deterioro AV-MCPS\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ P4_1: Penalizaci√≥n Normal - Interacci√≥n\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ P4_2: Clasificaci√≥n de interacci√≥n\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ P5_1: Frontera de colapso DL\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ P5_2: Brecha DL por escenario\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ P6_1: Consistencia Mejor Modelo - Global\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ P6_2: Consistencia por condiciones\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ P7_1: Segunda derivada - Aceleraci√≥n\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ P7_2: Comparaci√≥n de derivadas\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ P8_1: Interacci√≥n No-Lineal √ó Varianza - Ranking\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ P8_2: Cambio de ranking LSPM\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ P9_1: Mapa de decisi√≥n operacional\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ P9_2: Confiabilidad de reglas\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ P9_3: √Årbol de decisi√≥n textual\")\n",
    "        print(\"   ‚îî‚îÄ‚îÄ reglas_decision.csv\")\n",
    "        print(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"\\n‚ùå ERROR: No se encontr√≥ el archivo {RUTA_DATOS}\")\n",
    "        print(\"   Por favor, verifica que el archivo existe y la ruta es correcta.\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå ERROR INESPERADO: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670ebc68",
   "metadata": {},
   "source": [
    "# Pre analisis Arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f232cba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paso</th>\n",
       "      <th>Tipo de Modelo</th>\n",
       "      <th>Distribuci√≥n</th>\n",
       "      <th>Varianza error</th>\n",
       "      <th>AREPD</th>\n",
       "      <th>AV-MCPS</th>\n",
       "      <th>Block Bootstrapping</th>\n",
       "      <th>DeepAR</th>\n",
       "      <th>EnCQR-LSTM</th>\n",
       "      <th>LSPM</th>\n",
       "      <th>LSPMW</th>\n",
       "      <th>MCPS</th>\n",
       "      <th>Sieve Bootstrap</th>\n",
       "      <th>Mejor Modelo</th>\n",
       "      <th>Escenario</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ARIMA(0,1,0)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.860823</td>\n",
       "      <td>0.265008</td>\n",
       "      <td>0.253635</td>\n",
       "      <td>0.319481</td>\n",
       "      <td>0.488711</td>\n",
       "      <td>0.367279</td>\n",
       "      <td>0.360494</td>\n",
       "      <td>0.271048</td>\n",
       "      <td>0.273828</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Estacionario_Lineal_SIN_diferenciacion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ARIMA(0,1,0)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.244128</td>\n",
       "      <td>0.473415</td>\n",
       "      <td>0.275061</td>\n",
       "      <td>0.438099</td>\n",
       "      <td>0.322919</td>\n",
       "      <td>0.426187</td>\n",
       "      <td>0.430296</td>\n",
       "      <td>0.348663</td>\n",
       "      <td>0.272952</td>\n",
       "      <td>Sieve Bootstrap</td>\n",
       "      <td>No_Estacionario_Lineal_SIN_diferenciacion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ARIMA(0,1,0)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.799818</td>\n",
       "      <td>0.549386</td>\n",
       "      <td>0.272406</td>\n",
       "      <td>0.291500</td>\n",
       "      <td>0.396481</td>\n",
       "      <td>0.642530</td>\n",
       "      <td>0.639134</td>\n",
       "      <td>0.269410</td>\n",
       "      <td>0.275661</td>\n",
       "      <td>MCPS</td>\n",
       "      <td>No_Estacionario_Lineal_SIN_diferenciacion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ARIMA(0,1,0)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.912421</td>\n",
       "      <td>0.268028</td>\n",
       "      <td>0.255186</td>\n",
       "      <td>0.291577</td>\n",
       "      <td>0.495882</td>\n",
       "      <td>0.341570</td>\n",
       "      <td>0.341227</td>\n",
       "      <td>0.268167</td>\n",
       "      <td>0.275948</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Estacionario_Lineal_SIN_diferenciacion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ARIMA(0,1,0)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.822771</td>\n",
       "      <td>1.363146</td>\n",
       "      <td>0.257461</td>\n",
       "      <td>0.658698</td>\n",
       "      <td>1.291283</td>\n",
       "      <td>0.981902</td>\n",
       "      <td>0.969842</td>\n",
       "      <td>1.442151</td>\n",
       "      <td>0.338116</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Estacionario_Lineal_SIN_diferenciacion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>1</td>\n",
       "      <td>ARIMA(2,1,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.346697</td>\n",
       "      <td>0.986347</td>\n",
       "      <td>0.965096</td>\n",
       "      <td>1.143735</td>\n",
       "      <td>1.447968</td>\n",
       "      <td>1.556813</td>\n",
       "      <td>1.466557</td>\n",
       "      <td>0.961761</td>\n",
       "      <td>0.967362</td>\n",
       "      <td>MCPS</td>\n",
       "      <td>No_Estacionario_Lineal_CON_diferenciacion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>2</td>\n",
       "      <td>ARIMA(2,1,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.101475</td>\n",
       "      <td>1.370626</td>\n",
       "      <td>0.968726</td>\n",
       "      <td>1.008960</td>\n",
       "      <td>1.151123</td>\n",
       "      <td>1.219912</td>\n",
       "      <td>1.390756</td>\n",
       "      <td>1.134109</td>\n",
       "      <td>0.955304</td>\n",
       "      <td>Sieve Bootstrap</td>\n",
       "      <td>No_Estacionario_Lineal_CON_diferenciacion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>3</td>\n",
       "      <td>ARIMA(2,1,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.569159</td>\n",
       "      <td>1.449750</td>\n",
       "      <td>0.989232</td>\n",
       "      <td>1.430293</td>\n",
       "      <td>2.312624</td>\n",
       "      <td>1.765681</td>\n",
       "      <td>1.628852</td>\n",
       "      <td>1.635704</td>\n",
       "      <td>1.035373</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Estacionario_Lineal_CON_diferenciacion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>4</td>\n",
       "      <td>ARIMA(2,1,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.264614</td>\n",
       "      <td>1.419736</td>\n",
       "      <td>0.955854</td>\n",
       "      <td>2.590182</td>\n",
       "      <td>2.788029</td>\n",
       "      <td>1.392147</td>\n",
       "      <td>1.222623</td>\n",
       "      <td>2.114683</td>\n",
       "      <td>0.970941</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Estacionario_Lineal_CON_diferenciacion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>5</td>\n",
       "      <td>ARIMA(2,1,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.655988</td>\n",
       "      <td>1.075822</td>\n",
       "      <td>0.958286</td>\n",
       "      <td>1.469470</td>\n",
       "      <td>2.177742</td>\n",
       "      <td>0.986367</td>\n",
       "      <td>1.116117</td>\n",
       "      <td>1.149773</td>\n",
       "      <td>0.954639</td>\n",
       "      <td>Sieve Bootstrap</td>\n",
       "      <td>No_Estacionario_Lineal_CON_diferenciacion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows √ó 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Paso Tipo de Modelo Distribuci√≥n  Varianza error     AREPD   AV-MCPS  \\\n",
       "0       1   ARIMA(0,1,0)       normal             0.2  1.860823  0.265008   \n",
       "1       2   ARIMA(0,1,0)       normal             0.2  1.244128  0.473415   \n",
       "2       3   ARIMA(0,1,0)       normal             0.2  1.799818  0.549386   \n",
       "3       4   ARIMA(0,1,0)       normal             0.2  1.912421  0.268028   \n",
       "4       5   ARIMA(0,1,0)       normal             0.2  2.822771  1.363146   \n",
       "...   ...            ...          ...             ...       ...       ...   \n",
       "1395    1   ARIMA(2,1,2)      mixture             3.0  1.346697  0.986347   \n",
       "1396    2   ARIMA(2,1,2)      mixture             3.0  1.101475  1.370626   \n",
       "1397    3   ARIMA(2,1,2)      mixture             3.0  1.569159  1.449750   \n",
       "1398    4   ARIMA(2,1,2)      mixture             3.0  2.264614  1.419736   \n",
       "1399    5   ARIMA(2,1,2)      mixture             3.0  1.655988  1.075822   \n",
       "\n",
       "      Block Bootstrapping    DeepAR  EnCQR-LSTM      LSPM     LSPMW      MCPS  \\\n",
       "0                0.253635  0.319481    0.488711  0.367279  0.360494  0.271048   \n",
       "1                0.275061  0.438099    0.322919  0.426187  0.430296  0.348663   \n",
       "2                0.272406  0.291500    0.396481  0.642530  0.639134  0.269410   \n",
       "3                0.255186  0.291577    0.495882  0.341570  0.341227  0.268167   \n",
       "4                0.257461  0.658698    1.291283  0.981902  0.969842  1.442151   \n",
       "...                   ...       ...         ...       ...       ...       ...   \n",
       "1395             0.965096  1.143735    1.447968  1.556813  1.466557  0.961761   \n",
       "1396             0.968726  1.008960    1.151123  1.219912  1.390756  1.134109   \n",
       "1397             0.989232  1.430293    2.312624  1.765681  1.628852  1.635704   \n",
       "1398             0.955854  2.590182    2.788029  1.392147  1.222623  2.114683   \n",
       "1399             0.958286  1.469470    2.177742  0.986367  1.116117  1.149773   \n",
       "\n",
       "      Sieve Bootstrap         Mejor Modelo  \\\n",
       "0            0.273828  Block Bootstrapping   \n",
       "1            0.272952      Sieve Bootstrap   \n",
       "2            0.275661                 MCPS   \n",
       "3            0.275948  Block Bootstrapping   \n",
       "4            0.338116  Block Bootstrapping   \n",
       "...               ...                  ...   \n",
       "1395         0.967362                 MCPS   \n",
       "1396         0.955304      Sieve Bootstrap   \n",
       "1397         1.035373  Block Bootstrapping   \n",
       "1398         0.970941  Block Bootstrapping   \n",
       "1399         0.954639      Sieve Bootstrap   \n",
       "\n",
       "                                      Escenario  \n",
       "0     No_Estacionario_Lineal_SIN_diferenciacion  \n",
       "1     No_Estacionario_Lineal_SIN_diferenciacion  \n",
       "2     No_Estacionario_Lineal_SIN_diferenciacion  \n",
       "3     No_Estacionario_Lineal_SIN_diferenciacion  \n",
       "4     No_Estacionario_Lineal_SIN_diferenciacion  \n",
       "...                                         ...  \n",
       "1395  No_Estacionario_Lineal_CON_diferenciacion  \n",
       "1396  No_Estacionario_Lineal_CON_diferenciacion  \n",
       "1397  No_Estacionario_Lineal_CON_diferenciacion  \n",
       "1398  No_Estacionario_Lineal_CON_diferenciacion  \n",
       "1399  No_Estacionario_Lineal_CON_diferenciacion  \n",
       "\n",
       "[1400 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "¬°Proceso completado! Archivo guardado en: ./Datos/base_diferencias.xlsx\n",
      "Total de filas en el archivo combinado: 1400\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "# 1. Definir el diccionario de mapeo basado en nuestro an√°lisis\n",
    "mapeo_nombres_exacto = {\n",
    "    'SETAR(2,1)': 'SETAR-1',\n",
    "    'SETAR(2,2)': 'SETAR-2',\n",
    "    'SETAR(2,3)': 'SETAR-3',\n",
    "    'TAR(2,1)': 'SETAR-4',\n",
    "    'TAR(2,2)': 'SETAR-5',\n",
    "    'EXPAR(2,1)': 'SETAR Estoc√°stico',\n",
    "    'BILINEAR(1)': 'SETAR con Componente Bilinear'\n",
    "}\n",
    "\n",
    "# 2. Aplicar el reemplazo en la columna \"Tipo de Modelo\"\n",
    "\n",
    "\n",
    "# Cargar los dos archivos Excel\n",
    "sin_diferencias = pd.read_excel(\"./Datos/no_estacionario.xlsx\")\n",
    "sin_diferencias.drop(columns=['Valores de AR', 'Valores MA'], inplace=True)\n",
    "sin_diferencias[\"Escenario\"] = \"No_Estacionario_Lineal_SIN_diferenciacion\"\n",
    "sin_diferencias = sin_diferencias[sin_diferencias[\"Paso\"] != \"Promedio\"]\n",
    "sin_diferencias['Tipo de Modelo'] = sin_diferencias['Tipo de Modelo'].replace(mapeo_nombres_exacto)\n",
    "\n",
    "con_diferencias = pd.read_excel(\"./Datos/resultados_arima_CON_diferenciacion.xlsx\")\n",
    "con_diferencias.drop(columns=['Valores de AR', 'Valores MA'], inplace=True)\n",
    "con_diferencias[\"Escenario\"] = \"No_Estacionario_Lineal_CON_diferenciacion\"\n",
    "con_diferencias = con_diferencias[con_diferencias[\"Paso\"] != \"Promedio\"]\n",
    "con_diferencias['Tipo de Modelo'] = con_diferencias['Tipo de Modelo'].replace(mapeo_nombres_exacto)\n",
    "\n",
    "# Une los dos DataFrames en uno solo\n",
    "df_all = pd.concat([sin_diferencias, con_diferencias], ignore_index=True)\n",
    "\n",
    "# Guarda el DataFrame combinado en un archivo Excel\n",
    "df_all.to_excel(\"./Datos/base_diferencias.xlsx\", index=False)\n",
    "display(df_all)\n",
    "print(\"\\n¬°Proceso completado! Archivo guardado en: ./Datos/base_diferencias.xlsx\")\n",
    "print(f\"Total de filas en el archivo combinado: {len(df_all)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beebcd9",
   "metadata": {},
   "source": [
    "# Analisis Diferenciaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "819c1c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "AN√ÅLISIS DE SIGNIFICANCIA ESTAD√çSTICA - TEST DE DIEBOLD-MARIANO\n",
      "================================================================================\n",
      "\n",
      "Escenarios √∫nicos encontrados: ['No_Estacionario_Lineal_SIN_diferenciacion'\n",
      " 'No_Estacionario_Lineal_CON_diferenciacion']\n",
      "\n",
      "Modelos disponibles: ['AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', 'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
      "\n",
      "Escenario SIN diferenciaci√≥n: No_Estacionario_Lineal_SIN_diferenciacion\n",
      "Escenario CON diferenciaci√≥n: No_Estacionario_Lineal_CON_diferenciacion\n",
      "\n",
      "AREPD: Sin_dif=700 obs, Con_dif=700 obs\n",
      "\n",
      "AV-MCPS: Sin_dif=700 obs, Con_dif=700 obs\n",
      "\n",
      "Block Bootstrapping: Sin_dif=700 obs, Con_dif=700 obs\n",
      "\n",
      "DeepAR: Sin_dif=700 obs, Con_dif=700 obs\n",
      "\n",
      "EnCQR-LSTM: Sin_dif=700 obs, Con_dif=700 obs\n",
      "\n",
      "LSPM: Sin_dif=700 obs, Con_dif=700 obs\n",
      "\n",
      "LSPMW: Sin_dif=700 obs, Con_dif=700 obs\n",
      "\n",
      "MCPS: Sin_dif=700 obs, Con_dif=700 obs\n",
      "\n",
      "Sieve Bootstrap: Sin_dif=700 obs, Con_dif=700 obs\n",
      "\n",
      "             Modelo  ECRPS_Sin_Dif  ECRPS_Con_Dif  Diferencia  Mejora_%  Estad√≠stico       P-valor Significativo            Conclusi√≥n\n",
      "              AREPD       9.566965       0.636497    8.930468 93.346931        456.0 2.020104e-115            S√≠ Diferenciaci√≥n mejora\n",
      "            AV-MCPS       2.046925       0.614457    1.432468 69.981450      13473.0  1.550018e-92            S√≠ Diferenciaci√≥n mejora\n",
      "Block Bootstrapping       0.542499       0.538830    0.003669  0.676279     101044.0  5.308396e-05            S√≠ Diferenciaci√≥n mejora\n",
      "             DeepAR       1.955194       0.582594    1.372600 70.202748       3008.0 9.863663e-111            S√≠ Diferenciaci√≥n mejora\n",
      "         EnCQR-LSTM       3.662181       0.622304    3.039876 83.007272        238.0 7.948481e-116            S√≠ Diferenciaci√≥n mejora\n",
      "               LSPM       1.091187       0.649433    0.441754 40.483781      25863.0  3.911002e-73            S√≠ Diferenciaci√≥n mejora\n",
      "              LSPMW       1.090017       0.671505    0.418513 38.395060      29514.0  7.358886e-68            S√≠ Diferenciaci√≥n mejora\n",
      "               MCPS       2.541980       0.612138    1.929841 75.918840      14723.0  1.790797e-90            S√≠ Diferenciaci√≥n mejora\n",
      "    Sieve Bootstrap       0.748928       0.540324    0.208604 27.853716      28808.0  7.287535e-69            S√≠ Diferenciaci√≥n mejora\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS POR TIPO DE MODELO\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS POR DISTRIBUCI√ìN\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS POR VARIANZA DEL ERROR\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "VISUALIZACI√ìN DEL TEST DIEBOLD-MARIANO\n",
      "================================================================================\n",
      "\n",
      "Gr√°fico del Test Diebold-Mariano generado exitosamente\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS MULTI-DIMENSIONAL\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "GENERANDO RESUMEN ESTAD√çSTICO CONSOLIDADO\n",
      "================================================================================\n",
      "\n",
      "Resumen estad√≠stico guardado en: resumen_estadistico_completo.xlsx\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS COMPLETADO - Resultados guardados en: ./Resultados_diferenciacion/\n",
      "================================================================================\n",
      "\n",
      "Archivos generados:\n",
      "- 01_comparacion_general.png (Sin asteriscos)\n",
      "- 02_tipo_modelo_heatmap.png y 02_tipo_modelo_desagregado.png\n",
      "- 03_distribucion_heatmap.png y 03_distribucion_desagregado.png\n",
      "- 04_varianza_heatmap.png y 04_varianza_desagregado.png\n",
      "- 05_test_diebold_mariano_completo.png (NUEVO)\n",
      "- 06_[modelo]_combinado.png (an√°lisis multidimensional)\n",
      "- test_diebold_mariano.xlsx\n",
      "- resumen_estadistico_completo.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import wilcoxon\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Crear carpeta para resultados\n",
    "os.makedirs(\"./Resultados_diferenciacion\", exist_ok=True)\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_excel(\"./Datos/base_diferencias.xlsx\")\n",
    "\n",
    "# Lista de modelos a analizar\n",
    "modelos = ['AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', \n",
    "           'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
    "\n",
    "# Configuraci√≥n de estilo\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "\n",
    "# ============================================================================\n",
    "# 1. TEST DE DIEBOLD-MARIANO PARA CADA MODELO\n",
    "# ============================================================================\n",
    "print(\"=\"*80)\n",
    "print(\"AN√ÅLISIS DE SIGNIFICANCIA ESTAD√çSTICA - TEST DE DIEBOLD-MARIANO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "resultados_dm = []\n",
    "\n",
    "print(\"\\nEscenarios √∫nicos encontrados:\", df['Escenario'].unique())\n",
    "print(\"\\nModelos disponibles:\", [col for col in df.columns if col in modelos])\n",
    "\n",
    "# Detectar autom√°ticamente los nombres de escenarios\n",
    "escenarios = df['Escenario'].unique()\n",
    "sin_dif_escenario = [e for e in escenarios if 'SIN' in e.upper()][0] if any('SIN' in e.upper() for e in escenarios) else None\n",
    "con_dif_escenario = [e for e in escenarios if 'CON' in e.upper()][0] if any('CON' in e.upper() for e in escenarios) else None\n",
    "\n",
    "print(f\"\\nEscenario SIN diferenciaci√≥n: {sin_dif_escenario}\")\n",
    "print(f\"Escenario CON diferenciaci√≥n: {con_dif_escenario}\")\n",
    "\n",
    "if sin_dif_escenario is None or con_dif_escenario is None:\n",
    "    raise ValueError(\"No se pudieron identificar los escenarios. Verifica los nombres en la columna 'Escenario'\")\n",
    "\n",
    "for modelo in modelos:\n",
    "    # Verificar si el modelo existe en el DataFrame\n",
    "    if modelo not in df.columns:\n",
    "        print(f\"Advertencia: Modelo '{modelo}' no encontrado en los datos\")\n",
    "        continue\n",
    "    \n",
    "    # Separar datos por escenario usando los nombres detectados\n",
    "    sin_dif = df[df['Escenario'] == sin_dif_escenario][modelo].dropna()\n",
    "    con_dif = df[df['Escenario'] == con_dif_escenario][modelo].dropna()\n",
    "    \n",
    "    print(f\"\\n{modelo}: Sin_dif={len(sin_dif)} obs, Con_dif={len(con_dif)} obs\")\n",
    "    \n",
    "    if len(sin_dif) == 0 or len(con_dif) == 0:\n",
    "        print(f\"  Saltando {modelo} - datos insuficientes\")\n",
    "        continue\n",
    "    \n",
    "    # Asegurar misma longitud\n",
    "    min_len = min(len(sin_dif), len(con_dif))\n",
    "    sin_dif_arr = sin_dif.iloc[:min_len].values\n",
    "    con_dif_arr = con_dif.iloc[:min_len].values\n",
    "    \n",
    "    # Calcular diferencias de errores cuadrados (aproximaci√≥n DM test)\n",
    "    diferencias = sin_dif_arr**2 - con_dif_arr**2\n",
    "    \n",
    "    # Test de Wilcoxon (alternativa no param√©trica robusta)\n",
    "    try:\n",
    "        if len(diferencias) > 5 and not np.all(diferencias == 0):\n",
    "            statistic, p_value = wilcoxon(diferencias, alternative='two-sided')\n",
    "        else:\n",
    "            statistic, p_value = np.nan, 1.0\n",
    "    except:\n",
    "        statistic, p_value = np.nan, 1.0\n",
    "    \n",
    "    # Calcular mejora porcentual\n",
    "    if sin_dif_arr.mean() != 0:\n",
    "        mejora_pct = ((sin_dif_arr.mean() - con_dif_arr.mean()) / sin_dif_arr.mean()) * 100\n",
    "    else:\n",
    "        mejora_pct = 0\n",
    "    \n",
    "    resultados_dm.append({\n",
    "        'Modelo': modelo,\n",
    "        'ECRPS_Sin_Dif': sin_dif_arr.mean(),\n",
    "        'ECRPS_Con_Dif': con_dif_arr.mean(),\n",
    "        'Diferencia': sin_dif_arr.mean() - con_dif_arr.mean(),\n",
    "        'Mejora_%': mejora_pct,\n",
    "        'Estad√≠stico': statistic,\n",
    "        'P-valor': p_value,\n",
    "        'Significativo': 'S√≠' if p_value < 0.05 else 'No',\n",
    "        'Conclusi√≥n': 'Diferenciaci√≥n mejora' if mejora_pct > 0 and p_value < 0.05 \n",
    "                     else 'Diferenciaci√≥n empeora' if mejora_pct < 0 and p_value < 0.05\n",
    "                     else 'Sin diferencia significativa'\n",
    "    })\n",
    "\n",
    "df_dm = pd.DataFrame(resultados_dm)\n",
    "\n",
    "if len(df_dm) == 0:\n",
    "    print(\"\\n¬°ERROR! No se pudo generar ning√∫n resultado. Verifica:\")\n",
    "    print(\"1. Que los nombres de escenarios sean exactamente correctos\")\n",
    "    print(\"2. Que existan columnas para los modelos especificados\")\n",
    "    print(\"3. Que haya datos en ambos escenarios\")\n",
    "    print(\"\\nPrimeras filas del DataFrame:\")\n",
    "    print(df.head())\n",
    "    raise ValueError(\"No se generaron resultados para el an√°lisis\")\n",
    "\n",
    "print(\"\\n\" + df_dm.to_string(index=False))\n",
    "df_dm.to_excel(\"./Resultados_diferenciacion/test_diebold_mariano.xlsx\", index=False)\n",
    "\n",
    "# ============================================================================\n",
    "# 2. VISUALIZACI√ìN DE RESULTADOS DM TEST (SIN ASTERISCOS)\n",
    "# ============================================================================\n",
    "if len(df_dm) > 0:\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "    # Gr√°fico 1: Comparaci√≥n de ECRPS promedio\n",
    "    x = np.arange(len(df_dm))\n",
    "    width = 0.35\n",
    "\n",
    "    axes[0].bar(x - width/2, df_dm['ECRPS_Sin_Dif'], width, label='Sin Diferenciaci√≥n', \n",
    "                alpha=0.8, color='#e74c3c')\n",
    "    axes[0].bar(x + width/2, df_dm['ECRPS_Con_Dif'], width, label='Con Diferenciaci√≥n', \n",
    "                alpha=0.8, color='#3498db')\n",
    "\n",
    "    axes[0].set_xlabel('Modelo', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_ylabel('ECRPS Promedio', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_title('Comparaci√≥n de ECRPS: Con vs Sin Diferenciaci√≥n', \n",
    "                      fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xticks(x)\n",
    "    axes[0].set_xticklabels(df_dm['Modelo'], rotation=45, ha='right')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "    # Gr√°fico 2: Mejora porcentual (SIN ASTERISCOS)\n",
    "    colors = ['green' if (row['Mejora_%'] > 0 and row['Significativo'] == 'S√≠') \n",
    "              else 'red' if (row['Mejora_%'] < 0 and row['Significativo'] == 'S√≠')\n",
    "              else 'gray' for _, row in df_dm.iterrows()]\n",
    "\n",
    "    bars = axes[1].bar(x, df_dm['Mejora_%'], color=colors, alpha=0.7)\n",
    "    axes[1].axhline(y=0, color='black', linestyle='-', linewidth=0.8)\n",
    "    axes[1].set_xlabel('Modelo', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_ylabel('Mejora % (positivo = diferenciaci√≥n mejor)', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_title('Mejora Porcentual por Diferenciaci√≥n (Verde=Sig. Mejora, Rojo=Sig. Empeora, Gris=No Sig.)', \n",
    "                      fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xticks(x)\n",
    "    axes[1].set_xticklabels(df_dm['Modelo'], rotation=45, ha='right')\n",
    "    axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./Resultados_diferenciacion/01_comparacion_general.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# 3. AN√ÅLISIS POR TIPO DE MODELO - DESAGREGADO POR CADA TIPO\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AN√ÅLISIS POR TIPO DE MODELO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Crear matriz de datos para tipo de modelo\n",
    "tipos_modelo = df['Tipo de Modelo'].unique()\n",
    "matriz_tipo_sin = []\n",
    "matriz_tipo_con = []\n",
    "matriz_tipo_mejora = []\n",
    "\n",
    "for tipo in tipos_modelo:\n",
    "    sin_vals = []\n",
    "    con_vals = []\n",
    "    mejora_vals = []\n",
    "    \n",
    "    for modelo in modelos:\n",
    "        if modelo in df.columns:\n",
    "            sin_val = df[(df['Tipo de Modelo'] == tipo) & \n",
    "                        (df['Escenario'] == sin_dif_escenario)][modelo].mean()\n",
    "            con_val = df[(df['Tipo de Modelo'] == tipo) & \n",
    "                        (df['Escenario'] == con_dif_escenario)][modelo].mean()\n",
    "            \n",
    "            sin_vals.append(sin_val)\n",
    "            con_vals.append(con_val)\n",
    "            \n",
    "            if sin_val != 0:\n",
    "                mejora = ((sin_val - con_val) / sin_val) * 100\n",
    "            else:\n",
    "                mejora = 0\n",
    "            mejora_vals.append(mejora)\n",
    "    \n",
    "    matriz_tipo_sin.append(sin_vals)\n",
    "    matriz_tipo_con.append(con_vals)\n",
    "    matriz_tipo_mejora.append(mejora_vals)\n",
    "\n",
    "# Heatmap de mejora porcentual por tipo de modelo\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "df_tipo_mejora = pd.DataFrame(matriz_tipo_mejora, index=tipos_modelo, columns=modelos)\n",
    "sns.heatmap(df_tipo_mejora, annot=True, fmt='.1f', cmap='RdYlGn', center=0,\n",
    "            cbar_kws={'label': 'Mejora % (+ = mejor con diferenciaci√≥n)'}, \n",
    "            ax=ax, linewidths=1, vmin=-50, vmax=50)\n",
    "ax.set_title('Mejora Porcentual por Tipo de Modelo\\n(Verde = Diferenciaci√≥n Mejora, Rojo = Empeora)', \n",
    "            fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Modelos', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Tipo de Modelo', fontsize=12, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./Resultados_diferenciacion/02_tipo_modelo_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# NUEVO: Gr√°ficos desagregados - uno por cada tipo de modelo\n",
    "n_tipos = len(tipos_modelo)\n",
    "n_cols = min(2, n_tipos)\n",
    "n_rows = int(np.ceil(n_tipos / n_cols))\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 6*n_rows))\n",
    "if n_tipos == 1:\n",
    "    axes = np.array([axes])\n",
    "elif n_rows == 1 and n_cols > 1:\n",
    "    axes = np.array(axes)\n",
    "else:\n",
    "    axes = axes.flatten()\n",
    "\n",
    "for idx, tipo in enumerate(tipos_modelo):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Preparar datos para este tipo de modelo\n",
    "    datos_tipo = []\n",
    "    for modelo in modelos:\n",
    "        if modelo in df.columns:\n",
    "            sin_val = df[(df['Tipo de Modelo'] == tipo) & \n",
    "                        (df['Escenario'] == sin_dif_escenario)][modelo].mean()\n",
    "            con_val = df[(df['Tipo de Modelo'] == tipo) & \n",
    "                        (df['Escenario'] == con_dif_escenario)][modelo].mean()\n",
    "            datos_tipo.append([sin_val, con_val])\n",
    "    \n",
    "    datos_array = np.array(datos_tipo)\n",
    "    x_pos = np.arange(len(modelos))\n",
    "    \n",
    "    # Gr√°fico de puntos conectados\n",
    "    ax.plot(x_pos, datos_array[:, 0], marker='o', linestyle='-', \n",
    "           color='#e74c3c', label='Sin Diferenciaci√≥n', linewidth=2.5, \n",
    "           markersize=8, alpha=0.8)\n",
    "    ax.plot(x_pos, datos_array[:, 1], marker='s', linestyle='-', \n",
    "           color='#3498db', label='Con Diferenciaci√≥n', linewidth=2.5, \n",
    "           markersize=8, alpha=0.8)\n",
    "    \n",
    "    # Conectar puntos individuales con l√≠neas verticales\n",
    "    for i in range(len(x_pos)):\n",
    "        mejora = datos_array[i, 1] < datos_array[i, 0]\n",
    "        color = 'green' if mejora else 'red'\n",
    "        ax.plot([x_pos[i], x_pos[i]], [datos_array[i, 0], datos_array[i, 1]], \n",
    "               color=color, alpha=0.3, linewidth=1.5, linestyle=':')\n",
    "    \n",
    "    ax.set_title(f'{tipo}', fontsize=13, fontweight='bold')\n",
    "    ax.set_xlabel('Modelos', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('ECRPS Promedio', fontsize=11, fontweight='bold')\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(modelos, rotation=45, ha='right', fontsize=9)\n",
    "    ax.legend(loc='best', fontsize=10)\n",
    "    ax.grid(alpha=0.3, linestyle='--')\n",
    "\n",
    "# Ocultar subplots vac√≠os\n",
    "for idx in range(n_tipos, len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "plt.suptitle('Comparaci√≥n Detallada por Tipo de Modelo\\n(L√≠neas verdes punteadas = mejora con diferenciaci√≥n)', \n",
    "            fontsize=15, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./Resultados_diferenciacion/02_tipo_modelo_desagregado.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# 4. AN√ÅLISIS POR DISTRIBUCI√ìN - DESAGREGADO POR CADA DISTRIBUCI√ìN\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AN√ÅLISIS POR DISTRIBUCI√ìN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "distribuciones = df['Distribuci√≥n'].unique()\n",
    "matriz_dist_sin = []\n",
    "matriz_dist_con = []\n",
    "matriz_dist_mejora = []\n",
    "\n",
    "for dist in distribuciones:\n",
    "    sin_vals = []\n",
    "    con_vals = []\n",
    "    mejora_vals = []\n",
    "    \n",
    "    for modelo in modelos:\n",
    "        if modelo in df.columns:\n",
    "            sin_val = df[(df['Distribuci√≥n'] == dist) & \n",
    "                        (df['Escenario'] == sin_dif_escenario)][modelo].mean()\n",
    "            con_val = df[(df['Distribuci√≥n'] == dist) & \n",
    "                        (df['Escenario'] == con_dif_escenario)][modelo].mean()\n",
    "            \n",
    "            sin_vals.append(sin_val)\n",
    "            con_vals.append(con_val)\n",
    "            \n",
    "            if sin_val != 0:\n",
    "                mejora = ((sin_val - con_val) / sin_val) * 100\n",
    "            else:\n",
    "                mejora = 0\n",
    "            mejora_vals.append(mejora)\n",
    "    \n",
    "    matriz_dist_sin.append(sin_vals)\n",
    "    matriz_dist_con.append(con_vals)\n",
    "    matriz_dist_mejora.append(mejora_vals)\n",
    "\n",
    "# Heatmap de mejora porcentual por distribuci√≥n\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "df_dist_mejora = pd.DataFrame(matriz_dist_mejora, index=distribuciones, columns=modelos)\n",
    "sns.heatmap(df_dist_mejora, annot=True, fmt='.1f', cmap='RdYlGn', center=0,\n",
    "            cbar_kws={'label': 'Mejora % (+ = mejor con diferenciaci√≥n)'}, \n",
    "            ax=ax, linewidths=1, vmin=-50, vmax=50)\n",
    "ax.set_title('Mejora Porcentual por Distribuci√≥n\\n(Verde = Diferenciaci√≥n Mejora, Rojo = Empeora)', \n",
    "            fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Modelos', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Distribuci√≥n', fontsize=12, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./Resultados_diferenciacion/03_distribucion_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# NUEVO: Gr√°ficos desagregados - uno por cada distribuci√≥n\n",
    "n_dist = len(distribuciones)\n",
    "n_cols = min(2, n_dist)\n",
    "n_rows = int(np.ceil(n_dist / n_cols))\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 6*n_rows))\n",
    "if n_dist == 1:\n",
    "    axes = np.array([axes])\n",
    "elif n_rows == 1 and n_cols > 1:\n",
    "    axes = np.array(axes)\n",
    "else:\n",
    "    axes = axes.flatten()\n",
    "\n",
    "for idx, dist in enumerate(distribuciones):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Preparar datos para esta distribuci√≥n\n",
    "    datos_dist = []\n",
    "    for modelo in modelos:\n",
    "        if modelo in df.columns:\n",
    "            sin_val = df[(df['Distribuci√≥n'] == dist) & \n",
    "                        (df['Escenario'] == sin_dif_escenario)][modelo].mean()\n",
    "            con_val = df[(df['Distribuci√≥n'] == dist) & \n",
    "                        (df['Escenario'] == con_dif_escenario)][modelo].mean()\n",
    "            datos_dist.append([sin_val, con_val])\n",
    "    \n",
    "    datos_array = np.array(datos_dist)\n",
    "    x_pos = np.arange(len(modelos))\n",
    "    \n",
    "    # Gr√°fico de puntos conectados\n",
    "    ax.plot(x_pos, datos_array[:, 0], marker='o', linestyle='-', \n",
    "           color='#e74c3c', label='Sin Diferenciaci√≥n', linewidth=2.5, \n",
    "           markersize=8, alpha=0.8)\n",
    "    ax.plot(x_pos, datos_array[:, 1], marker='s', linestyle='-', \n",
    "           color='#3498db', label='Con Diferenciaci√≥n', linewidth=2.5, \n",
    "           markersize=8, alpha=0.8)\n",
    "    \n",
    "    # Conectar puntos individuales con l√≠neas verticales\n",
    "    for i in range(len(x_pos)):\n",
    "        mejora = datos_array[i, 1] < datos_array[i, 0]\n",
    "        color = 'green' if mejora else 'red'\n",
    "        ax.plot([x_pos[i], x_pos[i]], [datos_array[i, 0], datos_array[i, 1]], \n",
    "               color=color, alpha=0.3, linewidth=1.5, linestyle=':')\n",
    "    \n",
    "    ax.set_title(f'{dist}', fontsize=13, fontweight='bold')\n",
    "    ax.set_xlabel('Modelos', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('ECRPS Promedio', fontsize=11, fontweight='bold')\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(modelos, rotation=45, ha='right', fontsize=9)\n",
    "    ax.legend(loc='best', fontsize=10)\n",
    "    ax.grid(alpha=0.3, linestyle='--')\n",
    "\n",
    "# Ocultar subplots vac√≠os\n",
    "for idx in range(n_dist, len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "plt.suptitle('Comparaci√≥n Detallada por Distribuci√≥n\\n(L√≠neas verdes punteadas = mejora con diferenciaci√≥n)', \n",
    "            fontsize=15, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./Resultados_diferenciacion/03_distribucion_desagregado.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# 5. AN√ÅLISIS POR VARIANZA DEL ERROR - DESAGREGADO POR CADA NIVEL\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AN√ÅLISIS POR VARIANZA DEL ERROR\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "varianzas = sorted(df['Varianza error'].unique())\n",
    "matriz_var_sin = []\n",
    "matriz_var_con = []\n",
    "matriz_var_mejora = []\n",
    "\n",
    "for var in varianzas:\n",
    "    sin_vals = []\n",
    "    con_vals = []\n",
    "    mejora_vals = []\n",
    "    \n",
    "    for modelo in modelos:\n",
    "        if modelo in df.columns:\n",
    "            sin_val = df[(df['Varianza error'] == var) & \n",
    "                        (df['Escenario'] == sin_dif_escenario)][modelo].mean()\n",
    "            con_val = df[(df['Varianza error'] == var) & \n",
    "                        (df['Escenario'] == con_dif_escenario)][modelo].mean()\n",
    "            \n",
    "            sin_vals.append(sin_val)\n",
    "            con_vals.append(con_val)\n",
    "            \n",
    "            if sin_val != 0:\n",
    "                mejora = ((sin_val - con_val) / sin_val) * 100\n",
    "            else:\n",
    "                mejora = 0\n",
    "            mejora_vals.append(mejora)\n",
    "    \n",
    "    matriz_var_sin.append(sin_vals)\n",
    "    matriz_var_con.append(con_vals)\n",
    "    matriz_var_mejora.append(mejora_vals)\n",
    "\n",
    "# Heatmap de mejora porcentual por varianza\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "df_var_mejora = pd.DataFrame(matriz_var_mejora, \n",
    "                             index=[f'Var={v}' for v in varianzas], \n",
    "                             columns=modelos)\n",
    "sns.heatmap(df_var_mejora, annot=True, fmt='.1f', cmap='RdYlGn', center=0,\n",
    "            cbar_kws={'label': 'Mejora % (+ = mejor con diferenciaci√≥n)'}, \n",
    "            ax=ax, linewidths=1, vmin=-50, vmax=50)\n",
    "ax.set_title('Mejora Porcentual por Varianza del Error\\n(Verde = Diferenciaci√≥n Mejora, Rojo = Empeora)', \n",
    "            fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Modelos', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Varianza del Error', fontsize=12, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./Resultados_diferenciacion/04_varianza_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# NUEVO: Gr√°ficos desagregados - uno por cada nivel de varianza\n",
    "n_var = len(varianzas)\n",
    "n_cols = min(2, n_var)\n",
    "n_rows = int(np.ceil(n_var / n_cols))\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 6*n_rows))\n",
    "if n_var == 1:\n",
    "    axes = np.array([axes])\n",
    "elif n_rows == 1 and n_cols > 1:\n",
    "    axes = np.array(axes)\n",
    "else:\n",
    "    axes = axes.flatten()\n",
    "\n",
    "for idx, var in enumerate(varianzas):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Preparar datos para este nivel de varianza\n",
    "    datos_var = []\n",
    "    for modelo in modelos:\n",
    "        if modelo in df.columns:\n",
    "            sin_val = df[(df['Varianza error'] == var) & \n",
    "                        (df['Escenario'] == sin_dif_escenario)][modelo].mean()\n",
    "            con_val = df[(df['Varianza error'] == var) & \n",
    "                        (df['Escenario'] == con_dif_escenario)][modelo].mean()\n",
    "            datos_var.append([sin_val, con_val])\n",
    "    \n",
    "    datos_array = np.array(datos_var)\n",
    "    x_pos = np.arange(len(modelos))\n",
    "    \n",
    "    # Gr√°fico de puntos conectados\n",
    "    ax.plot(x_pos, datos_array[:, 0], marker='o', linestyle='-', \n",
    "           color='#e74c3c', label='Sin Diferenciaci√≥n', linewidth=2.5, \n",
    "           markersize=8, alpha=0.8)\n",
    "    ax.plot(x_pos, datos_array[:, 1], marker='s', linestyle='-', \n",
    "           color='#3498db', label='Con Diferenciaci√≥n', linewidth=2.5, \n",
    "           markersize=8, alpha=0.8)\n",
    "    \n",
    "    # Conectar puntos individuales con l√≠neas verticales\n",
    "    for i in range(len(x_pos)):\n",
    "        mejora = datos_array[i, 1] < datos_array[i, 0]\n",
    "        color = 'green' if mejora else 'red'\n",
    "        ax.plot([x_pos[i], x_pos[i]], [datos_array[i, 0], datos_array[i, 1]], \n",
    "               color=color, alpha=0.3, linewidth=1.5, linestyle=':')\n",
    "    \n",
    "    ax.set_title(f'Varianza = {var}', fontsize=13, fontweight='bold')\n",
    "    ax.set_xlabel('Modelos', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('ECRPS Promedio', fontsize=11, fontweight='bold')\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(modelos, rotation=45, ha='right', fontsize=9)\n",
    "    ax.legend(loc='best', fontsize=10)\n",
    "    ax.grid(alpha=0.3, linestyle='--')\n",
    "\n",
    "# Ocultar subplots vac√≠os\n",
    "for idx in range(n_var, len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "plt.suptitle('Comparaci√≥n Detallada por Varianza del Error\\n(L√≠neas verdes punteadas = mejora con diferenciaci√≥n)', \n",
    "            fontsize=15, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./Resultados_diferenciacion/04_varianza_desagregado.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# 6. VISUALIZACI√ìN AVANZADA DEL TEST DIEBOLD-MARIANO\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VISUALIZACI√ìN DEL TEST DIEBOLD-MARIANO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if len(df_dm) > 0:\n",
    "    # Crear figura con m√∫ltiples subplots\n",
    "    fig = plt.figure(figsize=(18, 12))\n",
    "    gs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # 1. Gr√°fico de significancia estad√≠stica (tipo lollipop)\n",
    "    ax1 = fig.add_subplot(gs[0, :])\n",
    "    x_pos = np.arange(len(df_dm))\n",
    "    \n",
    "    # Colores basados en significancia y direcci√≥n\n",
    "    colors_sig = []\n",
    "    for _, row in df_dm.iterrows():\n",
    "        if row['Significativo'] == 'S√≠':\n",
    "            if row['Mejora_%'] > 0:\n",
    "                colors_sig.append('#27ae60')  # Verde fuerte\n",
    "            else:\n",
    "                colors_sig.append('#c0392b')  # Rojo fuerte\n",
    "        else:\n",
    "            colors_sig.append('#95a5a6')  # Gris\n",
    "    \n",
    "    # Lollipop plot\n",
    "    ax1.hlines(y=x_pos, xmin=0, xmax=df_dm['Mejora_%'], colors=colors_sig, alpha=0.7, linewidth=4)\n",
    "    ax1.scatter(df_dm['Mejora_%'], x_pos, s=200, c=colors_sig, alpha=0.9, edgecolors='black', linewidth=1.5)\n",
    "    \n",
    "    # L√≠nea de referencia\n",
    "    ax1.axvline(x=0, color='black', linestyle='-', linewidth=1, alpha=0.5)\n",
    "    \n",
    "    # A√±adir valores de p-valor\n",
    "    for i, (idx, row) in enumerate(df_dm.iterrows()):\n",
    "        if not np.isnan(row['P-valor']):\n",
    "            p_text = f\"p={row['P-valor']:.4f}\" if row['P-valor'] >= 0.0001 else \"p<0.0001\"\n",
    "            x_offset = 2 if row['Mejora_%'] > 0 else -2\n",
    "            ax1.text(row['Mejora_%'] + x_offset, i, p_text, \n",
    "                    va='center', ha='left' if row['Mejora_%'] > 0 else 'right',\n",
    "                    fontsize=8, style='italic')\n",
    "    \n",
    "    ax1.set_yticks(x_pos)\n",
    "    ax1.set_yticklabels(df_dm['Modelo'], fontsize=10)\n",
    "    ax1.set_xlabel('Mejora Porcentual (%)', fontsize=12, fontweight='bold')\n",
    "    ax1.set_title('Test de Diebold-Mariano: Significancia Estad√≠stica de la Diferenciaci√≥n\\n(Verde=Mejora Sig., Rojo=Empeora Sig., Gris=No Sig.)', \n",
    "                 fontsize=13, fontweight='bold')\n",
    "    ax1.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    # 2. Comparaci√≥n de ECRPS absolutos\n",
    "    ax2 = fig.add_subplot(gs[1, 0])\n",
    "    x = np.arange(len(df_dm))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = ax2.barh(x + width/2, df_dm['ECRPS_Sin_Dif'], width, \n",
    "                     label='Sin Diferenciaci√≥n', alpha=0.8, color='#e74c3c')\n",
    "    bars2 = ax2.barh(x - width/2, df_dm['ECRPS_Con_Dif'], width, \n",
    "                     label='Con Diferenciaci√≥n', alpha=0.8, color='#3498db')\n",
    "    \n",
    "    ax2.set_yticks(x)\n",
    "    ax2.set_yticklabels(df_dm['Modelo'], fontsize=9)\n",
    "    ax2.set_xlabel('ECRPS Promedio', fontsize=11, fontweight='bold')\n",
    "    ax2.set_title('Comparaci√≥n de ECRPS Absolutos', fontsize=12, fontweight='bold')\n",
    "    ax2.legend(loc='best', fontsize=9)\n",
    "    ax2.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # 3. Distribuci√≥n de p-valores\n",
    "    ax3 = fig.add_subplot(gs[1, 1])\n",
    "    p_valores_validos = df_dm[~df_dm['P-valor'].isna()]['P-valor']\n",
    "    \n",
    "    if len(p_valores_validos) > 0:\n",
    "        # Histograma de p-valores\n",
    "        n, bins, patches = ax3.hist(p_valores_validos, bins=10, alpha=0.7, \n",
    "                                     color='#3498db', edgecolor='black')\n",
    "        \n",
    "        # L√≠nea de significancia\n",
    "        ax3.axvline(x=0.05, color='red', linestyle='--', linewidth=2, \n",
    "                   label='Œ± = 0.05', alpha=0.8)\n",
    "        ax3.axvline(x=0.01, color='darkred', linestyle='--', linewidth=2, \n",
    "                   label='Œ± = 0.01', alpha=0.8)\n",
    "        \n",
    "        # Colorear barras seg√∫n significancia\n",
    "        for i, patch in enumerate(patches):\n",
    "            if bins[i] < 0.05:\n",
    "                patch.set_facecolor('#27ae60')\n",
    "        \n",
    "        ax3.set_xlabel('P-valor', fontsize=11, fontweight='bold')\n",
    "        ax3.set_ylabel('Frecuencia', fontsize=11, fontweight='bold')\n",
    "        ax3.set_title('Distribuci√≥n de P-valores\\n(Barras verdes = significativo Œ±=0.05)', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "        ax3.legend(loc='best', fontsize=9)\n",
    "        ax3.grid(alpha=0.3)\n",
    "    \n",
    "    # 4. Mapa de calor de conclusiones\n",
    "    ax4 = fig.add_subplot(gs[2, :])\n",
    "    \n",
    "    # Crear matriz para el heatmap\n",
    "    conclusiones_matrix = []\n",
    "    conclusiones_text = []\n",
    "    \n",
    "    for _, row in df_dm.iterrows():\n",
    "        if row['Significativo'] == 'S√≠' and row['Mejora_%'] > 0:\n",
    "            conclusiones_matrix.append([2])  # Mejora significativa\n",
    "            conclusiones_text.append([f\"+{row['Mejora_%']:.1f}%\\n(p={row['P-valor']:.3f})\"])\n",
    "        elif row['Significativo'] == 'S√≠' and row['Mejora_%'] < 0:\n",
    "            conclusiones_matrix.append([-2])  # Empeora significativo\n",
    "            conclusiones_text.append([f\"{row['Mejora_%']:.1f}%\\n(p={row['P-valor']:.3f})\"])\n",
    "        else:\n",
    "            conclusiones_matrix.append([0])  # No significativo\n",
    "            conclusiones_text.append([f\"{row['Mejora_%']:.1f}%\\n(NS)\"])\n",
    "    \n",
    "    # Crear heatmap\n",
    "    im = ax4.imshow(conclusiones_matrix, cmap='RdYlGn', aspect='auto', \n",
    "                    vmin=-2, vmax=2, alpha=0.8)\n",
    "    \n",
    "    # A√±adir anotaciones\n",
    "    for i in range(len(df_dm)):\n",
    "        ax4.text(0, i, conclusiones_text[i][0], ha='center', va='center',\n",
    "                fontsize=9, fontweight='bold')\n",
    "    \n",
    "    ax4.set_yticks(np.arange(len(df_dm)))\n",
    "    ax4.set_yticklabels(df_dm['Modelo'], fontsize=10)\n",
    "    ax4.set_xticks([0])\n",
    "    ax4.set_xticklabels(['Resultado Test DM'], fontsize=11, fontweight='bold')\n",
    "    ax4.set_title('Resumen de Conclusiones del Test Diebold-Mariano\\n(Verde=Mejora Sig., Rojo=Empeora Sig., Amarillo=No Sig.)', \n",
    "                 fontsize=13, fontweight='bold')\n",
    "    \n",
    "    # A√±adir colorbar\n",
    "    cbar = plt.colorbar(im, ax=ax4, orientation='horizontal', pad=0.1, aspect=30)\n",
    "    cbar.set_ticks([-2, 0, 2])\n",
    "    cbar.set_ticklabels(['Empeora\\nSig.', 'No\\nSig.', 'Mejora\\nSig.'])\n",
    "    cbar.ax.tick_params(labelsize=9)\n",
    "    \n",
    "    plt.suptitle('An√°lisis Completo del Test de Diebold-Mariano', \n",
    "                fontsize=16, fontweight='bold', y=0.995)\n",
    "    \n",
    "    plt.savefig('./Resultados_diferenciacion/05_test_diebold_mariano_completo.png', \n",
    "               dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"\\nGr√°fico del Test Diebold-Mariano generado exitosamente\")\n",
    "else:\n",
    "    print(\"No se pudo generar visualizaci√≥n del Test DM - datos insuficientes\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AN√ÅLISIS MULTI-DIMENSIONAL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Crear an√°lisis por subplots para cada modelo\n",
    "fig, axes = plt.subplots(3, 3, figsize=(20, 16))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, modelo in enumerate(modelos):\n",
    "    if modelo not in df.columns:\n",
    "        continue\n",
    "        \n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Preparar datos\n",
    "    datos_plot = []\n",
    "    labels = []\n",
    "    \n",
    "    for tipo in tipos_modelo:\n",
    "        for dist in distribuciones:\n",
    "            sin_val = df[(df['Tipo de Modelo'] == tipo) & \n",
    "                        (df['Distribuci√≥n'] == dist) &\n",
    "                        (df['Escenario'] == sin_dif_escenario)][modelo].mean()\n",
    "            con_val = df[(df['Tipo de Modelo'] == tipo) & \n",
    "                        (df['Distribuci√≥n'] == dist) &\n",
    "                        (df['Escenario'] == con_dif_escenario)][modelo].mean()\n",
    "            \n",
    "            if not np.isnan(sin_val) and not np.isnan(con_val):\n",
    "                datos_plot.append([sin_val, con_val])\n",
    "                labels.append(f'{tipo[:3]}-{dist[:3]}')\n",
    "    \n",
    "    if datos_plot:\n",
    "        datos_array = np.array(datos_plot)\n",
    "        x_pos = np.arange(len(labels))\n",
    "        width = 0.35\n",
    "        \n",
    "        ax.scatter(x_pos - width/2, datos_array[:, 0], alpha=0.6, s=100, \n",
    "                  c='red', marker='o', label='Sin Dif')\n",
    "        ax.scatter(x_pos + width/2, datos_array[:, 1], alpha=0.6, s=100, \n",
    "                  c='blue', marker='s', label='Con Dif')\n",
    "        \n",
    "        # Conectar puntos con l√≠neas\n",
    "        for i in range(len(x_pos)):\n",
    "            ax.plot([x_pos[i] - width/2, x_pos[i] + width/2], \n",
    "                   [datos_array[i, 0], datos_array[i, 1]], \n",
    "                   'gray', alpha=0.3, linewidth=1)\n",
    "        \n",
    "        ax.set_title(f'{modelo}', fontsize=11, fontweight='bold')\n",
    "        ax.set_xticks(x_pos)\n",
    "        ax.set_xticklabels(labels, rotation=90, fontsize=8)\n",
    "        ax.set_ylabel('ECRPS', fontsize=9)\n",
    "        ax.grid(alpha=0.3)\n",
    "        ax.legend(fontsize=8, loc='best')\n",
    "\n",
    "plt.suptitle('An√°lisis Multi-dimensional: Tipo Modelo + Distribuci√≥n\\n(Rojo=Sin Dif, Azul=Con Dif)', \n",
    "            fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./Resultados_diferenciacion/05_analisis_multidimensional.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# 7. RESUMEN ESTAD√çSTICO CONSOLIDADO\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GENERANDO RESUMEN ESTAD√çSTICO CONSOLIDADO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Crear tabla resumen\n",
    "resumen_caracteristicas = []\n",
    "\n",
    "for caracteristica in ['Tipo de Modelo', 'Distribuci√≥n', 'Varianza error']:\n",
    "    valores = df[caracteristica].unique()\n",
    "    \n",
    "    for valor in valores:\n",
    "        for modelo in modelos:\n",
    "            if modelo not in df.columns:\n",
    "                continue\n",
    "                \n",
    "            sin_vals = df[(df[caracteristica] == valor) & \n",
    "                         (df['Escenario'] == sin_dif_escenario)][modelo].values\n",
    "            con_vals = df[(df[caracteristica] == valor) & \n",
    "                         (df['Escenario'] == con_dif_escenario)][modelo].values\n",
    "            \n",
    "            if len(sin_vals) > 0 and len(con_vals) > 0:\n",
    "                resumen_caracteristicas.append({\n",
    "                    'Caracter√≠stica': caracteristica,\n",
    "                    'Valor': str(valor),\n",
    "                    'Modelo': modelo,\n",
    "                    'ECRPS_Sin_Media': np.mean(sin_vals),\n",
    "                    'ECRPS_Sin_Std': np.std(sin_vals),\n",
    "                    'ECRPS_Con_Media': np.mean(con_vals),\n",
    "                    'ECRPS_Con_Std': np.std(con_vals),\n",
    "                    'Mejora_%': ((np.mean(sin_vals) - np.mean(con_vals)) / np.mean(sin_vals)) * 100 if np.mean(sin_vals) != 0 else 0\n",
    "                })\n",
    "\n",
    "df_resumen = pd.DataFrame(resumen_caracteristicas)\n",
    "df_resumen.to_excel('./Resultados_diferenciacion/resumen_estadistico_completo.xlsx', index=False)\n",
    "print(\"\\nResumen estad√≠stico guardado en: resumen_estadistico_completo.xlsx\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AN√ÅLISIS COMPLETADO - Resultados guardados en: ./Resultados_diferenciacion/\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nArchivos generados:\")\n",
    "print(\"- 01_comparacion_general.png (Sin asteriscos)\")\n",
    "print(\"- 02_tipo_modelo_heatmap.png y 02_tipo_modelo_desagregado.png\")\n",
    "print(\"- 03_distribucion_heatmap.png y 03_distribucion_desagregado.png\")\n",
    "print(\"- 04_varianza_heatmap.png y 04_varianza_desagregado.png\")\n",
    "print(\"- 05_test_diebold_mariano_completo.png (NUEVO)\")\n",
    "print(\"- 06_[modelo]_combinado.png (an√°lisis multidimensional)\")\n",
    "print(\"- test_diebold_mariano.xlsx\")\n",
    "print(\"- resumen_estadistico_completo.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

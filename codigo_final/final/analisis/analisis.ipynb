{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b99d120",
   "metadata": {},
   "source": [
    "# Analisis Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b278203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS COMPREHENSIVO DE MODELOS DE PREDICCI√ìN PROBABIL√çSTICA\n",
      "================================================================================\n",
      "\n",
      "Cargando datos...\n",
      "‚úì Estacionario: 1320 filas\n",
      "  Columnas: ['Paso', 'Valores de AR', 'Valores MA', 'Distribuci√≥n', 'Varianza error', 'AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', 'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap', 'Mejor Modelo', 'Escenario']\n",
      "‚úì No Estacionario: 840 filas\n",
      "  Columnas: ['Paso', 'Tipo de Modelo', 'Valores de AR', 'Valores MA', 'Distribuci√≥n', 'Varianza error', 'AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', 'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap', 'Mejor Modelo', 'Escenario']\n",
      "‚úì No Lineal: 840 filas\n",
      "  Columnas: ['Paso', 'Tipo de Modelo', 'Distribuci√≥n', 'Varianza error', 'AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', 'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap', 'Mejor Modelo', 'Escenario']\n",
      "‚úì Tipos de datos convertidos\n",
      "‚úì Filas despu√©s de limpieza: 2600\n",
      "\n",
      "‚úì Datos combinados: 2600 observaciones totales\n",
      "‚úì Columnas finales: ['Paso', 'Valores de AR', 'Valores MA', 'Distribuci√≥n', 'Varianza', 'AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', 'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap', 'Mejor Modelo', 'Escenario', 'Tipo de Modelo']\n",
      "\n",
      "================================================================================\n",
      "INICIANDO AN√ÅLISIS COMPREHENSIVO DE MODELOS\n",
      "================================================================================\n",
      "\n",
      "1. Analizando caracter√≠sticas del proceso generador...\n",
      "  - Analizando efecto de estacionaridad...\n",
      "  - Analizando efecto de no linealidad...\n",
      "  - Analizando efecto del tipo de modelo...\n",
      "\n",
      "2. Analizando efecto de distribuciones...\n",
      "  - Analizando efectos de distribuciones...\n",
      "  - Analizando efectos de varianza...\n",
      "\n",
      "3. Analizando horizonte de predicci√≥n...\n",
      "  - Analizando deterioro por horizonte...\n",
      "  - Analizando consistencia de ranking...\n",
      "\n",
      "4. Analizando interacciones complejas...\n",
      "  - Analizando interacciones Escenario √ó Distribuci√≥n...\n",
      "  - Analizando interacci√≥n triple...\n",
      "\n",
      "5. Analizando robustez y estabilidad...\n",
      "  - Calculando m√©tricas de robustez...\n",
      "  - Identificando peores casos...\n",
      "\n",
      "6. Realizando tests de Diebold-Mariano...\n",
      "  - Realizando tests de Diebold-Mariano...\n",
      "  - Realizando tests pareados de Diebold-Mariano...\n",
      "  - Creando matriz de p-valores...\n",
      "  - Analizando dominancia estad√≠stica...\n",
      "  - Analizando DM por escenario...\n",
      "\n",
      "7. Generando perfiles por modelo...\n",
      "  - Generando perfiles individuales...\n",
      "    > Analizando AREPD...\n",
      "    > Analizando AV-MCPS...\n",
      "    > Analizando Block Bootstrapping...\n",
      "    > Analizando DeepAR...\n",
      "    > Analizando EnCQR-LSTM...\n",
      "    > Analizando LSPM...\n",
      "    > Analizando LSPMW...\n",
      "    > Analizando MCPS...\n",
      "    > Analizando Sieve Bootstrap...\n",
      "\n",
      "8. Generando recomendaciones...\n",
      "  - Generando recomendaciones estrat√©gicas...\n",
      "================================================================================\n",
      "RECOMENDACIONES Y CONCLUSIONES\n",
      "================================================================================\n",
      "\n",
      "1. MODELO CAMPE√ìN GENERAL\n",
      "----------------------------------------\n",
      "Mejor rendimiento promedio: Block Bootstrapping\n",
      "ECRPS: 0.557547\n",
      "Desviaci√≥n Est√°ndar: 0.293355\n",
      "\n",
      "Peor rendimiento promedio: AREPD\n",
      "ECRPS: 3.083010\n",
      "\n",
      "2. RECOMENDACIONES POR ESCENARIO\n",
      "----------------------------------------\n",
      "\n",
      "Estacionario_Lineal:\n",
      "  Modelo Recomendado: Block Bootstrapping\n",
      "  ECRPS Promedio: 0.539612\n",
      "\n",
      "No_Estacionario_Lineal:\n",
      "  Modelo Recomendado: Block Bootstrapping\n",
      "  ECRPS Promedio: 0.542499\n",
      "\n",
      "No_Lineal:\n",
      "  Modelo Recomendado: Block Bootstrapping\n",
      "  ECRPS Promedio: 0.603341\n",
      "\n",
      "3. RECOMENDACIONES POR DISTRIBUCI√ìN DE ERRORES\n",
      "----------------------------------------\n",
      "\n",
      "Distribuci√≥n normal:\n",
      "  Modelo Recomendado: Block Bootstrapping\n",
      "  ECRPS Promedio: 0.567834\n",
      "\n",
      "Distribuci√≥n uniform:\n",
      "  Modelo Recomendado: Block Bootstrapping\n",
      "  ECRPS Promedio: 0.585653\n",
      "\n",
      "Distribuci√≥n exponential:\n",
      "  Modelo Recomendado: Block Bootstrapping\n",
      "  ECRPS Promedio: 0.514920\n",
      "\n",
      "Distribuci√≥n t-student:\n",
      "  Modelo Recomendado: Block Bootstrapping\n",
      "  ECRPS Promedio: 0.547263\n",
      "\n",
      "Distribuci√≥n mixture:\n",
      "  Modelo Recomendado: Block Bootstrapping\n",
      "  ECRPS Promedio: 0.572066\n",
      "\n",
      "4. MODELOS M√ÅS ROBUSTOS (MENOR VARIABILIDAD)\n",
      "----------------------------------------\n",
      "1. Block Bootstrapping: CV = 0.5262\n",
      "2. LSPMW: CV = 0.7688\n",
      "3. LSPM: CV = 0.7896\n",
      "\n",
      "5. RECOMENDACIONES POR HORIZONTE DE PREDICCI√ìN\n",
      "----------------------------------------\n",
      "\n",
      "Paso 1.0:\n",
      "  Modelo Recomendado: Block Bootstrapping\n",
      "  ECRPS Promedio: 0.548020\n",
      "\n",
      "Paso 3.0:\n",
      "  Modelo Recomendado: Block Bootstrapping\n",
      "  ECRPS Promedio: 0.560285\n",
      "\n",
      "Paso 5.0:\n",
      "  Modelo Recomendado: Block Bootstrapping\n",
      "  ECRPS Promedio: 0.554843\n",
      "\n",
      "6. ESTRATEGIA DE ENSAMBLE SUGERIDA\n",
      "----------------------------------------\n",
      "Combinar los siguientes modelos:\n",
      "1. Block Bootstrapping (ECRPS: 0.557547)\n",
      "2. Sieve Bootstrap (ECRPS: 0.614997)\n",
      "3. LSPM (ECRPS: 0.811114)\n",
      "\n",
      "Justificaci√≥n:\n",
      "  - Estos modelos muestran el mejor rendimiento promedio\n",
      "  - Un ensamble puede capturar fortalezas complementarias\n",
      "  - Reduce el riesgo de seleccionar un modelo sub√≥ptimo\n",
      "\n",
      "7. MODELOS CON DOMINANCIA ESTAD√çSTICA\n",
      "----------------------------------------\n",
      "Modelos estad√≠sticamente superiores (test Diebold-Mariano):\n",
      "1. Block Bootstrapping: 7 victorias significativas\n",
      "2. LSPM: 6 victorias significativas\n",
      "3. LSPMW: 5 victorias significativas\n",
      "4. Sieve Bootstrap: 5 victorias significativas\n",
      "5. DeepAR: 3 victorias significativas\n",
      "\n",
      "8. REGLAS DE DECISI√ìN SUGERIDAS\n",
      "----------------------------------------\n",
      "\n",
      "SI el proceso es ESTACIONARIO y LINEAL:\n",
      "  ‚Üí Primera opci√≥n: Block Bootstrapping\n",
      "  ‚Üí Segunda opci√≥n: Sieve Bootstrap\n",
      "\n",
      "SI el proceso es NO ESTACIONARIO y LINEAL:\n",
      "  ‚Üí Primera opci√≥n: Block Bootstrapping\n",
      "  ‚Üí Segunda opci√≥n: Sieve Bootstrap\n",
      "\n",
      "SI el proceso es NO LINEAL:\n",
      "  ‚Üí Primera opci√≥n: Block Bootstrapping\n",
      "  ‚Üí Segunda opci√≥n: DeepAR\n",
      "\n",
      "SI la distribuci√≥n de errores:\n",
      "  ‚Ä¢ Es normal ‚Üí Usar Block Bootstrapping\n",
      "  ‚Ä¢ Es uniform ‚Üí Usar Block Bootstrapping\n",
      "  ‚Ä¢ Es exponential ‚Üí Usar Block Bootstrapping\n",
      "  ‚Ä¢ Es t-student ‚Üí Usar Block Bootstrapping\n",
      "  ‚Ä¢ Es mixture ‚Üí Usar Block Bootstrapping\n",
      "\n",
      "SI el nivel de varianza:\n",
      "  ‚Ä¢ Es bajo (0.2) ‚Üí Usar Block Bootstrapping\n",
      "  ‚Ä¢ Es alto (3.0) ‚Üí Usar Block Bootstrapping\n",
      "\n",
      "9. CONCLUSIONES PRINCIPALES\n",
      "----------------------------------------\n",
      "\n",
      "‚Ä¢ El modelo Block Bootstrapping muestra el mejor rendimiento general\n",
      "  con ECRPS promedio de 0.557547\n",
      "\n",
      "‚Ä¢ El modelo m√°s robusto (menor CV) es Block Bootstrapping\n",
      "\n",
      "‚Ä¢ Block Bootstrapping es consistentemente superior en procesos\n",
      "  estacionarios y no estacionarios\n",
      "\n",
      "‚Ä¢ Para procesos no lineales: Block Bootstrapping es la mejor opci√≥n\n",
      "\n",
      "‚Ä¢ Se recomienda implementar un ENSAMBLE de los top 3 modelos\n",
      "  para maximizar robustez y rendimiento\n",
      "\n",
      "10. CONSIDERACIONES PR√ÅCTICAS\n",
      "----------------------------------------\n",
      "\n",
      "Factores a considerar en la selecci√≥n:\n",
      "  1. Costo computacional vs ganancia en precisi√≥n\n",
      "  2. Robustez ante cambios en la distribuci√≥n de errores\n",
      "  3. Consistencia a trav√©s de horizontes de predicci√≥n\n",
      "  4. Facilidad de interpretaci√≥n y explicabilidad\n",
      "  5. Disponibilidad de recursos para implementaci√≥n\n",
      "\n",
      "Trade-offs identificados:\n",
      "  ‚Ä¢ Algunos modelos son especialistas en escenarios espec√≠ficos\n",
      "  ‚Ä¢ Otros modelos son generalistas con buen rendimiento global\n",
      "\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS COMPLETO. Resultados guardados en: resultados_analisis_completo/\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "‚úì An√°lisis completado exitosamente\n",
      "‚úì Todos los resultados guardados en: resultados_analisis_completo/\n",
      "================================================================================\n",
      "\n",
      "Archivos generados:\n",
      "  üìä An√°lisis de caracter√≠sticas del DGP\n",
      "  üìà Efectos de distribuci√≥n y varianza\n",
      "  üéØ An√°lisis de horizonte de predicci√≥n\n",
      "  üîÑ Interacciones complejas\n",
      "  üí™ M√©tricas de robustez\n",
      "  üìâ Tests de Diebold-Mariano\n",
      "  üë§ Perfiles individuales por modelo\n",
      "  üí° Recomendaciones estrat√©gicas\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import friedmanchisquare\n",
    "from itertools import combinations\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class DieboldMarianoTest:\n",
    "    \"\"\"\n",
    "    Implementaci√≥n del test de Diebold-Mariano para comparar pron√≥sticos\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def dm_test(errors1, errors2, h=1, crit=\"MSE\", power=2):\n",
    "        \"\"\"\n",
    "        Realiza el test de Diebold-Mariano\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        errors1 : array-like\n",
    "            Errores del primer modelo\n",
    "        errors2 : array-like\n",
    "            Errores del segundo modelo\n",
    "        h : int\n",
    "            Horizonte de predicci√≥n (para ajustar autocorrelaci√≥n)\n",
    "        crit : str\n",
    "            Criterio de p√©rdida: \"MSE\", \"MAE\", \"MAPE\"\n",
    "        power : int\n",
    "            Potencia para la funci√≥n de p√©rdida\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        dm_stat : float\n",
    "            Estad√≠stico DM\n",
    "        p_value : float\n",
    "            P-valor (two-tailed)\n",
    "        \"\"\"\n",
    "        errors1 = np.array(errors1)\n",
    "        errors2 = np.array(errors2)\n",
    "        \n",
    "        # Calcular diferencias de p√©rdida\n",
    "        if crit == \"MSE\":\n",
    "            loss_diff = errors1**2 - errors2**2\n",
    "        elif crit == \"MAE\":\n",
    "            loss_diff = np.abs(errors1) - np.abs(errors2)\n",
    "        elif crit == \"MAPE\":\n",
    "            loss_diff = np.abs(errors1) - np.abs(errors2)\n",
    "        else:\n",
    "            loss_diff = errors1**power - errors2**power\n",
    "        \n",
    "        # Media de las diferencias\n",
    "        mean_diff = np.mean(loss_diff)\n",
    "        \n",
    "        # Varianza de las diferencias (ajustada por autocorrelaci√≥n)\n",
    "        n = len(loss_diff)\n",
    "        \n",
    "        # Calcular varianza con correcci√≥n de Newey-West\n",
    "        gamma0 = np.var(loss_diff, ddof=1)\n",
    "        \n",
    "        if h > 1:\n",
    "            gamma_sum = 0\n",
    "            for k in range(1, h):\n",
    "                gamma_k = np.cov(loss_diff[:-k], loss_diff[k:])[0, 1]\n",
    "                gamma_sum += (1 - k/h) * gamma_k\n",
    "            variance = (gamma0 + 2 * gamma_sum) / n\n",
    "        else:\n",
    "            variance = gamma0 / n\n",
    "        \n",
    "        # Estad√≠stico DM\n",
    "        dm_stat = mean_diff / np.sqrt(variance) if variance > 0 else 0\n",
    "        \n",
    "        # P-valor (two-tailed)\n",
    "        p_value = 2 * (1 - stats.norm.cdf(np.abs(dm_stat)))\n",
    "        \n",
    "        return dm_stat, p_value\n",
    "\n",
    "\n",
    "class ModelPerformanceAnalyzer:\n",
    "    \"\"\"\n",
    "    Clase para an√°lisis exhaustivo de rendimiento de modelos de predicci√≥n\n",
    "    en diferentes escenarios de simulaci√≥n.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Inicializa el analizador cargando los datos de los tres escenarios.\n",
    "        \"\"\"\n",
    "        self.models = ['AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', \n",
    "                      'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
    "        \n",
    "        # Cargar datos con las rutas especificadas\n",
    "        print(\"Cargando datos...\")\n",
    "        \n",
    "        try:\n",
    "            self.df_estacionario = pd.read_excel(\"./Datos/estacionario.xlsx\")\n",
    "            self.df_estacionario['Escenario'] = 'Estacionario_Lineal'\n",
    "            print(f\"‚úì Estacionario: {len(self.df_estacionario)} filas\")\n",
    "            print(f\"  Columnas: {self.df_estacionario.columns.tolist()}\")\n",
    "            \n",
    "            self.df_no_estacionario = pd.read_excel(\"./Datos/no_estacionario.xlsx\")\n",
    "            self.df_no_estacionario['Escenario'] = 'No_Estacionario_Lineal'\n",
    "            print(f\"‚úì No Estacionario: {len(self.df_no_estacionario)} filas\")\n",
    "            print(f\"  Columnas: {self.df_no_estacionario.columns.tolist()}\")\n",
    "            \n",
    "            self.df_no_lineal = pd.read_excel(\"./Datos/no_lineal.xlsx\")\n",
    "            self.df_no_lineal['Escenario'] = 'No_Lineal'\n",
    "            print(f\"‚úì No Lineal: {len(self.df_no_lineal)} filas\")\n",
    "            print(f\"  Columnas: {self.df_no_lineal.columns.tolist()}\")\n",
    "            \n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"ERROR: No se encontr√≥ el archivo - {e}\")\n",
    "            print(\"Verifica que los archivos est√©n en la carpeta './Datos/'\")\n",
    "            raise\n",
    "        \n",
    "        # Estandarizar nombres de columnas\n",
    "        self._standardize_columns()\n",
    "        \n",
    "        # Combinar todos los datos\n",
    "        self.df_all = pd.concat([self.df_estacionario, self.df_no_estacionario, \n",
    "                                 self.df_no_lineal], ignore_index=True)\n",
    "        \n",
    "        # Convertir tipos de datos cr√≠ticos\n",
    "        self._convert_data_types()\n",
    "        \n",
    "        print(f\"\\n‚úì Datos combinados: {len(self.df_all)} observaciones totales\")\n",
    "        print(f\"‚úì Columnas finales: {self.df_all.columns.tolist()}\")\n",
    "        \n",
    "    def _standardize_columns(self):\n",
    "        \"\"\"Estandariza nombres de columnas entre datasets\"\"\"\n",
    "        # Para estacionario\n",
    "        if 'Varianza error' in self.df_estacionario.columns:\n",
    "            self.df_estacionario.rename(columns={'Varianza error': 'Varianza'}, inplace=True)\n",
    "        \n",
    "        # Agregar columna 'Tipo de Modelo' si no existe en estacionario\n",
    "        if 'Tipo de Modelo' not in self.df_estacionario.columns:\n",
    "            # Crear tipo de modelo basado en valores AR y MA\n",
    "            def create_model_type(row):\n",
    "                ar_vals = row.get('Valores de AR', '')\n",
    "                ma_vals = row.get('Valores MA', '')\n",
    "                \n",
    "                ar_str = str(ar_vals) if pd.notna(ar_vals) else ''\n",
    "                ma_str = str(ma_vals) if pd.notna(ma_vals) else ''\n",
    "                \n",
    "                # Contar √≥rdenes\n",
    "                ar_order = len([x for x in ar_str.split(',') if x.strip() and x.strip() != '[]']) if ar_str else 0\n",
    "                ma_order = len([x for x in ma_str.split(',') if x.strip() and x.strip() != '[]']) if ma_str else 0\n",
    "                \n",
    "                if ar_order > 0 and ma_order > 0:\n",
    "                    return f'ARMA({ar_order},{ma_order})'\n",
    "                elif ar_order > 0:\n",
    "                    return f'AR({ar_order})'\n",
    "                elif ma_order > 0:\n",
    "                    return f'MA({ma_order})'\n",
    "                else:\n",
    "                    return 'Unknown'\n",
    "            \n",
    "            self.df_estacionario['Tipo de Modelo'] = self.df_estacionario.apply(create_model_type, axis=1)\n",
    "        \n",
    "        # Para no estacionario\n",
    "        if 'Varianza error' in self.df_no_estacionario.columns:\n",
    "            self.df_no_estacionario.rename(columns={'Varianza error': 'Varianza'}, inplace=True)\n",
    "        \n",
    "        # Para no lineal\n",
    "        if 'Varianza error' in self.df_no_lineal.columns:\n",
    "            self.df_no_lineal.rename(columns={'Varianza error': 'Varianza'}, inplace=True)\n",
    "    \n",
    "    def _convert_data_types(self):\n",
    "        \"\"\"Convierte tipos de datos para evitar errores de comparaci√≥n\"\"\"\n",
    "        # Convertir 'Paso' a num√©rico\n",
    "        self.df_all['Paso'] = pd.to_numeric(self.df_all['Paso'], errors='coerce')\n",
    "        \n",
    "        # Convertir 'Varianza' a num√©rico\n",
    "        self.df_all['Varianza'] = pd.to_numeric(self.df_all['Varianza'], errors='coerce')\n",
    "        \n",
    "        # Convertir columnas de modelos a num√©rico\n",
    "        for model in self.models:\n",
    "            self.df_all[model] = pd.to_numeric(self.df_all[model], errors='coerce')\n",
    "        \n",
    "        # Eliminar filas con valores NaN cr√≠ticos\n",
    "        critical_cols = ['Paso', 'Varianza'] + self.models\n",
    "        self.df_all.dropna(subset=critical_cols, inplace=True)\n",
    "        \n",
    "        print(f\"‚úì Tipos de datos convertidos\")\n",
    "        print(f\"‚úì Filas despu√©s de limpieza: {len(self.df_all)}\")\n",
    "        \n",
    "    def generate_full_report(self, output_dir='resultados_analisis'):\n",
    "        \"\"\"\n",
    "        Genera reporte completo respondiendo a todas las preguntas clave.\n",
    "        \"\"\"\n",
    "        import os\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"INICIANDO AN√ÅLISIS COMPREHENSIVO DE MODELOS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Crear archivo de reporte\n",
    "        report_file = f\"{output_dir}/reporte_completo.txt\"\n",
    "        with open(report_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"REPORTE COMPLETO DE AN√ÅLISIS DE MODELOS DE PREDICCI√ìN\\n\")\n",
    "            f.write(\"=\"*80 + \"\\n\\n\")\n",
    "        \n",
    "        # 1. AN√ÅLISIS POR CARACTER√çSTICAS DEL DGP\n",
    "        print(\"\\n1. Analizando caracter√≠sticas del proceso generador...\")\n",
    "        self.analyze_dgp_characteristics(output_dir)\n",
    "        \n",
    "        # 2. AN√ÅLISIS POR DISTRIBUCI√ìN DE ERRORES\n",
    "        print(\"\\n2. Analizando efecto de distribuciones...\")\n",
    "        self.analyze_distribution_effects(output_dir)\n",
    "        \n",
    "        # 3. AN√ÅLISIS POR HORIZONTE DE PREDICCI√ìN\n",
    "        print(\"\\n3. Analizando horizonte de predicci√≥n...\")\n",
    "        self.analyze_horizon_effects(output_dir)\n",
    "        \n",
    "        # 4. AN√ÅLISIS DE INTERACCIONES COMPLEJAS\n",
    "        print(\"\\n4. Analizando interacciones complejas...\")\n",
    "        self.analyze_interactions(output_dir)\n",
    "        \n",
    "        # 5. AN√ÅLISIS DE ROBUSTEZ Y ESTABILIDAD\n",
    "        print(\"\\n5. Analizando robustez y estabilidad...\")\n",
    "        self.analyze_robustness(output_dir)\n",
    "        \n",
    "        # 6. AN√ÅLISIS DE SIGNIFICANCIA ESTAD√çSTICA (DIEBOLD-MARIANO)\n",
    "        print(\"\\n6. Realizando tests de Diebold-Mariano...\")\n",
    "        self.analyze_statistical_significance_dm(output_dir)\n",
    "        \n",
    "        # 7. AN√ÅLISIS POR MODELO INDIVIDUAL\n",
    "        print(\"\\n7. Generando perfiles por modelo...\")\n",
    "        self.analyze_individual_models(output_dir)\n",
    "        \n",
    "        # 8. RECOMENDACIONES Y CONCLUSIONES\n",
    "        print(\"\\n8. Generando recomendaciones...\")\n",
    "        self.generate_recommendations(output_dir)\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"AN√ÅLISIS COMPLETO. Resultados guardados en: {output_dir}/\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "    def analyze_dgp_characteristics(self, output_dir):\n",
    "        \"\"\"\n",
    "        1. AN√ÅLISIS DE CARACTER√çSTICAS DEL PROCESO GENERADOR\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        \n",
    "        # 1.1 Efecto de estacionaridad\n",
    "        print(\"  - Analizando efecto de estacionaridad...\")\n",
    "        for model in self.models:\n",
    "            est_mean = self.df_estacionario[model].mean()\n",
    "            no_est_mean = self.df_no_estacionario[model].mean()\n",
    "            diff = no_est_mean - est_mean\n",
    "            pct_change = (diff / est_mean) * 100 if est_mean != 0 else 0\n",
    "            \n",
    "            results.append({\n",
    "                'Modelo': model,\n",
    "                'ECRPS_Estacionario': est_mean,\n",
    "                'ECRPS_No_Estacionario': no_est_mean,\n",
    "                'Diferencia': diff,\n",
    "                'Cambio_%': pct_change\n",
    "            })\n",
    "        \n",
    "        df_estacionaridad = pd.DataFrame(results)\n",
    "        df_estacionaridad = df_estacionaridad.sort_values('Cambio_%')\n",
    "        df_estacionaridad.to_csv(f'{output_dir}/1_efecto_estacionaridad.csv', index=False)\n",
    "        \n",
    "        # Visualizaci√≥n\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # Gr√°fico de barras comparativas\n",
    "        x = np.arange(len(self.models))\n",
    "        width = 0.35\n",
    "        axes[0].bar(x - width/2, df_estacionaridad['ECRPS_Estacionario'], \n",
    "                   width, label='Estacionario', alpha=0.8)\n",
    "        axes[0].bar(x + width/2, df_estacionaridad['ECRPS_No_Estacionario'], \n",
    "                   width, label='No Estacionario', alpha=0.8)\n",
    "        axes[0].set_xlabel('Modelo')\n",
    "        axes[0].set_ylabel('ECRPS Promedio')\n",
    "        axes[0].set_title('Rendimiento: Estacionario vs No Estacionario')\n",
    "        axes[0].set_xticks(x)\n",
    "        axes[0].set_xticklabels(df_estacionaridad['Modelo'], rotation=45, ha='right')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Gr√°fico de cambio porcentual\n",
    "        colors = ['green' if x < 0 else 'red' for x in df_estacionaridad['Cambio_%']]\n",
    "        axes[1].barh(df_estacionaridad['Modelo'], df_estacionaridad['Cambio_%'], color=colors, alpha=0.7)\n",
    "        axes[1].set_xlabel('Cambio Porcentual (%)')\n",
    "        axes[1].set_title('Impacto de No Estacionaridad\\n(Negativo = Mejor en No Estacionario)')\n",
    "        axes[1].axvline(x=0, color='black', linestyle='--', linewidth=0.8)\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/1_estacionaridad.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # 1.2 Efecto de no linealidad\n",
    "        print(\"  - Analizando efecto de no linealidad...\")\n",
    "        results_nl = []\n",
    "        for model in self.models:\n",
    "            lin_mean = self.df_estacionario[model].mean()\n",
    "            nl_mean = self.df_no_lineal[model].mean()\n",
    "            diff = nl_mean - lin_mean\n",
    "            pct_change = (diff / lin_mean) * 100 if lin_mean != 0 else 0\n",
    "            \n",
    "            results_nl.append({\n",
    "                'Modelo': model,\n",
    "                'ECRPS_Lineal': lin_mean,\n",
    "                'ECRPS_No_Lineal': nl_mean,\n",
    "                'Diferencia': diff,\n",
    "                'Cambio_%': pct_change\n",
    "            })\n",
    "        \n",
    "        df_linealidad = pd.DataFrame(results_nl)\n",
    "        df_linealidad = df_linealidad.sort_values('Cambio_%')\n",
    "        df_linealidad.to_csv(f'{output_dir}/1_efecto_no_linealidad.csv', index=False)\n",
    "        \n",
    "        # Visualizaci√≥n no linealidad\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        x = np.arange(len(self.models))\n",
    "        axes[0].bar(x - width/2, df_linealidad['ECRPS_Lineal'], \n",
    "                   width, label='Lineal', alpha=0.8)\n",
    "        axes[0].bar(x + width/2, df_linealidad['ECRPS_No_Lineal'], \n",
    "                   width, label='No Lineal', alpha=0.8)\n",
    "        axes[0].set_xlabel('Modelo')\n",
    "        axes[0].set_ylabel('ECRPS Promedio')\n",
    "        axes[0].set_title('Rendimiento: Lineal vs No Lineal')\n",
    "        axes[0].set_xticks(x)\n",
    "        axes[0].set_xticklabels(df_linealidad['Modelo'], rotation=45, ha='right')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        colors = ['green' if x < 0 else 'red' for x in df_linealidad['Cambio_%']]\n",
    "        axes[1].barh(df_linealidad['Modelo'], df_linealidad['Cambio_%'], color=colors, alpha=0.7)\n",
    "        axes[1].set_xlabel('Cambio Porcentual (%)')\n",
    "        axes[1].set_title('Impacto de No Linealidad\\n(Negativo = Mejor en No Lineal)')\n",
    "        axes[1].axvline(x=0, color='black', linestyle='--', linewidth=0.8)\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/1_no_linealidad.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # 1.3 An√°lisis por tipo de modelo\n",
    "        print(\"  - Analizando efecto del tipo de modelo...\")\n",
    "        self.analyze_model_type_effect(output_dir)\n",
    "        \n",
    "    def analyze_model_type_effect(self, output_dir):\n",
    "        \"\"\"Analiza el efecto del tipo de modelo en el rendimiento\"\"\"\n",
    "        \n",
    "        # An√°lisis para datos estacionarios\n",
    "        if 'Tipo de Modelo' in self.df_estacionario.columns:\n",
    "            results_type = []\n",
    "            for model in self.models:\n",
    "                for model_type in self.df_estacionario['Tipo de Modelo'].unique():\n",
    "                    subset = self.df_estacionario[self.df_estacionario['Tipo de Modelo'] == model_type]\n",
    "                    if len(subset) > 0:\n",
    "                        results_type.append({\n",
    "                            'Modelo_Predictor': model,\n",
    "                            'Tipo_Proceso': model_type,\n",
    "                            'ECRPS_Mean': subset[model].mean(),\n",
    "                            'ECRPS_Std': subset[model].std(),\n",
    "                            'N_Obs': len(subset)\n",
    "                        })\n",
    "            \n",
    "            df_type = pd.DataFrame(results_type)\n",
    "            df_type.to_csv(f'{output_dir}/1_efecto_tipo_modelo.csv', index=False)\n",
    "            \n",
    "            # Crear heatmap para tipos m√°s comunes\n",
    "            common_types = df_type['Tipo_Proceso'].value_counts().head(10).index\n",
    "            df_type_filtered = df_type[df_type['Tipo_Proceso'].isin(common_types)]\n",
    "            \n",
    "            if len(df_type_filtered) > 0:\n",
    "                pivot = df_type_filtered.pivot_table(\n",
    "                    index='Modelo_Predictor', \n",
    "                    columns='Tipo_Proceso', \n",
    "                    values='ECRPS_Mean'\n",
    "                )\n",
    "                \n",
    "                fig, ax = plt.subplots(figsize=(14, 8))\n",
    "                sns.heatmap(pivot, annot=True, fmt='.4f', cmap='RdYlGn_r', ax=ax, \n",
    "                           cbar_kws={'label': 'ECRPS'})\n",
    "                ax.set_title('Rendimiento por Modelo Predictor y Tipo de Proceso', fontsize=14)\n",
    "                ax.set_xlabel('Tipo de Proceso')\n",
    "                ax.set_ylabel('Modelo Predictor')\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f'{output_dir}/1_heatmap_tipo_modelo.png', dpi=300, bbox_inches='tight')\n",
    "                plt.close()\n",
    "        \n",
    "    def analyze_distribution_effects(self, output_dir):\n",
    "        \"\"\"\n",
    "        2. AN√ÅLISIS DE EFECTOS DE DISTRIBUCI√ìN\n",
    "        \"\"\"\n",
    "        print(\"  - Analizando efectos de distribuciones...\")\n",
    "        \n",
    "        results_dist = []\n",
    "        for model in self.models:\n",
    "            for dist in self.df_all['Distribuci√≥n'].unique():\n",
    "                if pd.notna(dist):\n",
    "                    subset = self.df_all[self.df_all['Distribuci√≥n'] == dist]\n",
    "                    if len(subset) > 0:\n",
    "                        results_dist.append({\n",
    "                            'Modelo': model,\n",
    "                            'Distribuci√≥n': dist,\n",
    "                            'ECRPS_Mean': subset[model].mean(),\n",
    "                            'ECRPS_Std': subset[model].std(),\n",
    "                            'ECRPS_Min': subset[model].min(),\n",
    "                            'ECRPS_Max': subset[model].max()\n",
    "                        })\n",
    "        \n",
    "        df_dist = pd.DataFrame(results_dist)\n",
    "        df_dist.to_csv(f'{output_dir}/2_efecto_distribucion.csv', index=False)\n",
    "        \n",
    "        # Heatmap\n",
    "        if len(df_dist) > 0:\n",
    "            pivot = df_dist.pivot(index='Modelo', columns='Distribuci√≥n', values='ECRPS_Mean')\n",
    "            \n",
    "            fig, ax = plt.subplots(figsize=(10, 8))\n",
    "            sns.heatmap(pivot, annot=True, fmt='.4f', cmap='RdYlGn_r', ax=ax, cbar_kws={'label': 'ECRPS'})\n",
    "            ax.set_title('Rendimiento por Modelo y Distribuci√≥n', fontsize=14)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'{output_dir}/2_heatmap_distribucion.png', dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "        \n",
    "        # An√°lisis por varianza\n",
    "        print(\"  - Analizando efectos de varianza...\")\n",
    "        results_var = []\n",
    "        varianzas_unicas = sorted([v for v in self.df_all['Varianza'].unique() if pd.notna(v)])\n",
    "        \n",
    "        for model in self.models:\n",
    "            for var in varianzas_unicas:\n",
    "                subset = self.df_all[self.df_all['Varianza'] == var]\n",
    "                if len(subset) > 0:\n",
    "                    results_var.append({\n",
    "                        'Modelo': model,\n",
    "                        'Varianza': var,\n",
    "                        'ECRPS_Mean': subset[model].mean(),\n",
    "                        'ECRPS_Std': subset[model].std()\n",
    "                    })\n",
    "        \n",
    "        df_var = pd.DataFrame(results_var)\n",
    "        df_var.to_csv(f'{output_dir}/2_efecto_varianza.csv', index=False)\n",
    "        \n",
    "        # Gr√°fico de l√≠neas por varianza\n",
    "        if len(df_var) > 0:\n",
    "            fig, ax = plt.subplots(figsize=(12, 8))\n",
    "            for model in self.models:\n",
    "                data = df_var[df_var['Modelo'] == model].sort_values('Varianza')\n",
    "                if len(data) > 0:\n",
    "                    ax.plot(data['Varianza'], data['ECRPS_Mean'], marker='o', label=model, linewidth=2)\n",
    "            \n",
    "            ax.set_xlabel('Varianza', fontsize=12)\n",
    "            ax.set_ylabel('ECRPS Promedio', fontsize=12)\n",
    "            ax.set_title('Rendimiento seg√∫n Nivel de Varianza', fontsize=14)\n",
    "            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'{output_dir}/2_efecto_varianza.png', dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "        \n",
    "    def analyze_horizon_effects(self, output_dir):\n",
    "        \"\"\"\n",
    "        3. AN√ÅLISIS DE HORIZONTE DE PREDICCI√ìN\n",
    "        \"\"\"\n",
    "        print(\"  - Analizando deterioro por horizonte...\")\n",
    "        \n",
    "        results_horizon = []\n",
    "        pasos_unicos = sorted([p for p in self.df_all['Paso'].unique() if pd.notna(p)])\n",
    "        \n",
    "        for model in self.models:\n",
    "            for paso in pasos_unicos:\n",
    "                subset = self.df_all[self.df_all['Paso'] == paso]\n",
    "                if len(subset) > 0:\n",
    "                    mean_val = subset[model].mean()\n",
    "                    std_val = subset[model].std()\n",
    "                    cv_val = std_val / mean_val if mean_val != 0 and pd.notna(mean_val) else 0\n",
    "                    \n",
    "                    results_horizon.append({\n",
    "                        'Modelo': model,\n",
    "                        'Paso': int(paso),\n",
    "                        'ECRPS_Mean': mean_val,\n",
    "                        'ECRPS_Std': std_val,\n",
    "                        'ECRPS_CV': cv_val\n",
    "                    })\n",
    "        \n",
    "        df_horizon = pd.DataFrame(results_horizon)\n",
    "        df_horizon.to_csv(f'{output_dir}/3_efecto_horizonte.csv', index=False)\n",
    "        \n",
    "        # Gr√°fico de deterioro\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        \n",
    "        # ECRPS promedio por paso\n",
    "        for model in self.models:\n",
    "            data = df_horizon[df_horizon['Modelo'] == model].sort_values('Paso')\n",
    "            if len(data) > 0:\n",
    "                axes[0].plot(data['Paso'], data['ECRPS_Mean'], marker='o', label=model, linewidth=2)\n",
    "        \n",
    "        axes[0].set_xlabel('Paso de Predicci√≥n', fontsize=12)\n",
    "        axes[0].set_ylabel('ECRPS Promedio', fontsize=12)\n",
    "        axes[0].set_title('Deterioro del Rendimiento por Horizonte', fontsize=14)\n",
    "        axes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Tasa de deterioro\n",
    "        deterioro = []\n",
    "        for model in self.models:\n",
    "            data = df_horizon[df_horizon['Modelo'] == model].sort_values('Paso')\n",
    "            if len(data) >= 2:\n",
    "                paso_values = data['Paso'].tolist()\n",
    "                ecrps_paso1 = data.iloc[0]['ECRPS_Mean']\n",
    "                ecrps_paso_final = data.iloc[-1]['ECRPS_Mean']\n",
    "                \n",
    "                if pd.notna(ecrps_paso1) and pd.notna(ecrps_paso_final) and ecrps_paso1 != 0:\n",
    "                    tasa = ((ecrps_paso_final - ecrps_paso1) / ecrps_paso1) * 100\n",
    "                    deterioro.append({'Modelo': model, 'Deterioro_%': tasa})\n",
    "        \n",
    "        if deterioro:\n",
    "            df_deterioro = pd.DataFrame(deterioro).sort_values('Deterioro_%')\n",
    "            colors = ['green' if x < df_deterioro['Deterioro_%'].median() else 'red' \n",
    "                     for x in df_deterioro['Deterioro_%']]\n",
    "            axes[1].barh(df_deterioro['Modelo'], df_deterioro['Deterioro_%'], color=colors, alpha=0.7)\n",
    "            axes[1].set_xlabel(f'Deterioro Paso {pasos_unicos[0]}‚Üí{pasos_unicos[-1]} (%)', fontsize=12)\n",
    "            axes[1].set_title('Tasa de Deterioro por Modelo', fontsize=14)\n",
    "            axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/3_horizonte_prediccion.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # An√°lisis de consistencia de ranking\n",
    "        print(\"  - Analizando consistencia de ranking...\")\n",
    "        ranking_consistency = []\n",
    "        for paso in pasos_unicos:\n",
    "            subset = self.df_all[self.df_all['Paso'] == paso]\n",
    "            if len(subset) > 0:\n",
    "                ranks = subset[self.models].mean().rank()\n",
    "                rank_dict = ranks.to_dict()\n",
    "                rank_dict['Paso'] = int(paso)\n",
    "                ranking_consistency.append(rank_dict)\n",
    "        \n",
    "        df_ranks = pd.DataFrame(ranking_consistency)\n",
    "        df_ranks.to_csv(f'{output_dir}/3_ranking_por_paso.csv', index=False)\n",
    "        \n",
    "    def analyze_interactions(self, output_dir):\n",
    "        \"\"\"\n",
    "        4. AN√ÅLISIS DE INTERACCIONES COMPLEJAS\n",
    "        \"\"\"\n",
    "        print(\"  - Analizando interacciones Escenario √ó Distribuci√≥n...\")\n",
    "        \n",
    "        results_int = []\n",
    "        for model in self.models:\n",
    "            for escenario in self.df_all['Escenario'].unique():\n",
    "                for dist in self.df_all['Distribuci√≥n'].unique():\n",
    "                    subset = self.df_all[(self.df_all['Escenario'] == escenario) & \n",
    "                                        (self.df_all['Distribuci√≥n'] == dist)]\n",
    "                    if len(subset) > 0:\n",
    "                        results_int.append({\n",
    "                            'Modelo': model,\n",
    "                            'Escenario': escenario,\n",
    "                            'Distribuci√≥n': dist,\n",
    "                            'ECRPS_Mean': subset[model].mean()\n",
    "                        })\n",
    "        \n",
    "        df_int = pd.DataFrame(results_int)\n",
    "        df_int.to_csv(f'{output_dir}/4_interacciones.csv', index=False)\n",
    "        \n",
    "        # Heatmap de interacciones para cada modelo\n",
    "        for model in self.models[:3]:  # Solo primeros 3 por espacio\n",
    "            model_data = df_int[df_int['Modelo'] == model]\n",
    "            if len(model_data) > 0:\n",
    "                pivot = model_data.pivot(\n",
    "                    index='Escenario', columns='Distribuci√≥n', values='ECRPS_Mean')\n",
    "                \n",
    "                fig, ax = plt.subplots(figsize=(10, 6))\n",
    "                sns.heatmap(pivot, annot=True, fmt='.4f', cmap='RdYlGn_r', ax=ax)\n",
    "                ax.set_title(f'Interacci√≥n Escenario √ó Distribuci√≥n: {model}', fontsize=12)\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f'{output_dir}/4_interaccion_{model.replace(\" \", \"_\")}.png', \n",
    "                           dpi=300, bbox_inches='tight')\n",
    "                plt.close()\n",
    "        \n",
    "        # Interacci√≥n triple: Escenario √ó Varianza √ó Paso\n",
    "        print(\"  - Analizando interacci√≥n triple...\")\n",
    "        results_triple = []\n",
    "        \n",
    "        varianzas_unicas = sorted([v for v in self.df_all['Varianza'].unique() if pd.notna(v)])\n",
    "        pasos_unicos = sorted([p for p in self.df_all['Paso'].unique() if pd.notna(p)])\n",
    "        \n",
    "        for model in self.models:\n",
    "            for escenario in self.df_all['Escenario'].unique():\n",
    "                for var in varianzas_unicas:\n",
    "                    for paso in pasos_unicos:\n",
    "                        subset = self.df_all[\n",
    "                            (self.df_all['Escenario'] == escenario) & \n",
    "                            (self.df_all['Varianza'] == var) &\n",
    "                            (self.df_all['Paso'] == paso)\n",
    "                        ]\n",
    "                        if len(subset) > 0:\n",
    "                            results_triple.append({\n",
    "                                'Modelo': model,\n",
    "                                'Escenario': escenario,\n",
    "                                'Varianza': var,\n",
    "                                'Paso': int(paso),\n",
    "                                'ECRPS_Mean': subset[model].mean()\n",
    "                            })\n",
    "        \n",
    "        df_triple = pd.DataFrame(results_triple)\n",
    "        df_triple.to_csv(f'{output_dir}/4_interaccion_triple.csv', index=False)\n",
    "        \n",
    "    def analyze_robustness(self, output_dir):\n",
    "        \"\"\"\n",
    "        5. AN√ÅLISIS DE ROBUSTEZ Y ESTABILIDAD\n",
    "        \"\"\"\n",
    "        print(\"  - Calculando m√©tricas de robustez...\")\n",
    "        \n",
    "        results_robust = []\n",
    "        for model in self.models:\n",
    "            ecrps_values = self.df_all[model]\n",
    "            \n",
    "            results_robust.append({\n",
    "                'Modelo': model,\n",
    "                'ECRPS_Mean': ecrps_values.mean(),\n",
    "                'ECRPS_Std': ecrps_values.std(),\n",
    "                'ECRPS_CV': ecrps_values.std() / ecrps_values.mean() if ecrps_values.mean() != 0 else 0,\n",
    "                'ECRPS_Min': ecrps_values.min(),\n",
    "                'ECRPS_Q25': ecrps_values.quantile(0.25),\n",
    "                'ECRPS_Median': ecrps_values.median(),\n",
    "                'ECRPS_Q75': ecrps_values.quantile(0.75),\n",
    "                'ECRPS_Max': ecrps_values.max(),\n",
    "                'ECRPS_IQR': ecrps_values.quantile(0.75) - ecrps_values.quantile(0.25)\n",
    "            })\n",
    "        \n",
    "        df_robust = pd.DataFrame(results_robust)\n",
    "        df_robust = df_robust.sort_values('ECRPS_CV')\n",
    "        df_robust.to_csv(f'{output_dir}/5_robustez.csv', index=False)\n",
    "        \n",
    "        # Gr√°fico de robustez\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        \n",
    "        # Coeficiente de variaci√≥n\n",
    "        axes[0, 0].barh(df_robust['Modelo'], df_robust['ECRPS_CV'], alpha=0.7)\n",
    "        axes[0, 0].set_xlabel('Coeficiente de Variaci√≥n')\n",
    "        axes[0, 0].set_title('Estabilidad (Menor CV = M√°s Estable)')\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Rango intercuart√≠lico\n",
    "        axes[0, 1].barh(df_robust['Modelo'], df_robust['ECRPS_IQR'], alpha=0.7, color='coral')\n",
    "        axes[0, 1].set_xlabel('Rango Intercuart√≠lico')\n",
    "        axes[0, 1].set_title('Variabilidad (Menor IQR = M√°s Consistente)')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Boxplot comparativo\n",
    "        data_box = [self.df_all[model] for model in self.models]\n",
    "        bp = axes[1, 0].boxplot(data_box, labels=self.models, patch_artist=True)\n",
    "        for patch in bp['boxes']:\n",
    "            patch.set_facecolor('lightblue')\n",
    "        axes[1, 0].set_ylabel('ECRPS')\n",
    "        axes[1, 0].set_title('Distribuci√≥n de ECRPS por Modelo')\n",
    "        axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Scatter: Media vs Variabilidad\n",
    "        axes[1, 1].scatter(df_robust['ECRPS_Mean'], df_robust['ECRPS_Std'], \n",
    "                          s=100, alpha=0.6, c=range(len(df_robust)), cmap='viridis')\n",
    "        for idx, row in df_robust.iterrows():\n",
    "            axes[1, 1].annotate(row['Modelo'], \n",
    "                               (row['ECRPS_Mean'], row['ECRPS_Std']),\n",
    "                               fontsize=8, alpha=0.7)\n",
    "        axes[1, 1].set_xlabel('ECRPS Promedio')\n",
    "        axes[1, 1].set_ylabel('Desviaci√≥n Est√°ndar')\n",
    "        axes[1, 1].set_title('Trade-off Rendimiento vs Estabilidad')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/5_robustez.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # An√°lisis de peores casos\n",
    "        print(\"  - Identificando peores casos...\")\n",
    "        worst_cases = []\n",
    "        for model in self.models:\n",
    "            df_temp = self.df_all.copy()\n",
    "            df_temp['ECRPS'] = df_temp[model]\n",
    "            worst = df_temp.nlargest(10, 'ECRPS')[\n",
    "                ['Escenario', 'Tipo de Modelo', 'Distribuci√≥n', 'Varianza', 'Paso', 'ECRPS']\n",
    "            ]\n",
    "            worst['Modelo_Predictor'] = model\n",
    "            worst_cases.append(worst)\n",
    "        \n",
    "        df_worst = pd.concat(worst_cases, ignore_index=True)\n",
    "        df_worst.to_csv(f'{output_dir}/5_peores_casos.csv', index=False)\n",
    "        \n",
    "    def analyze_statistical_significance_dm(self, output_dir):\n",
    "        \"\"\"\n",
    "        6. AN√ÅLISIS DE SIGNIFICANCIA ESTAD√çSTICA CON DIEBOLD-MARIANO\n",
    "        \"\"\"\n",
    "        print(\"  - Realizando tests de Diebold-Mariano...\")\n",
    "        \n",
    "        # Test de Friedman por escenario (para comparaci√≥n general)\n",
    "        results_friedman = []\n",
    "        for escenario in self.df_all['Escenario'].unique():\n",
    "            subset = self.df_all[self.df_all['Escenario'] == escenario]\n",
    "            data_matrix = subset[self.models].values\n",
    "            \n",
    "            try:\n",
    "                statistic, p_value = friedmanchisquare(*[data_matrix[:, i] for i in range(len(self.models))])\n",
    "                \n",
    "                results_friedman.append({\n",
    "                    'Escenario': escenario,\n",
    "                    'Friedman_Statistic': statistic,\n",
    "                    'P_Value': p_value,\n",
    "                    'Significativo': 'S√≠' if p_value < 0.05 else 'No'\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"    Advertencia: Error en test de Friedman para {escenario}: {e}\")\n",
    "        \n",
    "        if results_friedman:\n",
    "            df_friedman = pd.DataFrame(results_friedman)\n",
    "            df_friedman.to_csv(f'{output_dir}/6_test_friedman.csv', index=False)\n",
    "        \n",
    "        # Tests de Diebold-Mariano pareados\n",
    "        print(\"  - Realizando tests pareados de Diebold-Mariano...\")\n",
    "        pairs = list(combinations(self.models, 2))\n",
    "        dm_results = []\n",
    "        \n",
    "        for model1, model2 in pairs:\n",
    "            # Calcular errores (usamos ECRPS directamente como m√©trica de p√©rdida)\n",
    "            errors1 = self.df_all[model1].values\n",
    "            errors2 = self.df_all[model2].values\n",
    "            \n",
    "            # Test de Diebold-Mariano\n",
    "            dm_stat, p_value = DieboldMarianoTest.dm_test(errors1, errors2, h=1, crit=\"MSE\")\n",
    "            \n",
    "            mean_diff = self.df_all[model1].mean() - self.df_all[model2].mean()\n",
    "            \n",
    "            # Determinar ganador\n",
    "            if p_value < 0.05:\n",
    "                if mean_diff < 0:\n",
    "                    ganador = model1\n",
    "                else:\n",
    "                    ganador = model2\n",
    "            else:\n",
    "                ganador = 'Empate'\n",
    "            \n",
    "            dm_results.append({\n",
    "                'Modelo_1': model1,\n",
    "                'Modelo_2': model2,\n",
    "                'Diferencia_Media': mean_diff,\n",
    "                'DM_Statistic': dm_stat,\n",
    "                'P_Value': p_value,\n",
    "                'Significativo_0.05': 'S√≠' if p_value < 0.05 else 'No',\n",
    "                'Significativo_0.01': 'S√≠' if p_value < 0.01 else 'No',\n",
    "                'Ganador': ganador\n",
    "            })\n",
    "        \n",
    "        df_dm = pd.DataFrame(dm_results)\n",
    "        df_dm = df_dm.sort_values('P_Value')\n",
    "        df_dm.to_csv(f'{output_dir}/6_tests_diebold_mariano.csv', index=False)\n",
    "        \n",
    "        # Matriz de p-valores (Diebold-Mariano)\n",
    "        print(\"  - Creando matriz de p-valores...\")\n",
    "        p_matrix = np.ones((len(self.models), len(self.models)))\n",
    "        for i, model1 in enumerate(self.models):\n",
    "            for j, model2 in enumerate(self.models):\n",
    "                if i != j:\n",
    "                    errors1 = self.df_all[model1].values\n",
    "                    errors2 = self.df_all[model2].values\n",
    "                    _, p_val = DieboldMarianoTest.dm_test(errors1, errors2, h=1, crit=\"MSE\")\n",
    "                    p_matrix[i, j] = p_val\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 10))\n",
    "        sns.heatmap(p_matrix, annot=True, fmt='.3f', cmap='RdYlGn', \n",
    "                   xticklabels=self.models, yticklabels=self.models, \n",
    "                   ax=ax, vmin=0, vmax=0.1, cbar_kws={'label': 'P-valor'})\n",
    "        ax.set_title('Matriz de P-valores (Test de Diebold-Mariano)\\nVerde = Diferencia Significativa', \n",
    "                    fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/6_matriz_pvalores_dm.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # Dominancia estad√≠stica con Diebold-Mariano\n",
    "        print(\"  - Analizando dominancia estad√≠stica...\")\n",
    "        dominance = []\n",
    "        for model in self.models:\n",
    "            wins = 0\n",
    "            losses = 0\n",
    "            ties = 0\n",
    "            for other_model in self.models:\n",
    "                if model != other_model:\n",
    "                    errors1 = self.df_all[model].values\n",
    "                    errors2 = self.df_all[other_model].values\n",
    "                    _, p_val = DieboldMarianoTest.dm_test(errors1, errors2, h=1, crit=\"MSE\")\n",
    "                    mean_diff = self.df_all[model].mean() - self.df_all[other_model].mean()\n",
    "                    \n",
    "                    if p_val < 0.05:\n",
    "                        if mean_diff < 0:  # modelo es mejor (menor ECRPS)\n",
    "                            wins += 1\n",
    "                        else:\n",
    "                            losses += 1\n",
    "                    else:\n",
    "                        ties += 1\n",
    "            \n",
    "            dominance.append({\n",
    "                'Modelo': model,\n",
    "                'Victorias_Significativas': wins,\n",
    "                'Derrotas_Significativas': losses,\n",
    "                'Empates': ties,\n",
    "                'Score_Neto': wins - losses\n",
    "            })\n",
    "        \n",
    "        df_dominance = pd.DataFrame(dominance)\n",
    "        df_dominance = df_dominance.sort_values('Score_Neto', ascending=False)\n",
    "        df_dominance.to_csv(f'{output_dir}/6_dominancia_estadistica_dm.csv', index=False)\n",
    "        \n",
    "        # Visualizaci√≥n de dominancia\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        x = np.arange(len(df_dominance))\n",
    "        width = 0.25\n",
    "        \n",
    "        ax.bar(x - width, df_dominance['Victorias_Significativas'], \n",
    "               width, label='Victorias', color='green', alpha=0.7)\n",
    "        ax.bar(x, df_dominance['Empates'], \n",
    "               width, label='Empates', color='gray', alpha=0.7)\n",
    "        ax.bar(x + width, df_dominance['Derrotas_Significativas'], \n",
    "               width, label='Derrotas', color='red', alpha=0.7)\n",
    "        \n",
    "        ax.set_xlabel('Modelo')\n",
    "        ax.set_ylabel('N√∫mero de Comparaciones')\n",
    "        ax.set_title('Dominancia Estad√≠stica (Test Diebold-Mariano)')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(df_dominance['Modelo'], rotation=45, ha='right')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/6_dominancia_dm.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # An√°lisis de Diebold-Mariano por escenario\n",
    "        print(\"  - Analizando DM por escenario...\")\n",
    "        dm_by_scenario = []\n",
    "        for escenario in self.df_all['Escenario'].unique():\n",
    "            subset = self.df_all[self.df_all['Escenario'] == escenario]\n",
    "            \n",
    "            for model1, model2 in combinations(self.models, 2):\n",
    "                errors1 = subset[model1].values\n",
    "                errors2 = subset[model2].values\n",
    "                \n",
    "                if len(errors1) > 0 and len(errors2) > 0:\n",
    "                    dm_stat, p_value = DieboldMarianoTest.dm_test(errors1, errors2, h=1, crit=\"MSE\")\n",
    "                    mean_diff = subset[model1].mean() - subset[model2].mean()\n",
    "                    \n",
    "                    dm_by_scenario.append({\n",
    "                        'Escenario': escenario,\n",
    "                        'Modelo_1': model1,\n",
    "                        'Modelo_2': model2,\n",
    "                        'DM_Statistic': dm_stat,\n",
    "                        'P_Value': p_value,\n",
    "                        'Diferencia_Media': mean_diff,\n",
    "                        'Significativo': 'S√≠' if p_value < 0.05 else 'No'\n",
    "                    })\n",
    "        \n",
    "        df_dm_scenario = pd.DataFrame(dm_by_scenario)\n",
    "        df_dm_scenario.to_csv(f'{output_dir}/6_dm_por_escenario.csv', index=False)\n",
    "    \n",
    "    def analyze_individual_models(self, output_dir):\n",
    "        \"\"\"\n",
    "        7. PERFILES INDIVIDUALES POR MODELO\n",
    "        \"\"\"\n",
    "        print(\"  - Generando perfiles individuales...\")\n",
    "        \n",
    "        for model in self.models:\n",
    "            print(f\"    > Analizando {model}...\")\n",
    "            \n",
    "            # Crear subdirectorio para el modelo\n",
    "            model_dir = f\"{output_dir}/perfiles_modelos/{model.replace(' ', '_')}\"\n",
    "            import os\n",
    "            os.makedirs(model_dir, exist_ok=True)\n",
    "            \n",
    "            # Reporte del modelo\n",
    "            report = []\n",
    "            report.append(f\"=\"*80)\n",
    "            report.append(f\"PERFIL DETALLADO: {model}\")\n",
    "            report.append(f\"=\"*80)\n",
    "            report.append(\"\")\n",
    "            \n",
    "            # Estad√≠sticas generales\n",
    "            report.append(\"1. ESTAD√çSTICAS GENERALES\")\n",
    "            report.append(\"-\" * 40)\n",
    "            report.append(f\"ECRPS Promedio Global: {self.df_all[model].mean():.6f}\")\n",
    "            report.append(f\"Desviaci√≥n Est√°ndar: {self.df_all[model].std():.6f}\")\n",
    "            cv = self.df_all[model].std()/self.df_all[model].mean() if self.df_all[model].mean() != 0 else 0\n",
    "            report.append(f\"Coeficiente de Variaci√≥n: {cv:.4f}\")\n",
    "            report.append(f\"M√≠nimo: {self.df_all[model].min():.6f}\")\n",
    "            report.append(f\"Mediana: {self.df_all[model].median():.6f}\")\n",
    "            report.append(f\"M√°ximo: {self.df_all[model].max():.6f}\")\n",
    "            report.append(\"\")\n",
    "            \n",
    "            # Ranking general\n",
    "            mean_scores = self.df_all[self.models].mean()\n",
    "            ranking = mean_scores.rank().astype(int)\n",
    "            report.append(f\"Ranking General: {ranking[model]}¬∞ de {len(self.models)}\")\n",
    "            report.append(\"\")\n",
    "            \n",
    "            # Mejor escenario\n",
    "            report.append(\"2. MEJORES ESCENARIOS\")\n",
    "            report.append(\"-\" * 40)\n",
    "            best_idx = self.df_all[model].idxmin()\n",
    "            best_row = self.df_all.loc[best_idx]\n",
    "            report.append(f\"Mejor ECRPS: {best_row[model]:.6f}\")\n",
    "            report.append(f\"  - Escenario: {best_row['Escenario']}\")\n",
    "            if 'Tipo de Modelo' in best_row:\n",
    "                report.append(f\"  - Tipo Modelo: {best_row['Tipo de Modelo']}\")\n",
    "            report.append(f\"  - Distribuci√≥n: {best_row['Distribuci√≥n']}\")\n",
    "            report.append(f\"  - Varianza: {best_row['Varianza']}\")\n",
    "            report.append(f\"  - Paso: {best_row['Paso']}\")\n",
    "            report.append(\"\")\n",
    "            \n",
    "            # Peor escenario\n",
    "            report.append(\"3. PEORES ESCENARIOS\")\n",
    "            report.append(\"-\" * 40)\n",
    "            worst_idx = self.df_all[model].idxmax()\n",
    "            worst_row = self.df_all.loc[worst_idx]\n",
    "            report.append(f\"Peor ECRPS: {worst_row[model]:.6f}\")\n",
    "            report.append(f\"  - Escenario: {worst_row['Escenario']}\")\n",
    "            if 'Tipo de Modelo' in worst_row:\n",
    "                report.append(f\"  - Tipo Modelo: {worst_row['Tipo de Modelo']}\")\n",
    "            report.append(f\"  - Distribuci√≥n: {worst_row['Distribuci√≥n']}\")\n",
    "            report.append(f\"  - Varianza: {worst_row['Varianza']}\")\n",
    "            report.append(f\"  - Paso: {worst_row['Paso']}\")\n",
    "            report.append(\"\")\n",
    "            \n",
    "            # Rendimiento por escenario\n",
    "            report.append(\"4. RENDIMIENTO POR ESCENARIO\")\n",
    "            report.append(\"-\" * 40)\n",
    "            for escenario in ['Estacionario_Lineal', 'No_Estacionario_Lineal', 'No_Lineal']:\n",
    "                subset = self.df_all[self.df_all['Escenario'] == escenario]\n",
    "                if len(subset) > 0:\n",
    "                    mean_val = subset[model].mean()\n",
    "                    rank = subset[self.models].mean().rank()[model]\n",
    "                    report.append(f\"{escenario}:\")\n",
    "                    report.append(f\"  ECRPS: {mean_val:.6f} (Ranking: {int(rank)}¬∞)\")\n",
    "            report.append(\"\")\n",
    "            \n",
    "            # Fortalezas y debilidades\n",
    "            report.append(\"5. FORTALEZAS Y DEBILIDADES\")\n",
    "            report.append(\"-\" * 40)\n",
    "            \n",
    "            # Por distribuci√≥n\n",
    "            report.append(\"Por Distribuci√≥n:\")\n",
    "            dist_performance = []\n",
    "            for dist in self.df_all['Distribuci√≥n'].unique():\n",
    "                subset = self.df_all[self.df_all['Distribuci√≥n'] == dist]\n",
    "                if len(subset) > 0:\n",
    "                    mean_val = subset[model].mean()\n",
    "                    rank = subset[self.models].mean().rank()[model]\n",
    "                    dist_performance.append((dist, mean_val, rank))\n",
    "            \n",
    "            if dist_performance:\n",
    "                dist_performance.sort(key=lambda x: x[2])\n",
    "                report.append(f\"  Mejor: {dist_performance[0][0]} (Ranking {int(dist_performance[0][2])}¬∞)\")\n",
    "                report.append(f\"  Peor: {dist_performance[-1][0]} (Ranking {int(dist_performance[-1][2])}¬∞)\")\n",
    "            report.append(\"\")\n",
    "            \n",
    "            # Por varianza\n",
    "            report.append(\"Por Varianza:\")\n",
    "            var_performance = []\n",
    "            for var in sorted(self.df_all['Varianza'].unique()):\n",
    "                subset = self.df_all[self.df_all['Varianza'] == var]\n",
    "                if len(subset) > 0:\n",
    "                    mean_val = subset[model].mean()\n",
    "                    rank = subset[self.models].mean().rank()[model]\n",
    "                    var_performance.append((var, mean_val, rank))\n",
    "            \n",
    "            if var_performance:\n",
    "                var_performance.sort(key=lambda x: x[2])\n",
    "                report.append(f\"  Mejor: Varianza {var_performance[0][0]} (Ranking {int(var_performance[0][2])}¬∞)\")\n",
    "                report.append(f\"  Peor: Varianza {var_performance[-1][0]} (Ranking {int(var_performance[-1][2])}¬∞)\")\n",
    "            report.append(\"\")\n",
    "            \n",
    "            # Comparaciones con Diebold-Mariano\n",
    "            report.append(\"6. COMPARACIONES ESTAD√çSTICAS (DIEBOLD-MARIANO)\")\n",
    "            report.append(\"-\" * 40)\n",
    "            \n",
    "            wins = 0\n",
    "            losses = 0\n",
    "            for other_model in self.models:\n",
    "                if model != other_model:\n",
    "                    errors1 = self.df_all[model].values\n",
    "                    errors2 = self.df_all[other_model].values\n",
    "                    _, p_val = DieboldMarianoTest.dm_test(errors1, errors2, h=1, crit=\"MSE\")\n",
    "                    mean_diff = self.df_all[model].mean() - self.df_all[other_model].mean()\n",
    "                    \n",
    "                    if p_val < 0.05:\n",
    "                        if mean_diff < 0:\n",
    "                            wins += 1\n",
    "                        else:\n",
    "                            losses += 1\n",
    "            \n",
    "            report.append(f\"Victorias significativas: {wins}\")\n",
    "            report.append(f\"Derrotas significativas: {losses}\")\n",
    "            report.append(f\"Score neto: {wins - losses}\")\n",
    "            report.append(\"\")\n",
    "            \n",
    "            # Guardar reporte\n",
    "            with open(f\"{model_dir}/perfil_{model.replace(' ', '_')}.txt\", 'w', encoding='utf-8') as f:\n",
    "                f.write('\\n'.join(report))\n",
    "            \n",
    "            # Visualizaciones del modelo\n",
    "            self._create_model_visualizations(model, model_dir)\n",
    "    \n",
    "    def _create_model_visualizations(self, model, model_dir):\n",
    "        \"\"\"Crea visualizaciones espec√≠ficas para un modelo\"\"\"\n",
    "        \n",
    "        # 1. Distribuci√≥n de ECRPS\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        \n",
    "        # Histograma\n",
    "        axes[0, 0].hist(self.df_all[model], bins=50, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "        axes[0, 0].axvline(self.df_all[model].mean(), color='red', linestyle='--', \n",
    "                          linewidth=2, label=f'Media: {self.df_all[model].mean():.4f}')\n",
    "        axes[0, 0].axvline(self.df_all[model].median(), color='green', linestyle='--', \n",
    "                          linewidth=2, label=f'Mediana: {self.df_all[model].median():.4f}')\n",
    "        axes[0, 0].set_xlabel('ECRPS')\n",
    "        axes[0, 0].set_ylabel('Frecuencia')\n",
    "        axes[0, 0].set_title(f'Distribuci√≥n de ECRPS - {model}')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Boxplot por escenario\n",
    "        data_by_scenario = [self.df_all[self.df_all['Escenario'] == esc][model] \n",
    "                           for esc in ['Estacionario_Lineal', 'No_Estacionario_Lineal', 'No_Lineal']]\n",
    "        bp = axes[0, 1].boxplot(data_by_scenario, labels=['Est. Lin.', 'No Est. Lin.', 'No Lin.'], \n",
    "                               patch_artist=True)\n",
    "        for patch, color in zip(bp['boxes'], ['lightblue', 'lightcoral', 'lightgreen']):\n",
    "            patch.set_facecolor(color)\n",
    "        axes[0, 1].set_ylabel('ECRPS')\n",
    "        axes[0, 1].set_title(f'ECRPS por Escenario - {model}')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Rendimiento por paso\n",
    "        paso_data = []\n",
    "        for p in sorted(self.df_all['Paso'].unique()):\n",
    "            subset = self.df_all[self.df_all['Paso'] == p]\n",
    "            if len(subset) > 0:\n",
    "                paso_data.append((p, subset[model].mean()))\n",
    "        \n",
    "        if paso_data:\n",
    "            pasos, means = zip(*paso_data)\n",
    "            axes[1, 0].plot(pasos, means, marker='o', linewidth=2, markersize=8, color='darkblue')\n",
    "            axes[1, 0].set_xlabel('Paso de Predicci√≥n')\n",
    "            axes[1, 0].set_ylabel('ECRPS Promedio')\n",
    "            axes[1, 0].set_title(f'Rendimiento por Horizonte - {model}')\n",
    "            axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Heatmap: Distribuci√≥n √ó Varianza\n",
    "        pivot_data = []\n",
    "        dist_labels = []\n",
    "        var_labels = sorted(self.df_all['Varianza'].unique())\n",
    "        \n",
    "        for dist in self.df_all['Distribuci√≥n'].unique():\n",
    "            row = []\n",
    "            for var in var_labels:\n",
    "                subset = self.df_all[(self.df_all['Distribuci√≥n'] == dist) & \n",
    "                                    (self.df_all['Varianza'] == var)]\n",
    "                if len(subset) > 0:\n",
    "                    row.append(subset[model].mean())\n",
    "                else:\n",
    "                    row.append(np.nan)\n",
    "            if not all(np.isnan(row)):\n",
    "                pivot_data.append(row)\n",
    "                dist_labels.append(dist)\n",
    "        \n",
    "        if pivot_data:\n",
    "            pivot_df = pd.DataFrame(pivot_data, index=dist_labels, columns=var_labels)\n",
    "            \n",
    "            sns.heatmap(pivot_df, annot=True, fmt='.4f', cmap='RdYlGn_r', ax=axes[1, 1],\n",
    "                       cbar_kws={'label': 'ECRPS'})\n",
    "            axes[1, 1].set_title(f'ECRPS: Distribuci√≥n √ó Varianza - {model}')\n",
    "            axes[1, 1].set_xlabel('Varianza')\n",
    "            axes[1, 1].set_ylabel('Distribuci√≥n')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{model_dir}/visualizaciones_{model.replace(\" \", \"_\")}.png', \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # 2. Comparaci√≥n con otros modelos\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        \n",
    "        means = self.df_all[self.models].mean().sort_values()\n",
    "        colors = ['red' if m == model else 'steelblue' for m in means.index]\n",
    "        bars = ax.barh(means.index, means.values, color=colors, alpha=0.7)\n",
    "        \n",
    "        # Destacar el modelo actual\n",
    "        for i, bar in enumerate(bars):\n",
    "            if means.index[i] == model:\n",
    "                bar.set_edgecolor('black')\n",
    "                bar.set_linewidth(3)\n",
    "        \n",
    "        ax.set_xlabel('ECRPS Promedio')\n",
    "        ax.set_title(f'Comparaci√≥n Global - {model} (Destacado en Rojo)')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{model_dir}/comparacion_{model.replace(\" \", \"_\")}.png', \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    def generate_recommendations(self, output_dir):\n",
    "        \"\"\"\n",
    "        8. GENERACI√ìN DE RECOMENDACIONES\n",
    "        \"\"\"\n",
    "        print(\"  - Generando recomendaciones estrat√©gicas...\")\n",
    "        \n",
    "        recommendations = []\n",
    "        recommendations.append(\"=\"*80)\n",
    "        recommendations.append(\"RECOMENDACIONES Y CONCLUSIONES\")\n",
    "        recommendations.append(\"=\"*80)\n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # 1. Modelo campe√≥n general\n",
    "        overall_best = self.df_all[self.models].mean().idxmin()\n",
    "        overall_worst = self.df_all[self.models].mean().idxmax()\n",
    "        \n",
    "        recommendations.append(\"1. MODELO CAMPE√ìN GENERAL\")\n",
    "        recommendations.append(\"-\" * 40)\n",
    "        recommendations.append(f\"Mejor rendimiento promedio: {overall_best}\")\n",
    "        recommendations.append(f\"ECRPS: {self.df_all[overall_best].mean():.6f}\")\n",
    "        recommendations.append(f\"Desviaci√≥n Est√°ndar: {self.df_all[overall_best].std():.6f}\")\n",
    "        recommendations.append(\"\")\n",
    "        recommendations.append(f\"Peor rendimiento promedio: {overall_worst}\")\n",
    "        recommendations.append(f\"ECRPS: {self.df_all[overall_worst].mean():.6f}\")\n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # 2. Modelos por escenario\n",
    "        recommendations.append(\"2. RECOMENDACIONES POR ESCENARIO\")\n",
    "        recommendations.append(\"-\" * 40)\n",
    "        \n",
    "        for escenario in ['Estacionario_Lineal', 'No_Estacionario_Lineal', 'No_Lineal']:\n",
    "            subset = self.df_all[self.df_all['Escenario'] == escenario]\n",
    "            if len(subset) > 0:\n",
    "                best_model = subset[self.models].mean().idxmin()\n",
    "                best_score = subset[best_model].mean()\n",
    "                \n",
    "                recommendations.append(f\"\\n{escenario}:\")\n",
    "                recommendations.append(f\"  Modelo Recomendado: {best_model}\")\n",
    "                recommendations.append(f\"  ECRPS Promedio: {best_score:.6f}\")\n",
    "        \n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # 3. Modelos por distribuci√≥n\n",
    "        recommendations.append(\"3. RECOMENDACIONES POR DISTRIBUCI√ìN DE ERRORES\")\n",
    "        recommendations.append(\"-\" * 40)\n",
    "        \n",
    "        for dist in self.df_all['Distribuci√≥n'].unique():\n",
    "            subset = self.df_all[self.df_all['Distribuci√≥n'] == dist]\n",
    "            if len(subset) > 0:\n",
    "                best_model = subset[self.models].mean().idxmin()\n",
    "                best_score = subset[best_model].mean()\n",
    "                \n",
    "                recommendations.append(f\"\\nDistribuci√≥n {dist}:\")\n",
    "                recommendations.append(f\"  Modelo Recomendado: {best_model}\")\n",
    "                recommendations.append(f\"  ECRPS Promedio: {best_score:.6f}\")\n",
    "        \n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # 4. Modelos m√°s robustos\n",
    "        recommendations.append(\"4. MODELOS M√ÅS ROBUSTOS (MENOR VARIABILIDAD)\")\n",
    "        recommendations.append(\"-\" * 40)\n",
    "        \n",
    "        cv_scores = {model: self.df_all[model].std() / self.df_all[model].mean() \n",
    "                    for model in self.models if self.df_all[model].mean() != 0}\n",
    "        cv_sorted = sorted(cv_scores.items(), key=lambda x: x[1])\n",
    "        \n",
    "        for i, (model, cv) in enumerate(cv_sorted[:3], 1):\n",
    "            recommendations.append(f\"{i}. {model}: CV = {cv:.4f}\")\n",
    "        \n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # 5. Modelos por horizonte\n",
    "        recommendations.append(\"5. RECOMENDACIONES POR HORIZONTE DE PREDICCI√ìN\")\n",
    "        recommendations.append(\"-\" * 40)\n",
    "        \n",
    "        pasos_unicos = sorted(self.df_all['Paso'].unique())\n",
    "        for paso in [pasos_unicos[0], pasos_unicos[len(pasos_unicos)//2], pasos_unicos[-1]]:\n",
    "            subset = self.df_all[self.df_all['Paso'] == paso]\n",
    "            if len(subset) > 0:\n",
    "                best_model = subset[self.models].mean().idxmin()\n",
    "                best_score = subset[best_model].mean()\n",
    "                \n",
    "                recommendations.append(f\"\\nPaso {paso}:\")\n",
    "                recommendations.append(f\"  Modelo Recomendado: {best_model}\")\n",
    "                recommendations.append(f\"  ECRPS Promedio: {best_score:.6f}\")\n",
    "        \n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # 6. Estrategia de ensamble\n",
    "        recommendations.append(\"6. ESTRATEGIA DE ENSAMBLE SUGERIDA\")\n",
    "        recommendations.append(\"-\" * 40)\n",
    "        \n",
    "        # Top 3 modelos complementarios\n",
    "        top3 = self.df_all[self.models].mean().nsmallest(3)\n",
    "        recommendations.append(\"Combinar los siguientes modelos:\")\n",
    "        for i, (model, score) in enumerate(top3.items(), 1):\n",
    "            recommendations.append(f\"{i}. {model} (ECRPS: {score:.6f})\")\n",
    "        \n",
    "        recommendations.append(\"\")\n",
    "        recommendations.append(\"Justificaci√≥n:\")\n",
    "        recommendations.append(\"  - Estos modelos muestran el mejor rendimiento promedio\")\n",
    "        recommendations.append(\"  - Un ensamble puede capturar fortalezas complementarias\")\n",
    "        recommendations.append(\"  - Reduce el riesgo de seleccionar un modelo sub√≥ptimo\")\n",
    "        \n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # 7. Modelos con dominancia estad√≠stica\n",
    "        recommendations.append(\"7. MODELOS CON DOMINANCIA ESTAD√çSTICA\")\n",
    "        recommendations.append(\"-\" * 40)\n",
    "        \n",
    "        dominance_scores = []\n",
    "        for model in self.models:\n",
    "            wins = 0\n",
    "            for other_model in self.models:\n",
    "                if model != other_model:\n",
    "                    errors1 = self.df_all[model].values\n",
    "                    errors2 = self.df_all[other_model].values\n",
    "                    _, p_val = DieboldMarianoTest.dm_test(errors1, errors2, h=1, crit=\"MSE\")\n",
    "                    mean_diff = self.df_all[model].mean() - self.df_all[other_model].mean()\n",
    "                    \n",
    "                    if p_val < 0.05 and mean_diff < 0:\n",
    "                        wins += 1\n",
    "            \n",
    "            dominance_scores.append((model, wins))\n",
    "        \n",
    "        dominance_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        recommendations.append(\"Modelos estad√≠sticamente superiores (test Diebold-Mariano):\")\n",
    "        for i, (model, wins) in enumerate(dominance_scores[:5], 1):\n",
    "            recommendations.append(f\"{i}. {model}: {wins} victorias significativas\")\n",
    "        \n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # 8. Reglas de decisi√≥n\n",
    "        recommendations.append(\"8. REGLAS DE DECISI√ìN SUGERIDAS\")\n",
    "        recommendations.append(\"-\" * 40)\n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # Reglas por escenario\n",
    "        for escenario in ['Estacionario_Lineal', 'No_Estacionario_Lineal', 'No_Lineal']:\n",
    "            subset = self.df_all[self.df_all['Escenario'] == escenario]\n",
    "            if len(subset) > 0:\n",
    "                top2 = subset[self.models].mean().nsmallest(2)\n",
    "                \n",
    "                if escenario == 'Estacionario_Lineal':\n",
    "                    recommendations.append(\"SI el proceso es ESTACIONARIO y LINEAL:\")\n",
    "                elif escenario == 'No_Estacionario_Lineal':\n",
    "                    recommendations.append(\"SI el proceso es NO ESTACIONARIO y LINEAL:\")\n",
    "                else:\n",
    "                    recommendations.append(\"SI el proceso es NO LINEAL:\")\n",
    "                \n",
    "                recommendations.append(f\"  ‚Üí Primera opci√≥n: {top2.index[0]}\")\n",
    "                recommendations.append(f\"  ‚Üí Segunda opci√≥n: {top2.index[1]}\")\n",
    "                recommendations.append(\"\")\n",
    "        \n",
    "        # Reglas por distribuci√≥n\n",
    "        recommendations.append(\"SI la distribuci√≥n de errores:\")\n",
    "        for dist in self.df_all['Distribuci√≥n'].unique():\n",
    "            subset = self.df_all[self.df_all['Distribuci√≥n'] == dist]\n",
    "            if len(subset) > 0:\n",
    "                best = subset[self.models].mean().idxmin()\n",
    "                recommendations.append(f\"  ‚Ä¢ Es {dist} ‚Üí Usar {best}\")\n",
    "        \n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # Reglas por varianza\n",
    "        recommendations.append(\"SI el nivel de varianza:\")\n",
    "        variances = sorted(self.df_all['Varianza'].unique())\n",
    "        if len(variances) >= 2:\n",
    "            low_var = variances[0]\n",
    "            high_var = variances[-1]\n",
    "            \n",
    "            subset_low = self.df_all[self.df_all['Varianza'] == low_var]\n",
    "            subset_high = self.df_all[self.df_all['Varianza'] == high_var]\n",
    "            \n",
    "            best_low = subset_low[self.models].mean().idxmin()\n",
    "            best_high = subset_high[self.models].mean().idxmin()\n",
    "            \n",
    "            recommendations.append(f\"  ‚Ä¢ Es bajo ({low_var}) ‚Üí Usar {best_low}\")\n",
    "            recommendations.append(f\"  ‚Ä¢ Es alto ({high_var}) ‚Üí Usar {best_high}\")\n",
    "        \n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # 9. Conclusiones finales\n",
    "        recommendations.append(\"9. CONCLUSIONES PRINCIPALES\")\n",
    "        recommendations.append(\"-\" * 40)\n",
    "        recommendations.append(\"\")\n",
    "        recommendations.append(f\"‚Ä¢ El modelo {overall_best} muestra el mejor rendimiento general\")\n",
    "        recommendations.append(f\"  con ECRPS promedio de {self.df_all[overall_best].mean():.6f}\")\n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # An√°lisis de robustez\n",
    "        most_robust = min(cv_scores.items(), key=lambda x: x[1])[0]\n",
    "        recommendations.append(f\"‚Ä¢ El modelo m√°s robusto (menor CV) es {most_robust}\")\n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # Comparaci√≥n estacionario vs no estacionario\n",
    "        est_best = self.df_estacionario[self.models].mean().idxmin()\n",
    "        no_est_best = self.df_no_estacionario[self.models].mean().idxmin()\n",
    "        \n",
    "        if est_best == no_est_best:\n",
    "            recommendations.append(f\"‚Ä¢ {est_best} es consistentemente superior en procesos\")\n",
    "            recommendations.append(\"  estacionarios y no estacionarios\")\n",
    "        else:\n",
    "            recommendations.append(f\"‚Ä¢ Para procesos estacionarios: preferir {est_best}\")\n",
    "            recommendations.append(f\"‚Ä¢ Para procesos no estacionarios: preferir {no_est_best}\")\n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # An√°lisis de no linealidad\n",
    "        nl_best = self.df_no_lineal[self.models].mean().idxmin()\n",
    "        recommendations.append(f\"‚Ä¢ Para procesos no lineales: {nl_best} es la mejor opci√≥n\")\n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # Recomendaci√≥n de ensamble\n",
    "        recommendations.append(\"‚Ä¢ Se recomienda implementar un ENSAMBLE de los top 3 modelos\")\n",
    "        recommendations.append(\"  para maximizar robustez y rendimiento\")\n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # Consideraciones pr√°cticas\n",
    "        recommendations.append(\"10. CONSIDERACIONES PR√ÅCTICAS\")\n",
    "        recommendations.append(\"-\" * 40)\n",
    "        recommendations.append(\"\")\n",
    "        recommendations.append(\"Factores a considerar en la selecci√≥n:\")\n",
    "        recommendations.append(\"  1. Costo computacional vs ganancia en precisi√≥n\")\n",
    "        recommendations.append(\"  2. Robustez ante cambios en la distribuci√≥n de errores\")\n",
    "        recommendations.append(\"  3. Consistencia a trav√©s de horizontes de predicci√≥n\")\n",
    "        recommendations.append(\"  4. Facilidad de interpretaci√≥n y explicabilidad\")\n",
    "        recommendations.append(\"  5. Disponibilidad de recursos para implementaci√≥n\")\n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # Trade-offs identificados\n",
    "        recommendations.append(\"Trade-offs identificados:\")\n",
    "        \n",
    "        # Mejor vs m√°s robusto\n",
    "        if overall_best != most_robust:\n",
    "            recommendations.append(f\"  ‚Ä¢ Rendimiento vs Robustez: {overall_best} (mejor) vs {most_robust} (m√°s robusto)\")\n",
    "        \n",
    "        # Modelos especializados\n",
    "        recommendations.append(\"  ‚Ä¢ Algunos modelos son especialistas en escenarios espec√≠ficos\")\n",
    "        recommendations.append(\"  ‚Ä¢ Otros modelos son generalistas con buen rendimiento global\")\n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # Guardar recomendaciones\n",
    "        with open(f'{output_dir}/8_recomendaciones.txt', 'w', encoding='utf-8') as f:\n",
    "            f.write('\\n'.join(recommendations))\n",
    "        \n",
    "        print('\\n'.join(recommendations))\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# C√ìDIGO DE EJECUCI√ìN PRINCIPAL\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Funci√≥n principal para ejecutar el an√°lisis completo\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"AN√ÅLISIS COMPREHENSIVO DE MODELOS DE PREDICCI√ìN PROBABIL√çSTICA\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # Crear analizador\n",
    "    try:\n",
    "        analyzer = ModelPerformanceAnalyzer()\n",
    "    except FileNotFoundError:\n",
    "        print(\"\\nERROR: No se encontraron los archivos de datos\")\n",
    "        print(\"Verifica que existan los siguientes archivos:\")\n",
    "        print(\"  - ./Datos/estacionario.xlsx\")\n",
    "        print(\"  - ./Datos/no_estacionario.xlsx\")\n",
    "        print(\"  - ./Datos/no_lineal.xlsx\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"\\nERROR al cargar datos: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return\n",
    "    \n",
    "    # Ejecutar an√°lisis completo\n",
    "    output_directory = 'resultados_analisis_completo'\n",
    "    \n",
    "    try:\n",
    "        analyzer.generate_full_report(output_dir=output_directory)\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"‚úì An√°lisis completado exitosamente\")\n",
    "        print(f\"‚úì Todos los resultados guardados en: {output_directory}/\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        print(\"Archivos generados:\")\n",
    "        print(\"  üìä An√°lisis de caracter√≠sticas del DGP\")\n",
    "        print(\"  üìà Efectos de distribuci√≥n y varianza\")\n",
    "        print(\"  üéØ An√°lisis de horizonte de predicci√≥n\")\n",
    "        print(\"  üîÑ Interacciones complejas\")\n",
    "        print(\"  üí™ M√©tricas de robustez\")\n",
    "        print(\"  üìâ Tests de Diebold-Mariano\")\n",
    "        print(\"  üë§ Perfiles individuales por modelo\")\n",
    "        print(\"  üí° Recomendaciones estrat√©gicas\")\n",
    "        print(\"\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå ERROR durante el an√°lisis: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee1784b",
   "metadata": {},
   "source": [
    "# Pre analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f559ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores √∫nicos encontrados en 'Tipo de Modelo':\n",
      "['AR(1)' 'AR(2)' 'MA(1)' 'MA(2)' 'ARMA(1,1)' 'ARMA(2,2)']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paso</th>\n",
       "      <th>Tipo de Modelo</th>\n",
       "      <th>Distribuci√≥n</th>\n",
       "      <th>Varianza error</th>\n",
       "      <th>AREPD</th>\n",
       "      <th>AV-MCPS</th>\n",
       "      <th>Block Bootstrapping</th>\n",
       "      <th>DeepAR</th>\n",
       "      <th>EnCQR-LSTM</th>\n",
       "      <th>LSPM</th>\n",
       "      <th>LSPMW</th>\n",
       "      <th>MCPS</th>\n",
       "      <th>Sieve Bootstrap</th>\n",
       "      <th>Mejor Modelo</th>\n",
       "      <th>Escenario</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AR(1)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.294667</td>\n",
       "      <td>0.355344</td>\n",
       "      <td>0.248447</td>\n",
       "      <td>0.263419</td>\n",
       "      <td>0.306622</td>\n",
       "      <td>0.440706</td>\n",
       "      <td>0.431452</td>\n",
       "      <td>0.285427</td>\n",
       "      <td>0.248691</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AR(1)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.604540</td>\n",
       "      <td>0.307449</td>\n",
       "      <td>0.254264</td>\n",
       "      <td>0.273001</td>\n",
       "      <td>0.565522</td>\n",
       "      <td>0.470424</td>\n",
       "      <td>0.474111</td>\n",
       "      <td>0.285430</td>\n",
       "      <td>0.254193</td>\n",
       "      <td>Sieve Bootstrap</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>AR(1)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.273622</td>\n",
       "      <td>0.276230</td>\n",
       "      <td>0.258388</td>\n",
       "      <td>0.315765</td>\n",
       "      <td>0.269452</td>\n",
       "      <td>0.520070</td>\n",
       "      <td>0.517876</td>\n",
       "      <td>0.337990</td>\n",
       "      <td>0.258039</td>\n",
       "      <td>Sieve Bootstrap</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>AR(1)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.261423</td>\n",
       "      <td>0.279697</td>\n",
       "      <td>0.254453</td>\n",
       "      <td>0.289443</td>\n",
       "      <td>0.269285</td>\n",
       "      <td>0.287989</td>\n",
       "      <td>0.288111</td>\n",
       "      <td>0.282999</td>\n",
       "      <td>0.254655</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>AR(1)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.626252</td>\n",
       "      <td>0.273680</td>\n",
       "      <td>0.254842</td>\n",
       "      <td>0.272827</td>\n",
       "      <td>0.639437</td>\n",
       "      <td>0.763960</td>\n",
       "      <td>0.753066</td>\n",
       "      <td>0.308347</td>\n",
       "      <td>0.254952</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>1</td>\n",
       "      <td>ARMA(2,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.082513</td>\n",
       "      <td>0.999066</td>\n",
       "      <td>0.953857</td>\n",
       "      <td>1.116455</td>\n",
       "      <td>1.053269</td>\n",
       "      <td>2.030504</td>\n",
       "      <td>2.165650</td>\n",
       "      <td>0.990087</td>\n",
       "      <td>0.954156</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>2</td>\n",
       "      <td>ARMA(2,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.903173</td>\n",
       "      <td>0.971148</td>\n",
       "      <td>0.954440</td>\n",
       "      <td>1.005615</td>\n",
       "      <td>1.518301</td>\n",
       "      <td>1.431610</td>\n",
       "      <td>1.522051</td>\n",
       "      <td>1.141614</td>\n",
       "      <td>0.954065</td>\n",
       "      <td>Sieve Bootstrap</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>3</td>\n",
       "      <td>ARMA(2,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.310542</td>\n",
       "      <td>1.021845</td>\n",
       "      <td>0.976235</td>\n",
       "      <td>1.002865</td>\n",
       "      <td>1.615073</td>\n",
       "      <td>1.026140</td>\n",
       "      <td>1.036051</td>\n",
       "      <td>1.484601</td>\n",
       "      <td>0.962417</td>\n",
       "      <td>Sieve Bootstrap</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>4</td>\n",
       "      <td>ARMA(2,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.324103</td>\n",
       "      <td>0.968827</td>\n",
       "      <td>0.961514</td>\n",
       "      <td>0.977739</td>\n",
       "      <td>1.072897</td>\n",
       "      <td>1.453428</td>\n",
       "      <td>1.530595</td>\n",
       "      <td>1.125230</td>\n",
       "      <td>0.960919</td>\n",
       "      <td>Sieve Bootstrap</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>5</td>\n",
       "      <td>ARMA(2,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.522689</td>\n",
       "      <td>1.011090</td>\n",
       "      <td>0.960863</td>\n",
       "      <td>1.001003</td>\n",
       "      <td>1.123328</td>\n",
       "      <td>1.061991</td>\n",
       "      <td>1.038016</td>\n",
       "      <td>1.179879</td>\n",
       "      <td>0.962942</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows √ó 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Paso Tipo de Modelo Distribuci√≥n  Varianza error     AREPD   AV-MCPS  \\\n",
       "0       1          AR(1)       normal             0.2  0.294667  0.355344   \n",
       "2       2          AR(1)       normal             0.2  0.604540  0.307449   \n",
       "4       3          AR(1)       normal             0.2  0.273622  0.276230   \n",
       "6       4          AR(1)       normal             0.2  0.261423  0.279697   \n",
       "8       5          AR(1)       normal             0.2  0.626252  0.273680   \n",
       "...   ...            ...          ...             ...       ...       ...   \n",
       "1309    1      ARMA(2,2)      mixture             3.0  1.082513  0.999066   \n",
       "1311    2      ARMA(2,2)      mixture             3.0  1.903173  0.971148   \n",
       "1313    3      ARMA(2,2)      mixture             3.0  2.310542  1.021845   \n",
       "1315    4      ARMA(2,2)      mixture             3.0  1.324103  0.968827   \n",
       "1317    5      ARMA(2,2)      mixture             3.0  1.522689  1.011090   \n",
       "\n",
       "      Block Bootstrapping    DeepAR  EnCQR-LSTM      LSPM     LSPMW      MCPS  \\\n",
       "0                0.248447  0.263419    0.306622  0.440706  0.431452  0.285427   \n",
       "2                0.254264  0.273001    0.565522  0.470424  0.474111  0.285430   \n",
       "4                0.258388  0.315765    0.269452  0.520070  0.517876  0.337990   \n",
       "6                0.254453  0.289443    0.269285  0.287989  0.288111  0.282999   \n",
       "8                0.254842  0.272827    0.639437  0.763960  0.753066  0.308347   \n",
       "...                   ...       ...         ...       ...       ...       ...   \n",
       "1309             0.953857  1.116455    1.053269  2.030504  2.165650  0.990087   \n",
       "1311             0.954440  1.005615    1.518301  1.431610  1.522051  1.141614   \n",
       "1313             0.976235  1.002865    1.615073  1.026140  1.036051  1.484601   \n",
       "1315             0.961514  0.977739    1.072897  1.453428  1.530595  1.125230   \n",
       "1317             0.960863  1.001003    1.123328  1.061991  1.038016  1.179879   \n",
       "\n",
       "      Sieve Bootstrap         Mejor Modelo            Escenario  \n",
       "0            0.248691  Block Bootstrapping  Estacionario_Lineal  \n",
       "2            0.254193      Sieve Bootstrap  Estacionario_Lineal  \n",
       "4            0.258039      Sieve Bootstrap  Estacionario_Lineal  \n",
       "6            0.254655  Block Bootstrapping  Estacionario_Lineal  \n",
       "8            0.254952  Block Bootstrapping  Estacionario_Lineal  \n",
       "...               ...                  ...                  ...  \n",
       "1309         0.954156  Block Bootstrapping  Estacionario_Lineal  \n",
       "1311         0.954065      Sieve Bootstrap  Estacionario_Lineal  \n",
       "1313         0.962417      Sieve Bootstrap  Estacionario_Lineal  \n",
       "1315         0.960919      Sieve Bootstrap  Estacionario_Lineal  \n",
       "1317         0.962942  Block Bootstrapping  Estacionario_Lineal  \n",
       "\n",
       "[600 rows x 15 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "    \n",
    "estacionario = pd.read_excel(\"./Datos/estacionario.xlsx\")\n",
    "\n",
    "estacionario = estacionario.drop_duplicates()\n",
    "estacionario = estacionario[estacionario[\"Paso\"] != \"Promedio\"]\n",
    "\n",
    "def determinar_tipo_modelo_mejorado(row):\n",
    "    \"\"\"\n",
    "    Determina el tipo de modelo (AR, MA, ARMA) y su orden a partir de los valores\n",
    "    en las columnas 'Valores de AR' y 'Valores MA'.\n",
    "    \"\"\"\n",
    "    ar_str = str(row['Valores de AR'])\n",
    "    ma_str = str(row['Valores MA'])\n",
    "    \n",
    "    # Expresi√≥n regular para encontrar n√∫meros (enteros o decimales, positivos o negativos)\n",
    "    regex_numeros = r'-?\\d+\\.?\\d*'\n",
    "    \n",
    "    # Cuenta cu√°ntos n√∫meros v√°lidos hay en cada string\n",
    "    p = len(re.findall(regex_numeros, ar_str))\n",
    "    q = len(re.findall(regex_numeros, ma_str))\n",
    "    \n",
    "    if p > 0 and q == 0:\n",
    "        return f\"AR({p})\"\n",
    "    elif p == 0 and q > 0:\n",
    "        return f\"MA({q})\"\n",
    "    elif p > 0 and q > 0:\n",
    "        return f\"ARMA({p},{q})\"\n",
    "    else:\n",
    "        return None # O \"Ruido Blanco\" si p=0 y q=0\n",
    "\n",
    "# Aplica la funci√≥n mejorada para crear la columna \"Tipo de Modelo\"\n",
    "estacionario['Tipo de Modelo'] = estacionario.apply(determinar_tipo_modelo_mejorado, axis=1)\n",
    "\n",
    "# Imprime los valores √∫nicos de la columna Tipo de modelo para verificar\n",
    "print(\"Valores √∫nicos encontrados en 'Tipo de Modelo':\")\n",
    "print(estacionario['Tipo de Modelo'].unique())\n",
    "\n",
    "# Ordena las columnas 'Paso' y 'Tipo de modelo' al inicio\n",
    "cols = estacionario.columns.tolist()\n",
    "# Aseguramos que las columnas existan antes de moverlas\n",
    "if 'Paso' in cols:\n",
    "    cols.insert(0, cols.pop(cols.index('Paso')))\n",
    "if 'Tipo de Modelo' in cols:\n",
    "    cols.insert(1, cols.pop(cols.index('Tipo de Modelo')))\n",
    "\n",
    "estacionario = estacionario.reindex(columns=cols)\n",
    "\n",
    "\n",
    "# Borra las columnas originales 'Valores de AR' y 'Valores MA'\n",
    "estacionario = estacionario.drop(columns=['Valores de AR', 'Valores MA'])\n",
    "estacionario[\"Escenario\"] = \"Estacionario_Lineal\"\n",
    "\n",
    "# Muestra el DataFrame resultante\n",
    "estacionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba423eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paso</th>\n",
       "      <th>Tipo de Modelo</th>\n",
       "      <th>Distribuci√≥n</th>\n",
       "      <th>Varianza error</th>\n",
       "      <th>AREPD</th>\n",
       "      <th>AV-MCPS</th>\n",
       "      <th>Block Bootstrapping</th>\n",
       "      <th>DeepAR</th>\n",
       "      <th>EnCQR-LSTM</th>\n",
       "      <th>LSPM</th>\n",
       "      <th>LSPMW</th>\n",
       "      <th>MCPS</th>\n",
       "      <th>Sieve Bootstrap</th>\n",
       "      <th>Mejor Modelo</th>\n",
       "      <th>Escenario</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ARIMA(0,1,0)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.860823</td>\n",
       "      <td>0.258474</td>\n",
       "      <td>0.253635</td>\n",
       "      <td>0.319481</td>\n",
       "      <td>0.488711</td>\n",
       "      <td>0.367279</td>\n",
       "      <td>0.360494</td>\n",
       "      <td>0.270816</td>\n",
       "      <td>0.273828</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ARIMA(0,1,0)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.244128</td>\n",
       "      <td>0.528968</td>\n",
       "      <td>0.275061</td>\n",
       "      <td>0.438099</td>\n",
       "      <td>0.322919</td>\n",
       "      <td>0.426187</td>\n",
       "      <td>0.430296</td>\n",
       "      <td>0.576792</td>\n",
       "      <td>0.272952</td>\n",
       "      <td>Sieve Bootstrap</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ARIMA(0,1,0)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.799818</td>\n",
       "      <td>0.864295</td>\n",
       "      <td>0.272406</td>\n",
       "      <td>0.291500</td>\n",
       "      <td>0.396481</td>\n",
       "      <td>0.642530</td>\n",
       "      <td>0.639134</td>\n",
       "      <td>0.269655</td>\n",
       "      <td>0.275661</td>\n",
       "      <td>MCPS</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ARIMA(0,1,0)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.912421</td>\n",
       "      <td>0.481159</td>\n",
       "      <td>0.255186</td>\n",
       "      <td>0.291577</td>\n",
       "      <td>0.495882</td>\n",
       "      <td>0.341570</td>\n",
       "      <td>0.341227</td>\n",
       "      <td>0.533788</td>\n",
       "      <td>0.275948</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ARIMA(0,1,0)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.822771</td>\n",
       "      <td>0.792130</td>\n",
       "      <td>0.257461</td>\n",
       "      <td>0.658698</td>\n",
       "      <td>1.291283</td>\n",
       "      <td>0.981902</td>\n",
       "      <td>0.969842</td>\n",
       "      <td>1.455485</td>\n",
       "      <td>0.338116</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>1</td>\n",
       "      <td>ARIMA(2,1,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>76.766114</td>\n",
       "      <td>5.668568</td>\n",
       "      <td>0.965836</td>\n",
       "      <td>7.254422</td>\n",
       "      <td>13.176312</td>\n",
       "      <td>4.421885</td>\n",
       "      <td>4.173484</td>\n",
       "      <td>20.231134</td>\n",
       "      <td>2.612414</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>2</td>\n",
       "      <td>ARIMA(2,1,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>80.630681</td>\n",
       "      <td>6.161741</td>\n",
       "      <td>0.974398</td>\n",
       "      <td>8.767931</td>\n",
       "      <td>9.287902</td>\n",
       "      <td>1.733689</td>\n",
       "      <td>1.596168</td>\n",
       "      <td>21.251698</td>\n",
       "      <td>1.956761</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>3</td>\n",
       "      <td>ARIMA(2,1,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>86.539087</td>\n",
       "      <td>10.452450</td>\n",
       "      <td>0.982561</td>\n",
       "      <td>24.631292</td>\n",
       "      <td>18.639842</td>\n",
       "      <td>6.195609</td>\n",
       "      <td>5.953120</td>\n",
       "      <td>23.480752</td>\n",
       "      <td>3.623684</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>4</td>\n",
       "      <td>ARIMA(2,1,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>93.057798</td>\n",
       "      <td>13.911382</td>\n",
       "      <td>0.958507</td>\n",
       "      <td>27.567728</td>\n",
       "      <td>17.852720</td>\n",
       "      <td>7.288522</td>\n",
       "      <td>6.952830</td>\n",
       "      <td>28.286507</td>\n",
       "      <td>4.681807</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>5</td>\n",
       "      <td>ARIMA(2,1,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>99.120410</td>\n",
       "      <td>13.899543</td>\n",
       "      <td>0.955009</td>\n",
       "      <td>17.064311</td>\n",
       "      <td>8.945594</td>\n",
       "      <td>4.716275</td>\n",
       "      <td>4.320090</td>\n",
       "      <td>31.056370</td>\n",
       "      <td>4.177879</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows √ó 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Paso Tipo de Modelo Distribuci√≥n  Varianza error      AREPD    AV-MCPS  \\\n",
       "0      1   ARIMA(0,1,0)       normal             0.2   1.860823   0.258474   \n",
       "1      2   ARIMA(0,1,0)       normal             0.2   1.244128   0.528968   \n",
       "2      3   ARIMA(0,1,0)       normal             0.2   1.799818   0.864295   \n",
       "3      4   ARIMA(0,1,0)       normal             0.2   1.912421   0.481159   \n",
       "4      5   ARIMA(0,1,0)       normal             0.2   2.822771   0.792130   \n",
       "..   ...            ...          ...             ...        ...        ...   \n",
       "834    1   ARIMA(2,1,2)      mixture             3.0  76.766114   5.668568   \n",
       "835    2   ARIMA(2,1,2)      mixture             3.0  80.630681   6.161741   \n",
       "836    3   ARIMA(2,1,2)      mixture             3.0  86.539087  10.452450   \n",
       "837    4   ARIMA(2,1,2)      mixture             3.0  93.057798  13.911382   \n",
       "838    5   ARIMA(2,1,2)      mixture             3.0  99.120410  13.899543   \n",
       "\n",
       "     Block Bootstrapping     DeepAR  EnCQR-LSTM      LSPM     LSPMW  \\\n",
       "0               0.253635   0.319481    0.488711  0.367279  0.360494   \n",
       "1               0.275061   0.438099    0.322919  0.426187  0.430296   \n",
       "2               0.272406   0.291500    0.396481  0.642530  0.639134   \n",
       "3               0.255186   0.291577    0.495882  0.341570  0.341227   \n",
       "4               0.257461   0.658698    1.291283  0.981902  0.969842   \n",
       "..                   ...        ...         ...       ...       ...   \n",
       "834             0.965836   7.254422   13.176312  4.421885  4.173484   \n",
       "835             0.974398   8.767931    9.287902  1.733689  1.596168   \n",
       "836             0.982561  24.631292   18.639842  6.195609  5.953120   \n",
       "837             0.958507  27.567728   17.852720  7.288522  6.952830   \n",
       "838             0.955009  17.064311    8.945594  4.716275  4.320090   \n",
       "\n",
       "          MCPS  Sieve Bootstrap         Mejor Modelo               Escenario  \n",
       "0     0.270816         0.273828  Block Bootstrapping  No_Estacionario_Lineal  \n",
       "1     0.576792         0.272952      Sieve Bootstrap  No_Estacionario_Lineal  \n",
       "2     0.269655         0.275661                 MCPS  No_Estacionario_Lineal  \n",
       "3     0.533788         0.275948  Block Bootstrapping  No_Estacionario_Lineal  \n",
       "4     1.455485         0.338116  Block Bootstrapping  No_Estacionario_Lineal  \n",
       "..         ...              ...                  ...                     ...  \n",
       "834  20.231134         2.612414  Block Bootstrapping  No_Estacionario_Lineal  \n",
       "835  21.251698         1.956761  Block Bootstrapping  No_Estacionario_Lineal  \n",
       "836  23.480752         3.623684  Block Bootstrapping  No_Estacionario_Lineal  \n",
       "837  28.286507         4.681807  Block Bootstrapping  No_Estacionario_Lineal  \n",
       "838  31.056370         4.177879  Block Bootstrapping  No_Estacionario_Lineal  \n",
       "\n",
       "[700 rows x 15 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_estacionario = pd.read_excel(\"./Datos/no_estacionario.xlsx\")\n",
    "no_estacionario.drop(columns=['Valores de AR', 'Valores MA'], inplace=True)\n",
    "no_estacionario[\"Escenario\"] = \"No_Estacionario_Lineal\"\n",
    "no_estacionario = no_estacionario[no_estacionario[\"Paso\"] != \"Promedio\"]\n",
    "no_estacionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e7ce88d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paso</th>\n",
       "      <th>Tipo de Modelo</th>\n",
       "      <th>Distribuci√≥n</th>\n",
       "      <th>Varianza error</th>\n",
       "      <th>AREPD</th>\n",
       "      <th>AV-MCPS</th>\n",
       "      <th>Block Bootstrapping</th>\n",
       "      <th>DeepAR</th>\n",
       "      <th>EnCQR-LSTM</th>\n",
       "      <th>LSPM</th>\n",
       "      <th>LSPMW</th>\n",
       "      <th>MCPS</th>\n",
       "      <th>Sieve Bootstrap</th>\n",
       "      <th>Mejor Modelo</th>\n",
       "      <th>Escenario</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>SETAR(2,1)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.257043</td>\n",
       "      <td>0.253521</td>\n",
       "      <td>0.251524</td>\n",
       "      <td>0.263274</td>\n",
       "      <td>0.257984</td>\n",
       "      <td>0.285655</td>\n",
       "      <td>0.282110</td>\n",
       "      <td>0.257015</td>\n",
       "      <td>0.251188</td>\n",
       "      <td>Sieve Bootstrap</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>SETAR(2,1)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.305723</td>\n",
       "      <td>0.383340</td>\n",
       "      <td>0.288529</td>\n",
       "      <td>0.297164</td>\n",
       "      <td>0.324101</td>\n",
       "      <td>0.316846</td>\n",
       "      <td>0.319675</td>\n",
       "      <td>0.347319</td>\n",
       "      <td>0.290022</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>SETAR(2,1)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.292055</td>\n",
       "      <td>0.258555</td>\n",
       "      <td>0.287265</td>\n",
       "      <td>0.275374</td>\n",
       "      <td>0.278881</td>\n",
       "      <td>0.320347</td>\n",
       "      <td>0.320181</td>\n",
       "      <td>0.270736</td>\n",
       "      <td>0.262183</td>\n",
       "      <td>AV-MCPS</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>SETAR(2,1)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.298469</td>\n",
       "      <td>0.269290</td>\n",
       "      <td>0.263802</td>\n",
       "      <td>0.255605</td>\n",
       "      <td>0.270449</td>\n",
       "      <td>0.290893</td>\n",
       "      <td>0.290581</td>\n",
       "      <td>0.329900</td>\n",
       "      <td>0.258734</td>\n",
       "      <td>DeepAR</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>SETAR(2,1)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.298007</td>\n",
       "      <td>0.368342</td>\n",
       "      <td>0.501202</td>\n",
       "      <td>0.323900</td>\n",
       "      <td>0.348571</td>\n",
       "      <td>0.326254</td>\n",
       "      <td>0.329508</td>\n",
       "      <td>0.423889</td>\n",
       "      <td>0.442319</td>\n",
       "      <td>AREPD</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>1</td>\n",
       "      <td>SETAR(2,3)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.164445</td>\n",
       "      <td>0.992519</td>\n",
       "      <td>0.962026</td>\n",
       "      <td>0.989297</td>\n",
       "      <td>1.046459</td>\n",
       "      <td>0.971555</td>\n",
       "      <td>1.076860</td>\n",
       "      <td>1.003262</td>\n",
       "      <td>0.961513</td>\n",
       "      <td>Sieve Bootstrap</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>2</td>\n",
       "      <td>SETAR(2,3)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.191648</td>\n",
       "      <td>1.034591</td>\n",
       "      <td>0.986347</td>\n",
       "      <td>1.077081</td>\n",
       "      <td>0.972263</td>\n",
       "      <td>0.957417</td>\n",
       "      <td>0.986525</td>\n",
       "      <td>0.963721</td>\n",
       "      <td>0.984072</td>\n",
       "      <td>LSPM</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>3</td>\n",
       "      <td>SETAR(2,3)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.193252</td>\n",
       "      <td>1.387456</td>\n",
       "      <td>1.012627</td>\n",
       "      <td>0.981861</td>\n",
       "      <td>0.955903</td>\n",
       "      <td>0.987603</td>\n",
       "      <td>0.977201</td>\n",
       "      <td>1.041540</td>\n",
       "      <td>1.009812</td>\n",
       "      <td>EnCQR-LSTM</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>4</td>\n",
       "      <td>SETAR(2,3)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.229893</td>\n",
       "      <td>1.182221</td>\n",
       "      <td>1.124342</td>\n",
       "      <td>0.983326</td>\n",
       "      <td>0.960088</td>\n",
       "      <td>1.036372</td>\n",
       "      <td>0.978720</td>\n",
       "      <td>1.029875</td>\n",
       "      <td>1.103310</td>\n",
       "      <td>EnCQR-LSTM</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>5</td>\n",
       "      <td>SETAR(2,3)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.149135</td>\n",
       "      <td>1.068179</td>\n",
       "      <td>1.046778</td>\n",
       "      <td>0.999776</td>\n",
       "      <td>0.961731</td>\n",
       "      <td>0.961208</td>\n",
       "      <td>0.977492</td>\n",
       "      <td>1.069917</td>\n",
       "      <td>1.059325</td>\n",
       "      <td>LSPM</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows √ó 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Paso Tipo de Modelo Distribuci√≥n  Varianza error     AREPD   AV-MCPS  \\\n",
       "0      1     SETAR(2,1)       normal             0.2  0.257043  0.253521   \n",
       "1      2     SETAR(2,1)       normal             0.2  0.305723  0.383340   \n",
       "2      3     SETAR(2,1)       normal             0.2  0.292055  0.258555   \n",
       "3      4     SETAR(2,1)       normal             0.2  0.298469  0.269290   \n",
       "4      5     SETAR(2,1)       normal             0.2  0.298007  0.368342   \n",
       "..   ...            ...          ...             ...       ...       ...   \n",
       "834    1     SETAR(2,3)      mixture             3.0  1.164445  0.992519   \n",
       "835    2     SETAR(2,3)      mixture             3.0  1.191648  1.034591   \n",
       "836    3     SETAR(2,3)      mixture             3.0  1.193252  1.387456   \n",
       "837    4     SETAR(2,3)      mixture             3.0  1.229893  1.182221   \n",
       "838    5     SETAR(2,3)      mixture             3.0  1.149135  1.068179   \n",
       "\n",
       "     Block Bootstrapping    DeepAR  EnCQR-LSTM      LSPM     LSPMW      MCPS  \\\n",
       "0               0.251524  0.263274    0.257984  0.285655  0.282110  0.257015   \n",
       "1               0.288529  0.297164    0.324101  0.316846  0.319675  0.347319   \n",
       "2               0.287265  0.275374    0.278881  0.320347  0.320181  0.270736   \n",
       "3               0.263802  0.255605    0.270449  0.290893  0.290581  0.329900   \n",
       "4               0.501202  0.323900    0.348571  0.326254  0.329508  0.423889   \n",
       "..                   ...       ...         ...       ...       ...       ...   \n",
       "834             0.962026  0.989297    1.046459  0.971555  1.076860  1.003262   \n",
       "835             0.986347  1.077081    0.972263  0.957417  0.986525  0.963721   \n",
       "836             1.012627  0.981861    0.955903  0.987603  0.977201  1.041540   \n",
       "837             1.124342  0.983326    0.960088  1.036372  0.978720  1.029875   \n",
       "838             1.046778  0.999776    0.961731  0.961208  0.977492  1.069917   \n",
       "\n",
       "     Sieve Bootstrap         Mejor Modelo               Escenario  \n",
       "0           0.251188      Sieve Bootstrap  No_Lineal_Estacionario  \n",
       "1           0.290022  Block Bootstrapping  No_Lineal_Estacionario  \n",
       "2           0.262183              AV-MCPS  No_Lineal_Estacionario  \n",
       "3           0.258734               DeepAR  No_Lineal_Estacionario  \n",
       "4           0.442319                AREPD  No_Lineal_Estacionario  \n",
       "..               ...                  ...                     ...  \n",
       "834         0.961513      Sieve Bootstrap  No_Lineal_Estacionario  \n",
       "835         0.984072                 LSPM  No_Lineal_Estacionario  \n",
       "836         1.009812           EnCQR-LSTM  No_Lineal_Estacionario  \n",
       "837         1.103310           EnCQR-LSTM  No_Lineal_Estacionario  \n",
       "838         1.059325                 LSPM  No_Lineal_Estacionario  \n",
       "\n",
       "[700 rows x 15 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_lineal = pd.read_excel(\"./Datos/no_lineal.xlsx\")\n",
    "no_lineal = no_lineal[no_lineal[\"Paso\"] != \"Promedio\"]\n",
    "no_lineal[\"Escenario\"] = \"No_Lineal_Estacionario\"\n",
    "no_lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f2c36b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Une los tres DataFrames en uno solo uno debajo de otro\n",
    "df_all = pd.concat([estacionario, no_estacionario, no_lineal], ignore_index=True)\n",
    "# Guarda el DataFrame combinado en un archivo Excel\n",
    "df_all.to_excel(\"./Datos/datos_combinados.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaf7f35",
   "metadata": {},
   "source": [
    "# Analisis con la correcion del profe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ac9a3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio 'resultados_completos_media_mediana' creado.\n",
      "‚úì Datos cargados exitosamente.\n",
      "\n",
      "================================================================================\n",
      "--- INICIANDO AN√ÅLISIS BASADO EN LA MEAN ---\n",
      "================================================================================\n",
      " -> 1. Analizando por estacionariedad (mean)...\n",
      " -> 2. Analizando por linealidad (mean)...\n",
      " -> 3. Generando heatmaps generales (mean)...\n",
      " -> 4. Analizando ECRPS vs Varianza (mean)...\n",
      " -> 5. Analizando ECRPS vs Paso (mean)...\n",
      " -> Analizando robustez y estabilidad (basado en mean)...\n",
      "\n",
      "================================================================================\n",
      "--- INICIANDO AN√ÅLISIS BASADO EN LA MEDIAN ---\n",
      "================================================================================\n",
      " -> 1. Analizando por estacionariedad (median)...\n",
      " -> 2. Analizando por linealidad (median)...\n",
      " -> 3. Generando heatmaps generales (median)...\n",
      " -> 4. Analizando ECRPS vs Varianza (median)...\n",
      " -> 5. Analizando ECRPS vs Paso (median)...\n",
      " -> Analizando robustez y estabilidad (basado en median)...\n",
      "\n",
      "================================================================================\n",
      "--- INICIANDO AN√ÅLISIS INDEPENDIENTES DE AGREGACI√ìN ---\n",
      "================================================================================\n",
      " -> Generando gr√°ficos de densidad individuales (an√°lisis √∫nico)...\n",
      " -> Realizando Test de Diebold-Mariano (an√°lisis √∫nico)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pleal\\AppData\\Local\\Temp\\ipykernel_16608\\4105642524.py:199: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  annot_matrix = result_matrix.applymap(lambda x: {1: 'Gana', -1: 'Pierde', 0: 'Empate'}[x])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì An√°lisis completo. Resultados guardados en la carpeta 'resultados_completos_media_mediana'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "from scipy import stats\n",
    "from itertools import combinations\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURACI√ìN\n",
    "# ============================================================================\n",
    "RUTA_DATOS = \"./Datos/datos_combinados.xlsx\"\n",
    "CARPETA_RESULTADOS = \"resultados_completos_media_mediana\"\n",
    "MODELOS = ['AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', \n",
    "           'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
    "ESCENARIOS_ESTACIONARIOS = ['Estacionario_Lineal', 'No_Lineal_Estacionario']\n",
    "ESCENARIOS_NO_ESTACIONARIOS = ['No_Estacionario_Lineal']\n",
    "ESCENARIOS_LINEALES = ['Estacionario_Lineal', 'No_Estacionario_Lineal']\n",
    "ESCENARIOS_NO_LINEALES = ['No_Lineal_Estacionario']\n",
    "\n",
    "# ============================================================================\n",
    "# CLASE PARA TEST ESTAD√çSTICO\n",
    "# ============================================================================\n",
    "class DieboldMarianoTest:\n",
    "    @staticmethod\n",
    "    def dm_test(errors1, errors2, h=1, power=2):\n",
    "        # Implementaci√≥n del test... (sin cambios)\n",
    "        errors1, errors2 = np.array(errors1), np.array(errors2)\n",
    "        loss_diff = (errors1**power) - (errors2**power)\n",
    "        mean_diff = np.mean(loss_diff)\n",
    "        n = len(loss_diff)\n",
    "        gamma0 = np.var(loss_diff, ddof=1)\n",
    "        if h > 1:\n",
    "            gamma_sum = sum((1 - k/h) * np.cov(loss_diff[:-k], loss_diff[k:])[0, 1] for k in range(1, h))\n",
    "            variance = (gamma0 + 2 * gamma_sum) / n\n",
    "        else:\n",
    "            variance = gamma0 / n\n",
    "        dm_stat = mean_diff / np.sqrt(variance) if variance > 0 else 0\n",
    "        p_value = 2 * (1 - stats.norm.cdf(np.abs(dm_stat)))\n",
    "        return dm_stat, p_value\n",
    "\n",
    "# ============================================================================\n",
    "# FUNCIONES DE AN√ÅLISIS Y VISUALIZACI√ìN (MODIFICADAS)\n",
    "# ============================================================================\n",
    "def crear_directorio_resultados(nombre_carpeta):\n",
    "    if not os.path.exists(nombre_carpeta):\n",
    "        os.makedirs(nombre_carpeta)\n",
    "        print(f\"Directorio '{nombre_carpeta}' creado.\")\n",
    "\n",
    "def guardar_grafico(nombre_archivo):\n",
    "    ruta_completa = os.path.join(CARPETA_RESULTADOS, nombre_archivo)\n",
    "    plt.savefig(ruta_completa, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def graficar_comparacion_barras(promedios1, promedios2, orden, etiqueta1, etiqueta2, agg_method, nombre_archivo):\n",
    "    \"\"\"Grafica la comparaci√≥n de barras para media o mediana.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    x = np.arange(len(orden))\n",
    "    width = 0.35\n",
    "    bars1 = ax.bar(x - width/2, promedios1[orden], width, label=etiqueta1, alpha=0.8, color='#3498db')\n",
    "    bars2 = ax.bar(x + width/2, promedios2[orden], width, label=etiqueta2, alpha=0.8, color='#e74c3c')\n",
    "    \n",
    "    ylabel = f'ECRPS {\"Promedio\" if agg_method == \"mean\" else \"Mediano\"} (menor es mejor)'\n",
    "    titulo = f'Comparaci√≥n de Desempe√±o ({agg_method.capitalize()})'\n",
    "    \n",
    "    ax.set_xlabel('Modelos', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel(ylabel, fontsize=12, fontweight='bold')\n",
    "    ax.set_title(titulo, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(orden, rotation=45, ha='right')\n",
    "    ax.legend(fontsize=11)\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    for bars in [bars1, bars2]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width() / 2., height, f'{height:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    guardar_grafico(nombre_archivo)\n",
    "\n",
    "def generar_heatmap(data, agg_method, titulo_sufijo, nombre_archivo, figsize=(14, 8)):\n",
    "    \"\"\"Genera un heatmap basado en media o mediana.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    cbar_label = f'ECRPS {\"Promedio\" if agg_method == \"mean\" else \"Mediano\"}'\n",
    "    titulo = f'Heatmap: {titulo_sufijo} ({agg_method.capitalize()})'\n",
    "    \n",
    "    sns.heatmap(data, annot=True, fmt='.3f', cmap='RdYlGn_r',\n",
    "                cbar_kws={'label': cbar_label},\n",
    "                linewidths=0.5, linecolor='gray', ax=ax)\n",
    "    ax.set_title(titulo, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Modelos', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel(data.index.name, fontsize=12, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    guardar_grafico(nombre_archivo)\n",
    "\n",
    "def graficar_evolucion_metrica_por_tipo(df, metrica_eje_x, agg_method, xlabel, nombre_archivo_sufijo):\n",
    "    \"\"\"Genera gr√°ficos de evoluci√≥n para cada tipo de modelo, usando media o mediana.\"\"\"\n",
    "    valores_unicos = sorted(df[metrica_eje_x].unique())\n",
    "    tipos_modelo_unicos = df['Tipo de Modelo'].unique()\n",
    "    \n",
    "    for tipo in tipos_modelo_unicos:\n",
    "        df_tipo = df[df['Tipo de Modelo'] == tipo]\n",
    "        fig, ax = plt.subplots(figsize=(12, 7))\n",
    "        \n",
    "        for modelo in MODELOS:\n",
    "            agregados = [df_tipo[df_tipo[metrica_eje_x] == val][modelo].agg(agg_method) for val in valores_unicos]\n",
    "            if not all(np.isnan(agregados)):\n",
    "                ax.plot(valores_unicos, agregados, marker='o', linewidth=2, markersize=8, label=modelo, alpha=0.8)\n",
    "        \n",
    "        ylabel = f'ECRPS {\"Promedio\" if agg_method == \"mean\" else \"Mediano\"}'\n",
    "        titulo = f'ECRPS vs {metrica_eje_x} ({agg_method.capitalize()}) - Tipo: {tipo}'\n",
    "        \n",
    "        ax.set_xlabel(xlabel, fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel(ylabel, fontsize=12, fontweight='bold')\n",
    "        ax.set_title(titulo, fontsize=13, fontweight='bold', pad=15)\n",
    "        ax.legend(fontsize=9, loc='best', ncol=2)\n",
    "        ax.grid(True, alpha=0.3, linestyle='--')\n",
    "        if metrica_eje_x == 'Paso':\n",
    "            ax.set_xticks(valores_unicos)\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        nombre_archivo_tipo = f'ecrps_vs_{nombre_archivo_sufijo}_tipo_{tipo.replace(\" \", \"_\").lower()}_{agg_method}.png'\n",
    "        guardar_grafico(nombre_archivo_tipo)\n",
    "\n",
    "def analizar_robustez_estabilidad(df, agg_method):\n",
    "    \"\"\"Calcula y grafica m√©tricas de robustez y estabilidad.\"\"\"\n",
    "    print(f\" -> Analizando robustez y estabilidad (basado en {agg_method})...\")\n",
    "    \n",
    "    if agg_method == 'mean':\n",
    "        # An√°lisis basado en la media (como antes)\n",
    "        metrics = [{'Modelo': m, 'Centralidad': df[m].mean(), 'Dispersion': df[m].std()} for m in MODELOS]\n",
    "        df_robust = pd.DataFrame(metrics)\n",
    "        label_centralidad = 'ECRPS Promedio (Rendimiento)'\n",
    "        label_dispersion = 'Desviaci√≥n Est√°ndar (Estabilidad)'\n",
    "        titulo_compromiso = 'Compromiso Rendimiento vs. Estabilidad (Media vs Std)'\n",
    "        \n",
    "    else: # agg_method == 'median'\n",
    "        # An√°lisis basado en la mediana (m√°s robusto a outliers)\n",
    "        metrics = [{'Modelo': m, 'Centralidad': df[m].median(), 'Dispersion': df[m].quantile(0.75) - df[m].quantile(0.25)} for m in MODELOS]\n",
    "        df_robust = pd.DataFrame(metrics)\n",
    "        label_centralidad = 'ECRPS Mediano (Rendimiento T√≠pico)'\n",
    "        label_dispersion = 'Rango Intercuart√≠lico (IQR - Estabilidad Robusta)'\n",
    "        titulo_compromiso = 'Compromiso Rendimiento vs. Estabilidad (Mediana vs IQR)'\n",
    "\n",
    "    # Gr√°fico de dispersi√≥n Rendimiento vs Estabilidad\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    sns.scatterplot(data=df_robust, x='Centralidad', y='Dispersion', hue='Modelo', s=150, alpha=0.8, ax=ax)\n",
    "    for _, row in df_robust.iterrows():\n",
    "        ax.text(row['Centralidad'], row['Dispersion'], row['Modelo'], fontsize=9, ha='left', va='bottom')\n",
    "    ax.set_xlabel(label_centralidad, fontweight='bold')\n",
    "    ax.set_ylabel(label_dispersion, fontweight='bold')\n",
    "    ax.set_title(titulo_compromiso, fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, linestyle='--', alpha=0.6)\n",
    "    ax.legend(title='Modelos', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    guardar_grafico(f\"6_compromiso_rendimiento_estabilidad_{agg_method}.png\")\n",
    "\n",
    "# --- Funciones que no dependen de la agregaci√≥n (se ejecutan una sola vez) ---\n",
    "def graficar_densidades_individuales(df):\n",
    "    \"\"\"Crea un gr√°fico de densidad individual para cada modelo.\"\"\"\n",
    "    print(\" -> Generando gr√°ficos de densidad individuales (an√°lisis √∫nico)...\")\n",
    "    all_ecrps_values = df[MODELOS].values.flatten()\n",
    "    xlim_max = np.quantile(all_ecrps_values[~np.isnan(all_ecrps_values)], 0.995)\n",
    "    for modelo in MODELOS:\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        sns.kdeplot(df[modelo].dropna(), fill=True, color='teal', ax=ax, lw=2.5)\n",
    "        mean_val, median_val = df[modelo].mean(), df[modelo].median()\n",
    "        ax.axvline(mean_val, color='red', linestyle='--', label=f'Media: {mean_val:.3f}')\n",
    "        ax.axvline(median_val, color='green', linestyle=':', label=f'Mediana: {median_val:.3f}')\n",
    "        ax.set_title(f'Distribuci√≥n del ECRPS - Modelo: {modelo}', fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel('ECRPS', fontweight='bold')\n",
    "        ax.set_ylabel('Densidad', fontweight='bold')\n",
    "        ax.set_xlim(left=0, right=xlim_max)\n",
    "        ax.legend()\n",
    "        ax.grid(True, linestyle='--', alpha=0.5)\n",
    "        plt.tight_layout()\n",
    "        guardar_grafico(f\"7_densidad_{modelo.replace(' ', '_').lower()}.png\")\n",
    "\n",
    "def realizar_test_diebold_mariano(df):\n",
    "    \"\"\"Realiza el test de Diebold-Mariano con correcci√≥n de Bonferroni.\"\"\"\n",
    "    print(\" -> Realizando Test de Diebold-Mariano (an√°lisis √∫nico)...\")\n",
    "    pairs = list(combinations(MODELOS, 2))\n",
    "    alpha_bonferroni = 0.05 / len(pairs)\n",
    "    dm_results = []\n",
    "    for m1, m2 in pairs:\n",
    "        e1, e2 = df[m1].dropna(), df[m2].dropna()\n",
    "        min_len = min(len(e1), len(e2))\n",
    "        _, p_value = DieboldMarianoTest.dm_test(e1[:min_len], e2[:min_len])\n",
    "        winner = 'Empate' if p_value >= alpha_bonferroni else (m1 if df[m1].mean() < df[m2].mean() else m2)\n",
    "        dm_results.append({'Modelo_1': m1, 'Modelo_2': m2, 'Ganador_Bonferroni': winner})\n",
    "    \n",
    "    # Heatmap de resultados\n",
    "    result_matrix = pd.DataFrame(index=MODELOS, columns=MODELOS, data=0)\n",
    "    for _, row in pd.DataFrame(dm_results).iterrows():\n",
    "        if row['Ganador_Bonferroni'] == row['Modelo_1']:\n",
    "            result_matrix.loc[row['Modelo_1'], row['Modelo_2']], result_matrix.loc[row['Modelo_2'], row['Modelo_1']] = 1, -1\n",
    "        elif row['Ganador_Bonferroni'] == row['Modelo_2']:\n",
    "            result_matrix.loc[row['Modelo_1'], row['Modelo_2']], result_matrix.loc[row['Modelo_2'], row['Modelo_1']] = -1, 1\n",
    "\n",
    "    annot_matrix = result_matrix.applymap(lambda x: {1: 'Gana', -1: 'Pierde', 0: 'Empate'}[x])\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    sns.heatmap(result_matrix.astype(float), annot=annot_matrix, fmt='s', cmap=['red', 'lightgray', 'green'], cbar=False, ax=ax)\n",
    "    ax.set_title('Resultado Test Diebold-Mariano (con correcci√≥n de Bonferroni)', fontweight='bold')\n",
    "    guardar_grafico(\"8_dm_heatmap_bonferroni.png\")\n",
    "\n",
    "# ============================================================================\n",
    "# SCRIPT PRINCIPAL\n",
    "# ============================================================================\n",
    "def main():\n",
    "    crear_directorio_resultados(CARPETA_RESULTADOS)\n",
    "    try:\n",
    "        df = pd.read_excel(RUTA_DATOS)\n",
    "        print(\"‚úì Datos cargados exitosamente.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: No se encontr√≥ el archivo en la ruta '{RUTA_DATOS}'.\")\n",
    "        return\n",
    "\n",
    "    # Bucle principal para ejecutar an√°lisis por media y mediana\n",
    "    for agg_method in ['mean', 'median']:\n",
    "        print(f\"\\n{'='*80}\\n--- INICIANDO AN√ÅLISIS BASADO EN LA {agg_method.upper()} ---\\n{'='*80}\")\n",
    "\n",
    "        # --- AN√ÅLISIS 1: ESTACIONARIEDAD ---\n",
    "        print(f\" -> 1. Analizando por estacionariedad ({agg_method})...\")\n",
    "        df_est = df[df['Escenario'].isin(ESCENARIOS_ESTACIONARIOS)]\n",
    "        df_no_est = df[df['Escenario'].isin(ESCENARIOS_NO_ESTACIONARIOS)]\n",
    "        agregados_est = df_est[MODELOS].agg(agg_method)\n",
    "        agregados_no_est = df_no_est[MODELOS].agg(agg_method)\n",
    "        orden_est = (agregados_est + agregados_no_est).sort_values().index\n",
    "        graficar_comparacion_barras(agregados_est, agregados_no_est, orden_est, 'Estacionarios', 'No Estacionarios', agg_method, f'1_comparacion_estacionariedad_{agg_method}.png')\n",
    "        \n",
    "        # --- AN√ÅLISIS 2: LINEALIDAD ---\n",
    "        print(f\" -> 2. Analizando por linealidad ({agg_method})...\")\n",
    "        df_lin = df[df['Escenario'].isin(ESCENARIOS_LINEALES)]\n",
    "        df_no_lin = df[df['Escenario'].isin(ESCENARIOS_NO_LINEALES)]\n",
    "        agregados_lin = df_lin[MODELOS].agg(agg_method)\n",
    "        agregados_no_lin = df_no_lin[MODELOS].agg(agg_method)\n",
    "        orden_lin = (agregados_lin + agregados_no_lin).sort_values().index\n",
    "        graficar_comparacion_barras(agregados_lin, agregados_no_lin, orden_lin, 'Lineales', 'No Lineales', agg_method, f'2_comparacion_linealidad_{agg_method}.png')\n",
    "\n",
    "        # --- AN√ÅLISIS 3: HEATMAPS GENERALES ---\n",
    "        print(f\" -> 3. Generando heatmaps generales ({agg_method})...\")\n",
    "        heatmap_esc_df = df.groupby('Escenario')[MODELOS].agg(agg_method)\n",
    "        generar_heatmap(heatmap_esc_df, agg_method, 'Desempe√±o por Escenario', f'3_heatmap_escenario_{agg_method}.png', figsize=(14, 6))\n",
    "        heatmap_dist_df = df.groupby('Distribuci√≥n')[MODELOS].agg(agg_method)\n",
    "        generar_heatmap(heatmap_dist_df, agg_method, 'Desempe√±o por Distribuci√≥n', f'3_heatmap_distribucion_{agg_method}.png')\n",
    "\n",
    "        # --- AN√ÅLISIS 4 & 5: EVOLUCI√ìN VS VARIANZA Y PASO ---\n",
    "        print(f\" -> 4. Analizando ECRPS vs Varianza ({agg_method})...\")\n",
    "        graficar_evolucion_metrica_por_tipo(df, 'Varianza error', agg_method, 'Varianza error', 'varianza')\n",
    "        print(f\" -> 5. Analizando ECRPS vs Paso ({agg_method})...\")\n",
    "        graficar_evolucion_metrica_por_tipo(df, 'Paso', agg_method, 'Paso (Horizonte)', 'paso')\n",
    "        \n",
    "        # --- AN√ÅLISIS 6: ROBUSTEZ Y ESTABILIDAD ---\n",
    "        analizar_robustez_estabilidad(df, agg_method)\n",
    "\n",
    "    # --- AN√ÅLISIS QUE SE EJECUTAN UNA SOLA VEZ ---\n",
    "    print(f\"\\n{'='*80}\\n--- INICIANDO AN√ÅLISIS INDEPENDIENTES DE AGREGACI√ìN ---\\n{'='*80}\")\n",
    "    # --- AN√ÅLISIS 7: DENSIDAD DE ERRORES ---\n",
    "    graficar_densidades_individuales(df)\n",
    "    \n",
    "    # --- AN√ÅLISIS 8: TEST DE DIEBOLD-MARIANO ---\n",
    "    realizar_test_diebold_mariano(df)\n",
    "    \n",
    "    print(f\"\\n‚úì An√°lisis completo. Resultados guardados en la carpeta '{CARPETA_RESULTADOS}'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08f9926",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76b3b6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio 'resultados_meta_modelo' creado.\n",
      "1. Cargando y preparando los datos para el meta-modelo...\n",
      "2. Realizando preprocesamiento (One-Hot Encoding)...\n",
      "\n",
      "3. Entrenando y evaluando los modelos recomendadores...\n",
      "\n",
      "--- Analizando: √Årbol de Decisi√≥n ---\n",
      "Precisi√≥n: 45.83%\n",
      "Reporte de Clasificaci√≥n:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              AREPD       0.00      0.00      0.00         9\n",
      "            AV-MCPS       0.00      0.00      0.00        22\n",
      "Block Bootstrapping       0.50      0.88      0.64       286\n",
      "             DeepAR       0.00      0.00      0.00        31\n",
      "         EnCQR-LSTM       0.18      0.29      0.22        35\n",
      "               LSPM       0.00      0.00      0.00        42\n",
      "              LSPMW       0.00      0.00      0.00        16\n",
      "               MCPS       0.00      0.00      0.00        20\n",
      "    Sieve Bootstrap       0.29      0.09      0.13       139\n",
      "\n",
      "           accuracy                           0.46       600\n",
      "          macro avg       0.11      0.14      0.11       600\n",
      "       weighted avg       0.32      0.46      0.35       600\n",
      "\n",
      "Generando visualizaciones...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pleal\\Documents\\Unal\\Tesis\\Codigo\\Prediccion_Probabilistica\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\pleal\\Documents\\Unal\\Tesis\\Codigo\\Prediccion_Probabilistica\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\pleal\\Documents\\Unal\\Tesis\\Codigo\\Prediccion_Probabilistica\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> Gr√°fico guardado en: resultados_meta_modelo\\feature_importance_√°rbol_de_decisi√≥n.png\n",
      " -> Gr√°fico guardado en: resultados_meta_modelo\\confusion_matrix_√°rbol_de_decisi√≥n.png\n",
      " -> Gr√°fico guardado en: resultados_meta_modelo\\decision_tree_visualization.png\n",
      "\n",
      "--- Analizando: Gradient Boosting ---\n",
      "Precisi√≥n: 43.17%\n",
      "Reporte de Clasificaci√≥n:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              AREPD       0.00      0.00      0.00         9\n",
      "            AV-MCPS       0.00      0.00      0.00        22\n",
      "Block Bootstrapping       0.58      0.71      0.64       286\n",
      "             DeepAR       0.21      0.26      0.23        31\n",
      "         EnCQR-LSTM       0.21      0.20      0.20        35\n",
      "               LSPM       0.18      0.10      0.12        42\n",
      "              LSPMW       0.12      0.06      0.08        16\n",
      "               MCPS       0.00      0.00      0.00        20\n",
      "    Sieve Bootstrap       0.30      0.26      0.28       139\n",
      "\n",
      "           accuracy                           0.43       600\n",
      "          macro avg       0.18      0.18      0.17       600\n",
      "       weighted avg       0.39      0.43      0.40       600\n",
      "\n",
      "Generando visualizaciones...\n",
      " -> Gr√°fico guardado en: resultados_meta_modelo\\feature_importance_gradient_boosting.png\n",
      " -> Gr√°fico guardado en: resultados_meta_modelo\\confusion_matrix_gradient_boosting.png\n",
      "\n",
      "‚úì An√°lisis del meta-modelo completado.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURACI√ìN\n",
    "# ============================================================================\n",
    "RUTA_DATOS = \"./Datos/datos_combinados.xlsx\"\n",
    "CARPETA_RESULTADOS = \"resultados_meta_modelo\"\n",
    "MODELOS = ['AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', \n",
    "           'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
    "\n",
    "# ============================================================================\n",
    "# FUNCIONES AUXILIARES\n",
    "# ============================================================================\n",
    "def crear_directorio_resultados(nombre_carpeta):\n",
    "    \"\"\"Crea la carpeta de resultados si no existe.\"\"\"\n",
    "    if not os.path.exists(nombre_carpeta):\n",
    "        os.makedirs(nombre_carpeta)\n",
    "        print(f\"Directorio '{nombre_carpeta}' creado.\")\n",
    "\n",
    "def guardar_grafico(nombre_archivo):\n",
    "    \"\"\"Guarda la figura actual en un archivo y la cierra.\"\"\"\n",
    "    ruta_completa = os.path.join(CARPETA_RESULTADOS, nombre_archivo)\n",
    "    plt.savefig(ruta_completa, dpi=300, bbox_inches='tight')\n",
    "    print(f\" -> Gr√°fico guardado en: {ruta_completa}\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_feature_importance(model, feature_names, model_name):\n",
    "    \"\"\"Grafica la importancia de las caracter√≠sticas del modelo.\"\"\"\n",
    "    importances = model.feature_importances_\n",
    "    df_importance = pd.DataFrame({\n",
    "        'Caracter√≠stica': feature_names,\n",
    "        'Importancia': importances\n",
    "    }).sort_values(by='Importancia', ascending=True)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    ax.barh(df_importance['Caracter√≠stica'], df_importance['Importancia'], color='steelblue')\n",
    "    ax.set_xlabel('Importancia')\n",
    "    ax.set_title(f'Importancia de Caracter√≠sticas - {model_name}')\n",
    "    plt.tight_layout()\n",
    "    guardar_grafico(f\"feature_importance_{model_name.replace(' ', '_').lower()}.png\")\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, model_name, class_labels):\n",
    "    \"\"\"Grafica la matriz de confusi√≥n normalizada.\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=class_labels, normalize='true')\n",
    "    df_cm = pd.DataFrame(cm, index=class_labels, columns=class_labels)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 12))\n",
    "    sns.heatmap(df_cm, annot=True, fmt='.2f', cmap='Blues', ax=ax)\n",
    "    ax.set_xlabel('Predicci√≥n del Recomendador', fontweight='bold')\n",
    "    ax.set_ylabel('Mejor Modelo Real', fontweight='bold')\n",
    "    ax.set_title(f'Matriz de Confusi√≥n Normalizada - {model_name}', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    guardar_grafico(f\"confusion_matrix_{model_name.replace(' ', '_').lower()}.png\")\n",
    "\n",
    "# ============================================================================\n",
    "# SCRIPT PRINCIPAL\n",
    "# ============================================================================\n",
    "def main():\n",
    "    \"\"\"Funci√≥n principal para crear y analizar el meta-modelo.\"\"\"\n",
    "    crear_directorio_resultados(CARPETA_RESULTADOS)\n",
    "    \n",
    "    # 1. Cargar y preparar los datos\n",
    "    print(\"1. Cargando y preparando los datos para el meta-modelo...\")\n",
    "    try:\n",
    "        df = pd.read_excel(RUTA_DATOS)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: No se encontr√≥ el archivo en la ruta '{RUTA_DATOS}'.\")\n",
    "        return\n",
    "\n",
    "    features = ['Escenario', 'Distribuci√≥n', 'Varianza error', 'Paso', 'Tipo de Modelo']\n",
    "    df_meta = df[features + MODELOS].copy()\n",
    "    df_meta['Mejor_Modelo'] = df_meta[MODELOS].idxmin(axis=1)\n",
    "    df_meta.dropna(subset=features, inplace=True)\n",
    "\n",
    "    X = df_meta[features]\n",
    "    y = df_meta['Mejor_Modelo']\n",
    "    \n",
    "    # 2. Preprocesamiento de caracter√≠sticas\n",
    "    print(\"2. Realizando preprocesamiento (One-Hot Encoding)...\")\n",
    "    categorical_features = ['Escenario', 'Distribuci√≥n', 'Tipo de Modelo']\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    X_encoded_cats = encoder.fit_transform(X[categorical_features])\n",
    "    \n",
    "    # Obtener los nombres de las nuevas columnas codificadas\n",
    "    encoded_feature_names = encoder.get_feature_names_out(categorical_features)\n",
    "    \n",
    "    # Combinar caracter√≠sticas num√©ricas y codificadas\n",
    "    X_numeric = X.drop(columns=categorical_features)\n",
    "    X_processed = np.hstack((X_numeric.values, X_encoded_cats))\n",
    "    \n",
    "    # Nombres de todas las caracter√≠sticas finales\n",
    "    final_feature_names = list(X_numeric.columns) + list(encoded_feature_names)\n",
    "\n",
    "    # 3. Dividir en conjuntos de entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_processed, y, test_size=0.3, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # 4. Definir y entrenar los modelos\n",
    "    print(\"\\n3. Entrenando y evaluando los modelos recomendadores...\")\n",
    "    models_to_train = {\n",
    "        \"√Årbol de Decisi√≥n\": DecisionTreeClassifier(max_depth=5, min_samples_leaf=20, random_state=42),\n",
    "        \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, max_depth=4, learning_rate=0.1, random_state=42)\n",
    "    }\n",
    "    \n",
    "    class_labels = sorted(y.unique())\n",
    "\n",
    "    for name, model in models_to_train.items():\n",
    "        print(f\"\\n--- Analizando: {name} ---\")\n",
    "        \n",
    "        # Entrenar\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predecir\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Evaluar y mostrar reporte\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Precisi√≥n: {accuracy:.2%}\")\n",
    "        print(\"Reporte de Clasificaci√≥n:\")\n",
    "        print(classification_report(y_test, y_pred, labels=class_labels))\n",
    "        \n",
    "        # Generar visualizaciones\n",
    "        print(\"Generando visualizaciones...\")\n",
    "        plot_feature_importance(model, final_feature_names, name)\n",
    "        plot_confusion_matrix(y_test, y_pred, name, class_labels)\n",
    "        \n",
    "        # Visualizar el √°rbol de decisi√≥n si corresponde\n",
    "        if name == \"√Årbol de Decisi√≥n\":\n",
    "            fig, ax = plt.subplots(figsize=(25, 15))\n",
    "            plot_tree(model, feature_names=final_feature_names, class_names=class_labels, \n",
    "                      filled=True, rounded=True, fontsize=10, ax=ax)\n",
    "            ax.set_title(\"√Årbol de Decisi√≥n para Recomendaci√≥n de Modelos\", fontsize=20)\n",
    "            guardar_grafico(\"decision_tree_visualization.png\")\n",
    "\n",
    "    print(\"\\n‚úì An√°lisis del meta-modelo completado.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a1dff2",
   "metadata": {},
   "source": [
    "# Analisis Escalonado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df7c3a4",
   "metadata": {},
   "source": [
    "## Analisis Especifico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a536136e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "‚ñà                                                                              ‚ñà\n",
      "‚ñà               AN√ÅLISIS DETALLADO DE MODELOS DE PREDICCI√ìN                     ‚ñà\n",
      "‚ñà                    CON GR√ÅFICAS INDIVIDUALES Y RANKING DM                     ‚ñà\n",
      "‚ñà                                                                              ‚ñà\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "‚úì Datos cargados: 2000 filas, 15 columnas\n",
      "\n",
      "Escenarios encontrados: ['Estacionario_Lineal' 'No_Estacionario_Lineal' 'No_Lineal_Estacionario']\n",
      "Modelos a analizar: 9\n",
      "\n",
      "================================================================================\n",
      "INICIANDO AN√ÅLISIS COMPLETO DE MODELOS\n",
      "================================================================================\n",
      "\n",
      "\n",
      "[1/27] Procesando...\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS: AREPD en escenario Estacionario_Lineal\n",
      "================================================================================\n",
      "\n",
      "üìä Generando: Rendimiento por Distribuci√≥n...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Varianza vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Importancia de Caracter√≠sticas...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Distribuci√≥n General del Rendimiento...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Outliers...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Heatmap de Configuraciones...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Estabilidad...\n",
      "‚úì Completado\n",
      "\n",
      "üíæ Guardando estad√≠sticas completas...\n",
      "‚úì Completado\n",
      "\n",
      "\n",
      "[2/27] Procesando...\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS: AV-MCPS en escenario Estacionario_Lineal\n",
      "================================================================================\n",
      "\n",
      "üìä Generando: Rendimiento por Distribuci√≥n...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Varianza vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Importancia de Caracter√≠sticas...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Distribuci√≥n General del Rendimiento...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Outliers...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Heatmap de Configuraciones...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Estabilidad...\n",
      "‚úì Completado\n",
      "\n",
      "üíæ Guardando estad√≠sticas completas...\n",
      "‚úì Completado\n",
      "\n",
      "\n",
      "[3/27] Procesando...\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS: Block Bootstrapping en escenario Estacionario_Lineal\n",
      "================================================================================\n",
      "\n",
      "üìä Generando: Rendimiento por Distribuci√≥n...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Varianza vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Importancia de Caracter√≠sticas...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Distribuci√≥n General del Rendimiento...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Outliers...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Heatmap de Configuraciones...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Estabilidad...\n",
      "‚úì Completado\n",
      "\n",
      "üíæ Guardando estad√≠sticas completas...\n",
      "‚úì Completado\n",
      "\n",
      "\n",
      "[4/27] Procesando...\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS: DeepAR en escenario Estacionario_Lineal\n",
      "================================================================================\n",
      "\n",
      "üìä Generando: Rendimiento por Distribuci√≥n...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Varianza vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Importancia de Caracter√≠sticas...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Distribuci√≥n General del Rendimiento...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Outliers...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Heatmap de Configuraciones...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Estabilidad...\n",
      "‚úì Completado\n",
      "\n",
      "üíæ Guardando estad√≠sticas completas...\n",
      "‚úì Completado\n",
      "\n",
      "\n",
      "[5/27] Procesando...\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS: EnCQR-LSTM en escenario Estacionario_Lineal\n",
      "================================================================================\n",
      "\n",
      "üìä Generando: Rendimiento por Distribuci√≥n...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Varianza vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Importancia de Caracter√≠sticas...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Distribuci√≥n General del Rendimiento...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Outliers...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Heatmap de Configuraciones...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Estabilidad...\n",
      "‚úì Completado\n",
      "\n",
      "üíæ Guardando estad√≠sticas completas...\n",
      "‚úì Completado\n",
      "\n",
      "\n",
      "[6/27] Procesando...\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS: LSPM en escenario Estacionario_Lineal\n",
      "================================================================================\n",
      "\n",
      "üìä Generando: Rendimiento por Distribuci√≥n...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Varianza vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Importancia de Caracter√≠sticas...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Distribuci√≥n General del Rendimiento...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Outliers...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Heatmap de Configuraciones...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Estabilidad...\n",
      "‚úì Completado\n",
      "\n",
      "üíæ Guardando estad√≠sticas completas...\n",
      "‚úì Completado\n",
      "\n",
      "\n",
      "[7/27] Procesando...\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS: LSPMW en escenario Estacionario_Lineal\n",
      "================================================================================\n",
      "\n",
      "üìä Generando: Rendimiento por Distribuci√≥n...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Varianza vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Importancia de Caracter√≠sticas...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Distribuci√≥n General del Rendimiento...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Outliers...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Heatmap de Configuraciones...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Estabilidad...\n",
      "‚úì Completado\n",
      "\n",
      "üíæ Guardando estad√≠sticas completas...\n",
      "‚úì Completado\n",
      "\n",
      "\n",
      "[8/27] Procesando...\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS: MCPS en escenario Estacionario_Lineal\n",
      "================================================================================\n",
      "\n",
      "üìä Generando: Rendimiento por Distribuci√≥n...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Varianza vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Importancia de Caracter√≠sticas...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Distribuci√≥n General del Rendimiento...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Outliers...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Heatmap de Configuraciones...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Estabilidad...\n",
      "‚úì Completado\n",
      "\n",
      "üíæ Guardando estad√≠sticas completas...\n",
      "‚úì Completado\n",
      "\n",
      "\n",
      "[9/27] Procesando...\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS: Sieve Bootstrap en escenario Estacionario_Lineal\n",
      "================================================================================\n",
      "\n",
      "üìä Generando: Rendimiento por Distribuci√≥n...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Varianza vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Importancia de Caracter√≠sticas...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Distribuci√≥n General del Rendimiento...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Outliers...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Heatmap de Configuraciones...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Estabilidad...\n",
      "‚úì Completado\n",
      "\n",
      "üíæ Guardando estad√≠sticas completas...\n",
      "‚úì Completado\n",
      "\n",
      "\n",
      "================================================================================\n",
      "GENERANDO RANKING PARA ESCENARIO: Estacionario_Lineal\n",
      "================================================================================\n",
      "\n",
      "üìä Generando ranking con Test Diebold-Mariano para Estacionario_Lineal...\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üèÜ RANKING (Test Diebold-Mariano):\n",
      "             Modelo  Victorias  Derrotas  Empates  Score  Pct_Victorias  Rank\n",
      "Block Bootstrapping          7         0        1      7           87.5     1\n",
      "    Sieve Bootstrap          7         0        1      7           87.5     2\n",
      "             DeepAR          6         2        0      4           75.0     3\n",
      "               MCPS          4         3        1      1           50.0     4\n",
      "            AV-MCPS          4         3        1      1           50.0     5\n",
      "         EnCQR-LSTM          3         5        0     -2           37.5     6\n",
      "              AREPD          1         6        1     -5           12.5     7\n",
      "               LSPM          1         6        1     -5           12.5     8\n",
      "              LSPMW          0         8        0     -8            0.0     9\n",
      "‚úÖ Ranking guardado: RANKING_Estacionario_Lineal.png\n",
      "\n",
      "\n",
      "[10/27] Procesando...\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS: AREPD en escenario No_Lineal_Estacionario\n",
      "================================================================================\n",
      "\n",
      "üìä Generando: Rendimiento por Distribuci√≥n...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Varianza vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Importancia de Caracter√≠sticas...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Distribuci√≥n General del Rendimiento...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Outliers...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Heatmap de Configuraciones...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Estabilidad...\n",
      "‚úì Completado\n",
      "\n",
      "üíæ Guardando estad√≠sticas completas...\n",
      "‚úì Completado\n",
      "\n",
      "\n",
      "[11/27] Procesando...\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS: AV-MCPS en escenario No_Lineal_Estacionario\n",
      "================================================================================\n",
      "\n",
      "üìä Generando: Rendimiento por Distribuci√≥n...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Varianza vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Importancia de Caracter√≠sticas...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Distribuci√≥n General del Rendimiento...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Outliers...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Heatmap de Configuraciones...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Estabilidad...\n",
      "‚úì Completado\n",
      "\n",
      "üíæ Guardando estad√≠sticas completas...\n",
      "‚úì Completado\n",
      "\n",
      "\n",
      "[12/27] Procesando...\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS: Block Bootstrapping en escenario No_Lineal_Estacionario\n",
      "================================================================================\n",
      "\n",
      "üìä Generando: Rendimiento por Distribuci√≥n...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Varianza vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Importancia de Caracter√≠sticas...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Distribuci√≥n General del Rendimiento...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Outliers...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Heatmap de Configuraciones...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Estabilidad...\n",
      "‚úì Completado\n",
      "\n",
      "üíæ Guardando estad√≠sticas completas...\n",
      "‚úì Completado\n",
      "\n",
      "\n",
      "[13/27] Procesando...\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS: DeepAR en escenario No_Lineal_Estacionario\n",
      "================================================================================\n",
      "\n",
      "üìä Generando: Rendimiento por Distribuci√≥n...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Varianza vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Importancia de Caracter√≠sticas...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Distribuci√≥n General del Rendimiento...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Outliers...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Heatmap de Configuraciones...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Estabilidad...\n",
      "‚úì Completado\n",
      "\n",
      "üíæ Guardando estad√≠sticas completas...\n",
      "‚úì Completado\n",
      "\n",
      "\n",
      "[14/27] Procesando...\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS: EnCQR-LSTM en escenario No_Lineal_Estacionario\n",
      "================================================================================\n",
      "\n",
      "üìä Generando: Rendimiento por Distribuci√≥n...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Varianza vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Importancia de Caracter√≠sticas...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Distribuci√≥n General del Rendimiento...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Outliers...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Heatmap de Configuraciones...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Estabilidad...\n",
      "‚úì Completado\n",
      "\n",
      "üíæ Guardando estad√≠sticas completas...\n",
      "‚úì Completado\n",
      "\n",
      "\n",
      "[15/27] Procesando...\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS: LSPM en escenario No_Lineal_Estacionario\n",
      "================================================================================\n",
      "\n",
      "üìä Generando: Rendimiento por Distribuci√≥n...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Varianza vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Importancia de Caracter√≠sticas...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Distribuci√≥n General del Rendimiento...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Outliers...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Heatmap de Configuraciones...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Estabilidad...\n",
      "‚úì Completado\n",
      "\n",
      "üíæ Guardando estad√≠sticas completas...\n",
      "‚úì Completado\n",
      "\n",
      "\n",
      "[16/27] Procesando...\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS: LSPMW en escenario No_Lineal_Estacionario\n",
      "================================================================================\n",
      "\n",
      "üìä Generando: Rendimiento por Distribuci√≥n...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Varianza vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Importancia de Caracter√≠sticas...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Distribuci√≥n General del Rendimiento...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Outliers...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Heatmap de Configuraciones...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Estabilidad...\n",
      "‚úì Completado\n",
      "\n",
      "üíæ Guardando estad√≠sticas completas...\n",
      "‚úì Completado\n",
      "\n",
      "\n",
      "[17/27] Procesando...\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS: MCPS en escenario No_Lineal_Estacionario\n",
      "================================================================================\n",
      "\n",
      "üìä Generando: Rendimiento por Distribuci√≥n...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Varianza vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Importancia de Caracter√≠sticas...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Distribuci√≥n General del Rendimiento...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Outliers...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Heatmap de Configuraciones...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Estabilidad...\n",
      "‚úì Completado\n",
      "\n",
      "üíæ Guardando estad√≠sticas completas...\n",
      "‚úì Completado\n",
      "\n",
      "\n",
      "[18/27] Procesando...\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS: Sieve Bootstrap en escenario No_Lineal_Estacionario\n",
      "================================================================================\n",
      "\n",
      "üìä Generando: Rendimiento por Distribuci√≥n...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Varianza vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Importancia de Caracter√≠sticas...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Distribuci√≥n General del Rendimiento...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Outliers...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Heatmap de Configuraciones...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Estabilidad...\n",
      "‚úì Completado\n",
      "\n",
      "üíæ Guardando estad√≠sticas completas...\n",
      "‚úì Completado\n",
      "\n",
      "\n",
      "================================================================================\n",
      "GENERANDO RANKING PARA ESCENARIO: No_Lineal_Estacionario\n",
      "================================================================================\n",
      "\n",
      "üìä Generando ranking con Test Diebold-Mariano para No_Lineal_Estacionario...\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üèÜ RANKING (Test Diebold-Mariano):\n",
      "             Modelo  Victorias  Derrotas  Empates  Score  Pct_Victorias  Rank\n",
      "Block Bootstrapping          6         0        2      6           75.0     1\n",
      "    Sieve Bootstrap          6         0        2      6           75.0     2\n",
      "             DeepAR          4         0        4      4           50.0     3\n",
      "         EnCQR-LSTM          3         2        3      1           37.5     4\n",
      "               MCPS          2         2        4      0           25.0     5\n",
      "            AV-MCPS          1         3        4     -2           12.5     6\n",
      "              AREPD          0         4        4     -4            0.0     7\n",
      "               LSPM          1         5        2     -4           12.5     8\n",
      "              LSPMW          0         7        1     -7            0.0     9\n",
      "‚úÖ Ranking guardado: RANKING_No_Lineal_Estacionario.png\n",
      "\n",
      "\n",
      "[19/27] Procesando...\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS: AREPD en escenario No_Estacionario_Lineal\n",
      "================================================================================\n",
      "\n",
      "üìä Generando: Rendimiento por Distribuci√≥n...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Varianza vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Importancia de Caracter√≠sticas...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Distribuci√≥n General del Rendimiento...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Outliers...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Heatmap de Configuraciones...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Estabilidad...\n",
      "‚úì Completado\n",
      "\n",
      "üíæ Guardando estad√≠sticas completas...\n",
      "‚úì Completado\n",
      "\n",
      "\n",
      "[20/27] Procesando...\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS: AV-MCPS en escenario No_Estacionario_Lineal\n",
      "================================================================================\n",
      "\n",
      "üìä Generando: Rendimiento por Distribuci√≥n...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Varianza vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Importancia de Caracter√≠sticas...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Distribuci√≥n General del Rendimiento...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Outliers...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Heatmap de Configuraciones...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Estabilidad...\n",
      "‚úì Completado\n",
      "\n",
      "üíæ Guardando estad√≠sticas completas...\n",
      "‚úì Completado\n",
      "\n",
      "\n",
      "[21/27] Procesando...\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS: Block Bootstrapping en escenario No_Estacionario_Lineal\n",
      "================================================================================\n",
      "\n",
      "üìä Generando: Rendimiento por Distribuci√≥n...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Varianza vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Importancia de Caracter√≠sticas...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Distribuci√≥n General del Rendimiento...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Outliers...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Heatmap de Configuraciones...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Estabilidad...\n",
      "‚úì Completado\n",
      "\n",
      "üíæ Guardando estad√≠sticas completas...\n",
      "‚úì Completado\n",
      "\n",
      "\n",
      "[22/27] Procesando...\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS: DeepAR en escenario No_Estacionario_Lineal\n",
      "================================================================================\n",
      "\n",
      "üìä Generando: Rendimiento por Distribuci√≥n...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Varianza vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Importancia de Caracter√≠sticas...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Distribuci√≥n General del Rendimiento...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Outliers...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Heatmap de Configuraciones...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Estabilidad...\n",
      "‚úì Completado\n",
      "\n",
      "üíæ Guardando estad√≠sticas completas...\n",
      "‚úì Completado\n",
      "\n",
      "\n",
      "[23/27] Procesando...\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS: EnCQR-LSTM en escenario No_Estacionario_Lineal\n",
      "================================================================================\n",
      "\n",
      "üìä Generando: Rendimiento por Distribuci√≥n...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Varianza vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Importancia de Caracter√≠sticas...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Distribuci√≥n General del Rendimiento...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Outliers...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Heatmap de Configuraciones...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Estabilidad...\n",
      "‚úì Completado\n",
      "\n",
      "üíæ Guardando estad√≠sticas completas...\n",
      "‚úì Completado\n",
      "\n",
      "\n",
      "[24/27] Procesando...\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS: LSPM en escenario No_Estacionario_Lineal\n",
      "================================================================================\n",
      "\n",
      "üìä Generando: Rendimiento por Distribuci√≥n...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Varianza vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Importancia de Caracter√≠sticas...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Distribuci√≥n General del Rendimiento...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Outliers...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Heatmap de Configuraciones...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Estabilidad...\n",
      "‚úì Completado\n",
      "\n",
      "üíæ Guardando estad√≠sticas completas...\n",
      "‚úì Completado\n",
      "\n",
      "\n",
      "[25/27] Procesando...\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS: LSPMW en escenario No_Estacionario_Lineal\n",
      "================================================================================\n",
      "\n",
      "üìä Generando: Rendimiento por Distribuci√≥n...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Varianza vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Importancia de Caracter√≠sticas...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Distribuci√≥n General del Rendimiento...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Outliers...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Heatmap de Configuraciones...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Estabilidad...\n",
      "‚úì Completado\n",
      "\n",
      "üíæ Guardando estad√≠sticas completas...\n",
      "‚úì Completado\n",
      "\n",
      "\n",
      "[26/27] Procesando...\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS: MCPS en escenario No_Estacionario_Lineal\n",
      "================================================================================\n",
      "\n",
      "üìä Generando: Rendimiento por Distribuci√≥n...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Varianza vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Importancia de Caracter√≠sticas...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Distribuci√≥n General del Rendimiento...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Outliers...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Heatmap de Configuraciones...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Estabilidad...\n",
      "‚úì Completado\n",
      "\n",
      "üíæ Guardando estad√≠sticas completas...\n",
      "‚úì Completado\n",
      "\n",
      "\n",
      "[27/27] Procesando...\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS: Sieve Bootstrap en escenario No_Estacionario_Lineal\n",
      "================================================================================\n",
      "\n",
      "üìä Generando: Rendimiento por Distribuci√≥n...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Rendimiento por Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Tipo de Generador...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Distribuci√≥n vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Tipo de Generador vs Varianza...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Interacci√≥n Varianza vs Paso...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Importancia de Caracter√≠sticas...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Distribuci√≥n General del Rendimiento...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Outliers...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: Heatmap de Configuraciones...\n",
      "‚úì Completado\n",
      "\n",
      "üìä Generando: An√°lisis de Estabilidad...\n",
      "‚úì Completado\n",
      "\n",
      "üíæ Guardando estad√≠sticas completas...\n",
      "‚úì Completado\n",
      "\n",
      "\n",
      "================================================================================\n",
      "GENERANDO RANKING PARA ESCENARIO: No_Estacionario_Lineal\n",
      "================================================================================\n",
      "\n",
      "üìä Generando ranking con Test Diebold-Mariano para No_Estacionario_Lineal...\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üèÜ RANKING (Test Diebold-Mariano):\n",
      "             Modelo  Victorias  Derrotas  Empates  Score  Pct_Victorias  Rank\n",
      "Block Bootstrapping          8         0        0      8          100.0     1\n",
      "    Sieve Bootstrap          7         1        0      6           87.5     2\n",
      "               LSPM          5         2        1      3           62.5     3\n",
      "              LSPMW          5         2        1      3           62.5     4\n",
      "            AV-MCPS          3         4        1     -1           37.5     5\n",
      "             DeepAR          3         4        1     -1           37.5     6\n",
      "               MCPS          2         6        0     -4           25.0     7\n",
      "         EnCQR-LSTM          1         7        0     -6           12.5     8\n",
      "              AREPD          0         8        0     -8            0.0     9\n",
      "‚úÖ Ranking guardado: RANKING_No_Estacionario_Lineal.png\n",
      "\n",
      "\n",
      "================================================================================\n",
      "GENERANDO RESUMEN COMPARATIVO GLOBAL\n",
      "================================================================================\n",
      "\n",
      "üìä Calculando ranking global (todos los escenarios)...\n",
      "\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üèÜ RANKING GLOBAL (TODOS LOS ESCENARIOS):\n",
      "             Modelo  Victorias  Derrotas  Empates  Score  Pct_Victorias  Rank\n",
      "Block Bootstrapping          8         0        0      8          100.0     1\n",
      "    Sieve Bootstrap          7         1        0      6           87.5     2\n",
      "               LSPM          6         2        0      4           75.0     3\n",
      "              LSPMW          5         3        0      2           62.5     4\n",
      "            AV-MCPS          3         4        1     -1           37.5     5\n",
      "             DeepAR          3         4        1     -1           37.5     6\n",
      "               MCPS          2         6        0     -4           25.0     7\n",
      "         EnCQR-LSTM          1         7        0     -6           12.5     8\n",
      "              AREPD          0         8        0     -8            0.0     9\n",
      "\n",
      "‚úÖ Ranking global guardado: RANKING_GLOBAL.png\n",
      "\n",
      "================================================================================\n",
      "üèÜ MEJORES MODELOS POR ESCENARIO\n",
      "================================================================================\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Estacionario_Lineal:\n",
      "  ü•á Mejor modelo: Block Bootstrapping\n",
      "  üìä Score DM: 7 (V:7, D:0, E:1)\n",
      "  üìà % Victorias: 87.5%\n",
      "  üìä Rendimiento: 0.5396 ¬± 0.2681\n",
      "  üìä Rango: [0.2215, 1.0419]\n",
      "\n",
      "  Top 3:\n",
      "    1. Block Bootstrapping (Score: 7, 87.5% victorias)\n",
      "    2. Sieve Bootstrap (Score: 7, 87.5% victorias)\n",
      "    3. DeepAR (Score: 4, 75.0% victorias)\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "No_Lineal_Estacionario:\n",
      "  ü•á Mejor modelo: Block Bootstrapping\n",
      "  üìä Score DM: 6 (V:6, D:0, E:2)\n",
      "  üìà % Victorias: 75.0%\n",
      "  üìä Rendimiento: 0.5913 ¬± 0.4241\n",
      "  üìä Rango: [0.2224, 6.2332]\n",
      "\n",
      "  Top 3:\n",
      "    1. Block Bootstrapping (Score: 6, 75.0% victorias)\n",
      "    2. Sieve Bootstrap (Score: 6, 75.0% victorias)\n",
      "    3. DeepAR (Score: 4, 50.0% victorias)\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "No_Estacionario_Lineal:\n",
      "  ü•á Mejor modelo: Block Bootstrapping\n",
      "  üìä Score DM: 8 (V:8, D:0, E:0)\n",
      "  üìà % Victorias: 100.0%\n",
      "  üìä Rendimiento: 0.5425 ¬± 0.2714\n",
      "  üìä Rango: [0.2211, 1.2894]\n",
      "\n",
      "  Top 3:\n",
      "    1. Block Bootstrapping (Score: 8, 100.0% victorias)\n",
      "    2. Sieve Bootstrap (Score: 6, 87.5% victorias)\n",
      "    3. LSPM (Score: 3, 62.5% victorias)\n",
      "\n",
      "================================================================================\n",
      "‚úÖ An√°lisis comparativo global completado\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä GENERANDO EXCEL CONSOLIDADO\n",
      "================================================================================\n",
      "\n",
      "üìã Generando HOJA 1: Resumen General por Modelo-Escenario...\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "‚úì Completado\n",
      "\n",
      "üìã Generando HOJA 2: Rendimiento por Caracter√≠sticas...\n",
      "‚úì Completado\n",
      "\n",
      "üìã Generando HOJA 3: Importancia de Caracter√≠sticas...\n",
      "‚úì Completado\n",
      "\n",
      "üìã Generando HOJA 4: Estabilidad y Outliers...\n",
      "‚úì Completado\n",
      "\n",
      "üìã Generando HOJA 5: Mejores/Peores Configuraciones...\n",
      "‚úì Completado\n",
      "\n",
      "üìã Generando HOJA 6: Resultados DM Detallados...\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "‚úì Completado\n",
      "\n",
      "üìã Generando HOJA 7: Ranking Final...\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "‚úì Completado\n",
      "\n",
      "üìã Generando HOJA 8: An√°lisis de Sensibilidad Completo...\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha original: 0.05\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "----------------------------------------------------------------------\n",
      "‚úì Completado\n",
      "\n",
      "‚úÖ Excel consolidado generado: Resultados\\ANALISIS_CONSOLIDADO_COMPLETO.xlsx\n",
      "   üìä 8 hojas creadas con an√°lisis completo\n",
      "\n",
      "\n",
      "================================================================================\n",
      "‚úÖ AN√ÅLISIS COMPLETO FINALIZADO\n",
      "   Total de an√°lisis realizados: 27\n",
      "   Resultados guardados en: ./Resultados/\n",
      "================================================================================\n",
      "\n",
      "\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "‚ñà                                                                              ‚ñà\n",
      "‚ñà                         AN√ÅLISIS COMPLETADO EXITOSAMENTE                      ‚ñà\n",
      "‚ñà                                                                              ‚ñà\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "üìÅ Los resultados se encuentran en:\n",
      "   ‚îî‚îÄ‚îÄ ./Resultados/\n",
      "       ‚îú‚îÄ‚îÄ Estacionario_Lineal/\n",
      "       ‚îÇ   ‚îú‚îÄ‚îÄ RANKING_Estacionario_Lineal.png  ‚≠ê\n",
      "       ‚îÇ   ‚îú‚îÄ‚îÄ LSPM/\n",
      "       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 01_rendimiento_distribucion.png\n",
      "       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 02_rendimiento_tipo_generador.png\n",
      "       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 03_rendimiento_paso.png\n",
      "       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 04_rendimiento_varianza.png\n",
      "       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 05-10_interacciones (6 gr√°ficas)\n",
      "       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 11_importancia_caracteristicas.png\n",
      "       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 12_distribucion_general.png\n",
      "       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 13_analisis_outliers.png\n",
      "       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 14_heatmap_configuraciones.png\n",
      "       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 15_analisis_estabilidad.png\n",
      "       ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ estadisticas_completas.txt\n",
      "       ‚îÇ   ‚îî‚îÄ‚îÄ ... (todos los modelos)\n",
      "       ‚îú‚îÄ‚îÄ No_Lineal_Estacionario/\n",
      "       ‚îÇ   ‚îî‚îÄ‚îÄ RANKING_No_Lineal_Estacionario.png  ‚≠ê\n",
      "       ‚îú‚îÄ‚îÄ No_Estacionario_Lineal/\n",
      "       ‚îÇ   ‚îî‚îÄ‚îÄ RANKING_No_Estacionario_Lineal.png  ‚≠ê\n",
      "       ‚îú‚îÄ‚îÄ Comparativo_Global/\n",
      "       ‚îÇ   ‚îú‚îÄ‚îÄ RANKING_GLOBAL.png  ‚≠ê‚≠ê‚≠ê\n",
      "       ‚îÇ   ‚îú‚îÄ‚îÄ ranking_dm_global.xlsx\n",
      "       ‚îÇ   ‚îî‚îÄ‚îÄ resumen_mejores_por_escenario.xlsx\n",
      "       ‚îî‚îÄ‚îÄ ANALISIS_CONSOLIDADO_COMPLETO.xlsx  üìäüìäüìä\n",
      "           ‚îú‚îÄ‚îÄ Hoja 1: Resumen General\n",
      "           ‚îú‚îÄ‚îÄ Hoja 2: Rendimiento por Caracter√≠sticas\n",
      "           ‚îú‚îÄ‚îÄ Hoja 3: Importancia de Caracter√≠sticas\n",
      "           ‚îú‚îÄ‚îÄ Hoja 4: Estabilidad y Outliers\n",
      "           ‚îú‚îÄ‚îÄ Hoja 5: Configuraciones Extremas\n",
      "           ‚îú‚îÄ‚îÄ Hoja 6: Resultados DM Detallados\n",
      "           ‚îî‚îÄ‚îÄ Hoja 7: Ranking Final\n",
      "\n",
      "================================================================================\n",
      "NOTA: Cada modelo en cada escenario tiene 15 gr√°ficas individuales\n",
      "      + 1 ranking por escenario + 1 ranking global\n",
      "      + 1 Excel consolidado con 7 hojas de an√°lisis completo\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from itertools import combinations\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuraci√≥n de estilo\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Ruta de datos\n",
    "RUTA_DATOS = \"./Datos/datos_combinados.xlsx\"\n",
    "\n",
    "# Modelos a analizar\n",
    "MODELOS = ['AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', \n",
    "           'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
    "\n",
    "# Escenarios\n",
    "ESCENARIOS = ['Estacionario_Lineal', 'No_Lineal_Estacionario', 'No_Estacionario_Lineal']\n",
    "\n",
    "# Caracter√≠sticas de simulaci√≥n\n",
    "CARACTERISTICAS = ['Paso', 'Tipo de Modelo', 'Distribuci√≥n', 'Varianza error']\n",
    "\n",
    "\n",
    "def diebold_mariano_test(errores1, errores2, h=1, alternative='two-sided'):\n",
    "    \"\"\"\n",
    "    Test de Diebold-Mariano para comparar la precisi√≥n de dos pron√≥sticos\n",
    "    \n",
    "    Args:\n",
    "        errores1: Errores del modelo 1 (valores menores = mejor)\n",
    "        errores2: Errores del modelo 2 (valores menores = mejor)\n",
    "        h: Horizonte de predicci√≥n\n",
    "        alternative: 'two-sided', 'less' (modelo1 < modelo2), 'greater' (modelo1 > modelo2)\n",
    "    \n",
    "    Returns:\n",
    "        dict con estad√≠stico DM, p-valor y conclusi√≥n\n",
    "    \"\"\"\n",
    "    # Asegurar que son arrays numpy\n",
    "    e1 = np.asarray(errores1)\n",
    "    e2 = np.asarray(errores2)\n",
    "    \n",
    "    # Verificar misma longitud\n",
    "    if len(e1) != len(e2):\n",
    "        raise ValueError(\"Los vectores de errores deben tener la misma longitud\")\n",
    "    \n",
    "    n = len(e1)\n",
    "    \n",
    "    # Calcular diferencias de p√©rdidas (loss differential)\n",
    "    d = e1 - e2  # Si d < 0, modelo 1 es mejor\n",
    "    \n",
    "    # Media de diferencias\n",
    "    d_mean = np.mean(d)\n",
    "    \n",
    "    # Calcular varianza con correcci√≥n de autocorrelaci√≥n (Harvey, Leybourne y Newbold, 1997)\n",
    "    gamma_0 = np.var(d, ddof=1)\n",
    "    \n",
    "    # Autocovarianzas hasta lag h\n",
    "    gamma_sum = 0\n",
    "    for k in range(1, h):\n",
    "        if k < n:\n",
    "            gamma_k = np.mean((d[:-k] - d_mean) * (d[k:] - d_mean))\n",
    "            gamma_sum += 2 * gamma_k\n",
    "    \n",
    "    # Varianza de largo plazo\n",
    "    var_d = (gamma_0 + gamma_sum) / n\n",
    "    \n",
    "    # Correcci√≥n de Harvey-Leybourne-Newbold para muestras peque√±as\n",
    "    hlnc = np.sqrt((n + 1 - 2*h + h*(h-1)/n) / n)\n",
    "    \n",
    "    # Estad√≠stico DM\n",
    "    if var_d > 0:\n",
    "        dm_stat = d_mean / np.sqrt(var_d)\n",
    "        dm_stat_corrected = dm_stat * hlnc\n",
    "    else:\n",
    "        dm_stat = 0\n",
    "        dm_stat_corrected = 0\n",
    "    \n",
    "    # P-valor usando distribuci√≥n t con n-1 grados de libertad\n",
    "    if alternative == 'two-sided':\n",
    "        p_value = 2 * (1 - stats.t.cdf(abs(dm_stat_corrected), df=n-1))\n",
    "    elif alternative == 'less':\n",
    "        p_value = stats.t.cdf(dm_stat_corrected, df=n-1)\n",
    "    elif alternative == 'greater':\n",
    "        p_value = 1 - stats.t.cdf(dm_stat_corrected, df=n-1)\n",
    "    else:\n",
    "        raise ValueError(\"alternative debe ser 'two-sided', 'less' o 'greater'\")\n",
    "    \n",
    "    return {\n",
    "        'dm_statistic': dm_stat,\n",
    "        'dm_statistic_corrected': dm_stat_corrected,\n",
    "        'p_value': p_value,\n",
    "        'mean_diff': d_mean,\n",
    "        'modelo1_mejor': d_mean < 0,\n",
    "        'n': n\n",
    "    }\n",
    "\n",
    "\n",
    "def comparaciones_multiples_dm(df, modelos, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Realiza comparaciones m√∫ltiples usando test Diebold-Mariano \n",
    "    con correcci√≥n de Bonferroni\n",
    "    \"\"\"\n",
    "    n_comparaciones = len(list(combinations(modelos, 2)))\n",
    "    alpha_bonferroni = alpha / n_comparaciones\n",
    "    \n",
    "    print(f\"\\nüî¨ TEST DE DIEBOLD-MARIANO CON CORRECCI√ìN DE BONFERRONI\")\n",
    "    print(f\"   N√∫mero de comparaciones: {n_comparaciones}\")\n",
    "    print(f\"   Alpha original: {alpha}\")\n",
    "    print(f\"   Alpha corregido (Bonferroni): {alpha_bonferroni:.6f}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    resultados = []\n",
    "    \n",
    "    for modelo1, modelo2 in combinations(modelos, 2):\n",
    "        try:\n",
    "            dm_result = diebold_mariano_test(\n",
    "                df[modelo1].values, \n",
    "                df[modelo2].values,\n",
    "                h=1,\n",
    "                alternative='two-sided'\n",
    "            )\n",
    "            \n",
    "            significativo = dm_result['p_value'] < alpha_bonferroni\n",
    "            \n",
    "            if significativo:\n",
    "                if dm_result['mean_diff'] < 0:\n",
    "                    ganador = modelo1\n",
    "                    interpretacion = f\"{modelo1} significativamente mejor\"\n",
    "                else:\n",
    "                    ganador = modelo2\n",
    "                    interpretacion = f\"{modelo2} significativamente mejor\"\n",
    "            else:\n",
    "                ganador = \"No hay diferencia\"\n",
    "                interpretacion = \"Sin diferencia significativa\"\n",
    "            \n",
    "            resultados.append({\n",
    "                'Modelo_1': modelo1,\n",
    "                'Modelo_2': modelo2,\n",
    "                'DM_Statistic': dm_result['dm_statistic_corrected'],\n",
    "                'p_value': dm_result['p_value'],\n",
    "                'p_value_bonferroni': alpha_bonferroni,\n",
    "                'Significativo': significativo,\n",
    "                'Ganador': ganador,\n",
    "                'Diff_Media': dm_result['mean_diff'],\n",
    "                'Interpretacion': interpretacion\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Error comparando {modelo1} vs {modelo2}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    df_resultados = pd.DataFrame(resultados)\n",
    "    return df_resultados, alpha_bonferroni\n",
    "\n",
    "\n",
    "def crear_matriz_superioridad(df_comparaciones, modelos):\n",
    "    \"\"\"Crea una matriz mostrando qu√© modelo es superior a cu√°l\"\"\"\n",
    "    n = len(modelos)\n",
    "    matriz = pd.DataFrame(np.zeros((n, n)), index=modelos, columns=modelos)\n",
    "    \n",
    "    for _, row in df_comparaciones.iterrows():\n",
    "        m1, m2 = row['Modelo_1'], row['Modelo_2']\n",
    "        \n",
    "        if row['Significativo']:\n",
    "            if row['Ganador'] == m1:\n",
    "                matriz.loc[m1, m2] = 1\n",
    "                matriz.loc[m2, m1] = -1\n",
    "            elif row['Ganador'] == m2:\n",
    "                matriz.loc[m2, m1] = 1\n",
    "                matriz.loc[m1, m2] = -1\n",
    "    \n",
    "    return matriz\n",
    "\n",
    "\n",
    "def calcular_ranking_dm(df_comparaciones, modelos):\n",
    "    \"\"\"Calcula ranking basado en resultados de Diebold-Mariano\"\"\"\n",
    "    matriz_sup = crear_matriz_superioridad(df_comparaciones, modelos)\n",
    "    \n",
    "    ranking_data = []\n",
    "    \n",
    "    for modelo in modelos:\n",
    "        victorias = (matriz_sup.loc[modelo] == 1).sum()\n",
    "        derrotas = (matriz_sup.loc[modelo] == -1).sum()\n",
    "        empates = (matriz_sup.loc[modelo] == 0).sum() - 1\n",
    "        \n",
    "        score = victorias - derrotas\n",
    "        \n",
    "        total_comparaciones = victorias + derrotas + empates\n",
    "        pct_victorias = (victorias / total_comparaciones * 100) if total_comparaciones > 0 else 0\n",
    "        \n",
    "        ranking_data.append({\n",
    "            'Modelo': modelo,\n",
    "            'Victorias': int(victorias),\n",
    "            'Derrotas': int(derrotas),\n",
    "            'Empates': int(empates),\n",
    "            'Score': int(score),\n",
    "            'Pct_Victorias': round(pct_victorias, 2)\n",
    "        })\n",
    "    \n",
    "    df_ranking = pd.DataFrame(ranking_data)\n",
    "    df_ranking = df_ranking.sort_values('Score', ascending=False).reset_index(drop=True)\n",
    "    df_ranking['Rank'] = range(1, len(df_ranking) + 1)\n",
    "    \n",
    "    return df_ranking, matriz_sup\n",
    "\n",
    "\n",
    "class AnalizadorModelos:\n",
    "    \"\"\"Clase para analizar el desempe√±o de modelos de predicci√≥n\"\"\"\n",
    "    \n",
    "    def __init__(self, ruta_datos):\n",
    "        \"\"\"Inicializa el analizador cargando los datos\"\"\"\n",
    "        self.df = pd.read_excel(ruta_datos)\n",
    "        self.resultados_analisis = {}\n",
    "        print(f\"‚úì Datos cargados: {self.df.shape[0]} filas, {self.df.shape[1]} columnas\")\n",
    "        print(f\"\\nEscenarios encontrados: {self.df['Escenario'].unique()}\")\n",
    "        print(f\"Modelos a analizar: {len(MODELOS)}\")\n",
    "        \n",
    "    def analizar_modelo_escenario(self, escenario, modelo):\n",
    "        \"\"\"\n",
    "        Realiza an√°lisis completo de un modelo en un escenario espec√≠fico\n",
    "        con gr√°ficas individuales\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"AN√ÅLISIS: {modelo} en escenario {escenario}\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        # Filtrar datos\n",
    "        df_filtrado = self.df[self.df['Escenario'] == escenario].copy()\n",
    "        \n",
    "        if df_filtrado.empty:\n",
    "            print(f\"‚ö† No hay datos para el escenario {escenario}\")\n",
    "            return\n",
    "        \n",
    "        # Crear directorio para guardar resultados\n",
    "        dir_salida = Path(f\"./Resultados/{escenario}/{modelo}\")\n",
    "        dir_salida.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        resultados = {\n",
    "            'escenario': escenario,\n",
    "            'modelo': modelo,\n",
    "            'n_observaciones': len(df_filtrado)\n",
    "        }\n",
    "        \n",
    "        # ===== GR√ÅFICAS INDIVIDUALES =====\n",
    "        \n",
    "        # 1. Barras de rendimiento por distribuci√≥n\n",
    "        self._grafica_rendimiento_distribucion(df_filtrado, modelo, dir_salida)\n",
    "        \n",
    "        # 2. Barras de rendimiento por Tipo de Modelo (Generador)\n",
    "        self._grafica_rendimiento_tipo_generador(df_filtrado, modelo, dir_salida)\n",
    "        \n",
    "        # 3. Rendimiento por Paso\n",
    "        self._grafica_rendimiento_paso(df_filtrado, modelo, dir_salida)\n",
    "        \n",
    "        # 4. Rendimiento por Varianza\n",
    "        self._grafica_rendimiento_varianza(df_filtrado, modelo, dir_salida)\n",
    "        \n",
    "        # 5-10. Interacciones (6 gr√°ficas)\n",
    "        self._grafica_interaccion_dist_tipo(df_filtrado, modelo, dir_salida)\n",
    "        self._grafica_interaccion_dist_paso(df_filtrado, modelo, dir_salida)\n",
    "        self._grafica_interaccion_dist_varianza(df_filtrado, modelo, dir_salida)\n",
    "        self._grafica_interaccion_tipo_paso(df_filtrado, modelo, dir_salida)\n",
    "        self._grafica_interaccion_tipo_varianza(df_filtrado, modelo, dir_salida)\n",
    "        self._grafica_interaccion_varianza_paso(df_filtrado, modelo, dir_salida)\n",
    "        \n",
    "        # 11. Caracter√≠sticas que m√°s afectan el rendimiento\n",
    "        self._grafica_importancia_caracteristicas(df_filtrado, modelo, dir_salida, resultados)\n",
    "        \n",
    "        # 12. Distribuci√≥n general del rendimiento\n",
    "        self._grafica_distribucion_general(df_filtrado, modelo, dir_salida)\n",
    "        \n",
    "        # 13. An√°lisis de outliers\n",
    "        self._grafica_analisis_outliers(df_filtrado, modelo, dir_salida)\n",
    "        \n",
    "        # 14. Mapa de calor de configuraciones\n",
    "        self._grafica_heatmap_configuraciones(df_filtrado, modelo, dir_salida)\n",
    "        \n",
    "        # 15. An√°lisis de estabilidad\n",
    "        self._grafica_estabilidad(df_filtrado, modelo, dir_salida)\n",
    "        \n",
    "        # Guardar estad√≠sticas y resumen\n",
    "        self._guardar_estadisticas_completas(df_filtrado, modelo, dir_salida, resultados)\n",
    "        \n",
    "        return resultados\n",
    "    \n",
    "    def _grafica_rendimiento_distribucion(self, df, modelo, dir_salida):\n",
    "        \"\"\"Gr√°fica 1: Barras de rendimiento por distribuci√≥n\"\"\"\n",
    "        print(\"üìä Generando: Rendimiento por Distribuci√≥n...\")\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 7))\n",
    "        \n",
    "        # Calcular estad√≠sticas\n",
    "        stats_dist = df.groupby('Distribuci√≥n')[modelo].agg(['mean', 'std', 'count'])\n",
    "        stats_dist = stats_dist.sort_values('mean')\n",
    "        \n",
    "        # Crear barras con error\n",
    "        x_pos = np.arange(len(stats_dist))\n",
    "        colors = plt.cm.RdYlGn_r(np.linspace(0.3, 0.9, len(stats_dist)))\n",
    "        \n",
    "        bars = ax.bar(x_pos, stats_dist['mean'], yerr=stats_dist['std'], \n",
    "                     capsize=8, alpha=0.8, color=colors, edgecolor='black', linewidth=1.5)\n",
    "        \n",
    "        # Etiquetas y t√≠tulo\n",
    "        ax.set_xlabel('Distribuci√≥n', fontsize=13, fontweight='bold')\n",
    "        ax.set_ylabel('Rendimiento Promedio', fontsize=13, fontweight='bold')\n",
    "        ax.set_title(f'{modelo} - Rendimiento por Distribuci√≥n\\n(Barras de error: ¬±1 std)', \n",
    "                    fontsize=15, fontweight='bold', pad=20)\n",
    "        ax.set_xticks(x_pos)\n",
    "        ax.set_xticklabels(stats_dist.index, rotation=45, ha='right', fontsize=11)\n",
    "        \n",
    "        # A√±adir valores sobre las barras\n",
    "        for i, (bar, mean, count) in enumerate(zip(bars, stats_dist['mean'], stats_dist['count'])):\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{mean:.4f}\\n(n={int(count)})',\n",
    "                   ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "        \n",
    "        ax.grid(True, alpha=0.3, axis='y', linestyle='--')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(dir_salida / '01_rendimiento_distribucion.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"‚úì Completado\\n\")\n",
    "    \n",
    "    def _grafica_rendimiento_tipo_generador(self, df, modelo, dir_salida):\n",
    "        \"\"\"Gr√°fica 2: Barras de rendimiento por Tipo de Generador\"\"\"\n",
    "        print(\"üìä Generando: Rendimiento por Tipo de Generador...\")\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(14, 7))\n",
    "        \n",
    "        # Calcular estad√≠sticas\n",
    "        stats_tipo = df.groupby('Tipo de Modelo')[modelo].agg(['mean', 'std', 'count', 'median'])\n",
    "        stats_tipo = stats_tipo.sort_values('mean')\n",
    "        \n",
    "        # Crear barras con error\n",
    "        x_pos = np.arange(len(stats_tipo))\n",
    "        colors = plt.cm.viridis(np.linspace(0.2, 0.9, len(stats_tipo)))\n",
    "        \n",
    "        bars = ax.bar(x_pos, stats_tipo['mean'], yerr=stats_tipo['std'], \n",
    "                     capsize=8, alpha=0.8, color=colors, edgecolor='black', linewidth=1.5)\n",
    "        \n",
    "        # A√±adir l√≠nea de mediana\n",
    "        ax.plot(x_pos, stats_tipo['median'], 'ro-', linewidth=2, markersize=8, \n",
    "               label='Mediana', zorder=5)\n",
    "        \n",
    "        # Etiquetas y t√≠tulo\n",
    "        ax.set_xlabel('Tipo de Generador', fontsize=13, fontweight='bold')\n",
    "        ax.set_ylabel('Rendimiento', fontsize=13, fontweight='bold')\n",
    "        ax.set_title(f'{modelo} - Rendimiento por Tipo de Generador\\n(Media ¬± std, L√≠nea roja: Mediana)', \n",
    "                    fontsize=15, fontweight='bold', pad=20)\n",
    "        ax.set_xticks(x_pos)\n",
    "        ax.set_xticklabels(stats_tipo.index, rotation=45, ha='right', fontsize=10)\n",
    "        \n",
    "        # A√±adir valores\n",
    "        for i, (bar, mean, count) in enumerate(zip(bars, stats_tipo['mean'], stats_tipo['count'])):\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{mean:.4f}\\n(n={int(count)})',\n",
    "                   ha='center', va='bottom', fontsize=8, fontweight='bold')\n",
    "        \n",
    "        ax.legend(fontsize=11)\n",
    "        ax.grid(True, alpha=0.3, axis='y', linestyle='--')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(dir_salida / '02_rendimiento_tipo_generador.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"‚úì Completado\\n\")\n",
    "    \n",
    "    def _grafica_rendimiento_paso(self, df, modelo, dir_salida):\n",
    "        \"\"\"Gr√°fica 3: Rendimiento por Paso\"\"\"\n",
    "        print(\"üìä Generando: Rendimiento por Paso...\")\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 7))\n",
    "        \n",
    "        # Calcular estad√≠sticas por paso\n",
    "        paso_stats = df.groupby('Paso')[modelo].agg(['mean', 'std', 'min', 'max', 'median'])\n",
    "        \n",
    "        # Gr√°fica de l√≠nea con banda de confianza\n",
    "        x = paso_stats.index\n",
    "        ax.plot(x, paso_stats['mean'], 'o-', linewidth=3, markersize=10, \n",
    "               label='Media', color='darkblue')\n",
    "        ax.fill_between(x, \n",
    "                        paso_stats['mean'] - paso_stats['std'],\n",
    "                        paso_stats['mean'] + paso_stats['std'],\n",
    "                        alpha=0.3, label='¬±1 std', color='lightblue')\n",
    "        \n",
    "        # A√±adir min y max\n",
    "        ax.plot(x, paso_stats['min'], 's--', linewidth=2, markersize=7, \n",
    "               label='M√≠nimo', color='green', alpha=0.7)\n",
    "        ax.plot(x, paso_stats['max'], '^--', linewidth=2, markersize=7, \n",
    "               label='M√°ximo', color='red', alpha=0.7)\n",
    "        \n",
    "        # Etiquetas y t√≠tulo\n",
    "        ax.set_xlabel('Paso', fontsize=13, fontweight='bold')\n",
    "        ax.set_ylabel('Rendimiento', fontsize=13, fontweight='bold')\n",
    "        ax.set_title(f'{modelo} - Evoluci√≥n del Rendimiento por Paso', \n",
    "                    fontsize=15, fontweight='bold', pad=20)\n",
    "        \n",
    "        # A√±adir valores sobre los puntos\n",
    "        for i, (paso, mean) in enumerate(zip(x, paso_stats['mean'])):\n",
    "            ax.annotate(f'{mean:.4f}', \n",
    "                       xy=(paso, mean), \n",
    "                       xytext=(0, 10), \n",
    "                       textcoords='offset points',\n",
    "                       ha='center', \n",
    "                       fontsize=9, \n",
    "                       fontweight='bold',\n",
    "                       bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7))\n",
    "        \n",
    "        ax.legend(fontsize=11, loc='best')\n",
    "        ax.grid(True, alpha=0.3, linestyle='--')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(dir_salida / '03_rendimiento_paso.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"‚úì Completado\\n\")\n",
    "    \n",
    "    def _grafica_rendimiento_varianza(self, df, modelo, dir_salida):\n",
    "        \"\"\"Gr√°fica 4: Rendimiento por Varianza\"\"\"\n",
    "        print(\"üìä Generando: Rendimiento por Varianza...\")\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 7))\n",
    "        \n",
    "        # Calcular estad√≠sticas por varianza\n",
    "        var_stats = df.groupby('Varianza error')[modelo].agg(['mean', 'std', 'count'])\n",
    "        \n",
    "        # Crear scatter plot con todos los puntos\n",
    "        for var in df['Varianza error'].unique():\n",
    "            df_var = df[df['Varianza error'] == var]\n",
    "            ax.scatter([var] * len(df_var), df_var[modelo], \n",
    "                      alpha=0.4, s=50, label=f'Var={var}')\n",
    "        \n",
    "        # L√≠nea de tendencia\n",
    "        x = var_stats.index\n",
    "        ax.plot(x, var_stats['mean'], 'ro-', linewidth=3, markersize=12, \n",
    "               label='Media', zorder=10)\n",
    "        \n",
    "        # Banda de confianza\n",
    "        ax.fill_between(x, \n",
    "                        var_stats['mean'] - var_stats['std'],\n",
    "                        var_stats['mean'] + var_stats['std'],\n",
    "                        alpha=0.2, color='red', label='¬±1 std')\n",
    "        \n",
    "        # Etiquetas y t√≠tulo\n",
    "        ax.set_xlabel('Varianza del Error', fontsize=13, fontweight='bold')\n",
    "        ax.set_ylabel('Rendimiento', fontsize=13, fontweight='bold')\n",
    "        ax.set_title(f'{modelo} - Rendimiento vs Varianza del Error', \n",
    "                    fontsize=15, fontweight='bold', pad=20)\n",
    "        \n",
    "        # A√±adir valores y conteos\n",
    "        for var, mean, count in zip(x, var_stats['mean'], var_stats['count']):\n",
    "            ax.annotate(f'{mean:.4f}\\n(n={int(count)})', \n",
    "                       xy=(var, mean), \n",
    "                       xytext=(15, 15), \n",
    "                       textcoords='offset points',\n",
    "                       ha='left', \n",
    "                       fontsize=9, \n",
    "                       fontweight='bold',\n",
    "                       bbox=dict(boxstyle='round,pad=0.4', facecolor='yellow', alpha=0.7),\n",
    "                       arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "        \n",
    "        # Calcular correlaci√≥n\n",
    "        corr = df[['Varianza error', modelo]].corr().iloc[0, 1]\n",
    "        ax.text(0.02, 0.98, f'Correlaci√≥n: {corr:.4f}', \n",
    "               transform=ax.transAxes, fontsize=12, fontweight='bold',\n",
    "               verticalalignment='top',\n",
    "               bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "        \n",
    "        ax.legend(fontsize=10, loc='best', ncol=2)\n",
    "        ax.grid(True, alpha=0.3, linestyle='--')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(dir_salida / '04_rendimiento_varianza.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"‚úì Completado\\n\")\n",
    "    \n",
    "    def _grafica_interaccion_dist_tipo(self, df, modelo, dir_salida):\n",
    "        \"\"\"Gr√°fica 5: Interacci√≥n Distribuci√≥n vs Tipo de Generador\"\"\"\n",
    "        print(\"üìä Generando: Interacci√≥n Distribuci√≥n vs Tipo de Generador...\")\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        \n",
    "        # Crear gr√°fica de interacci√≥n\n",
    "        for dist in df['Distribuci√≥n'].unique():\n",
    "            df_dist = df[df['Distribuci√≥n'] == dist]\n",
    "            tipo_mean = df_dist.groupby('Tipo de Modelo')[modelo].mean().sort_index()\n",
    "            ax.plot(range(len(tipo_mean)), tipo_mean.values, \n",
    "                   marker='o', linewidth=2.5, markersize=8, label=dist)\n",
    "        \n",
    "        # Etiquetas\n",
    "        tipos = sorted(df['Tipo de Modelo'].unique())\n",
    "        ax.set_xticks(range(len(tipos)))\n",
    "        ax.set_xticklabels(tipos, rotation=45, ha='right', fontsize=10)\n",
    "        ax.set_xlabel('Tipo de Generador', fontsize=13, fontweight='bold')\n",
    "        ax.set_ylabel('Rendimiento Promedio', fontsize=13, fontweight='bold')\n",
    "        ax.set_title(f'{modelo} - Interacci√≥n: Distribuci√≥n √ó Tipo de Generador', \n",
    "                    fontsize=15, fontweight='bold', pad=20)\n",
    "        \n",
    "        ax.legend(title='Distribuci√≥n', fontsize=11, title_fontsize=12, loc='best')\n",
    "        ax.grid(True, alpha=0.3, linestyle='--')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(dir_salida / '05_interaccion_dist_tipo.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"‚úì Completado\\n\")\n",
    "    \n",
    "    def _grafica_interaccion_dist_paso(self, df, modelo, dir_salida):\n",
    "        \"\"\"Gr√°fica 6: Interacci√≥n Distribuci√≥n vs Paso\"\"\"\n",
    "        print(\"üìä Generando: Interacci√≥n Distribuci√≥n vs Paso...\")\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 7))\n",
    "        \n",
    "        for dist in df['Distribuci√≥n'].unique():\n",
    "            df_dist = df[df['Distribuci√≥n'] == dist]\n",
    "            paso_mean = df_dist.groupby('Paso')[modelo].mean()\n",
    "            ax.plot(paso_mean.index, paso_mean.values, \n",
    "                   marker='s', linewidth=2.5, markersize=9, label=dist)\n",
    "        \n",
    "        ax.set_xlabel('Paso', fontsize=13, fontweight='bold')\n",
    "        ax.set_ylabel('Rendimiento Promedio', fontsize=13, fontweight='bold')\n",
    "        ax.set_title(f'{modelo} - Interacci√≥n: Distribuci√≥n √ó Paso', \n",
    "                    fontsize=15, fontweight='bold', pad=20)\n",
    "        \n",
    "        ax.legend(title='Distribuci√≥n', fontsize=11, title_fontsize=12, loc='best')\n",
    "        ax.grid(True, alpha=0.3, linestyle='--')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(dir_salida / '06_interaccion_dist_paso.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"‚úì Completado\\n\")\n",
    "    \n",
    "    def _grafica_interaccion_dist_varianza(self, df, modelo, dir_salida):\n",
    "        \"\"\"Gr√°fica 7: Interacci√≥n Distribuci√≥n vs Varianza\"\"\"\n",
    "        print(\"üìä Generando: Interacci√≥n Distribuci√≥n vs Varianza...\")\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 7))\n",
    "        \n",
    "        for dist in df['Distribuci√≥n'].unique():\n",
    "            df_dist = df[df['Distribuci√≥n'] == dist]\n",
    "            var_mean = df_dist.groupby('Varianza error')[modelo].mean()\n",
    "            ax.plot(var_mean.index, var_mean.values, \n",
    "                   marker='^', linewidth=2.5, markersize=9, label=dist)\n",
    "        \n",
    "        ax.set_xlabel('Varianza del Error', fontsize=13, fontweight='bold')\n",
    "        ax.set_ylabel('Rendimiento Promedio', fontsize=13, fontweight='bold')\n",
    "        ax.set_title(f'{modelo} - Interacci√≥n: Distribuci√≥n √ó Varianza', \n",
    "                    fontsize=15, fontweight='bold', pad=20)\n",
    "        \n",
    "        ax.legend(title='Distribuci√≥n', fontsize=11, title_fontsize=12, loc='best')\n",
    "        ax.grid(True, alpha=0.3, linestyle='--')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(dir_salida / '07_interaccion_dist_varianza.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"‚úì Completado\\n\")\n",
    "    \n",
    "    def _grafica_interaccion_tipo_paso(self, df, modelo, dir_salida):\n",
    "        \"\"\"Gr√°fica 8: Interacci√≥n Tipo de Generador vs Paso\"\"\"\n",
    "        print(\"üìä Generando: Interacci√≥n Tipo de Generador vs Paso...\")\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 7))\n",
    "        \n",
    "        tipos = df['Tipo de Modelo'].unique()\n",
    "        colors = plt.cm.tab10(np.linspace(0, 1, len(tipos)))\n",
    "        \n",
    "        for tipo, color in zip(tipos, colors):\n",
    "            df_tipo = df[df['Tipo de Modelo'] == tipo]\n",
    "            paso_mean = df_tipo.groupby('Paso')[modelo].mean()\n",
    "            ax.plot(paso_mean.index, paso_mean.values, \n",
    "                   marker='o', linewidth=2, markersize=8, label=tipo, color=color)\n",
    "        \n",
    "        ax.set_xlabel('Paso', fontsize=13, fontweight='bold')\n",
    "        ax.set_ylabel('Rendimiento Promedio', fontsize=13, fontweight='bold')\n",
    "        ax.set_title(f'{modelo} - Interacci√≥n: Tipo de Generador √ó Paso', \n",
    "                    fontsize=15, fontweight='bold', pad=20)\n",
    "        \n",
    "        ax.legend(title='Tipo de Generador', fontsize=9, title_fontsize=11, \n",
    "                 loc='best', ncol=2)\n",
    "        ax.grid(True, alpha=0.3, linestyle='--')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(dir_salida / '08_interaccion_tipo_paso.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"‚úì Completado\\n\")\n",
    "    \n",
    "    def _grafica_interaccion_tipo_varianza(self, df, modelo, dir_salida):\n",
    "        \"\"\"Gr√°fica 9: Interacci√≥n Tipo de Generador vs Varianza\"\"\"\n",
    "        print(\"üìä Generando: Interacci√≥n Tipo de Generador vs Varianza...\")\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 7))\n",
    "        \n",
    "        tipos = df['Tipo de Modelo'].unique()\n",
    "        colors = plt.cm.Set2(np.linspace(0, 1, len(tipos)))\n",
    "        \n",
    "        for tipo, color in zip(tipos, colors):\n",
    "            df_tipo = df[df['Tipo de Modelo'] == tipo]\n",
    "            var_mean = df_tipo.groupby('Varianza error')[modelo].mean()\n",
    "            ax.plot(var_mean.index, var_mean.values, \n",
    "                   marker='D', linewidth=2, markersize=8, label=tipo, color=color)\n",
    "        \n",
    "        ax.set_xlabel('Varianza del Error', fontsize=13, fontweight='bold')\n",
    "        ax.set_ylabel('Rendimiento Promedio', fontsize=13, fontweight='bold')\n",
    "        ax.set_title(f'{modelo} - Interacci√≥n: Tipo de Generador √ó Varianza', \n",
    "                    fontsize=15, fontweight='bold', pad=20)\n",
    "        \n",
    "        ax.legend(title='Tipo de Generador', fontsize=9, title_fontsize=11, \n",
    "                 loc='best', ncol=2)\n",
    "        ax.grid(True, alpha=0.3, linestyle='--')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(dir_salida / '09_interaccion_tipo_varianza.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"‚úì Completado\\n\")\n",
    "    \n",
    "    def _grafica_interaccion_varianza_paso(self, df, modelo, dir_salida):\n",
    "        \"\"\"Gr√°fica 10: Interacci√≥n Varianza vs Paso\"\"\"\n",
    "        print(\"üìä Generando: Interacci√≥n Varianza vs Paso...\")\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 7))\n",
    "        \n",
    "        varianzas = sorted(df['Varianza error'].unique())\n",
    "        colors = plt.cm.plasma(np.linspace(0, 0.9, len(varianzas)))\n",
    "        \n",
    "        for var, color in zip(varianzas, colors):\n",
    "            df_var = df[df['Varianza error'] == var]\n",
    "            paso_mean = df_var.groupby('Paso')[modelo].mean()\n",
    "            ax.plot(paso_mean.index, paso_mean.values, \n",
    "                   marker='o', linewidth=2.5, markersize=9, \n",
    "                   label=f'Varianza={var}', color=color)\n",
    "        \n",
    "        ax.set_xlabel('Paso', fontsize=13, fontweight='bold')\n",
    "        ax.set_ylabel('Rendimiento Promedio', fontsize=13, fontweight='bold')\n",
    "        ax.set_title(f'{modelo} - Interacci√≥n: Varianza √ó Paso', \n",
    "                    fontsize=15, fontweight='bold', pad=20)\n",
    "        \n",
    "        ax.legend(title='Varianza del Error', fontsize=11, title_fontsize=12, loc='best')\n",
    "        ax.grid(True, alpha=0.3, linestyle='--')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(dir_salida / '10_interaccion_varianza_paso.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"‚úì Completado\\n\")\n",
    "    \n",
    "    def _grafica_importancia_caracteristicas(self, df, modelo, dir_salida, resultados):\n",
    "        \"\"\"Gr√°fica 11: Caracter√≠sticas que m√°s afectan el rendimiento\"\"\"\n",
    "        print(\"üìä Generando: Importancia de Caracter√≠sticas...\")\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        \n",
    "        # Calcular importancia basada en variaci√≥n del rendimiento\n",
    "        importancia = {}\n",
    "        \n",
    "        # 1. Por Distribuci√≥n\n",
    "        dist_var = df.groupby('Distribuci√≥n')[modelo].var().mean()\n",
    "        dist_rango = df.groupby('Distribuci√≥n')[modelo].mean().max() - df.groupby('Distribuci√≥n')[modelo].mean().min()\n",
    "        importancia['Distribuci√≥n'] = dist_rango\n",
    "        \n",
    "        # 2. Por Tipo de Modelo\n",
    "        tipo_var = df.groupby('Tipo de Modelo')[modelo].var().mean()\n",
    "        tipo_rango = df.groupby('Tipo de Modelo')[modelo].mean().max() - df.groupby('Tipo de Modelo')[modelo].mean().min()\n",
    "        importancia['Tipo de Generador'] = tipo_rango\n",
    "        \n",
    "        # 3. Por Paso\n",
    "        paso_var = df.groupby('Paso')[modelo].var().mean()\n",
    "        paso_rango = df.groupby('Paso')[modelo].mean().max() - df.groupby('Paso')[modelo].mean().min()\n",
    "        importancia['Paso'] = paso_rango\n",
    "        \n",
    "        # 4. Por Varianza\n",
    "        var_var = df.groupby('Varianza error')[modelo].var().mean()\n",
    "        var_rango = df.groupby('Varianza error')[modelo].mean().max() - df.groupby('Varianza error')[modelo].mean().min()\n",
    "        importancia['Varianza Error'] = var_rango\n",
    "        \n",
    "        # Calcular tambi√©n correlaciones absolutas\n",
    "        correlaciones = {}\n",
    "        correlaciones['Paso'] = abs(df['Paso'].corr(df[modelo]))\n",
    "        correlaciones['Varianza Error'] = abs(df['Varianza error'].corr(df[modelo]))\n",
    "        \n",
    "        # Convertir variables categ√≥ricas a num√©ricas para correlaci√≥n\n",
    "        df_temp = df.copy()\n",
    "        df_temp['Dist_num'] = pd.Categorical(df_temp['Distribuci√≥n']).codes\n",
    "        df_temp['Tipo_num'] = pd.Categorical(df_temp['Tipo de Modelo']).codes\n",
    "        correlaciones['Distribuci√≥n'] = abs(df_temp['Dist_num'].corr(df_temp[modelo]))\n",
    "        correlaciones['Tipo de Generador'] = abs(df_temp['Tipo_num'].corr(df_temp[modelo]))\n",
    "        \n",
    "        # Normalizar importancias (0-100)\n",
    "        max_importancia = max(importancia.values())\n",
    "        importancia_norm = {k: (v/max_importancia)*100 for k, v in importancia.items()}\n",
    "        \n",
    "        # Ordenar por importancia\n",
    "        items_ordenados = sorted(importancia_norm.items(), key=lambda x: x[1], reverse=True)\n",
    "        caracteristicas = [item[0] for item in items_ordenados]\n",
    "        valores = [item[1] for item in items_ordenados]\n",
    "        \n",
    "        # Crear barras\n",
    "        colors = plt.cm.RdYlGn_r(np.linspace(0.3, 0.9, len(caracteristicas)))\n",
    "        bars = ax.barh(caracteristicas, valores, color=colors, edgecolor='black', linewidth=2)\n",
    "        \n",
    "        # A√±adir valores y correlaciones\n",
    "        for i, (bar, car, val) in enumerate(zip(bars, caracteristicas, valores)):\n",
    "            width = bar.get_width()\n",
    "            corr = correlaciones.get(car, 0)\n",
    "            ax.text(width, i, f'  {val:.1f}%\\n  (corr={corr:.3f})', \n",
    "                   va='center', fontsize=10, fontweight='bold')\n",
    "        \n",
    "        ax.set_xlabel('Importancia Relativa (%)', fontsize=13, fontweight='bold')\n",
    "        ax.set_title(f'{modelo} - Caracter√≠sticas que m√°s Afectan el Rendimiento\\n' + \n",
    "                    '(Basado en rango de variaci√≥n de medias)',\n",
    "                    fontsize=15, fontweight='bold', pad=20)\n",
    "        ax.set_xlim(0, 110)\n",
    "        ax.grid(True, alpha=0.3, axis='x', linestyle='--')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(dir_salida / '11_importancia_caracteristicas.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # Guardar en resultados\n",
    "        resultados['importancia_caracteristicas'] = dict(items_ordenados)\n",
    "        resultados['correlaciones'] = correlaciones\n",
    "        \n",
    "        print(\"‚úì Completado\\n\")\n",
    "    \n",
    "    def _grafica_distribucion_general(self, df, modelo, dir_salida):\n",
    "        \"\"\"Gr√°fica 12: Distribuci√≥n general del rendimiento\"\"\"\n",
    "        print(\"üìä Generando: Distribuci√≥n General del Rendimiento...\")\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 7))\n",
    "        \n",
    "        # Histograma con curva de densidad\n",
    "        n, bins, patches = ax.hist(df[modelo], bins=40, density=True, \n",
    "                                   alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        \n",
    "        # A√±adir KDE\n",
    "        from scipy.stats import gaussian_kde\n",
    "        kde = gaussian_kde(df[modelo])\n",
    "        x_range = np.linspace(df[modelo].min(), df[modelo].max(), 200)\n",
    "        ax.plot(x_range, kde(x_range), 'r-', linewidth=3, label='KDE')\n",
    "        \n",
    "        # L√≠neas de estad√≠sticos\n",
    "        media = df[modelo].mean()\n",
    "        mediana = df[modelo].median()\n",
    "        ax.axvline(media, color='darkblue', linestyle='--', linewidth=2.5, \n",
    "                  label=f'Media: {media:.4f}')\n",
    "        ax.axvline(mediana, color='green', linestyle='--', linewidth=2.5, \n",
    "                  label=f'Mediana: {mediana:.4f}')\n",
    "        \n",
    "        # Cuartiles\n",
    "        q1 = df[modelo].quantile(0.25)\n",
    "        q3 = df[modelo].quantile(0.75)\n",
    "        ax.axvline(q1, color='orange', linestyle=':', linewidth=2, \n",
    "                  label=f'Q1: {q1:.4f}')\n",
    "        ax.axvline(q3, color='orange', linestyle=':', linewidth=2, \n",
    "                  label=f'Q3: {q3:.4f}')\n",
    "        \n",
    "        ax.set_xlabel('Rendimiento', fontsize=13, fontweight='bold')\n",
    "        ax.set_ylabel('Densidad', fontsize=13, fontweight='bold')\n",
    "        ax.set_title(f'{modelo} - Distribuci√≥n General del Rendimiento\\n' +\n",
    "                    f'(n={len(df)}, std={df[modelo].std():.4f})',\n",
    "                    fontsize=15, fontweight='bold', pad=20)\n",
    "        \n",
    "        ax.legend(fontsize=11, loc='best')\n",
    "        ax.grid(True, alpha=0.3, linestyle='--')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(dir_salida / '12_distribucion_general.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"‚úì Completado\\n\")\n",
    "    \n",
    "    def _grafica_analisis_outliers(self, df, modelo, dir_salida):\n",
    "        \"\"\"Gr√°fica 13: An√°lisis de outliers\"\"\"\n",
    "        print(\"üìä Generando: An√°lisis de Outliers...\")\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 7))\n",
    "        \n",
    "        # Boxplot detallado\n",
    "        bp = ax.boxplot([df[modelo]], labels=[modelo], vert=True, patch_artist=True,\n",
    "                       widths=0.5, showmeans=True, meanline=True)\n",
    "        \n",
    "        # Colorear\n",
    "        bp['boxes'][0].set_facecolor('lightblue')\n",
    "        bp['boxes'][0].set_alpha(0.7)\n",
    "        bp['medians'][0].set_color('red')\n",
    "        bp['medians'][0].set_linewidth(2.5)\n",
    "        bp['means'][0].set_color('darkblue')\n",
    "        bp['means'][0].set_linewidth(2.5)\n",
    "        \n",
    "        # Identificar outliers usando IQR\n",
    "        Q1 = df[modelo].quantile(0.25)\n",
    "        Q3 = df[modelo].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        outliers = df[(df[modelo] < lower_bound) | (df[modelo] > upper_bound)]\n",
    "        n_outliers = len(outliers)\n",
    "        pct_outliers = (n_outliers / len(df)) * 100\n",
    "        \n",
    "        # Scatter de todos los puntos con outliers resaltados\n",
    "        y_normal = df[(df[modelo] >= lower_bound) & (df[modelo] <= upper_bound)][modelo]\n",
    "        x_normal = np.random.normal(1, 0.04, size=len(y_normal))\n",
    "        ax.scatter(x_normal, y_normal, alpha=0.3, s=30, color='blue', label='Datos normales')\n",
    "        \n",
    "        if n_outliers > 0:\n",
    "            y_outliers = outliers[modelo]\n",
    "            x_outliers = np.random.normal(1, 0.04, size=len(y_outliers))\n",
    "            ax.scatter(x_outliers, y_outliers, alpha=0.8, s=80, color='red', \n",
    "                      marker='*', label=f'Outliers ({n_outliers})', zorder=10)\n",
    "        \n",
    "        # L√≠neas de l√≠mites\n",
    "        ax.axhline(lower_bound, color='orange', linestyle='--', linewidth=2, \n",
    "                  label=f'L√≠mite inferior: {lower_bound:.4f}')\n",
    "        ax.axhline(upper_bound, color='orange', linestyle='--', linewidth=2, \n",
    "                  label=f'L√≠mite superior: {upper_bound:.4f}')\n",
    "        \n",
    "        ax.set_ylabel('Rendimiento', fontsize=13, fontweight='bold')\n",
    "        ax.set_title(f'{modelo} - An√°lisis de Outliers (M√©todo IQR)\\n' +\n",
    "                    f'Outliers detectados: {n_outliers} ({pct_outliers:.2f}%)',\n",
    "                    fontsize=15, fontweight='bold', pad=20)\n",
    "        ax.set_xticks([])\n",
    "        ax.legend(fontsize=11, loc='best')\n",
    "        ax.grid(True, alpha=0.3, axis='y', linestyle='--')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(dir_salida / '13_analisis_outliers.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"‚úì Completado\\n\")\n",
    "    \n",
    "    def _grafica_heatmap_configuraciones(self, df, modelo, dir_salida):\n",
    "        \"\"\"Gr√°fica 14: Mapa de calor de configuraciones\"\"\"\n",
    "        print(\"üìä Generando: Heatmap de Configuraciones...\")\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "        \n",
    "        # Heatmap 1: Tipo de Modelo vs Distribuci√≥n\n",
    "        pivot1 = df.pivot_table(values=modelo, \n",
    "                                index='Tipo de Modelo', \n",
    "                                columns='Distribuci√≥n', \n",
    "                                aggfunc='mean')\n",
    "        \n",
    "        sns.heatmap(pivot1, annot=True, fmt='.4f', cmap='RdYlGn_r', \n",
    "                   ax=axes[0], cbar_kws={'label': 'Rendimiento'},\n",
    "                   linewidths=0.5, linecolor='gray')\n",
    "        axes[0].set_title('Tipo de Generador √ó Distribuci√≥n', \n",
    "                         fontsize=13, fontweight='bold', pad=15)\n",
    "        axes[0].set_xlabel('Distribuci√≥n', fontsize=11, fontweight='bold')\n",
    "        axes[0].set_ylabel('Tipo de Generador', fontsize=11, fontweight='bold')\n",
    "        \n",
    "        # Heatmap 2: Paso vs Varianza\n",
    "        pivot2 = df.pivot_table(values=modelo, \n",
    "                                index='Paso', \n",
    "                                columns='Varianza error', \n",
    "                                aggfunc='mean')\n",
    "        \n",
    "        sns.heatmap(pivot2, annot=True, fmt='.4f', cmap='RdYlGn_r', \n",
    "                   ax=axes[1], cbar_kws={'label': 'Rendimiento'},\n",
    "                   linewidths=0.5, linecolor='gray')\n",
    "        axes[1].set_title('Paso √ó Varianza del Error', \n",
    "                         fontsize=13, fontweight='bold', pad=15)\n",
    "        axes[1].set_xlabel('Varianza del Error', fontsize=11, fontweight='bold')\n",
    "        axes[1].set_ylabel('Paso', fontsize=11, fontweight='bold')\n",
    "        \n",
    "        fig.suptitle(f'{modelo} - Mapas de Calor de Configuraciones', \n",
    "                    fontsize=16, fontweight='bold', y=1.02)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(dir_salida / '14_heatmap_configuraciones.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"‚úì Completado\\n\")\n",
    "    \n",
    "    def _grafica_estabilidad(self, df, modelo, dir_salida):\n",
    "        \"\"\"Gr√°fica 15: An√°lisis de estabilidad\"\"\"\n",
    "        print(\"üìä Generando: An√°lisis de Estabilidad...\")\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        \n",
    "        # 1. Estabilidad por Paso\n",
    "        paso_std = df.groupby('Paso')[modelo].std()\n",
    "        paso_cv = (df.groupby('Paso')[modelo].std() / df.groupby('Paso')[modelo].mean()) * 100\n",
    "        \n",
    "        ax1 = axes[0, 0]\n",
    "        ax1_twin = ax1.twinx()\n",
    "        \n",
    "        bars = ax1.bar(paso_std.index, paso_std.values, alpha=0.7, \n",
    "                      color='steelblue', label='Desv. Est√°ndar')\n",
    "        line = ax1_twin.plot(paso_cv.index, paso_cv.values, 'ro-', \n",
    "                            linewidth=2.5, markersize=8, label='Coef. Variaci√≥n (%)')\n",
    "        \n",
    "        ax1.set_xlabel('Paso', fontsize=11, fontweight='bold')\n",
    "        ax1.set_ylabel('Desviaci√≥n Est√°ndar', fontsize=11, fontweight='bold', color='steelblue')\n",
    "        ax1_twin.set_ylabel('Coeficiente de Variaci√≥n (%)', fontsize=11, fontweight='bold', color='red')\n",
    "        ax1.set_title('Estabilidad por Paso', fontsize=12, fontweight='bold')\n",
    "        ax1.tick_params(axis='y', labelcolor='steelblue')\n",
    "        ax1_twin.tick_params(axis='y', labelcolor='red')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. Estabilidad por Tipo\n",
    "        tipo_std = df.groupby('Tipo de Modelo')[modelo].std().sort_values()\n",
    "        \n",
    "        ax2 = axes[0, 1]\n",
    "        colors = plt.cm.RdYlGn(np.linspace(0.3, 0.9, len(tipo_std)))\n",
    "        ax2.barh(range(len(tipo_std)), tipo_std.values, color=colors, \n",
    "                edgecolor='black', linewidth=1.5)\n",
    "        ax2.set_yticks(range(len(tipo_std)))\n",
    "        ax2.set_yticklabels(tipo_std.index, fontsize=9)\n",
    "        ax2.set_xlabel('Desviaci√≥n Est√°ndar', fontsize=11, fontweight='bold')\n",
    "        ax2.set_title('Estabilidad por Tipo de Generador\\n(menor = m√°s estable)', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "        ax2.grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        # 3. Estabilidad por Distribuci√≥n\n",
    "        dist_std = df.groupby('Distribuci√≥n')[modelo].std().sort_values()\n",
    "        \n",
    "        ax3 = axes[1, 0]\n",
    "        colors = plt.cm.RdYlGn(np.linspace(0.3, 0.9, len(dist_std)))\n",
    "        ax3.barh(range(len(dist_std)), dist_std.values, color=colors, \n",
    "                edgecolor='black', linewidth=1.5)\n",
    "        ax3.set_yticks(range(len(dist_std)))\n",
    "        ax3.set_yticklabels(dist_std.index, fontsize=10)\n",
    "        ax3.set_xlabel('Desviaci√≥n Est√°ndar', fontsize=11, fontweight='bold')\n",
    "        ax3.set_title('Estabilidad por Distribuci√≥n\\n(menor = m√°s estable)', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "        ax3.grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        # 4. Estabilidad por Varianza\n",
    "        var_std = df.groupby('Varianza error')[modelo].std()\n",
    "        var_mean = df.groupby('Varianza error')[modelo].mean()\n",
    "        \n",
    "        ax4 = axes[1, 1]\n",
    "        ax4.plot(var_std.index, var_std.values, 'bs-', \n",
    "                linewidth=2.5, markersize=10, label='Desv. Est√°ndar')\n",
    "        ax4.plot(var_mean.index, var_mean.values, 'ro-', \n",
    "                linewidth=2.5, markersize=10, label='Media')\n",
    "        ax4.set_xlabel('Varianza del Error', fontsize=11, fontweight='bold')\n",
    "        ax4.set_ylabel('Valor', fontsize=11, fontweight='bold')\n",
    "        ax4.set_title('Estabilidad vs Varianza del Error', fontsize=12, fontweight='bold')\n",
    "        ax4.legend(fontsize=10)\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "        \n",
    "        fig.suptitle(f'{modelo} - An√°lisis de Estabilidad del Modelo', \n",
    "                    fontsize=16, fontweight='bold', y=0.995)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(dir_salida / '15_analisis_estabilidad.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"‚úì Completado\\n\")\n",
    "    \n",
    "    def _guardar_estadisticas_completas(self, df, modelo, dir_salida, resultados):\n",
    "        \"\"\"Guarda estad√≠sticas completas en archivo de texto\"\"\"\n",
    "        print(\"üíæ Guardando estad√≠sticas completas...\")\n",
    "        \n",
    "        with open(dir_salida / 'estadisticas_completas.txt', 'w', encoding='utf-8') as f:\n",
    "            f.write(\"=\"*80 + \"\\n\")\n",
    "            f.write(f\"ESTAD√çSTICAS COMPLETAS: {modelo}\\n\")\n",
    "            f.write(f\"Escenario: {resultados['escenario']}\\n\")\n",
    "            f.write(f\"Observaciones: {resultados['n_observaciones']}\\n\")\n",
    "            f.write(\"=\"*80 + \"\\n\\n\")\n",
    "            \n",
    "            # Estad√≠sticas generales\n",
    "            f.write(\"ESTAD√çSTICAS GENERALES\\n\")\n",
    "            f.write(\"-\"*80 + \"\\n\")\n",
    "            f.write(f\"Media: {df[modelo].mean():.6f}\\n\")\n",
    "            f.write(f\"Mediana: {df[modelo].median():.6f}\\n\")\n",
    "            f.write(f\"Desv. Est√°ndar: {df[modelo].std():.6f}\\n\")\n",
    "            f.write(f\"M√≠nimo: {df[modelo].min():.6f}\\n\")\n",
    "            f.write(f\"M√°ximo: {df[modelo].max():.6f}\\n\")\n",
    "            f.write(f\"Rango: {df[modelo].max() - df[modelo].min():.6f}\\n\")\n",
    "            f.write(f\"Q1: {df[modelo].quantile(0.25):.6f}\\n\")\n",
    "            f.write(f\"Q3: {df[modelo].quantile(0.75):.6f}\\n\")\n",
    "            f.write(f\"IQR: {df[modelo].quantile(0.75) - df[modelo].quantile(0.25):.6f}\\n\\n\")\n",
    "            \n",
    "            # Por Distribuci√≥n\n",
    "            f.write(\"\\nESTAD√çSTICAS POR DISTRIBUCI√ìN\\n\")\n",
    "            f.write(\"-\"*80 + \"\\n\")\n",
    "            stats_dist = df.groupby('Distribuci√≥n')[modelo].describe()\n",
    "            f.write(stats_dist.to_string() + \"\\n\\n\")\n",
    "            \n",
    "            # Por Tipo de Modelo\n",
    "            f.write(\"\\nESTAD√çSTICAS POR TIPO DE GENERADOR\\n\")\n",
    "            f.write(\"-\"*80 + \"\\n\")\n",
    "            stats_tipo = df.groupby('Tipo de Modelo')[modelo].describe()\n",
    "            f.write(stats_tipo.to_string() + \"\\n\\n\")\n",
    "            \n",
    "            # Por Paso\n",
    "            f.write(\"\\nESTAD√çSTICAS POR PASO\\n\")\n",
    "            f.write(\"-\"*80 + \"\\n\")\n",
    "            stats_paso = df.groupby('Paso')[modelo].describe()\n",
    "            f.write(stats_paso.to_string() + \"\\n\\n\")\n",
    "            \n",
    "            # Por Varianza\n",
    "            f.write(\"\\nESTAD√çSTICAS POR VARIANZA\\n\")\n",
    "            f.write(\"-\"*80 + \"\\n\")\n",
    "            stats_var = df.groupby('Varianza error')[modelo].describe()\n",
    "            f.write(stats_var.to_string() + \"\\n\\n\")\n",
    "            \n",
    "            # Importancia de caracter√≠sticas\n",
    "            if 'importancia_caracteristicas' in resultados:\n",
    "                f.write(\"\\nIMPORTANCIA DE CARACTER√çSTICAS\\n\")\n",
    "                f.write(\"-\"*80 + \"\\n\")\n",
    "                for car, val in resultados['importancia_caracteristicas'].items():\n",
    "                    f.write(f\"{car}: {val:.2f}%\\n\")\n",
    "                f.write(\"\\n\")\n",
    "            \n",
    "            # Correlaciones\n",
    "            if 'correlaciones' in resultados:\n",
    "                f.write(\"\\nCORRELACIONES\\n\")\n",
    "                f.write(\"-\"*80 + \"\\n\")\n",
    "                for car, val in resultados['correlaciones'].items():\n",
    "                    f.write(f\"{car}: {val:.4f}\\n\")\n",
    "        \n",
    "        print(\"‚úì Completado\\n\")\n",
    "    \n",
    "    def ejecutar_analisis_completo(self):\n",
    "        \"\"\"Ejecuta el an√°lisis completo para todos los modelos y escenarios\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"INICIANDO AN√ÅLISIS COMPLETO DE MODELOS\")\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "        total_analisis = len(ESCENARIOS) * len(MODELOS)\n",
    "        contador = 0\n",
    "        \n",
    "        for escenario in ESCENARIOS:\n",
    "            for modelo in MODELOS:\n",
    "                contador += 1\n",
    "                print(f\"\\n[{contador}/{total_analisis}] Procesando...\")\n",
    "                \n",
    "                try:\n",
    "                    resultado = self.analizar_modelo_escenario(escenario, modelo)\n",
    "                    key = f\"{escenario}_{modelo}\"\n",
    "                    self.resultados_analisis[key] = resultado\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Error en {modelo} - {escenario}: {str(e)}\")\n",
    "                    import traceback\n",
    "                    traceback.print_exc()\n",
    "                    continue\n",
    "            \n",
    "            # Generar ranking DM despu√©s de cada escenario\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"GENERANDO RANKING PARA ESCENARIO: {escenario}\")\n",
    "            print(f\"{'='*80}\\n\")\n",
    "            self._generar_ranking_escenario(escenario)\n",
    "        \n",
    "        # Generar resumen comparativo global\n",
    "        self._generar_resumen_comparativo_global()\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"‚úÖ AN√ÅLISIS COMPLETO FINALIZADO\")\n",
    "        print(f\"   Total de an√°lisis realizados: {contador}\")\n",
    "        print(f\"   Resultados guardados en: ./Resultados/\")\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    def _generar_ranking_escenario(self, escenario):\n",
    "        \"\"\"Genera ranking con test DM para un escenario espec√≠fico\"\"\"\n",
    "        print(f\"üìä Generando ranking con Test Diebold-Mariano para {escenario}...\")\n",
    "        \n",
    "        dir_salida = Path(f\"./Resultados/{escenario}\")\n",
    "        dir_salida.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        df_esc = self.df[self.df['Escenario'] == escenario].copy()\n",
    "        \n",
    "        # Realizar comparaciones DM\n",
    "        df_comparaciones, alpha_bonf = comparaciones_multiples_dm(df_esc, MODELOS, alpha=0.05)\n",
    "        \n",
    "        # Calcular ranking\n",
    "        df_ranking, matriz_sup = calcular_ranking_dm(df_comparaciones, MODELOS)\n",
    "        \n",
    "        print(f\"\\nüèÜ RANKING (Test Diebold-Mariano):\")\n",
    "        print(df_ranking.to_string(index=False))\n",
    "        \n",
    "        # Guardar archivos\n",
    "        df_comparaciones.to_excel(dir_salida / f'comparaciones_dm_{escenario}.xlsx', index=False)\n",
    "        df_ranking.to_excel(dir_salida / f'ranking_dm_{escenario}.xlsx', index=False)\n",
    "        \n",
    "        # GR√ÅFICA √öNICA DEL RANKING\n",
    "        fig = plt.figure(figsize=(16, 10))\n",
    "        gs = fig.add_gridspec(2, 2, hspace=0.3, wspace=0.3)\n",
    "        \n",
    "        # 1. Ranking principal (m√°s grande)\n",
    "        ax1 = fig.add_subplot(gs[0, :])\n",
    "        colors_rank = plt.cm.RdYlGn_r(np.linspace(0.2, 0.9, len(df_ranking)))\n",
    "        bars = ax1.barh(df_ranking['Modelo'], df_ranking['Score'], \n",
    "                       color=colors_rank, edgecolor='black', linewidth=2)\n",
    "        \n",
    "        # A√±adir valores\n",
    "        for i, (bar, score, rank, vic, der) in enumerate(zip(bars, df_ranking['Score'], \n",
    "                                                              df_ranking['Rank'], \n",
    "                                                              df_ranking['Victorias'],\n",
    "                                                              df_ranking['Derrotas'])):\n",
    "            width = bar.get_width()\n",
    "            ax1.text(width, i, f'  #{rank} | Score: {int(score)} (V:{int(vic)} D:{int(der)})', \n",
    "                    va='center', fontsize=11, fontweight='bold')\n",
    "        \n",
    "        ax1.set_xlabel('Score (Victorias - Derrotas)', fontsize=14, fontweight='bold')\n",
    "        ax1.set_title(f'üèÜ RANKING DE MODELOS - {escenario}\\n(Test Diebold-Mariano con correcci√≥n Bonferroni)', \n",
    "                     fontsize=16, fontweight='bold', pad=20)\n",
    "        ax1.axvline(0, color='black', linestyle='-', linewidth=1.5)\n",
    "        ax1.grid(True, alpha=0.3, axis='x', linestyle='--')\n",
    "        ax1.set_ylabel('Modelo', fontsize=13, fontweight='bold')\n",
    "        \n",
    "        # 2. Matriz de superioridad\n",
    "        ax2 = fig.add_subplot(gs[1, 0])\n",
    "        sns.heatmap(matriz_sup, annot=True, fmt='.0f', cmap='RdYlGn', \n",
    "                   center=0, ax=ax2, cbar_kws={'label': 'Superioridad'},\n",
    "                   vmin=-1, vmax=1, linewidths=0.5, linecolor='gray')\n",
    "        ax2.set_title('Matriz de Superioridad\\n(1: gana, -1: pierde, 0: empate)', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "        ax2.set_xlabel('Modelo Comparado', fontsize=10)\n",
    "        ax2.set_ylabel('Modelo', fontsize=10)\n",
    "        ax2.tick_params(labelsize=9)\n",
    "        \n",
    "        # 3. Victorias vs Derrotas\n",
    "        ax3 = fig.add_subplot(gs[1, 1])\n",
    "        x = np.arange(len(df_ranking))\n",
    "        width_bar = 0.35\n",
    "        \n",
    "        bars_v = ax3.bar(x - width_bar/2, df_ranking['Victorias'], width_bar, \n",
    "                        label='Victorias', color='green', alpha=0.8, edgecolor='black')\n",
    "        bars_d = ax3.bar(x + width_bar/2, df_ranking['Derrotas'], width_bar, \n",
    "                        label='Derrotas', color='red', alpha=0.8, edgecolor='black')\n",
    "        \n",
    "        # A√±adir valores sobre barras\n",
    "        for bar in bars_v:\n",
    "            height = bar.get_height()\n",
    "            ax3.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{int(height)}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "        \n",
    "        for bar in bars_d:\n",
    "            height = bar.get_height()\n",
    "            ax3.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{int(height)}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "        \n",
    "        ax3.set_xlabel('Modelo', fontsize=11, fontweight='bold')\n",
    "        ax3.set_ylabel('Cantidad', fontsize=11, fontweight='bold')\n",
    "        ax3.set_title('Victorias vs Derrotas\\n(Comparaciones significativas)', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "        ax3.set_xticks(x)\n",
    "        ax3.set_xticklabels(df_ranking['Modelo'], rotation=45, ha='right', fontsize=9)\n",
    "        ax3.legend(fontsize=10)\n",
    "        ax3.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(dir_salida / f'RANKING_{escenario}.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"‚úÖ Ranking guardado: RANKING_{escenario}.png\\n\")\n",
    "    \n",
    "    def _generar_resumen_comparativo_global(self):\n",
    "        \"\"\"Genera resumen comparativo global entre todos los escenarios\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"GENERANDO RESUMEN COMPARATIVO GLOBAL\")\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "        dir_salida = Path(\"./Resultados/Comparativo_Global\")\n",
    "        dir_salida.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # ============================================================\n",
    "        # RANKING GLOBAL CON DM TEST\n",
    "        # ============================================================\n",
    "        print(\"üìä Calculando ranking global (todos los escenarios)...\\n\")\n",
    "        \n",
    "        df_comparaciones_global, alpha_bonf = comparaciones_multiples_dm(\n",
    "            self.df, MODELOS, alpha=0.05\n",
    "        )\n",
    "        \n",
    "        df_ranking_global, matriz_sup_global = calcular_ranking_dm(\n",
    "            df_comparaciones_global, MODELOS\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nüèÜ RANKING GLOBAL (TODOS LOS ESCENARIOS):\")\n",
    "        print(df_ranking_global.to_string(index=False))\n",
    "        \n",
    "        # Guardar resultados globales\n",
    "        df_comparaciones_global.to_excel(\n",
    "            dir_salida / 'comparaciones_dm_global.xlsx', \n",
    "            index=False\n",
    "        )\n",
    "        df_ranking_global.to_excel(\n",
    "            dir_salida / 'ranking_dm_global.xlsx', \n",
    "            index=False\n",
    "        )\n",
    "        \n",
    "        # GR√ÅFICA √öNICA DEL RANKING GLOBAL\n",
    "        fig = plt.figure(figsize=(18, 12))\n",
    "        gs = fig.add_gridspec(3, 2, hspace=0.35, wspace=0.3)\n",
    "        \n",
    "        # 1. Ranking global principal\n",
    "        ax1 = fig.add_subplot(gs[0, :])\n",
    "        colors_rank = plt.cm.RdYlGn_r(np.linspace(0.2, 0.9, len(df_ranking_global)))\n",
    "        bars = ax1.barh(df_ranking_global['Modelo'], df_ranking_global['Score'], \n",
    "                       color=colors_rank, edgecolor='black', linewidth=2.5)\n",
    "        \n",
    "        # A√±adir informaci√≥n detallada\n",
    "        for i, (bar, score, rank, vic, der, pct) in enumerate(zip(bars, \n",
    "                                                                   df_ranking_global['Score'],\n",
    "                                                                   df_ranking_global['Rank'],\n",
    "                                                                   df_ranking_global['Victorias'],\n",
    "                                                                   df_ranking_global['Derrotas'],\n",
    "                                                                   df_ranking_global['Pct_Victorias'])):\n",
    "            width = bar.get_width()\n",
    "            ax1.text(width, i, \n",
    "                    f'  #{rank} | Score: {int(score)} | V:{int(vic)} D:{int(der)} | {pct:.1f}%', \n",
    "                    va='center', fontsize=10, fontweight='bold')\n",
    "        \n",
    "        ax1.set_xlabel('Score Global (Victorias - Derrotas)', fontsize=14, fontweight='bold')\n",
    "        ax1.set_title('üèÜ RANKING GLOBAL DE MODELOS (Todos los Escenarios)\\n' +\n",
    "                     'Test Diebold-Mariano con correcci√≥n de Bonferroni', \n",
    "                     fontsize=17, fontweight='bold', pad=20)\n",
    "        ax1.axvline(0, color='black', linestyle='-', linewidth=2)\n",
    "        ax1.grid(True, alpha=0.3, axis='x', linestyle='--')\n",
    "        ax1.set_ylabel('Modelo', fontsize=13, fontweight='bold')\n",
    "        \n",
    "        # 2. Matriz de superioridad global\n",
    "        ax2 = fig.add_subplot(gs[1, :])\n",
    "        sns.heatmap(matriz_sup_global, annot=True, fmt='.0f', cmap='RdYlGn', \n",
    "                   center=0, ax=ax2, cbar_kws={'label': 'Superioridad Global'},\n",
    "                   vmin=-1, vmax=1, linewidths=1, linecolor='gray')\n",
    "        ax2.set_title('Matriz de Superioridad Global\\n(1: superior, -1: inferior, 0: sin diferencia)', \n",
    "                     fontsize=13, fontweight='bold', pad=15)\n",
    "        ax2.set_xlabel('Modelo Comparado', fontsize=11, fontweight='bold')\n",
    "        ax2.set_ylabel('Modelo', fontsize=11, fontweight='bold')\n",
    "        ax2.tick_params(labelsize=10)\n",
    "        \n",
    "        # 3. Rendimiento promedio por escenario\n",
    "        ax3 = fig.add_subplot(gs[2, 0])\n",
    "        \n",
    "        rendimientos_esc = []\n",
    "        for escenario in ESCENARIOS:\n",
    "            df_esc = self.df[self.df['Escenario'] == escenario]\n",
    "            medias = df_esc[MODELOS].mean()\n",
    "            rendimientos_esc.append(medias)\n",
    "        \n",
    "        df_rend = pd.DataFrame(rendimientos_esc, index=ESCENARIOS, columns=MODELOS)\n",
    "        \n",
    "        # Ordenar por ranking global\n",
    "        modelos_ordenados = df_ranking_global.sort_values('Rank')['Modelo'].tolist()\n",
    "        df_rend = df_rend[modelos_ordenados]\n",
    "        \n",
    "        # Plotear l√≠neas\n",
    "        for escenario in ESCENARIOS:\n",
    "            ax3.plot(range(len(modelos_ordenados)), df_rend.loc[escenario], \n",
    "                    marker='o', linewidth=2.5, markersize=8, label=escenario)\n",
    "        \n",
    "        ax3.set_xlabel('Modelos (ordenados por ranking)', fontsize=11, fontweight='bold')\n",
    "        ax3.set_ylabel('Rendimiento Promedio', fontsize=11, fontweight='bold')\n",
    "        ax3.set_title('Rendimiento por Escenario', fontsize=12, fontweight='bold')\n",
    "        ax3.set_xticks(range(len(modelos_ordenados)))\n",
    "        ax3.set_xticklabels(modelos_ordenados, rotation=45, ha='right', fontsize=9)\n",
    "        ax3.legend(fontsize=9)\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 4. Victorias totales\n",
    "        ax4 = fig.add_subplot(gs[2, 1])\n",
    "        \n",
    "        colors_vic = plt.cm.RdYlGn_r(np.linspace(0.3, 0.9, len(df_ranking_global)))\n",
    "        bars_vic = ax4.bar(range(len(df_ranking_global)), df_ranking_global['Victorias'], \n",
    "                          color=colors_vic, edgecolor='black', linewidth=1.5, alpha=0.8)\n",
    "        \n",
    "        # A√±adir porcentajes\n",
    "        for i, (bar, vic, pct) in enumerate(zip(bars_vic, \n",
    "                                                 df_ranking_global['Victorias'],\n",
    "                                                 df_ranking_global['Pct_Victorias'])):\n",
    "            height = bar.get_height()\n",
    "            ax4.text(i, height, f'{int(vic)}\\n({pct:.1f}%)', \n",
    "                    ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "        \n",
    "        ax4.set_xlabel('Modelo', fontsize=11, fontweight='bold')\n",
    "        ax4.set_ylabel('N√∫mero de Victorias', fontsize=11, fontweight='bold')\n",
    "        ax4.set_title('Total de Victorias Significativas', fontsize=12, fontweight='bold')\n",
    "        ax4.set_xticks(range(len(df_ranking_global)))\n",
    "        ax4.set_xticklabels(df_ranking_global['Modelo'], rotation=45, ha='right', fontsize=9)\n",
    "        ax4.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(dir_salida / 'RANKING_GLOBAL.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"\\n‚úÖ Ranking global guardado: RANKING_GLOBAL.png\")\n",
    "        \n",
    "        # ============================================================\n",
    "        # RESUMEN POR ESCENARIO\n",
    "        # ============================================================\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üèÜ MEJORES MODELOS POR ESCENARIO\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        resultados_por_escenario = []\n",
    "        \n",
    "        for escenario in ESCENARIOS:\n",
    "            df_esc = self.df[self.df['Escenario'] == escenario]\n",
    "            \n",
    "            # Realizar DM test para este escenario\n",
    "            df_comp_esc, _ = comparaciones_multiples_dm(df_esc, MODELOS, alpha=0.05)\n",
    "            df_rank_esc, _ = calcular_ranking_dm(df_comp_esc, MODELOS)\n",
    "            \n",
    "            mejor = df_rank_esc.iloc[0]\n",
    "            \n",
    "            print(f\"\\n{escenario}:\")\n",
    "            print(f\"  ü•á Mejor modelo: {mejor['Modelo']}\")\n",
    "            print(f\"  üìä Score DM: {mejor['Score']} (V:{mejor['Victorias']}, D:{mejor['Derrotas']}, E:{mejor['Empates']})\")\n",
    "            print(f\"  üìà % Victorias: {mejor['Pct_Victorias']:.1f}%\")\n",
    "            \n",
    "            # Estad√≠sticas descriptivas del mejor modelo\n",
    "            media = df_esc[mejor['Modelo']].mean()\n",
    "            std = df_esc[mejor['Modelo']].std()\n",
    "            minimo = df_esc[mejor['Modelo']].min()\n",
    "            maximo = df_esc[mejor['Modelo']].max()\n",
    "            \n",
    "            print(f\"  üìä Rendimiento: {media:.4f} ¬± {std:.4f}\")\n",
    "            print(f\"  üìä Rango: [{minimo:.4f}, {maximo:.4f}]\")\n",
    "            \n",
    "            # Top 3\n",
    "            print(f\"\\n  Top 3:\")\n",
    "            for i, row in df_rank_esc.head(3).iterrows():\n",
    "                print(f\"    {row['Rank']}. {row['Modelo']} (Score: {row['Score']}, {row['Pct_Victorias']:.1f}% victorias)\")\n",
    "            \n",
    "            resultados_por_escenario.append({\n",
    "                'Escenario': escenario,\n",
    "                'Mejor_Modelo': mejor['Modelo'],\n",
    "                'Rank': mejor['Rank'],\n",
    "                'Score_DM': mejor['Score'],\n",
    "                'Victorias': mejor['Victorias'],\n",
    "                'Derrotas': mejor['Derrotas'],\n",
    "                'Pct_Victorias': mejor['Pct_Victorias'],\n",
    "                'Media': media,\n",
    "                'Std': std,\n",
    "                'Min': minimo,\n",
    "                'Max': maximo\n",
    "            })\n",
    "        \n",
    "        # Guardar resumen por escenario\n",
    "        df_resumen_escenarios = pd.DataFrame(resultados_por_escenario)\n",
    "        df_resumen_escenarios.to_excel(\n",
    "            dir_salida / 'resumen_mejores_por_escenario.xlsx', \n",
    "            index=False\n",
    "        )\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"‚úÖ An√°lisis comparativo global completado\")\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "        # ============================================================\n",
    "        # GENERAR EXCEL CONSOLIDADO\n",
    "        # ============================================================\n",
    "        self._generar_excel_consolidado()\n",
    "        \n",
    "    def _generar_excel_consolidado(self):\n",
    "        \"\"\"Genera un archivo Excel consolidado con todas las m√©tricas y an√°lisis\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üìä GENERANDO EXCEL CONSOLIDADO\")\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "        dir_salida = Path(\"./Resultados\")\n",
    "        archivo_excel = dir_salida / \"ANALISIS_CONSOLIDADO_COMPLETO.xlsx\"\n",
    "        \n",
    "        with pd.ExcelWriter(archivo_excel, engine='openpyxl') as writer:\n",
    "            \n",
    "            # ============================================================\n",
    "            # HOJA 1: RESUMEN GENERAL POR MODELO-ESCENARIO\n",
    "            # ============================================================\n",
    "            print(\"üìã Generando HOJA 1: Resumen General por Modelo-Escenario...\")\n",
    "            \n",
    "            resumen_general = []\n",
    "            \n",
    "            # Obtener ranking global\n",
    "            df_comparaciones_global, _ = comparaciones_multiples_dm(self.df, MODELOS, alpha=0.05)\n",
    "            df_ranking_global, _ = calcular_ranking_dm(df_comparaciones_global, MODELOS)\n",
    "            \n",
    "            for escenario in ESCENARIOS:\n",
    "                df_esc = self.df[self.df['Escenario'] == escenario]\n",
    "                \n",
    "                # Obtener ranking del escenario\n",
    "                df_comp_esc, _ = comparaciones_multiples_dm(df_esc, MODELOS, alpha=0.05)\n",
    "                df_rank_esc, _ = calcular_ranking_dm(df_comp_esc, MODELOS)\n",
    "                \n",
    "                for modelo in MODELOS:\n",
    "                    # Estad√≠sticas b√°sicas\n",
    "                    rendimiento_prom = df_esc[modelo].mean()\n",
    "                    desv_est = df_esc[modelo].std()\n",
    "                    coef_var = (desv_est / rendimiento_prom * 100) if rendimiento_prom != 0 else 0\n",
    "                    \n",
    "                    # Ranking global del modelo\n",
    "                    rank_global = df_ranking_global[df_ranking_global['Modelo'] == modelo]['Rank'].values[0]\n",
    "                    score_dm_global = df_ranking_global[df_ranking_global['Modelo'] == modelo]['Score'].values[0]\n",
    "                    victorias_global = df_ranking_global[df_ranking_global['Modelo'] == modelo]['Victorias'].values[0]\n",
    "                    pct_victorias_global = df_ranking_global[df_ranking_global['Modelo'] == modelo]['Pct_Victorias'].values[0]\n",
    "                    \n",
    "                    # Ranking en el escenario\n",
    "                    rank_escenario = df_rank_esc[df_rank_esc['Modelo'] == modelo]['Rank'].values[0]\n",
    "                    score_dm_escenario = df_rank_esc[df_rank_esc['Modelo'] == modelo]['Score'].values[0]\n",
    "                    victorias_escenario = df_rank_esc[df_rank_esc['Modelo'] == modelo]['Victorias'].values[0]\n",
    "                    pct_victorias_escenario = df_rank_esc[df_rank_esc['Modelo'] == modelo]['Pct_Victorias'].values[0]\n",
    "                    \n",
    "                    resumen_general.append({\n",
    "                        'Escenario': escenario,\n",
    "                        'Modelo': modelo,\n",
    "                        'Rendimiento_Promedio': round(rendimiento_prom, 6),\n",
    "                        'Desviacion_Estandar': round(desv_est, 6),\n",
    "                        'Ranking_Global': int(rank_global),\n",
    "                        'Score_DM_Global': int(score_dm_global),\n",
    "                        'Victorias_Significativas_Global': int(victorias_global),\n",
    "                        '%_Victorias_Global': round(pct_victorias_global, 2),\n",
    "                        'Ranking_Escenario': int(rank_escenario),\n",
    "                        'Score_DM_Escenario': int(score_dm_escenario),\n",
    "                        'Victorias_Significativas_Escenario': int(victorias_escenario),\n",
    "                        '%_Victorias_Escenario': round(pct_victorias_escenario, 2),\n",
    "                        'Estabilidad_General': round(coef_var, 2),\n",
    "                        'Minimo': round(df_esc[modelo].min(), 6),\n",
    "                        'Maximo': round(df_esc[modelo].max(), 6),\n",
    "                        'Mediana': round(df_esc[modelo].median(), 6),\n",
    "                        'N_Observaciones': len(df_esc)\n",
    "                    })\n",
    "            \n",
    "            df_hoja1 = pd.DataFrame(resumen_general)\n",
    "            df_hoja1.to_excel(writer, sheet_name='Resumen_General', index=False)\n",
    "            print(\"‚úì Completado\\n\")\n",
    "            \n",
    "            # ============================================================\n",
    "            # HOJA 2: RENDIMIENTO POR CARACTER√çSTICAS\n",
    "            # ============================================================\n",
    "            print(\"üìã Generando HOJA 2: Rendimiento por Caracter√≠sticas...\")\n",
    "            \n",
    "            rendimiento_caracteristicas = []\n",
    "            \n",
    "            caracteristicas_cols = {\n",
    "                'Distribuci√≥n': 'Distribuci√≥n',\n",
    "                'Tipo_Generador': 'Tipo de Modelo',\n",
    "                'Paso': 'Paso',\n",
    "                'Varianza': 'Varianza error'\n",
    "            }\n",
    "            \n",
    "            for escenario in ESCENARIOS:\n",
    "                df_esc = self.df[self.df['Escenario'] == escenario]\n",
    "                \n",
    "                for modelo in MODELOS:\n",
    "                    for caract_nombre, caract_col in caracteristicas_cols.items():\n",
    "                        \n",
    "                        stats = df_esc.groupby(caract_col)[modelo].agg([\n",
    "                            'mean', 'std', 'count', 'min', 'max', 'median'\n",
    "                        ])\n",
    "                        \n",
    "                        for categoria in stats.index:\n",
    "                            rendimiento_caracteristicas.append({\n",
    "                                'Escenario': escenario,\n",
    "                                'Modelo': modelo,\n",
    "                                'Caracteristica': caract_nombre,\n",
    "                                'Categoria': str(categoria),\n",
    "                                'Rendimiento_Promedio': round(stats.loc[categoria, 'mean'], 6),\n",
    "                                'Desviacion_Estandar': round(stats.loc[categoria, 'std'], 6),\n",
    "                                'N_Observaciones': int(stats.loc[categoria, 'count']),\n",
    "                                'Minimo': round(stats.loc[categoria, 'min'], 6),\n",
    "                                'Maximo': round(stats.loc[categoria, 'max'], 6),\n",
    "                                'Mediana': round(stats.loc[categoria, 'median'], 6)\n",
    "                            })\n",
    "            \n",
    "            df_hoja2 = pd.DataFrame(rendimiento_caracteristicas)\n",
    "            df_hoja2.to_excel(writer, sheet_name='Rendimiento_Caracteristicas', index=False)\n",
    "            print(\"‚úì Completado\\n\")\n",
    "            \n",
    "            # ============================================================\n",
    "            # HOJA 3: IMPORTANCIA DE CARACTER√çSTICAS\n",
    "            # ============================================================\n",
    "            print(\"üìã Generando HOJA 3: Importancia de Caracter√≠sticas...\")\n",
    "            \n",
    "            importancia_caracteristicas = []\n",
    "            \n",
    "            for escenario in ESCENARIOS:\n",
    "                df_esc = self.df[self.df['Escenario'] == escenario]\n",
    "                \n",
    "                for modelo in MODELOS:\n",
    "                    # Calcular importancia basada en rango de variaci√≥n\n",
    "                    importancias = {}\n",
    "                    correlaciones = {}\n",
    "                    \n",
    "                    # Distribuci√≥n\n",
    "                    dist_rango = df_esc.groupby('Distribuci√≥n')[modelo].mean().max() - \\\n",
    "                                df_esc.groupby('Distribuci√≥n')[modelo].mean().min()\n",
    "                    importancias['Distribuci√≥n'] = dist_rango\n",
    "                    df_temp = df_esc.copy()\n",
    "                    df_temp['Dist_num'] = pd.Categorical(df_temp['Distribuci√≥n']).codes\n",
    "                    correlaciones['Distribuci√≥n'] = abs(df_temp['Dist_num'].corr(df_temp[modelo]))\n",
    "                    \n",
    "                    # Tipo de Generador\n",
    "                    tipo_rango = df_esc.groupby('Tipo de Modelo')[modelo].mean().max() - \\\n",
    "                                df_esc.groupby('Tipo de Modelo')[modelo].mean().min()\n",
    "                    importancias['Tipo_Generador'] = tipo_rango\n",
    "                    df_temp['Tipo_num'] = pd.Categorical(df_temp['Tipo de Modelo']).codes\n",
    "                    correlaciones['Tipo_Generador'] = abs(df_temp['Tipo_num'].corr(df_temp[modelo]))\n",
    "                    \n",
    "                    # Paso\n",
    "                    paso_rango = df_esc.groupby('Paso')[modelo].mean().max() - \\\n",
    "                                df_esc.groupby('Paso')[modelo].mean().min()\n",
    "                    importancias['Paso'] = paso_rango\n",
    "                    correlaciones['Paso'] = abs(df_esc['Paso'].corr(df_esc[modelo]))\n",
    "                    \n",
    "                    # Varianza\n",
    "                    var_rango = df_esc.groupby('Varianza error')[modelo].mean().max() - \\\n",
    "                            df_esc.groupby('Varianza error')[modelo].mean().min()\n",
    "                    importancias['Varianza'] = var_rango\n",
    "                    correlaciones['Varianza'] = abs(df_esc['Varianza error'].corr(df_esc[modelo]))\n",
    "                    \n",
    "                    # Normalizar importancias (0-100)\n",
    "                    max_imp = max(importancias.values())\n",
    "                    if max_imp > 0:\n",
    "                        importancias_norm = {k: (v/max_imp)*100 for k, v in importancias.items()}\n",
    "                    else:\n",
    "                        importancias_norm = {k: 0 for k in importancias.keys()}\n",
    "                    \n",
    "                    # Crear ranking\n",
    "                    items_ordenados = sorted(importancias_norm.items(), key=lambda x: x[1], reverse=True)\n",
    "                    \n",
    "                    for rank, (caract, imp_norm) in enumerate(items_ordenados, 1):\n",
    "                        importancia_caracteristicas.append({\n",
    "                            'Escenario': escenario,\n",
    "                            'Modelo': modelo,\n",
    "                            'Caracteristica': caract,\n",
    "                            'Importancia_Relativa': round(imp_norm, 2),\n",
    "                            'Correlacion_Absoluta': round(correlaciones[caract], 4),\n",
    "                            'Rank_Importancia': rank,\n",
    "                            'Rango_Variacion': round(importancias[caract], 6)\n",
    "                        })\n",
    "            \n",
    "            df_hoja3 = pd.DataFrame(importancia_caracteristicas)\n",
    "            df_hoja3.to_excel(writer, sheet_name='Importancia_Caracteristicas', index=False)\n",
    "            print(\"‚úì Completado\\n\")\n",
    "            \n",
    "            # ============================================================\n",
    "            # HOJA 4: ESTABILIDAD Y OUTLIERS\n",
    "            # ============================================================\n",
    "            print(\"üìã Generando HOJA 4: Estabilidad y Outliers...\")\n",
    "            \n",
    "            estabilidad_outliers = []\n",
    "            \n",
    "            for escenario in ESCENARIOS:\n",
    "                df_esc = self.df[self.df['Escenario'] == escenario]\n",
    "                \n",
    "                for modelo in MODELOS:\n",
    "                    # Coeficiente de variaci√≥n global\n",
    "                    media = df_esc[modelo].mean()\n",
    "                    std = df_esc[modelo].std()\n",
    "                    coef_var = (std / media * 100) if media != 0 else 0\n",
    "                    \n",
    "                    # Outliers usando IQR\n",
    "                    Q1 = df_esc[modelo].quantile(0.25)\n",
    "                    Q3 = df_esc[modelo].quantile(0.75)\n",
    "                    IQR = Q3 - Q1\n",
    "                    lower_bound = Q1 - 1.5 * IQR\n",
    "                    upper_bound = Q3 + 1.5 * IQR\n",
    "                    \n",
    "                    outliers = df_esc[(df_esc[modelo] < lower_bound) | (df_esc[modelo] > upper_bound)]\n",
    "                    n_outliers = len(outliers)\n",
    "                    pct_outliers = (n_outliers / len(df_esc)) * 100 if len(df_esc) > 0 else 0\n",
    "                    \n",
    "                    # Estabilidad por dimensiones\n",
    "                    estab_paso = df_esc.groupby('Paso')[modelo].std().mean()\n",
    "                    estab_tipo = df_esc.groupby('Tipo de Modelo')[modelo].std().mean()\n",
    "                    estab_dist = df_esc.groupby('Distribuci√≥n')[modelo].std().mean()\n",
    "                    estab_var = df_esc.groupby('Varianza error')[modelo].std().mean()\n",
    "                    \n",
    "                    estabilidad_outliers.append({\n",
    "                        'Escenario': escenario,\n",
    "                        'Modelo': modelo,\n",
    "                        'Coef_Variacion_Global': round(coef_var, 2),\n",
    "                        'N_Outliers': int(n_outliers),\n",
    "                        '%_Outliers': round(pct_outliers, 2),\n",
    "                        'Estabilidad_Paso': round(estab_paso, 6),\n",
    "                        'Estabilidad_Tipo': round(estab_tipo, 6),\n",
    "                        'Estabilidad_Distribucion': round(estab_dist, 6),\n",
    "                        'Estabilidad_Varianza': round(estab_var, 6),\n",
    "                        'Rango_IQR': round(IQR, 6),\n",
    "                        'Q1': round(Q1, 6),\n",
    "                        'Q3': round(Q3, 6),\n",
    "                        'Limite_Inferior': round(lower_bound, 6),\n",
    "                        'Limite_Superior': round(upper_bound, 6)\n",
    "                    })\n",
    "            \n",
    "            df_hoja4 = pd.DataFrame(estabilidad_outliers)\n",
    "            df_hoja4.to_excel(writer, sheet_name='Estabilidad_Outliers', index=False)\n",
    "            print(\"‚úì Completado\\n\")\n",
    "            \n",
    "            # ============================================================\n",
    "            # HOJA 5: MEJORES/PEORES CONFIGURACIONES\n",
    "            # ============================================================\n",
    "            print(\"üìã Generando HOJA 5: Mejores/Peores Configuraciones...\")\n",
    "            \n",
    "            configuraciones_extremas = []\n",
    "            \n",
    "            for escenario in ESCENARIOS:\n",
    "                df_esc = self.df[self.df['Escenario'] == escenario]\n",
    "                \n",
    "                for modelo in MODELOS:\n",
    "                    # Encontrar mejor configuraci√≥n\n",
    "                    idx_mejor = df_esc[modelo].idxmin()\n",
    "                    mejor_config = df_esc.loc[idx_mejor]\n",
    "                    mejor_configuracion = f\"{mejor_config['Distribuci√≥n']}+{mejor_config['Tipo de Modelo']}+Paso{mejor_config['Paso']}+Var{mejor_config['Varianza error']}\"\n",
    "                    rendimiento_mejor = df_esc[modelo].min()\n",
    "                    \n",
    "                    # Encontrar peor configuraci√≥n\n",
    "                    idx_peor = df_esc[modelo].idxmax()\n",
    "                    peor_config = df_esc.loc[idx_peor]\n",
    "                    peor_configuracion = f\"{peor_config['Distribuci√≥n']}+{peor_config['Tipo de Modelo']}+Paso{peor_config['Paso']}+Var{peor_config['Varianza error']}\"\n",
    "                    rendimiento_peor = df_esc[modelo].max()\n",
    "                    \n",
    "                    # Amplitud de rango\n",
    "                    amplitud_rango = rendimiento_peor - rendimiento_mejor\n",
    "                    \n",
    "                    # Top 3 mejores y peores\n",
    "                    df_sorted = df_esc.sort_values(by=modelo)\n",
    "                    \n",
    "                    top3_mejor = []\n",
    "                    for i in range(min(3, len(df_sorted))):\n",
    "                        row = df_sorted.iloc[i]\n",
    "                        config = f\"{row['Distribuci√≥n']}+{row['Tipo de Modelo']}+Paso{row['Paso']}+Var{row['Varianza error']}\"\n",
    "                        top3_mejor.append(f\"{config}({row[modelo]:.6f})\")\n",
    "                    \n",
    "                    top3_peor = []\n",
    "                    for i in range(max(0, len(df_sorted)-3), len(df_sorted)):\n",
    "                        row = df_sorted.iloc[i]\n",
    "                        config = f\"{row['Distribuci√≥n']}+{row['Tipo de Modelo']}+Paso{row['Paso']}+Var{row['Varianza error']}\"\n",
    "                        top3_peor.append(f\"{config}({row[modelo]:.6f})\")\n",
    "                    \n",
    "                    configuraciones_extremas.append({\n",
    "                        'Escenario': escenario,\n",
    "                        'Modelo': modelo,\n",
    "                        'Mejor_Configuracion': mejor_configuracion,\n",
    "                        'Rendimiento_Mejor': round(rendimiento_mejor, 6),\n",
    "                        'Distribucion_Mejor': mejor_config['Distribuci√≥n'],\n",
    "                        'Tipo_Generador_Mejor': mejor_config['Tipo de Modelo'],\n",
    "                        'Paso_Mejor': int(mejor_config['Paso']),\n",
    "                        'Varianza_Mejor': mejor_config['Varianza error'],\n",
    "                        'Peor_Configuracion': peor_configuracion,\n",
    "                        'Rendimiento_Peor': round(rendimiento_peor, 6),\n",
    "                        'Distribucion_Peor': peor_config['Distribuci√≥n'],\n",
    "                        'Tipo_Generador_Peor': peor_config['Tipo de Modelo'],\n",
    "                        'Paso_Peor': int(peor_config['Paso']),\n",
    "                        'Varianza_Peor': peor_config['Varianza error'],\n",
    "                        'Amplitud_Rango': round(amplitud_rango, 6),\n",
    "                        'Top3_Mejores': ' | '.join(top3_mejor),\n",
    "                        'Top3_Peores': ' | '.join(top3_peor)\n",
    "                    })\n",
    "            \n",
    "            df_hoja5 = pd.DataFrame(configuraciones_extremas)\n",
    "            df_hoja5.to_excel(writer, sheet_name='Configuraciones_Extremas', index=False)\n",
    "            print(\"‚úì Completado\\n\")\n",
    "            \n",
    "            # ============================================================\n",
    "            # HOJA 6: RESULTADOS DM DETALLADOS\n",
    "            # ============================================================\n",
    "            print(\"üìã Generando HOJA 6: Resultados DM Detallados...\")\n",
    "            \n",
    "            resultados_dm_todos = []\n",
    "            \n",
    "            for escenario in ESCENARIOS:\n",
    "                df_esc = self.df[self.df['Escenario'] == escenario]\n",
    "                df_comp_esc, alpha_bonf = comparaciones_multiples_dm(df_esc, MODELOS, alpha=0.05)\n",
    "                \n",
    "                for _, row in df_comp_esc.iterrows():\n",
    "                    resultados_dm_todos.append({\n",
    "                        'Escenario': escenario,\n",
    "                        'Modelo_1': row['Modelo_1'],\n",
    "                        'Modelo_2': row['Modelo_2'],\n",
    "                        'DM_Statistic': round(row['DM_Statistic'], 6),\n",
    "                        'p_value': round(row['p_value'], 6),\n",
    "                        'p_value_bonferroni': round(row['p_value_bonferroni'], 6),\n",
    "                        'Significativo': row['Significativo'],\n",
    "                        'Ganador': row['Ganador'],\n",
    "                        'Diff_Media': round(row['Diff_Media'], 6),\n",
    "                        'Interpretacion': row['Interpretacion']\n",
    "                    })\n",
    "            \n",
    "            df_hoja6 = pd.DataFrame(resultados_dm_todos)\n",
    "            df_hoja6.to_excel(writer, sheet_name='Resultados_DM_Detallados', index=False)\n",
    "            print(\"‚úì Completado\\n\")\n",
    "            \n",
    "            # ============================================================\n",
    "            # HOJA 7: RANKING FINAL\n",
    "            # ============================================================\n",
    "            print(\"üìã Generando HOJA 7: Ranking Final...\")\n",
    "            \n",
    "            ranking_final = []\n",
    "            \n",
    "            # Obtener ranking global\n",
    "            df_comp_global, _ = comparaciones_multiples_dm(self.df, MODELOS, alpha=0.05)\n",
    "            df_rank_global, _ = calcular_ranking_dm(df_comp_global, MODELOS)\n",
    "            \n",
    "            for modelo in MODELOS:\n",
    "                # Datos globales\n",
    "                rank_global_data = df_rank_global[df_rank_global['Modelo'] == modelo].iloc[0]\n",
    "                \n",
    "                # Calcular consistencia (% de escenarios donde est√° en top 3)\n",
    "                top3_count = 0\n",
    "                victorias_totales = 0\n",
    "                score_total = 0\n",
    "                rendimientos_ponderados = []\n",
    "                \n",
    "                for escenario in ESCENARIOS:\n",
    "                    df_esc = self.df[self.df['Escenario'] == escenario]\n",
    "                    df_comp_esc, _ = comparaciones_multiples_dm(df_esc, MODELOS, alpha=0.05)\n",
    "                    df_rank_esc, _ = calcular_ranking_dm(df_comp_esc, MODELOS)\n",
    "                    \n",
    "                    rank_data = df_rank_esc[df_rank_esc['Modelo'] == modelo].iloc[0]\n",
    "                    \n",
    "                    if rank_data['Rank'] <= 3:\n",
    "                        top3_count += 1\n",
    "                    \n",
    "                    victorias_totales += rank_data['Victorias']\n",
    "                    score_total += rank_data['Score']\n",
    "                    \n",
    "                    # Rendimiento promedio en el escenario\n",
    "                    rend_prom = df_esc[modelo].mean()\n",
    "                    rendimientos_ponderados.append(rend_prom)\n",
    "                \n",
    "                consistencia = (top3_count / len(ESCENARIOS)) * 100\n",
    "                rendimiento_promedio_ajustado = np.mean(rendimientos_ponderados)\n",
    "                \n",
    "                # Score final compuesto (normalizado)\n",
    "                score_final = (rank_global_data['Score'] * 0.4 + \n",
    "                            consistencia * 0.3 + \n",
    "                            (100 - rank_global_data['Rank'] * 10) * 0.3)\n",
    "                \n",
    "                ranking_final.append({\n",
    "                    'Rank_Global': int(rank_global_data['Rank']),\n",
    "                    'Modelo': modelo,\n",
    "                    'Score_Final': round(score_final, 2),\n",
    "                    'Score_DM_Global': int(rank_global_data['Score']),\n",
    "                    'Victorias_Totales': int(victorias_totales),\n",
    "                    'Victorias_Global': int(rank_global_data['Victorias']),\n",
    "                    'Derrotas_Global': int(rank_global_data['Derrotas']),\n",
    "                    '%_Victorias_Global': round(rank_global_data['Pct_Victorias'], 2),\n",
    "                    'Consistencia': round(consistencia, 2),\n",
    "                    'Top3_Count': int(top3_count),\n",
    "                    'Rendimiento_Promedio_Ajustado': round(rendimiento_promedio_ajustado, 6),\n",
    "                    'Mejor_Escenario': self._get_mejor_escenario(modelo),\n",
    "                    'Peor_Escenario': self._get_peor_escenario(modelo)\n",
    "                })\n",
    "            \n",
    "            df_hoja7 = pd.DataFrame(ranking_final)\n",
    "            df_hoja7 = df_hoja7.sort_values('Score_Final', ascending=False).reset_index(drop=True)\n",
    "            df_hoja7.to_excel(writer, sheet_name='Ranking_Final', index=False)\n",
    "            print(\"‚úì Completado\\n\")\n",
    "            \n",
    "            # ============================================================\n",
    "            # HOJA 8: AN√ÅLISIS DE SENSIBILIDAD COMPLETO\n",
    "            # ============================================================\n",
    "            print(\"üìã Generando HOJA 8: An√°lisis de Sensibilidad Completo...\")\n",
    "            \n",
    "            sensibilidad_completa = []\n",
    "            \n",
    "            for escenario in ESCENARIOS:\n",
    "                df_esc = self.df[self.df['Escenario'] == escenario]\n",
    "                \n",
    "                # Obtener ranking del escenario\n",
    "                df_comp_esc, _ = comparaciones_multiples_dm(df_esc, MODELOS, alpha=0.05)\n",
    "                df_rank_esc, _ = calcular_ranking_dm(df_comp_esc, MODELOS)\n",
    "                \n",
    "                for modelo in MODELOS:\n",
    "                    # Estad√≠sticas b√°sicas\n",
    "                    promedio = df_esc[modelo].mean()\n",
    "                    mediana = df_esc[modelo].median()\n",
    "                    desv_std = df_esc[modelo].std()\n",
    "                    \n",
    "                    # Ranking en el escenario\n",
    "                    rank_escenario = df_rank_esc[df_rank_esc['Modelo'] == modelo]['Rank'].values[0]\n",
    "                    \n",
    "                    # ===== AN√ÅLISIS POR DISTRIBUCI√ìN =====\n",
    "                    dist_stats = df_esc.groupby('Distribuci√≥n')[modelo].mean()\n",
    "                    mejor_dist = dist_stats.idxmin()\n",
    "                    peor_dist = dist_stats.idxmax()\n",
    "                    sensibilidad_dist = dist_stats.max() - dist_stats.min()\n",
    "                    \n",
    "                    # ===== AN√ÅLISIS POR PASO =====\n",
    "                    paso_stats = df_esc.groupby('Paso')[modelo].mean()\n",
    "                    mejor_paso = paso_stats.idxmin()\n",
    "                    peor_paso = paso_stats.idxmax()\n",
    "                    sensibilidad_paso = paso_stats.max() - paso_stats.min()\n",
    "                    \n",
    "                    # ===== AN√ÅLISIS POR VARIANZA =====\n",
    "                    var_stats = df_esc.groupby('Varianza error')[modelo].mean()\n",
    "                    mejor_varianza = var_stats.idxmin()\n",
    "                    peor_varianza = var_stats.idxmax()\n",
    "                    sensibilidad_varianza = var_stats.max() - var_stats.min()\n",
    "                    \n",
    "                    # ===== AN√ÅLISIS POR TIPO DE GENERADOR =====\n",
    "                    tipo_stats = df_esc.groupby('Tipo de Modelo')[modelo].mean()\n",
    "                    mejor_tipo = tipo_stats.idxmin()\n",
    "                    peor_tipo = tipo_stats.idxmax()\n",
    "                    sensibilidad_tipo = tipo_stats.max() - tipo_stats.min()\n",
    "                    \n",
    "                    # ===== MEJOR Y PEOR COMBINACI√ìN =====\n",
    "                    idx_mejor_comb = df_esc[modelo].idxmin()\n",
    "                    mejor_comb = df_esc.loc[idx_mejor_comb]\n",
    "                    mejor_combinacion = (f\"Dist:{mejor_comb['Distribuci√≥n']}|\"\n",
    "                                    f\"Tipo:{mejor_comb['Tipo de Modelo']}|\"\n",
    "                                    f\"Paso:{mejor_comb['Paso']}|\"\n",
    "                                    f\"Var:{mejor_comb['Varianza error']}\")\n",
    "                    mejor_comb_valor = df_esc[modelo].min()\n",
    "                    \n",
    "                    idx_peor_comb = df_esc[modelo].idxmax()\n",
    "                    peor_comb = df_esc.loc[idx_peor_comb]\n",
    "                    peor_combinacion = (f\"Dist:{peor_comb['Distribuci√≥n']}|\"\n",
    "                                    f\"Tipo:{peor_comb['Tipo de Modelo']}|\"\n",
    "                                    f\"Paso:{peor_comb['Paso']}|\"\n",
    "                                    f\"Var:{peor_comb['Varianza error']}\")\n",
    "                    peor_comb_valor = df_esc[modelo].max()\n",
    "                    \n",
    "                    # ===== CATEGOR√çA M√ÅS Y MENOS IMPORTANTE =====\n",
    "                    sensibilidades = {\n",
    "                        'Distribuci√≥n': sensibilidad_dist,\n",
    "                        'Paso': sensibilidad_paso,\n",
    "                        'Varianza': sensibilidad_varianza,\n",
    "                        'Tipo_Generador': sensibilidad_tipo\n",
    "                    }\n",
    "                    \n",
    "                    categoria_mas_importante = max(sensibilidades, key=sensibilidades.get)\n",
    "                    categoria_menos_importante = min(sensibilidades, key=sensibilidades.get)\n",
    "                    \n",
    "                    sensibilidad_completa.append({\n",
    "                        'Escenario': escenario,\n",
    "                        'Modelo': modelo,\n",
    "                        'Promedio': round(promedio, 6),\n",
    "                        'Mediana': round(mediana, 6),\n",
    "                        'Desviacion_Estandar': round(desv_std, 6),\n",
    "                        'Ranking_Escenario': int(rank_escenario),\n",
    "                        'Mejor_Distribucion': mejor_dist,\n",
    "                        'Mejor_Dist_Valor': round(dist_stats[mejor_dist], 6),\n",
    "                        'Peor_Distribucion': peor_dist,\n",
    "                        'Peor_Dist_Valor': round(dist_stats[peor_dist], 6),\n",
    "                        'Sensibilidad_Distribucion': round(sensibilidad_dist, 6),\n",
    "                        'Mejor_Paso': int(mejor_paso),\n",
    "                        'Mejor_Paso_Valor': round(paso_stats[mejor_paso], 6),\n",
    "                        'Peor_Paso': int(peor_paso),\n",
    "                        'Peor_Paso_Valor': round(paso_stats[peor_paso], 6),\n",
    "                        'Sensibilidad_Paso': round(sensibilidad_paso, 6),\n",
    "                        'Mejor_Varianza': mejor_varianza,\n",
    "                        'Mejor_Varianza_Valor': round(var_stats[mejor_varianza], 6),\n",
    "                        'Peor_Varianza': peor_varianza,\n",
    "                        'Peor_Varianza_Valor': round(var_stats[peor_varianza], 6),\n",
    "                        'Sensibilidad_Varianza': round(sensibilidad_varianza, 6),\n",
    "                        'Mejor_Tipo_Generador': mejor_tipo,\n",
    "                        'Mejor_Tipo_Valor': round(tipo_stats[mejor_tipo], 6),\n",
    "                        'Peor_Tipo_Generador': peor_tipo,\n",
    "                        'Peor_Tipo_Valor': round(tipo_stats[peor_tipo], 6),\n",
    "                        'Sensibilidad_Tipo_Generador': round(sensibilidad_tipo, 6),\n",
    "                        'Mejor_Combinacion': mejor_combinacion,\n",
    "                        'Mejor_Comb_Valor': round(mejor_comb_valor, 6),\n",
    "                        'Peor_Combinacion': peor_combinacion,\n",
    "                        'Peor_Comb_Valor': round(peor_comb_valor, 6),\n",
    "                        'Categoria_Mas_Importante': categoria_mas_importante,\n",
    "                        'Sensibilidad_Categoria_Max': round(sensibilidades[categoria_mas_importante], 6),\n",
    "                        'Categoria_Menos_Importante': categoria_menos_importante,\n",
    "                        'Sensibilidad_Categoria_Min': round(sensibilidades[categoria_menos_importante], 6)\n",
    "                    })\n",
    "            \n",
    "            df_hoja8 = pd.DataFrame(sensibilidad_completa)\n",
    "            df_hoja8 = df_hoja8.sort_values(['Escenario', 'Ranking_Escenario']).reset_index(drop=True)\n",
    "            df_hoja8.to_excel(writer, sheet_name='Analisis_Sensibilidad', index=False)\n",
    "            print(\"‚úì Completado\\n\")\n",
    "        \n",
    "        print(f\"‚úÖ Excel consolidado generado: {archivo_excel}\")\n",
    "        print(f\"   üìä 8 hojas creadas con an√°lisis completo\\n\")\n",
    "\n",
    "    def _get_mejor_escenario(self, modelo):\n",
    "            \"\"\"Obtiene el escenario donde el modelo tiene mejor ranking\"\"\"\n",
    "            mejor_rank = float('inf')\n",
    "            mejor_esc = \"\"\n",
    "            \n",
    "            for escenario in ESCENARIOS:\n",
    "                df_esc = self.df[self.df['Escenario'] == escenario]\n",
    "                df_comp_esc, _ = comparaciones_multiples_dm(df_esc, MODELOS, alpha=0.05)\n",
    "                df_rank_esc, _ = calcular_ranking_dm(df_comp_esc, MODELOS)\n",
    "                \n",
    "                rank = df_rank_esc[df_rank_esc['Modelo'] == modelo]['Rank'].values[0]\n",
    "                \n",
    "                if rank < mejor_rank:\n",
    "                    mejor_rank = rank\n",
    "                    mejor_esc = escenario\n",
    "            \n",
    "            return f\"{mejor_esc} (Rank #{int(mejor_rank)})\"\n",
    "        \n",
    "    def _get_peor_escenario(self, modelo):\n",
    "            \"\"\"Obtiene el escenario donde el modelo tiene peor ranking\"\"\"\n",
    "            peor_rank = 0\n",
    "            peor_esc = \"\"\n",
    "            \n",
    "            for escenario in ESCENARIOS:\n",
    "                df_esc = self.df[self.df['Escenario'] == escenario]\n",
    "                df_comp_esc, _ = comparaciones_multiples_dm(df_esc, MODELOS, alpha=0.05)\n",
    "                df_rank_esc, _ = calcular_ranking_dm(df_comp_esc, MODELOS)\n",
    "                \n",
    "                rank = df_rank_esc[df_rank_esc['Modelo'] == modelo]['Rank'].values[0]\n",
    "                \n",
    "                if rank > peor_rank:\n",
    "                    peor_rank = rank\n",
    "                    peor_esc = escenario\n",
    "            \n",
    "            return f\"{peor_esc} (Rank #{int(peor_rank)})\"\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# FUNCI√ìN PRINCIPAL DE EJECUCI√ìN\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Funci√≥n principal que ejecuta todo el an√°lisis\"\"\"\n",
    "    print(\"\\n\" + \"‚ñà\"*80)\n",
    "    print(\"‚ñà\" + \" \"*78 + \"‚ñà\")\n",
    "    print(\"‚ñà\" + \" \"*15 + \"AN√ÅLISIS DETALLADO DE MODELOS DE PREDICCI√ìN\" + \" \"*21 + \"‚ñà\")\n",
    "    print(\"‚ñà\" + \" \"*20 + \"CON GR√ÅFICAS INDIVIDUALES Y RANKING DM\" + \" \"*21 + \"‚ñà\")\n",
    "    print(\"‚ñà\" + \" \"*78 + \"‚ñà\")\n",
    "    print(\"‚ñà\"*80 + \"\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Crear instancia del analizador\n",
    "        analizador = AnalizadorModelos(RUTA_DATOS)\n",
    "        \n",
    "        # Ejecutar an√°lisis completo\n",
    "        analizador.ejecutar_analisis_completo()\n",
    "        \n",
    "        print(\"\\n\" + \"‚ñà\"*80)\n",
    "        print(\"‚ñà\" + \" \"*78 + \"‚ñà\")\n",
    "        print(\"‚ñà\" + \" \"*25 + \"AN√ÅLISIS COMPLETADO EXITOSAMENTE\" + \" \"*22 + \"‚ñà\")\n",
    "        print(\"‚ñà\" + \" \"*78 + \"‚ñà\")\n",
    "        print(\"‚ñà\"*80 + \"\\n\")\n",
    "        \n",
    "        print(\"üìÅ Los resultados se encuentran en:\")\n",
    "        print(\"   ‚îî‚îÄ‚îÄ ./Resultados/\")\n",
    "        print(\"       ‚îú‚îÄ‚îÄ Estacionario_Lineal/\")\n",
    "        print(\"       ‚îÇ   ‚îú‚îÄ‚îÄ RANKING_Estacionario_Lineal.png  ‚≠ê\")\n",
    "        print(\"       ‚îÇ   ‚îú‚îÄ‚îÄ LSPM/\")\n",
    "        print(\"       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 01_rendimiento_distribucion.png\")\n",
    "        print(\"       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 02_rendimiento_tipo_generador.png\")\n",
    "        print(\"       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 03_rendimiento_paso.png\")\n",
    "        print(\"       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 04_rendimiento_varianza.png\")\n",
    "        print(\"       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 05-10_interacciones (6 gr√°ficas)\")\n",
    "        print(\"       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 11_importancia_caracteristicas.png\")\n",
    "        print(\"       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 12_distribucion_general.png\")\n",
    "        print(\"       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 13_analisis_outliers.png\")\n",
    "        print(\"       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 14_heatmap_configuraciones.png\")\n",
    "        print(\"       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 15_analisis_estabilidad.png\")\n",
    "        print(\"       ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ estadisticas_completas.txt\")\n",
    "        print(\"       ‚îÇ   ‚îî‚îÄ‚îÄ ... (todos los modelos)\")\n",
    "        print(\"       ‚îú‚îÄ‚îÄ No_Lineal_Estacionario/\")\n",
    "        print(\"       ‚îÇ   ‚îî‚îÄ‚îÄ RANKING_No_Lineal_Estacionario.png  ‚≠ê\")\n",
    "        print(\"       ‚îú‚îÄ‚îÄ No_Estacionario_Lineal/\")\n",
    "        print(\"       ‚îÇ   ‚îî‚îÄ‚îÄ RANKING_No_Estacionario_Lineal.png  ‚≠ê\")\n",
    "        print(\"       ‚îú‚îÄ‚îÄ Comparativo_Global/\")\n",
    "        print(\"       ‚îÇ   ‚îú‚îÄ‚îÄ RANKING_GLOBAL.png  ‚≠ê‚≠ê‚≠ê\")\n",
    "        print(\"       ‚îÇ   ‚îú‚îÄ‚îÄ ranking_dm_global.xlsx\")\n",
    "        print(\"       ‚îÇ   ‚îî‚îÄ‚îÄ resumen_mejores_por_escenario.xlsx\")\n",
    "        print(\"       ‚îî‚îÄ‚îÄ ANALISIS_CONSOLIDADO_COMPLETO.xlsx  üìäüìäüìä\")\n",
    "        print(\"           ‚îú‚îÄ‚îÄ Hoja 1: Resumen General\")\n",
    "        print(\"           ‚îú‚îÄ‚îÄ Hoja 2: Rendimiento por Caracter√≠sticas\")\n",
    "        print(\"           ‚îú‚îÄ‚îÄ Hoja 3: Importancia de Caracter√≠sticas\")\n",
    "        print(\"           ‚îú‚îÄ‚îÄ Hoja 4: Estabilidad y Outliers\")\n",
    "        print(\"           ‚îú‚îÄ‚îÄ Hoja 5: Configuraciones Extremas\")\n",
    "        print(\"           ‚îú‚îÄ‚îÄ Hoja 6: Resultados DM Detallados\")\n",
    "        print(\"           ‚îî‚îÄ‚îÄ Hoja 7: Ranking Final\")\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"NOTA: Cada modelo en cada escenario tiene 15 gr√°ficas individuales\")\n",
    "        print(\"      + 1 ranking por escenario + 1 ranking global\")\n",
    "        print(\"      + 1 Excel consolidado con 7 hojas de an√°lisis completo\")\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"\\n‚ùå ERROR: No se encontr√≥ el archivo {RUTA_DATOS}\")\n",
    "        print(\"   Por favor, verifica que el archivo existe y la ruta es correcta.\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå ERROR INESPERADO: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6662db",
   "metadata": {},
   "source": [
    "## Analisis General Corregido*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7ce1242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "‚ñà                                                                              ‚ñà\n",
      "‚ñà               AN√ÅLISIS COMPLETO DE BASE DE DATOS - VERSI√ìN CORREGIDA        ‚ñà\n",
      "‚ñà                                                                              ‚ñà\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "\n",
      "================================================================================\n",
      "INICIANDO AN√ÅLISIS COMPLETO DE BASE DE DATOS\n",
      "================================================================================\n",
      "\n",
      "‚úì Caracter√≠sticas extra√≠das:\n",
      "  - Estacionariedad: ['Estacionario' 'No Estacionario']\n",
      "  - Linealidad: ['Lineal' 'No Lineal']\n",
      "  - Tipos de Modelo: ['AR(1)' 'AR(2)' 'MA(1)' 'MA(2)' 'ARMA(1,1)' 'ARMA(2,2)' 'ARIMA(0,1,0)'\n",
      " 'ARIMA(1,1,0)' 'ARIMA(2,1,0)' 'ARIMA(0,1,1)' 'ARIMA(0,1,2)'\n",
      " 'ARIMA(1,1,1)' 'ARIMA(2,1,2)' 'SETAR(2,1)' 'TAR(2,1)' 'EXPAR(2,1)'\n",
      " 'BILINEAR(1)' 'SETAR(2,2)' 'TAR(2,2)' 'SETAR(2,3)']\n",
      "  - Distribuciones: ['normal' 'uniform' 'exponential' 't-student' 'mixture']\n",
      "  - Varianzas: [np.float64(0.2), np.float64(0.5), np.float64(1.0), np.float64(3.0)]\n",
      "  - Pasos: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5)]\n",
      "‚úì Datos cargados: 2000 filas, 17 columnas\n",
      "‚úì Modelos a analizar: 9\n",
      "‚úì Directorio de salida: resultados_base_completa\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨\n",
      "\n",
      "1Ô∏è‚É£  Analizando impacto de Estacionariedad...\n",
      "   ‚úì 2 figuras generadas para estacionariedad\n",
      "\n",
      "2Ô∏è‚É£  Analizando impacto de Linealidad...\n",
      "   ‚úì 2 figuras generadas para linealidad\n",
      "\n",
      "3Ô∏è‚É£  Analizando efecto del Modelo Generador...\n",
      "   ‚úì 2 figuras generadas para modelo generador\n",
      "\n",
      "4Ô∏è‚É£  Analizando influencia de Distribuci√≥n...\n",
      "   ‚úì 2 figuras generadas para distribuci√≥n\n",
      "\n",
      "5Ô∏è‚É£  Analizando impacto de Varianza...\n",
      "   ‚úì 2 figuras generadas para varianza\n",
      "\n",
      "6Ô∏è‚É£  Analizando deterioro por Horizonte...\n",
      "   ‚úì 2 figuras generadas para horizonte\n",
      "\n",
      "7Ô∏è‚É£  Analizando Robustez y Estabilidad...\n",
      "   ‚úì 1 figura generada para robustez\n",
      "\n",
      "8Ô∏è‚É£  Analizando Diferencias Estad√≠sticamente Significativas...\n",
      "\n",
      "================================================================================\n",
      "REALIZANDO TEST DE DIEBOLD-MARIANO\n",
      "================================================================================\n",
      "\n",
      "   N√∫mero de comparaciones: 36\n",
      "   Alpha corregido (Bonferroni): 0.001389\n",
      "   Comparaciones significativas: 35\n",
      "\n",
      "   ‚úì Ranking guardado: Top 3\n",
      "      1. Block Bootstrapping - Score: 8 (V:8, D:0, E:0)\n",
      "      2. Sieve Bootstrap - Score: 6 (V:7, D:1, E:0)\n",
      "      3. LSPM - Score: 4 (V:6, D:2, E:0)\n",
      "\n",
      "   ‚úì 1 figura generada para significancia\n",
      "\n",
      "\n",
      "9Ô∏è‚É£  Generando Resumen Ejecutivo...\n",
      "\n",
      "================================================================================\n",
      "GENERANDO RESUMEN EJECUTIVO\n",
      "================================================================================\n",
      "\n",
      "   ‚úì 2 figuras generadas para resumen ejecutivo\n",
      "\n",
      "\n",
      "================================================================================\n",
      "‚úÖ AN√ÅLISIS COMPLETO FINALIZADO\n",
      "üìÅ Resultados guardados en: resultados_base_completa\n",
      "================================================================================\n",
      "\n",
      "\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "‚ñà                                                                              ‚ñà\n",
      "‚ñà                    ‚úÖ AN√ÅLISIS COMPLETADO EXITOSAMENTE                       ‚ñà\n",
      "‚ñà                                                                              ‚ñà\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "üìä TOTAL DE FIGURAS GENERADAS: 15 im√°genes PNG\n",
      "\n",
      "üìÅ ESTRUCTURA DE RESULTADOS:\n",
      "   ./resultados_base_completa/\n",
      "   ‚îú‚îÄ‚îÄ 1.1: Estacionariedad - Comparativo\n",
      "   ‚îú‚îÄ‚îÄ 1.2: Estacionariedad - Cambio Relativo\n",
      "   ‚îú‚îÄ‚îÄ 2.1: Linealidad - Comparativo\n",
      "   ‚îú‚îÄ‚îÄ 2.2: Linealidad - Cambio Relativo\n",
      "   ‚îú‚îÄ‚îÄ 3.2: Modelo Generador - Z-Score\n",
      "   ‚îú‚îÄ‚îÄ 3.3: Modelo Generador - Variabilidad\n",
      "   ‚îú‚îÄ‚îÄ 4.1: Distribuci√≥n - Heatmap Rendimiento\n",
      "   ‚îú‚îÄ‚îÄ 4.2: Distribuci√≥n - Heatmap Variabilidad\n",
      "   ‚îú‚îÄ‚îÄ 5.1: Varianza - Tendencias\n",
      "   ‚îú‚îÄ‚îÄ 5.2: Varianza - Tasa de Crecimiento\n",
      "   ‚îú‚îÄ‚îÄ 6.1: Horizonte - Evoluci√≥n\n",
      "   ‚îú‚îÄ‚îÄ 6.2: Horizonte - Tasa de Deterioro\n",
      "   ‚îú‚îÄ‚îÄ 7.2: Robustez - Coeficiente de Variaci√≥n\n",
      "   ‚îú‚îÄ‚îÄ 8.2: Significancia - Matriz de Superioridad\n",
      "   ‚îú‚îÄ‚îÄ 9.2: Resumen - Perfil Multidimensional\n",
      "   ‚îî‚îÄ‚îÄ 9.3: Resumen - Impacto de Caracter√≠sticas (normalizado)\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from itertools import combinations\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuraci√≥n de estilo\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURACI√ìN GLOBAL\n",
    "# ============================================================================\n",
    "\n",
    "RUTA_DATOS = \"./Datos/datos_combinados.xlsx\"\n",
    "DIR_SALIDA = \"./resultados_base_completa\"\n",
    "\n",
    "MODELOS = ['AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', \n",
    "           'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
    "\n",
    "# Colores √∫nicos para 9 modelos\n",
    "COLORES_MODELOS = {\n",
    "    'AREPD': '#e41a1c',\n",
    "    'AV-MCPS': '#377eb8', \n",
    "    'Block Bootstrapping': '#4daf4a',\n",
    "    'DeepAR': '#984ea3',\n",
    "    'EnCQR-LSTM': '#ff7f00',\n",
    "    'LSPM': '#ffff33',\n",
    "    'LSPMW': '#a65628',\n",
    "    'MCPS': '#f781bf',\n",
    "    'Sieve Bootstrap': '#999999'\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# FUNCIONES AUXILIARES - TEST DIEBOLD-MARIANO\n",
    "# ============================================================================\n",
    "\n",
    "def diebold_mariano_test(errores1, errores2, h=1, alternative='two-sided'):\n",
    "    \"\"\"Test de Diebold-Mariano para comparar precisi√≥n de pron√≥sticos\"\"\"\n",
    "    e1 = np.asarray(errores1)\n",
    "    e2 = np.asarray(errores2)\n",
    "    \n",
    "    if len(e1) != len(e2):\n",
    "        raise ValueError(\"Los vectores de errores deben tener la misma longitud\")\n",
    "    \n",
    "    n = len(e1)\n",
    "    d = e1 - e2\n",
    "    d_mean = np.mean(d)\n",
    "    \n",
    "    # Varianza con correcci√≥n de autocorrelaci√≥n\n",
    "    gamma_0 = np.var(d, ddof=1)\n",
    "    gamma_sum = 0\n",
    "    for k in range(1, h):\n",
    "        if k < n:\n",
    "            gamma_k = np.mean((d[:-k] - d_mean) * (d[k:] - d_mean))\n",
    "            gamma_sum += 2 * gamma_k\n",
    "    \n",
    "    var_d = (gamma_0 + gamma_sum) / n\n",
    "    \n",
    "    # Correcci√≥n de Harvey-Leybourne-Newbold\n",
    "    hlnc = np.sqrt((n + 1 - 2*h + h*(h-1)/n) / n)\n",
    "    \n",
    "    if var_d > 0:\n",
    "        dm_stat = d_mean / np.sqrt(var_d)\n",
    "        dm_stat_corrected = dm_stat * hlnc\n",
    "    else:\n",
    "        dm_stat = 0\n",
    "        dm_stat_corrected = 0\n",
    "    \n",
    "    # P-valor\n",
    "    if alternative == 'two-sided':\n",
    "        p_value = 2 * (1 - stats.t.cdf(abs(dm_stat_corrected), df=n-1))\n",
    "    elif alternative == 'less':\n",
    "        p_value = stats.t.cdf(dm_stat_corrected, df=n-1)\n",
    "    elif alternative == 'greater':\n",
    "        p_value = 1 - stats.t.cdf(dm_stat_corrected, df=n-1)\n",
    "    else:\n",
    "        raise ValueError(\"alternative debe ser 'two-sided', 'less' o 'greater'\")\n",
    "    \n",
    "    return {\n",
    "        'dm_statistic': dm_stat,\n",
    "        'dm_statistic_corrected': dm_stat_corrected,\n",
    "        'p_value': p_value,\n",
    "        'mean_diff': d_mean,\n",
    "        'modelo1_mejor': d_mean < 0,\n",
    "        'n': n\n",
    "    }\n",
    "\n",
    "\n",
    "def comparaciones_multiples_dm(df, modelos, alpha=0.05):\n",
    "    \"\"\"Comparaciones m√∫ltiples con correcci√≥n de Bonferroni\"\"\"\n",
    "    n_comparaciones = len(list(combinations(modelos, 2)))\n",
    "    alpha_bonferroni = alpha / n_comparaciones\n",
    "    \n",
    "    resultados = []\n",
    "    \n",
    "    for modelo1, modelo2 in combinations(modelos, 2):\n",
    "        try:\n",
    "            dm_result = diebold_mariano_test(\n",
    "                df[modelo1].values, \n",
    "                df[modelo2].values,\n",
    "                h=1,\n",
    "                alternative='two-sided'\n",
    "            )\n",
    "            \n",
    "            significativo = dm_result['p_value'] < alpha_bonferroni\n",
    "            \n",
    "            if significativo:\n",
    "                if dm_result['mean_diff'] < 0:\n",
    "                    ganador = modelo1\n",
    "                else:\n",
    "                    ganador = modelo2\n",
    "            else:\n",
    "                ganador = \"No hay diferencia\"\n",
    "            \n",
    "            resultados.append({\n",
    "                'Modelo_1': modelo1,\n",
    "                'Modelo_2': modelo2,\n",
    "                'DM_Statistic': dm_result['dm_statistic_corrected'],\n",
    "                'p_value': dm_result['p_value'],\n",
    "                'p_value_bonferroni': alpha_bonferroni,\n",
    "                'Significativo': significativo,\n",
    "                'Ganador': ganador,\n",
    "                'Diff_Media': dm_result['mean_diff']\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    return pd.DataFrame(resultados), alpha_bonferroni\n",
    "\n",
    "\n",
    "def calcular_ranking_dm(df_comparaciones, modelos):\n",
    "    \"\"\"Calcula ranking basado en resultados DM\"\"\"\n",
    "    n = len(modelos)\n",
    "    matriz = pd.DataFrame(np.zeros((n, n)), index=modelos, columns=modelos)\n",
    "    \n",
    "    for _, row in df_comparaciones.iterrows():\n",
    "        m1, m2 = row['Modelo_1'], row['Modelo_2']\n",
    "        if row['Significativo']:\n",
    "            if row['Ganador'] == m1:\n",
    "                matriz.loc[m1, m2] = 1\n",
    "                matriz.loc[m2, m1] = -1\n",
    "            elif row['Ganador'] == m2:\n",
    "                matriz.loc[m2, m1] = 1\n",
    "                matriz.loc[m1, m2] = -1\n",
    "    \n",
    "    ranking_data = []\n",
    "    for modelo in modelos:\n",
    "        victorias = (matriz.loc[modelo] == 1).sum()\n",
    "        derrotas = (matriz.loc[modelo] == -1).sum()\n",
    "        empates = (matriz.loc[modelo] == 0).sum() - 1\n",
    "        score = victorias - derrotas\n",
    "        total_comparaciones = victorias + derrotas + empates\n",
    "        pct_victorias = (victorias / total_comparaciones * 100) if total_comparaciones > 0 else 0\n",
    "        \n",
    "        ranking_data.append({\n",
    "            'Modelo': modelo,\n",
    "            'Victorias': int(victorias),\n",
    "            'Derrotas': int(derrotas),\n",
    "            'Empates': int(empates),\n",
    "            'Score': int(score),\n",
    "            'Pct_Victorias': round(pct_victorias, 2)\n",
    "        })\n",
    "    \n",
    "    df_ranking = pd.DataFrame(ranking_data)\n",
    "    df_ranking = df_ranking.sort_values('Score', ascending=False).reset_index(drop=True)\n",
    "    df_ranking['Rank'] = range(1, len(df_ranking) + 1)\n",
    "    \n",
    "    return df_ranking, matriz\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CLASE PRINCIPAL DE AN√ÅLISIS\n",
    "# ============================================================================\n",
    "\n",
    "class AnalizadorBaseCompleta:\n",
    "    \"\"\"An√°lisis completo de la base de datos en 8 dimensiones\"\"\"\n",
    "    \n",
    "    def __init__(self, ruta_datos):\n",
    "        \"\"\"Inicializa el analizador\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"INICIANDO AN√ÅLISIS COMPLETO DE BASE DE DATOS\")\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "        self.df = pd.read_excel(ruta_datos)\n",
    "        self.modelos = MODELOS\n",
    "        self.dir_salida = Path(DIR_SALIDA)\n",
    "        self.dir_salida.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Extraer caracter√≠sticas del escenario\n",
    "        self._extraer_caracteristicas()\n",
    "        \n",
    "        print(f\"‚úì Datos cargados: {self.df.shape[0]} filas, {self.df.shape[1]} columnas\")\n",
    "        print(f\"‚úì Modelos a analizar: {len(self.modelos)}\")\n",
    "        print(f\"‚úì Directorio de salida: {self.dir_salida}\")\n",
    "        print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    \n",
    "    def _extraer_caracteristicas(self):\n",
    "        \"\"\"Extrae caracter√≠sticas individuales del escenario\"\"\"\n",
    "        # Crear columnas binarias/categ√≥ricas\n",
    "        self.df['Estacionario'] = self.df['Escenario'].apply(\n",
    "            lambda x: 'Estacionario' if 'Estacionario' in x and 'No_Estacionario' not in x else 'No Estacionario'\n",
    "        )\n",
    "        \n",
    "        self.df['Lineal'] = self.df['Escenario'].apply(\n",
    "            lambda x: 'Lineal' if 'Lineal' in x and 'No_Lineal' not in x else 'No Lineal'\n",
    "        )\n",
    "        \n",
    "        print(\"‚úì Caracter√≠sticas extra√≠das:\")\n",
    "        print(f\"  - Estacionariedad: {self.df['Estacionario'].unique()}\")\n",
    "        print(f\"  - Linealidad: {self.df['Lineal'].unique()}\")\n",
    "        print(f\"  - Tipos de Modelo: {self.df['Tipo de Modelo'].unique()}\")\n",
    "        print(f\"  - Distribuciones: {self.df['Distribuci√≥n'].unique()}\")\n",
    "        print(f\"  - Varianzas: {sorted(self.df['Varianza error'].unique())}\")\n",
    "        print(f\"  - Pasos: {sorted(self.df['Paso'].unique())}\")\n",
    "    \n",
    "    def ejecutar_analisis_completo(self):\n",
    "        \"\"\"Ejecuta todos los an√°lisis\"\"\"\n",
    "        print(\"\\n\" + \"üî¨\"*40 + \"\\n\")\n",
    "        \n",
    "        # 1. Impacto de Estacionariedad\n",
    "        print(\"1Ô∏è‚É£  Analizando impacto de Estacionariedad...\")\n",
    "        self._analisis_estacionariedad()\n",
    "        \n",
    "        # 2. Impacto de Linealidad\n",
    "        print(\"2Ô∏è‚É£  Analizando impacto de Linealidad...\")\n",
    "        self._analisis_linealidad()\n",
    "        \n",
    "        # 3. Efecto del Modelo Generador\n",
    "        print(\"3Ô∏è‚É£  Analizando efecto del Modelo Generador...\")\n",
    "        self._analisis_modelo_generador()\n",
    "        \n",
    "        # 4. Influencia de Distribuci√≥n\n",
    "        print(\"4Ô∏è‚É£  Analizando influencia de Distribuci√≥n...\")\n",
    "        self._analisis_distribucion()\n",
    "        \n",
    "        # 5. Impacto de Varianza\n",
    "        print(\"5Ô∏è‚É£  Analizando impacto de Varianza...\")\n",
    "        self._analisis_varianza()\n",
    "        \n",
    "        # 6. Deterioro por Horizonte\n",
    "        print(\"6Ô∏è‚É£  Analizando deterioro por Horizonte...\")\n",
    "        self._analisis_horizonte()\n",
    "        \n",
    "        # 7. Robustez y Estabilidad\n",
    "        print(\"7Ô∏è‚É£  Analizando Robustez y Estabilidad...\")\n",
    "        self._analisis_robustez()\n",
    "        \n",
    "        # 8. Diferencias Estad√≠sticamente Significativas\n",
    "        print(\"8Ô∏è‚É£  Analizando Diferencias Estad√≠sticamente Significativas...\")\n",
    "        self._analisis_significancia()\n",
    "        \n",
    "        # Resumen ejecutivo\n",
    "        print(\"\\n9Ô∏è‚É£  Generando Resumen Ejecutivo...\")\n",
    "        self._generar_resumen_ejecutivo()\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"‚úÖ AN√ÅLISIS COMPLETO FINALIZADO\")\n",
    "        print(f\"üìÅ Resultados guardados en: {self.dir_salida}\")\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 1. IMPACTO DE ESTACIONARIEDAD\n",
    "    # ========================================================================\n",
    "    \n",
    "    def _analisis_estacionariedad(self):\n",
    "        \"\"\"Analiza el impacto de la estacionariedad\"\"\"\n",
    "        \n",
    "        # Calcular estad√≠sticas por estacionariedad\n",
    "        stats_est = []\n",
    "        for modelo in self.modelos:\n",
    "            for est in ['Estacionario', 'No Estacionario']:\n",
    "                df_subset = self.df[self.df['Estacionario'] == est]\n",
    "                stats_est.append({\n",
    "                    'Modelo': modelo,\n",
    "                    'Estacionariedad': est,\n",
    "                    'Media': df_subset[modelo].mean(),\n",
    "                    'Std': df_subset[modelo].std(),\n",
    "                    'Mediana': df_subset[modelo].median()\n",
    "                })\n",
    "        \n",
    "        df_stats = pd.DataFrame(stats_est)\n",
    "        \n",
    "        # FIGURA 1.1: Barras comparativas\n",
    "        fig, ax = plt.subplots(figsize=(14, 9))\n",
    "        pivot_media = df_stats.pivot(index='Modelo', columns='Estacionariedad', values='Media')\n",
    "        pivot_media = pivot_media.sort_values('Estacionario')\n",
    "        \n",
    "        x = np.arange(len(pivot_media))\n",
    "        width = 0.35\n",
    "        \n",
    "        ax.bar(x - width/2, pivot_media['Estacionario'], width, \n",
    "               label='Estacionario', color='lightblue', edgecolor='black', linewidth=1.5)\n",
    "        ax.bar(x + width/2, pivot_media['No Estacionario'], width, \n",
    "               label='No Estacionario', color='lightcoral', edgecolor='black', linewidth=1.5)\n",
    "        \n",
    "        ax.set_xlabel('Modelos', fontweight='bold', fontsize=12)\n",
    "        ax.set_ylabel('Rendimiento Promedio', fontweight='bold', fontsize=12)\n",
    "        ax.set_title('Impacto de Estacionariedad: Rendimiento Comparativo', \n",
    "                     fontweight='bold', fontsize=14, pad=20)\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(pivot_media.index, rotation=45, ha='right', fontsize=11)\n",
    "        ax.legend(fontsize=11, loc='best')\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '1_1_estacionariedad_comparativo.png', \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # FIGURA 1.2: Cambio relativo (barras horizontales) - CORREGIDO\n",
    "        fig, ax = plt.subplots(figsize=(12, 9))\n",
    "        cambio_rel = ((pivot_media['No Estacionario'] - pivot_media['Estacionario']) / \n",
    "                      pivot_media['Estacionario'] * 100)\n",
    "        cambio_rel = cambio_rel.sort_values()\n",
    "        \n",
    "        colors = ['green' if x < 0 else 'red' for x in cambio_rel.values]\n",
    "        bars = ax.barh(cambio_rel.index, cambio_rel.values, color=colors, \n",
    "                       alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "        ax.axvline(0, color='black', linestyle='-', linewidth=2)\n",
    "        ax.set_xlabel('Cambio Relativo (%)', fontweight='bold', fontsize=12)\n",
    "        ax.set_ylabel('Modelos', fontweight='bold', fontsize=12)\n",
    "        ax.set_title('Deterioro en Datos No Estacionarios\\n(Negativo = Mejora, Positivo = Deterioro)', \n",
    "                     fontweight='bold', fontsize=14, pad=20)\n",
    "        ax.grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        for i, (bar, val) in enumerate(zip(bars, cambio_rel.values)):\n",
    "            ax.text(val + (3 if val > 0 else -3), i, f'{val:.1f}%', \n",
    "                   va='center', ha='left' if val > 0 else 'right',\n",
    "                   fontweight='bold', fontsize=10)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '1_2_estacionariedad_cambio_relativo.png', \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(\"   ‚úì 2 figuras generadas para estacionariedad\\n\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 2. IMPACTO DE LINEALIDAD\n",
    "    # ========================================================================\n",
    "    \n",
    "    def _analisis_linealidad(self):\n",
    "        \"\"\"Analiza el impacto de la linealidad\"\"\"\n",
    "        \n",
    "        # Calcular estad√≠sticas\n",
    "        stats_lin = []\n",
    "        for modelo in self.modelos:\n",
    "            for lin in ['Lineal', 'No Lineal']:\n",
    "                df_subset = self.df[self.df['Lineal'] == lin]\n",
    "                stats_lin.append({\n",
    "                    'Modelo': modelo,\n",
    "                    'Linealidad': lin,\n",
    "                    'Media': df_subset[modelo].mean(),\n",
    "                    'Std': df_subset[modelo].std(),\n",
    "                    'Mediana': df_subset[modelo].median()\n",
    "                })\n",
    "        \n",
    "        df_stats = pd.DataFrame(stats_lin)\n",
    "        \n",
    "        # FIGURA 2.1: Barras comparativas\n",
    "        fig, ax = plt.subplots(figsize=(14, 9))\n",
    "        pivot_media = df_stats.pivot(index='Modelo', columns='Linealidad', values='Media')\n",
    "        pivot_media = pivot_media.sort_values('Lineal')\n",
    "        \n",
    "        x = np.arange(len(pivot_media))\n",
    "        width = 0.35\n",
    "        \n",
    "        ax.bar(x - width/2, pivot_media['Lineal'], width, \n",
    "              label='Lineal', color='lightgreen', edgecolor='black', linewidth=1.5)\n",
    "        ax.bar(x + width/2, pivot_media['No Lineal'], width, \n",
    "              label='No Lineal', color='orange', edgecolor='black', linewidth=1.5)\n",
    "        \n",
    "        ax.set_xlabel('Modelos', fontweight='bold', fontsize=12)\n",
    "        ax.set_ylabel('Rendimiento Promedio', fontweight='bold', fontsize=12)\n",
    "        ax.set_title('Impacto de Linealidad: Rendimiento Comparativo', \n",
    "                     fontweight='bold', fontsize=14, pad=20)\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(pivot_media.index, rotation=45, ha='right', fontsize=11)\n",
    "        ax.legend(fontsize=11, loc='best')\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '2_1_linealidad_comparativo.png', \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # FIGURA 2.2: Cambio relativo - CORREGIDO\n",
    "        fig, ax = plt.subplots(figsize=(14, 10))\n",
    "        cambio_rel = ((pivot_media['No Lineal'] - pivot_media['Lineal']) / \n",
    "                      pivot_media['Lineal'] * 100)\n",
    "        cambio_rel = cambio_rel.sort_values()\n",
    "        \n",
    "        colors = ['green' if x < 0 else 'red' for x in cambio_rel.values]\n",
    "        bars = ax.barh(cambio_rel.index, cambio_rel.values, color=colors, \n",
    "                       alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "        ax.axvline(0, color='black', linestyle='-', linewidth=2)\n",
    "        ax.set_xlabel('Cambio Relativo (%)', fontweight='bold', fontsize=12)\n",
    "        ax.set_ylabel('Modelos', fontweight='bold', fontsize=12)\n",
    "        ax.set_title('Deterioro en Datos No Lineales\\n(Negativo = Mejora, Positivo = Deterioro)', \n",
    "                     fontweight='bold', fontsize=14, pad=20)\n",
    "        ax.grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        # Ajustar m√°rgenes del eje x para dar espacio a las etiquetas\n",
    "        x_min = min(cambio_rel.values)\n",
    "        x_max = max(cambio_rel.values)\n",
    "        x_range = x_max - x_min\n",
    "        ax.set_xlim(x_min - x_range * 0.15, x_max + x_range * 0.15)\n",
    "        \n",
    "        for i, (bar, val) in enumerate(zip(bars, cambio_rel.values)):\n",
    "            offset = x_range * 0.02\n",
    "            ax.text(val + (offset if val > 0 else -offset), i, f'{val:.1f}%', \n",
    "                   va='center', ha='left' if val > 0 else 'right',\n",
    "                   fontweight='bold', fontsize=10)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '2_2_linealidad_cambio_relativo.png', \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(\"   ‚úì 2 figuras generadas para linealidad\\n\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 3. EFECTO DEL MODELO GENERADOR\n",
    "    # ========================================================================\n",
    "    \n",
    "    def _analisis_modelo_generador(self):\n",
    "        \"\"\"Analiza el efecto del modelo generador de datos\"\"\"\n",
    "        \n",
    "        pivot_media = self.df.groupby('Tipo de Modelo')[self.modelos].mean()\n",
    "        tipos = self.df['Tipo de Modelo'].unique()\n",
    "        \n",
    "        # FIGURA 3.2: Heatmap normalizado (Z-scores)\n",
    "        fig, ax = plt.subplots(figsize=(14, 10))\n",
    "        \n",
    "        pivot_norm = pivot_media.T.sub(pivot_media.T.mean(axis=1), axis=0).div(pivot_media.T.std(axis=1), axis=0)\n",
    "        \n",
    "        sns.heatmap(pivot_norm, annot=True, fmt='.2f', cmap='RdBu_r', center=0,\n",
    "                   ax=ax, cbar_kws={'label': 'Z-Score'},\n",
    "                   linewidths=0.5, linecolor='gray', vmin=-2, vmax=2)\n",
    "        ax.set_xlabel('Tipo de Modelo Generador', fontweight='bold', fontsize=12)\n",
    "        ax.set_ylabel('Modelo de Predicci√≥n', fontweight='bold', fontsize=12)\n",
    "        ax.set_title('Rendimiento Relativo (Z-Score por Modelo)', \n",
    "                     fontweight='bold', fontsize=14, pad=20)\n",
    "        ax.tick_params(axis='x', rotation=45, labelsize=10)\n",
    "        ax.tick_params(axis='y', rotation=0, labelsize=10)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '3_2_modelo_generador_zscore.png', \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # FIGURA 3.3: Variabilidad por tipo\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        \n",
    "        rankings = []\n",
    "        for tipo in tipos:\n",
    "            df_tipo = self.df[self.df['Tipo de Modelo'] == tipo]\n",
    "            medias = df_tipo[self.modelos].mean().sort_values()\n",
    "            rankings.append({\n",
    "                'Tipo': tipo,\n",
    "                'Mejor_Modelo': medias.index[0],\n",
    "                'Mejor_Rendimiento': medias.values[0],\n",
    "                'Peor_Modelo': medias.index[-1],\n",
    "                'Peor_Rendimiento': medias.values[-1],\n",
    "                'Rango': medias.values[-1] - medias.values[0]\n",
    "            })\n",
    "        \n",
    "        df_rankings = pd.DataFrame(rankings).sort_values('Rango', ascending=False)\n",
    "        \n",
    "        y_pos = np.arange(len(df_rankings))\n",
    "        bars = ax.barh(y_pos, df_rankings['Rango'].values, \n",
    "                       color='steelblue', alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "        ax.set_yticks(y_pos)\n",
    "        ax.set_yticklabels(df_rankings['Tipo'].values, fontsize=10)\n",
    "        ax.set_xlabel('Rango de Rendimiento (Max - Min)', fontweight='bold', fontsize=12)\n",
    "        ax.set_title('Variabilidad por Tipo de Generador', \n",
    "                     fontweight='bold', fontsize=14, pad=20)\n",
    "        ax.grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        for i, (bar, val) in enumerate(zip(bars, df_rankings['Rango'].values)):\n",
    "            ax.text(val + 0.001, i, f'{val:.3f}', va='center', fontweight='bold', fontsize=10)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '3_3_modelo_generador_variabilidad.png', \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(\"   ‚úì 2 figuras generadas para modelo generador\\n\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 4. INFLUENCIA DE LA DISTRIBUCI√ìN\n",
    "    # ========================================================================\n",
    "    \n",
    "    def _analisis_distribucion(self):\n",
    "        \"\"\"Analiza la influencia de la distribuci√≥n de errores\"\"\"\n",
    "        \n",
    "        pivot_media = self.df.groupby('Distribuci√≥n')[self.modelos].mean()\n",
    "        pivot_std = self.df.groupby('Distribuci√≥n')[self.modelos].std()\n",
    "        \n",
    "        # FIGURA 4.1: Heatmap de rendimiento\n",
    "        fig, ax = plt.subplots(figsize=(14, 10))\n",
    "        \n",
    "        sns.heatmap(pivot_media.T, annot=True, fmt='.3f', cmap='RdYlGn_r', \n",
    "                   ax=ax, cbar_kws={'label': 'Rendimiento Promedio'},\n",
    "                   linewidths=0.5, linecolor='gray')\n",
    "        ax.set_xlabel('Distribuci√≥n de Errores', fontweight='bold', fontsize=12)\n",
    "        ax.set_ylabel('Modelo de Predicci√≥n', fontweight='bold', fontsize=12)\n",
    "        ax.set_title('Rendimiento por Distribuci√≥n de Errores', \n",
    "                     fontweight='bold', fontsize=14, pad=20)\n",
    "        ax.tick_params(axis='x', rotation=45, labelsize=10)\n",
    "        ax.tick_params(axis='y', rotation=0, labelsize=10)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '4_1_distribucion_heatmap_rendimiento.png', \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # FIGURA 4.2: Heatmap de variabilidad\n",
    "        fig, ax = plt.subplots(figsize=(14, 10))\n",
    "        \n",
    "        sns.heatmap(pivot_std.T, annot=True, fmt='.3f', cmap='YlOrRd', \n",
    "                   ax=ax, cbar_kws={'label': 'Desviaci√≥n Est√°ndar'},\n",
    "                   linewidths=0.5, linecolor='gray')\n",
    "        ax.set_xlabel('Distribuci√≥n de Errores', fontweight='bold', fontsize=12)\n",
    "        ax.set_ylabel('Modelo de Predicci√≥n', fontweight='bold', fontsize=12)\n",
    "        ax.set_title('Variabilidad por Distribuci√≥n de Errores', \n",
    "                     fontweight='bold', fontsize=14, pad=20)\n",
    "        ax.tick_params(axis='x', rotation=45, labelsize=10)\n",
    "        ax.tick_params(axis='y', rotation=0, labelsize=10)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '4_2_distribucion_heatmap_variabilidad.png', \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(\"   ‚úì 2 figuras generadas para distribuci√≥n\\n\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 5. IMPACTO DE VARIANZA\n",
    "    # ========================================================================\n",
    "    \n",
    "    def _analisis_varianza(self):\n",
    "        \"\"\"Analiza el impacto del nivel de varianza (ruido)\"\"\"\n",
    "        \n",
    "        varianzas = sorted(self.df['Varianza error'].unique())\n",
    "        \n",
    "        # FIGURA 5.1: L√≠neas de tendencia - CORREGIDO (colores √∫nicos)\n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        \n",
    "        for modelo in self.modelos:\n",
    "            medias = [self.df[self.df['Varianza error'] == v][modelo].mean() \n",
    "                     for v in varianzas]\n",
    "            ax.plot(varianzas, medias, marker='o', label=modelo, \n",
    "                   linewidth=2.5, markersize=8, color=COLORES_MODELOS[modelo])\n",
    "        \n",
    "        ax.set_xlabel('Nivel de Varianza', fontweight='bold', fontsize=12)\n",
    "        ax.set_ylabel('Rendimiento Promedio', fontweight='bold', fontsize=12)\n",
    "        ax.set_title('Deterioro con Aumento de Varianza', \n",
    "                     fontweight='bold', fontsize=14, pad=20)\n",
    "        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_xticks(varianzas)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '5_1_varianza_tendencias.png', \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # FIGURA 5.2: Tasa de crecimiento\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        \n",
    "        tasas_crecimiento = {}\n",
    "        for modelo in self.modelos:\n",
    "            medias = [self.df[self.df['Varianza error'] == v][modelo].mean() \n",
    "                     for v in varianzas]\n",
    "            if len(medias) > 1:\n",
    "                pendiente = (medias[-1] - medias[0]) / (varianzas[-1] - varianzas[0])\n",
    "                tasas_crecimiento[modelo] = pendiente\n",
    "        \n",
    "        tc_sorted = dict(sorted(tasas_crecimiento.items(), key=lambda x: x[1]))\n",
    "        \n",
    "        colors_tc = ['green' if v < np.median(list(tc_sorted.values())) else 'red' \n",
    "                    for v in tc_sorted.values()]\n",
    "        bars = ax.barh(range(len(tc_sorted)), list(tc_sorted.values()), \n",
    "                       color=colors_tc, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "        ax.set_yticks(range(len(tc_sorted)))\n",
    "        ax.set_yticklabels(list(tc_sorted.keys()), fontsize=10)\n",
    "        ax.set_xlabel('Tasa de Crecimiento del Error', fontweight='bold', fontsize=12)\n",
    "        ax.set_title('Sensibilidad al Ruido\\n(Menor = M√°s Robusto)', \n",
    "                     fontweight='bold', fontsize=14, pad=20)\n",
    "        ax.axvline(np.median(list(tc_sorted.values())), color='black', \n",
    "                  linestyle='--', linewidth=2, label='Mediana')\n",
    "        ax.grid(True, alpha=0.3, axis='x')\n",
    "        ax.legend(fontsize=11)\n",
    "        \n",
    "        for i, (bar, val) in enumerate(zip(bars, tc_sorted.values())):\n",
    "            ax.text(val + (0.0001 if val > 0 else -0.0001), i, f'{val:.4f}', \n",
    "                   va='center', ha='left' if val > 0 else 'right',\n",
    "                   fontweight='bold', fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '5_2_varianza_tasa_crecimiento.png', \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(\"   ‚úì 2 figuras generadas para varianza\\n\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 6. DETERIORO POR HORIZONTE\n",
    "    # ========================================================================\n",
    "    \n",
    "    def _analisis_horizonte(self):\n",
    "        \"\"\"Analiza el deterioro del rendimiento con el horizonte de predicci√≥n\"\"\"\n",
    "        \n",
    "        pasos = sorted(self.df['Paso'].unique())\n",
    "        \n",
    "        # FIGURA 6.1: Evoluci√≥n paso a paso - CORREGIDO (colores √∫nicos)\n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        \n",
    "        for modelo in self.modelos:\n",
    "            medias = [self.df[self.df['Paso'] == p][modelo].mean() for p in pasos]\n",
    "            ax.plot(pasos, medias, marker='o', label=modelo, \n",
    "                   linewidth=2.5, markersize=8, color=COLORES_MODELOS[modelo])\n",
    "        \n",
    "        ax.set_xlabel('Horizonte de Predicci√≥n (Paso)', fontweight='bold', fontsize=12)\n",
    "        ax.set_ylabel('Rendimiento Promedio', fontweight='bold', fontsize=12)\n",
    "        ax.set_title('Evoluci√≥n del Rendimiento por Horizonte', \n",
    "                     fontweight='bold', fontsize=14, pad=20)\n",
    "        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_xticks(pasos)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '6_1_horizonte_evolucion.png', \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # FIGURA 6.2: Tasa de deterioro\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        \n",
    "        tasas_deterioro = {}\n",
    "        for modelo in self.modelos:\n",
    "            medias = [self.df[self.df['Paso'] == p][modelo].mean() for p in pasos]\n",
    "            if len(medias) > 1:\n",
    "                pendiente = (medias[-1] - medias[0]) / (pasos[-1] - pasos[0])\n",
    "                tasas_deterioro[modelo] = pendiente\n",
    "        \n",
    "        td_sorted = dict(sorted(tasas_deterioro.items(), key=lambda x: x[1]))\n",
    "        \n",
    "        colors_td = ['green' if v < np.median(list(td_sorted.values())) else 'red' \n",
    "                    for v in td_sorted.values()]\n",
    "        bars = ax.barh(range(len(td_sorted)), list(td_sorted.values()), \n",
    "                       color=colors_td, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "        ax.set_yticks(range(len(td_sorted)))\n",
    "        ax.set_yticklabels(list(td_sorted.keys()), fontsize=10)\n",
    "        ax.set_xlabel('Tasa de Deterioro por Paso', fontweight='bold', fontsize=12)\n",
    "        ax.set_title('Velocidad de Deterioro\\n(Menor = M√°s Estable)', \n",
    "                     fontweight='bold', fontsize=14, pad=20)\n",
    "        ax.axvline(0, color='black', linestyle='-', linewidth=2)\n",
    "        ax.grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        for i, (bar, val) in enumerate(zip(bars, td_sorted.values())):\n",
    "            ax.text(val + (0.0001 if val > 0 else -0.0001), i, f'{val:.4f}', \n",
    "                   va='center', ha='left' if val > 0 else 'right',\n",
    "                   fontweight='bold', fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '6_2_horizonte_tasa_deterioro.png', \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(\"   ‚úì 2 figuras generadas para horizonte\\n\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 7. ROBUSTEZ Y ESTABILIDAD\n",
    "    # ========================================================================\n",
    "    \n",
    "    def _analisis_robustez(self):\n",
    "        \"\"\"Analiza la robustez y estabilidad de los modelos\"\"\"\n",
    "        \n",
    "        # Calcular m√©tricas de robustez\n",
    "        metricas_robustez = []\n",
    "        \n",
    "        for modelo in self.modelos:\n",
    "            std_global = self.df[modelo].std()\n",
    "            cv = (self.df[modelo].std() / self.df[modelo].mean()) * 100\n",
    "            q75, q25 = self.df[modelo].quantile([0.75, 0.25])\n",
    "            iqr = q75 - q25\n",
    "            std_entre_escenarios = self.df.groupby('Escenario')[modelo].mean().std()\n",
    "            std_entre_dist = self.df.groupby('Distribuci√≥n')[modelo].mean().std()\n",
    "            std_entre_var = self.df.groupby('Varianza error')[modelo].mean().std()\n",
    "            \n",
    "            metricas_robustez.append({\n",
    "                'Modelo': modelo,\n",
    "                'Std_Global': std_global,\n",
    "                'CV': cv,\n",
    "                'IQR': iqr,\n",
    "                'Std_Escenarios': std_entre_escenarios,\n",
    "                'Std_Distribuciones': std_entre_dist,\n",
    "                'Std_Varianzas': std_entre_var\n",
    "            })\n",
    "        \n",
    "        df_robustez = pd.DataFrame(metricas_robustez)\n",
    "        \n",
    "        # FIGURA 7.2: Coeficiente de variaci√≥n\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        \n",
    "        df_sorted = df_robustez.sort_values('CV')\n",
    "        colors = plt.cm.RdYlGn(np.linspace(0.8, 0.2, len(df_sorted)))\n",
    "        bars = ax.barh(df_sorted['Modelo'], df_sorted['CV'], \n",
    "                       color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "        ax.set_xlabel('Coeficiente de Variaci√≥n (%)', fontweight='bold', fontsize=12)\n",
    "        ax.set_title('Variabilidad Relativa\\n(Menor = M√°s Consistente)', \n",
    "                     fontweight='bold', fontsize=14, pad=20)\n",
    "        ax.grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        for i, (bar, val) in enumerate(zip(bars, df_sorted['CV'].values)):\n",
    "            ax.text(val + 1, i, f'{val:.1f}%', va='center', fontweight='bold', fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '7_2_robustez_coef_variacion.png', \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # Guardar para usar despu√©s\n",
    "        self.df_robustez = df_robustez\n",
    "        \n",
    "        print(\"   ‚úì 1 figura generada para robustez\\n\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 8. DIFERENCIAS ESTAD√çSTICAMENTE SIGNIFICATIVAS\n",
    "    # ========================================================================\n",
    "    \n",
    "    def _analisis_significancia(self):\n",
    "        \"\"\"An√°lisis de diferencias estad√≠sticamente significativas con Test DM\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"REALIZANDO TEST DE DIEBOLD-MARIANO\")\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "        # Realizar comparaciones m√∫ltiples\n",
    "        df_comparaciones, alpha_bonf = comparaciones_multiples_dm(\n",
    "            self.df, self.modelos, alpha=0.05\n",
    "        )\n",
    "        \n",
    "        print(f\"   N√∫mero de comparaciones: {len(df_comparaciones)}\")\n",
    "        print(f\"   Alpha corregido (Bonferroni): {alpha_bonf:.6f}\")\n",
    "        print(f\"   Comparaciones significativas: {df_comparaciones['Significativo'].sum()}\")\n",
    "        \n",
    "        # Calcular ranking\n",
    "        df_ranking, matriz_sup = calcular_ranking_dm(df_comparaciones, self.modelos)\n",
    "        \n",
    "        # FIGURA 8.2: Matriz de superioridad\n",
    "        fig, ax = plt.subplots(figsize=(14, 12))\n",
    "        \n",
    "        sns.heatmap(matriz_sup, annot=True, fmt='.0f', cmap='RdYlGn', \n",
    "                   center=0, ax=ax, cbar_kws={'label': 'Superioridad'},\n",
    "                   vmin=-1, vmax=1, linewidths=1, linecolor='gray',\n",
    "                   annot_kws={'fontsize': 10, 'fontweight': 'bold'})\n",
    "        ax.set_title('Matriz de Superioridad\\n(1=Superior, -1=Inferior, 0=Sin diferencia)', \n",
    "                     fontweight='bold', fontsize=14, pad=20)\n",
    "        ax.set_xlabel('Modelo Comparado', fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel('Modelo', fontsize=12, fontweight='bold')\n",
    "        ax.tick_params(labelsize=10)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '8_2_significancia_matriz_superioridad.png', \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # Guardar para usar despu√©s\n",
    "        self.df_ranking = df_ranking\n",
    "        self.df_comparaciones = df_comparaciones\n",
    "        \n",
    "        print(f\"\\n   ‚úì Ranking guardado: Top 3\")\n",
    "        for i, row in df_ranking.head(3).iterrows():\n",
    "            print(f\"      {row['Rank']}. {row['Modelo']} - Score: {row['Score']} \"\n",
    "                  f\"(V:{row['Victorias']}, D:{row['Derrotas']}, E:{row['Empates']})\")\n",
    "        \n",
    "        print(\"\\n   ‚úì 1 figura generada para significancia\\n\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 9. RESUMEN EJECUTIVO\n",
    "    # ========================================================================\n",
    "    \n",
    "    def _generar_resumen_ejecutivo(self):\n",
    "        \"\"\"Genera un resumen ejecutivo consolidado\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"GENERANDO RESUMEN EJECUTIVO\")\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "        pasos = sorted(self.df['Paso'].unique())\n",
    "        distribuciones = self.df['Distribuci√≥n'].unique()\n",
    "        varianzas = sorted(self.df['Varianza error'].unique())\n",
    "        \n",
    "        # FIGURA 9.2: Comparaci√≥n multidimensional - CORREGIDO\n",
    "        fig, ax = plt.subplots(figsize=(14, 10))\n",
    "        \n",
    "        top5_modelos = self.df_ranking.head(5)['Modelo'].tolist()\n",
    "        \n",
    "        # Nuevas dimensiones\n",
    "        caracteristicas = ['Ranking DM', 'Estabilidad por Paso', \n",
    "                          'Estabilidad por Distribuci√≥n', 'Estabilidad por Varianza']\n",
    "        matriz_resumen = []\n",
    "        \n",
    "        for modelo in top5_modelos:\n",
    "            fila = []\n",
    "            \n",
    "            # 1. Ranking DM (normalizado)\n",
    "            rank_pos = self.df_ranking[self.df_ranking['Modelo'] == modelo].index[0]\n",
    "            rank_norm = 100 * (1 - rank_pos / (len(self.df_ranking) - 1))\n",
    "            fila.append(rank_norm)\n",
    "            \n",
    "            # 2. Estabilidad por Paso (inversa de la std)\n",
    "            stds_paso = [self.df[self.df['Paso'] == p][modelo].std() for p in pasos]\n",
    "            est_paso = 100 * (1 - (np.mean(stds_paso) - min([np.mean([self.df[self.df['Paso'] == p][m].std() for p in pasos]) for m in self.modelos])) / \n",
    "                             (max([np.mean([self.df[self.df['Paso'] == p][m].std() for p in pasos]) for m in self.modelos]) - \n",
    "                              min([np.mean([self.df[self.df['Paso'] == p][m].std() for p in pasos]) for m in self.modelos])))\n",
    "            fila.append(est_paso)\n",
    "            \n",
    "            # 3. Estabilidad por Distribuci√≥n\n",
    "            stds_dist = [self.df[self.df['Distribuci√≥n'] == d][modelo].std() for d in distribuciones]\n",
    "            est_dist = 100 * (1 - (np.mean(stds_dist) - min([np.mean([self.df[self.df['Distribuci√≥n'] == d][m].std() for d in distribuciones]) for m in self.modelos])) / \n",
    "                             (max([np.mean([self.df[self.df['Distribuci√≥n'] == d][m].std() for d in distribuciones]) for m in self.modelos]) - \n",
    "                              min([np.mean([self.df[self.df['Distribuci√≥n'] == d][m].std() for d in distribuciones]) for m in self.modelos])))\n",
    "            fila.append(est_dist)\n",
    "            \n",
    "            # 4. Estabilidad por Varianza\n",
    "            stds_var = [self.df[self.df['Varianza error'] == v][modelo].std() for v in varianzas]\n",
    "            est_var = 100 * (1 - (np.mean(stds_var) - min([np.mean([self.df[self.df['Varianza error'] == v][m].std() for v in varianzas]) for m in self.modelos])) / \n",
    "                            (max([np.mean([self.df[self.df['Varianza error'] == v][m].std() for v in varianzas]) for m in self.modelos]) - \n",
    "                             min([np.mean([self.df[self.df['Varianza error'] == v][m].std() for v in varianzas]) for m in self.modelos])))\n",
    "            fila.append(est_var)\n",
    "            \n",
    "            matriz_resumen.append(fila)\n",
    "        \n",
    "        df_heatmap = pd.DataFrame(matriz_resumen, columns=caracteristicas, index=top5_modelos)\n",
    "        \n",
    "        sns.heatmap(df_heatmap, annot=True, fmt='.1f', cmap='RdYlGn', \n",
    "                   ax=ax, cbar_kws={'label': 'Score Normalizado (0-100)'},\n",
    "                   linewidths=2, linecolor='white', vmin=0, vmax=100,\n",
    "                   annot_kws={'fontsize': 11, 'fontweight': 'bold'})\n",
    "        ax.set_title('Perfil Multidimensional - Top 5 Modelos', \n",
    "                     fontweight='bold', fontsize=14, pad=20)\n",
    "        ax.set_xlabel('Dimensi√≥n de Evaluaci√≥n', fontweight='bold', fontsize=12)\n",
    "        ax.set_ylabel('Modelo', fontweight='bold', fontsize=12)\n",
    "        ax.tick_params(labelsize=11)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '9_2_resumen_perfil_multidimensional.png', \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # FIGURA 9.3: Impacto de caracter√≠sticas - NORMALIZADO AL 100%\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        \n",
    "        impactos = []\n",
    "        \n",
    "        # Estacionariedad\n",
    "        est_data = []\n",
    "        for modelo in self.modelos:\n",
    "            est = self.df[self.df['Estacionario'] == 'Estacionario'][modelo].mean()\n",
    "            no_est = self.df[self.df['Estacionario'] == 'No Estacionario'][modelo].mean()\n",
    "            cambio = ((no_est - est) / est * 100) if est != 0 else 0\n",
    "            est_data.append(cambio)\n",
    "        impactos.append(('Estacionariedad', np.mean(np.abs(est_data))))\n",
    "        \n",
    "        # Linealidad\n",
    "        lin_data = []\n",
    "        for modelo in self.modelos:\n",
    "            lin = self.df[self.df['Lineal'] == 'Lineal'][modelo].mean()\n",
    "            no_lin = self.df[self.df['Lineal'] == 'No Lineal'][modelo].mean()\n",
    "            cambio = ((no_lin - lin) / lin * 100) if lin != 0 else 0\n",
    "            lin_data.append(cambio)\n",
    "        impactos.append(('Linealidad', np.mean(np.abs(lin_data))))\n",
    "        \n",
    "        # Varianza\n",
    "        var_data = []\n",
    "        for modelo in self.modelos:\n",
    "            corr = abs(self.df[['Varianza error', modelo]].corr().iloc[0, 1])\n",
    "            var_data.append(corr * 100)\n",
    "        impactos.append(('Varianza', np.mean(var_data)))\n",
    "        \n",
    "        # Horizonte\n",
    "        hor_data = []\n",
    "        pasos = sorted(self.df['Paso'].unique())\n",
    "        for modelo in self.modelos:\n",
    "            medias = [self.df[self.df['Paso'] == p][modelo].mean() for p in pasos]\n",
    "            if len(medias) > 1 and medias[0] != 0:\n",
    "                cambio = abs(((medias[-1] - medias[0]) / medias[0]) * 100)\n",
    "                hor_data.append(cambio)\n",
    "        impactos.append(('Horizonte', np.mean(hor_data)))\n",
    "        \n",
    "        # Distribuci√≥n\n",
    "        dist_data = []\n",
    "        for modelo in self.modelos:\n",
    "            medias_dist = self.df.groupby('Distribuci√≥n')[modelo].mean()\n",
    "            rango = medias_dist.max() - medias_dist.min()\n",
    "            dist_data.append(rango / medias_dist.mean() * 100 if medias_dist.mean() != 0 else 0)\n",
    "        impactos.append(('Distribuci√≥n', np.mean(dist_data)))\n",
    "        \n",
    "        # Tipo de Modelo\n",
    "        tipo_data = []\n",
    "        for modelo in self.modelos:\n",
    "            medias_tipo = self.df.groupby('Tipo de Modelo')[modelo].mean()\n",
    "            rango = medias_tipo.max() - medias_tipo.min()\n",
    "            tipo_data.append(rango / medias_tipo.mean() * 100 if medias_tipo.mean() != 0 else 0)\n",
    "        impactos.append(('Tipo Generador', np.mean(tipo_data)))\n",
    "        \n",
    "        # NORMALIZAR AL 100%\n",
    "        total_impacto = sum([x[1] for x in impactos])\n",
    "        impactos_norm = [(nombre, (valor / total_impacto) * 100) for nombre, valor in impactos]\n",
    "        \n",
    "        # Ordenar por impacto\n",
    "        impactos_sorted = sorted(impactos_norm, key=lambda x: x[1], reverse=True)\n",
    "        nombres_imp = [x[0] for x in impactos_sorted]\n",
    "        valores_imp = [x[1] for x in impactos_sorted]\n",
    "        \n",
    "        colors_imp = plt.cm.Reds(np.linspace(0.3, 0.9, len(impactos_sorted)))\n",
    "        bars = ax.barh(nombres_imp, valores_imp, color=colors_imp, alpha=0.8, \n",
    "                       edgecolor='black', linewidth=1.5)\n",
    "        ax.set_xlabel('Impacto Normalizado (%)', fontweight='bold', fontsize=12)\n",
    "        ax.set_title('Impacto de Caracter√≠sticas en el Rendimiento\\n(Total = 100%)', \n",
    "                     fontweight='bold', fontsize=14, pad=20)\n",
    "        ax.grid(True, alpha=0.3, axis='x')\n",
    "        ax.set_xlim(0, max(valores_imp) * 1.15)\n",
    "        \n",
    "        for i, (bar, val) in enumerate(zip(bars, valores_imp)):\n",
    "            ax.text(val + 1, i, f' {val:.1f}%', va='center', fontweight='bold', fontsize=11)\n",
    "        \n",
    "        # Agregar suma total\n",
    "        ax.text(0.98, 0.02, f'Suma Total: {sum(valores_imp):.1f}%', \n",
    "                transform=ax.transAxes, fontsize=11, fontweight='bold',\n",
    "                ha='right', va='bottom',\n",
    "                bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.dir_salida / '9_3_resumen_impacto_caracteristicas.png', \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(\"   ‚úì 2 figuras generadas para resumen ejecutivo\")\n",
    "        print()\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# FUNCI√ìN PRINCIPAL\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Funci√≥n principal de ejecuci√≥n\"\"\"\n",
    "    print(\"\\n\" + \"‚ñà\"*80)\n",
    "    print(\"‚ñà\" + \" \"*78 + \"‚ñà\")\n",
    "    print(\"‚ñà\" + \" \"*15 + \"AN√ÅLISIS COMPLETO DE BASE DE DATOS - VERSI√ìN CORREGIDA\" + \" \"*8 + \"‚ñà\")\n",
    "    print(\"‚ñà\" + \" \"*78 + \"‚ñà\")\n",
    "    print(\"‚ñà\"*80 + \"\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Crear instancia del analizador\n",
    "        analizador = AnalizadorBaseCompleta(RUTA_DATOS)\n",
    "        \n",
    "        # Ejecutar an√°lisis completo\n",
    "        analizador.ejecutar_analisis_completo()\n",
    "        \n",
    "        print(\"\\n\" + \"‚ñà\"*80)\n",
    "        print(\"‚ñà\" + \" \"*78 + \"‚ñà\")\n",
    "        print(\"‚ñà\" + \" \"*20 + \"‚úÖ AN√ÅLISIS COMPLETADO EXITOSAMENTE\" + \" \"*23 + \"‚ñà\")\n",
    "        print(\"‚ñà\" + \" \"*78 + \"‚ñà\")\n",
    "        print(\"‚ñà\"*80 + \"\\n\")\n",
    "        \n",
    "        print(\"üìä TOTAL DE FIGURAS GENERADAS: 15 im√°genes PNG\")\n",
    "        print(\"\\nüìÅ ESTRUCTURA DE RESULTADOS:\")\n",
    "        print(f\"   {DIR_SALIDA}/\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ 1.1: Estacionariedad - Comparativo\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ 1.2: Estacionariedad - Cambio Relativo\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ 2.1: Linealidad - Comparativo\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ 2.2: Linealidad - Cambio Relativo\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ 3.2: Modelo Generador - Z-Score\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ 3.3: Modelo Generador - Variabilidad\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ 4.1: Distribuci√≥n - Heatmap Rendimiento\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ 4.2: Distribuci√≥n - Heatmap Variabilidad\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ 5.1: Varianza - Tendencias\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ 5.2: Varianza - Tasa de Crecimiento\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ 6.1: Horizonte - Evoluci√≥n\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ 6.2: Horizonte - Tasa de Deterioro\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ 7.2: Robustez - Coeficiente de Variaci√≥n\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ 8.2: Significancia - Matriz de Superioridad\")\n",
    "        print(\"   ‚îú‚îÄ‚îÄ 9.2: Resumen - Perfil Multidimensional\")\n",
    "        print(\"   ‚îî‚îÄ‚îÄ 9.3: Resumen - Impacto de Caracter√≠sticas (normalizado)\")\n",
    "        print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"\\n‚ùå ERROR: No se encontr√≥ el archivo {RUTA_DATOS}\")\n",
    "        print(\"   Por favor, verifica que el archivo existe y la ruta es correcta.\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå ERROR INESPERADO: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b99d120",
   "metadata": {},
   "source": [
    "# Analisis Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b278203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ANÁLISIS COMPREHENSIVO DE MODELOS DE PREDICCIÓN PROBABILÍSTICA\n",
      "================================================================================\n",
      "\n",
      "Cargando datos...\n",
      "✓ Estacionario: 1320 filas\n",
      "  Columnas: ['Paso', 'Valores de AR', 'Valores MA', 'Distribución', 'Varianza error', 'AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', 'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap', 'Mejor Modelo', 'Escenario']\n",
      "✓ No Estacionario: 840 filas\n",
      "  Columnas: ['Paso', 'Tipo de Modelo', 'Valores de AR', 'Valores MA', 'Distribución', 'Varianza error', 'AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', 'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap', 'Mejor Modelo', 'Escenario']\n",
      "✓ No Lineal: 840 filas\n",
      "  Columnas: ['Paso', 'Tipo de Modelo', 'Distribución', 'Varianza error', 'AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', 'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap', 'Mejor Modelo', 'Escenario']\n",
      "✓ Tipos de datos convertidos\n",
      "✓ Filas después de limpieza: 2600\n",
      "\n",
      "✓ Datos combinados: 2600 observaciones totales\n",
      "✓ Columnas finales: ['Paso', 'Valores de AR', 'Valores MA', 'Distribución', 'Varianza', 'AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', 'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap', 'Mejor Modelo', 'Escenario', 'Tipo de Modelo']\n",
      "\n",
      "================================================================================\n",
      "INICIANDO ANÁLISIS COMPREHENSIVO DE MODELOS\n",
      "================================================================================\n",
      "\n",
      "1. Analizando características del proceso generador...\n",
      "  - Analizando efecto de estacionaridad...\n",
      "  - Analizando efecto de no linealidad...\n",
      "  - Analizando efecto del tipo de modelo...\n",
      "\n",
      "2. Analizando efecto de distribuciones...\n",
      "  - Analizando efectos de distribuciones...\n",
      "  - Analizando efectos de varianza...\n",
      "\n",
      "3. Analizando horizonte de predicción...\n",
      "  - Analizando deterioro por horizonte...\n",
      "  - Analizando consistencia de ranking...\n",
      "\n",
      "4. Analizando interacciones complejas...\n",
      "  - Analizando interacciones Escenario × Distribución...\n",
      "  - Analizando interacción triple...\n",
      "\n",
      "5. Analizando robustez y estabilidad...\n",
      "  - Calculando métricas de robustez...\n",
      "  - Identificando peores casos...\n",
      "\n",
      "6. Realizando tests de Diebold-Mariano...\n",
      "  - Realizando tests de Diebold-Mariano...\n",
      "  - Realizando tests pareados de Diebold-Mariano...\n",
      "  - Creando matriz de p-valores...\n",
      "  - Analizando dominancia estadística...\n",
      "  - Analizando DM por escenario...\n",
      "\n",
      "7. Generando perfiles por modelo...\n",
      "  - Generando perfiles individuales...\n",
      "    > Analizando AREPD...\n",
      "    > Analizando AV-MCPS...\n",
      "    > Analizando Block Bootstrapping...\n",
      "    > Analizando DeepAR...\n",
      "    > Analizando EnCQR-LSTM...\n",
      "    > Analizando LSPM...\n",
      "    > Analizando LSPMW...\n",
      "    > Analizando MCPS...\n",
      "    > Analizando Sieve Bootstrap...\n",
      "\n",
      "8. Generando recomendaciones...\n",
      "  - Generando recomendaciones estratégicas...\n",
      "================================================================================\n",
      "RECOMENDACIONES Y CONCLUSIONES\n",
      "================================================================================\n",
      "\n",
      "1. MODELO CAMPEÓN GENERAL\n",
      "----------------------------------------\n",
      "Mejor rendimiento promedio: Block Bootstrapping\n",
      "ECRPS: 0.557547\n",
      "Desviación Estándar: 0.293355\n",
      "\n",
      "Peor rendimiento promedio: AREPD\n",
      "ECRPS: 3.083010\n",
      "\n",
      "2. RECOMENDACIONES POR ESCENARIO\n",
      "----------------------------------------\n",
      "\n",
      "Estacionario_Lineal:\n",
      "  Modelo Recomendado: Block Bootstrapping\n",
      "  ECRPS Promedio: 0.539612\n",
      "\n",
      "No_Estacionario_Lineal:\n",
      "  Modelo Recomendado: Block Bootstrapping\n",
      "  ECRPS Promedio: 0.542499\n",
      "\n",
      "No_Lineal:\n",
      "  Modelo Recomendado: Block Bootstrapping\n",
      "  ECRPS Promedio: 0.603341\n",
      "\n",
      "3. RECOMENDACIONES POR DISTRIBUCIÓN DE ERRORES\n",
      "----------------------------------------\n",
      "\n",
      "Distribución normal:\n",
      "  Modelo Recomendado: Block Bootstrapping\n",
      "  ECRPS Promedio: 0.567834\n",
      "\n",
      "Distribución uniform:\n",
      "  Modelo Recomendado: Block Bootstrapping\n",
      "  ECRPS Promedio: 0.585653\n",
      "\n",
      "Distribución exponential:\n",
      "  Modelo Recomendado: Block Bootstrapping\n",
      "  ECRPS Promedio: 0.514920\n",
      "\n",
      "Distribución t-student:\n",
      "  Modelo Recomendado: Block Bootstrapping\n",
      "  ECRPS Promedio: 0.547263\n",
      "\n",
      "Distribución mixture:\n",
      "  Modelo Recomendado: Block Bootstrapping\n",
      "  ECRPS Promedio: 0.572066\n",
      "\n",
      "4. MODELOS MÁS ROBUSTOS (MENOR VARIABILIDAD)\n",
      "----------------------------------------\n",
      "1. Block Bootstrapping: CV = 0.5262\n",
      "2. LSPMW: CV = 0.7688\n",
      "3. LSPM: CV = 0.7896\n",
      "\n",
      "5. RECOMENDACIONES POR HORIZONTE DE PREDICCIÓN\n",
      "----------------------------------------\n",
      "\n",
      "Paso 1.0:\n",
      "  Modelo Recomendado: Block Bootstrapping\n",
      "  ECRPS Promedio: 0.548020\n",
      "\n",
      "Paso 3.0:\n",
      "  Modelo Recomendado: Block Bootstrapping\n",
      "  ECRPS Promedio: 0.560285\n",
      "\n",
      "Paso 5.0:\n",
      "  Modelo Recomendado: Block Bootstrapping\n",
      "  ECRPS Promedio: 0.554843\n",
      "\n",
      "6. ESTRATEGIA DE ENSAMBLE SUGERIDA\n",
      "----------------------------------------\n",
      "Combinar los siguientes modelos:\n",
      "1. Block Bootstrapping (ECRPS: 0.557547)\n",
      "2. Sieve Bootstrap (ECRPS: 0.614997)\n",
      "3. LSPM (ECRPS: 0.811114)\n",
      "\n",
      "Justificación:\n",
      "  - Estos modelos muestran el mejor rendimiento promedio\n",
      "  - Un ensamble puede capturar fortalezas complementarias\n",
      "  - Reduce el riesgo de seleccionar un modelo subóptimo\n",
      "\n",
      "7. MODELOS CON DOMINANCIA ESTADÍSTICA\n",
      "----------------------------------------\n",
      "Modelos estadísticamente superiores (test Diebold-Mariano):\n",
      "1. Block Bootstrapping: 7 victorias significativas\n",
      "2. LSPM: 6 victorias significativas\n",
      "3. LSPMW: 5 victorias significativas\n",
      "4. Sieve Bootstrap: 5 victorias significativas\n",
      "5. DeepAR: 3 victorias significativas\n",
      "\n",
      "8. REGLAS DE DECISIÓN SUGERIDAS\n",
      "----------------------------------------\n",
      "\n",
      "SI el proceso es ESTACIONARIO y LINEAL:\n",
      "  → Primera opción: Block Bootstrapping\n",
      "  → Segunda opción: Sieve Bootstrap\n",
      "\n",
      "SI el proceso es NO ESTACIONARIO y LINEAL:\n",
      "  → Primera opción: Block Bootstrapping\n",
      "  → Segunda opción: Sieve Bootstrap\n",
      "\n",
      "SI el proceso es NO LINEAL:\n",
      "  → Primera opción: Block Bootstrapping\n",
      "  → Segunda opción: DeepAR\n",
      "\n",
      "SI la distribución de errores:\n",
      "  • Es normal → Usar Block Bootstrapping\n",
      "  • Es uniform → Usar Block Bootstrapping\n",
      "  • Es exponential → Usar Block Bootstrapping\n",
      "  • Es t-student → Usar Block Bootstrapping\n",
      "  • Es mixture → Usar Block Bootstrapping\n",
      "\n",
      "SI el nivel de varianza:\n",
      "  • Es bajo (0.2) → Usar Block Bootstrapping\n",
      "  • Es alto (3.0) → Usar Block Bootstrapping\n",
      "\n",
      "9. CONCLUSIONES PRINCIPALES\n",
      "----------------------------------------\n",
      "\n",
      "• El modelo Block Bootstrapping muestra el mejor rendimiento general\n",
      "  con ECRPS promedio de 0.557547\n",
      "\n",
      "• El modelo más robusto (menor CV) es Block Bootstrapping\n",
      "\n",
      "• Block Bootstrapping es consistentemente superior en procesos\n",
      "  estacionarios y no estacionarios\n",
      "\n",
      "• Para procesos no lineales: Block Bootstrapping es la mejor opción\n",
      "\n",
      "• Se recomienda implementar un ENSAMBLE de los top 3 modelos\n",
      "  para maximizar robustez y rendimiento\n",
      "\n",
      "10. CONSIDERACIONES PRÁCTICAS\n",
      "----------------------------------------\n",
      "\n",
      "Factores a considerar en la selección:\n",
      "  1. Costo computacional vs ganancia en precisión\n",
      "  2. Robustez ante cambios en la distribución de errores\n",
      "  3. Consistencia a través de horizontes de predicción\n",
      "  4. Facilidad de interpretación y explicabilidad\n",
      "  5. Disponibilidad de recursos para implementación\n",
      "\n",
      "Trade-offs identificados:\n",
      "  • Algunos modelos son especialistas en escenarios específicos\n",
      "  • Otros modelos son generalistas con buen rendimiento global\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ANÁLISIS COMPLETO. Resultados guardados en: resultados_analisis_completo/\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "✓ Análisis completado exitosamente\n",
      "✓ Todos los resultados guardados en: resultados_analisis_completo/\n",
      "================================================================================\n",
      "\n",
      "Archivos generados:\n",
      "  📊 Análisis de características del DGP\n",
      "  📈 Efectos de distribución y varianza\n",
      "  🎯 Análisis de horizonte de predicción\n",
      "  🔄 Interacciones complejas\n",
      "  💪 Métricas de robustez\n",
      "  📉 Tests de Diebold-Mariano\n",
      "  👤 Perfiles individuales por modelo\n",
      "  💡 Recomendaciones estratégicas\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import friedmanchisquare\n",
    "from itertools import combinations\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class DieboldMarianoTest:\n",
    "    \"\"\"\n",
    "    Implementación del test de Diebold-Mariano para comparar pronósticos\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def dm_test(errors1, errors2, h=1, crit=\"MSE\", power=2):\n",
    "        \"\"\"\n",
    "        Realiza el test de Diebold-Mariano\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        errors1 : array-like\n",
    "            Errores del primer modelo\n",
    "        errors2 : array-like\n",
    "            Errores del segundo modelo\n",
    "        h : int\n",
    "            Horizonte de predicción (para ajustar autocorrelación)\n",
    "        crit : str\n",
    "            Criterio de pérdida: \"MSE\", \"MAE\", \"MAPE\"\n",
    "        power : int\n",
    "            Potencia para la función de pérdida\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        dm_stat : float\n",
    "            Estadístico DM\n",
    "        p_value : float\n",
    "            P-valor (two-tailed)\n",
    "        \"\"\"\n",
    "        errors1 = np.array(errors1)\n",
    "        errors2 = np.array(errors2)\n",
    "        \n",
    "        # Calcular diferencias de pérdida\n",
    "        if crit == \"MSE\":\n",
    "            loss_diff = errors1**2 - errors2**2\n",
    "        elif crit == \"MAE\":\n",
    "            loss_diff = np.abs(errors1) - np.abs(errors2)\n",
    "        elif crit == \"MAPE\":\n",
    "            loss_diff = np.abs(errors1) - np.abs(errors2)\n",
    "        else:\n",
    "            loss_diff = errors1**power - errors2**power\n",
    "        \n",
    "        # Media de las diferencias\n",
    "        mean_diff = np.mean(loss_diff)\n",
    "        \n",
    "        # Varianza de las diferencias (ajustada por autocorrelación)\n",
    "        n = len(loss_diff)\n",
    "        \n",
    "        # Calcular varianza con corrección de Newey-West\n",
    "        gamma0 = np.var(loss_diff, ddof=1)\n",
    "        \n",
    "        if h > 1:\n",
    "            gamma_sum = 0\n",
    "            for k in range(1, h):\n",
    "                gamma_k = np.cov(loss_diff[:-k], loss_diff[k:])[0, 1]\n",
    "                gamma_sum += (1 - k/h) * gamma_k\n",
    "            variance = (gamma0 + 2 * gamma_sum) / n\n",
    "        else:\n",
    "            variance = gamma0 / n\n",
    "        \n",
    "        # Estadístico DM\n",
    "        dm_stat = mean_diff / np.sqrt(variance) if variance > 0 else 0\n",
    "        \n",
    "        # P-valor (two-tailed)\n",
    "        p_value = 2 * (1 - stats.norm.cdf(np.abs(dm_stat)))\n",
    "        \n",
    "        return dm_stat, p_value\n",
    "\n",
    "\n",
    "class ModelPerformanceAnalyzer:\n",
    "    \"\"\"\n",
    "    Clase para análisis exhaustivo de rendimiento de modelos de predicción\n",
    "    en diferentes escenarios de simulación.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Inicializa el analizador cargando los datos de los tres escenarios.\n",
    "        \"\"\"\n",
    "        self.models = ['AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', \n",
    "                      'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
    "        \n",
    "        # Cargar datos con las rutas especificadas\n",
    "        print(\"Cargando datos...\")\n",
    "        \n",
    "        try:\n",
    "            self.df_estacionario = pd.read_excel(\"./Datos/estacionario.xlsx\")\n",
    "            self.df_estacionario['Escenario'] = 'Estacionario_Lineal'\n",
    "            print(f\"✓ Estacionario: {len(self.df_estacionario)} filas\")\n",
    "            print(f\"  Columnas: {self.df_estacionario.columns.tolist()}\")\n",
    "            \n",
    "            self.df_no_estacionario = pd.read_excel(\"./Datos/no_estacionario.xlsx\")\n",
    "            self.df_no_estacionario['Escenario'] = 'No_Estacionario_Lineal'\n",
    "            print(f\"✓ No Estacionario: {len(self.df_no_estacionario)} filas\")\n",
    "            print(f\"  Columnas: {self.df_no_estacionario.columns.tolist()}\")\n",
    "            \n",
    "            self.df_no_lineal = pd.read_excel(\"./Datos/no_lineal.xlsx\")\n",
    "            self.df_no_lineal['Escenario'] = 'No_Lineal'\n",
    "            print(f\"✓ No Lineal: {len(self.df_no_lineal)} filas\")\n",
    "            print(f\"  Columnas: {self.df_no_lineal.columns.tolist()}\")\n",
    "            \n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"ERROR: No se encontró el archivo - {e}\")\n",
    "            print(\"Verifica que los archivos estén en la carpeta './Datos/'\")\n",
    "            raise\n",
    "        \n",
    "        # Estandarizar nombres de columnas\n",
    "        self._standardize_columns()\n",
    "        \n",
    "        # Combinar todos los datos\n",
    "        self.df_all = pd.concat([self.df_estacionario, self.df_no_estacionario, \n",
    "                                 self.df_no_lineal], ignore_index=True)\n",
    "        \n",
    "        # Convertir tipos de datos críticos\n",
    "        self._convert_data_types()\n",
    "        \n",
    "        print(f\"\\n✓ Datos combinados: {len(self.df_all)} observaciones totales\")\n",
    "        print(f\"✓ Columnas finales: {self.df_all.columns.tolist()}\")\n",
    "        \n",
    "    def _standardize_columns(self):\n",
    "        \"\"\"Estandariza nombres de columnas entre datasets\"\"\"\n",
    "        # Para estacionario\n",
    "        if 'Varianza error' in self.df_estacionario.columns:\n",
    "            self.df_estacionario.rename(columns={'Varianza error': 'Varianza'}, inplace=True)\n",
    "        \n",
    "        # Agregar columna 'Tipo de Modelo' si no existe en estacionario\n",
    "        if 'Tipo de Modelo' not in self.df_estacionario.columns:\n",
    "            # Crear tipo de modelo basado en valores AR y MA\n",
    "            def create_model_type(row):\n",
    "                ar_vals = row.get('Valores de AR', '')\n",
    "                ma_vals = row.get('Valores MA', '')\n",
    "                \n",
    "                ar_str = str(ar_vals) if pd.notna(ar_vals) else ''\n",
    "                ma_str = str(ma_vals) if pd.notna(ma_vals) else ''\n",
    "                \n",
    "                # Contar órdenes\n",
    "                ar_order = len([x for x in ar_str.split(',') if x.strip() and x.strip() != '[]']) if ar_str else 0\n",
    "                ma_order = len([x for x in ma_str.split(',') if x.strip() and x.strip() != '[]']) if ma_str else 0\n",
    "                \n",
    "                if ar_order > 0 and ma_order > 0:\n",
    "                    return f'ARMA({ar_order},{ma_order})'\n",
    "                elif ar_order > 0:\n",
    "                    return f'AR({ar_order})'\n",
    "                elif ma_order > 0:\n",
    "                    return f'MA({ma_order})'\n",
    "                else:\n",
    "                    return 'Unknown'\n",
    "            \n",
    "            self.df_estacionario['Tipo de Modelo'] = self.df_estacionario.apply(create_model_type, axis=1)\n",
    "        \n",
    "        # Para no estacionario\n",
    "        if 'Varianza error' in self.df_no_estacionario.columns:\n",
    "            self.df_no_estacionario.rename(columns={'Varianza error': 'Varianza'}, inplace=True)\n",
    "        \n",
    "        # Para no lineal\n",
    "        if 'Varianza error' in self.df_no_lineal.columns:\n",
    "            self.df_no_lineal.rename(columns={'Varianza error': 'Varianza'}, inplace=True)\n",
    "    \n",
    "    def _convert_data_types(self):\n",
    "        \"\"\"Convierte tipos de datos para evitar errores de comparación\"\"\"\n",
    "        # Convertir 'Paso' a numérico\n",
    "        self.df_all['Paso'] = pd.to_numeric(self.df_all['Paso'], errors='coerce')\n",
    "        \n",
    "        # Convertir 'Varianza' a numérico\n",
    "        self.df_all['Varianza'] = pd.to_numeric(self.df_all['Varianza'], errors='coerce')\n",
    "        \n",
    "        # Convertir columnas de modelos a numérico\n",
    "        for model in self.models:\n",
    "            self.df_all[model] = pd.to_numeric(self.df_all[model], errors='coerce')\n",
    "        \n",
    "        # Eliminar filas con valores NaN críticos\n",
    "        critical_cols = ['Paso', 'Varianza'] + self.models\n",
    "        self.df_all.dropna(subset=critical_cols, inplace=True)\n",
    "        \n",
    "        print(f\"✓ Tipos de datos convertidos\")\n",
    "        print(f\"✓ Filas después de limpieza: {len(self.df_all)}\")\n",
    "        \n",
    "    def generate_full_report(self, output_dir='resultados_analisis'):\n",
    "        \"\"\"\n",
    "        Genera reporte completo respondiendo a todas las preguntas clave.\n",
    "        \"\"\"\n",
    "        import os\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"INICIANDO ANÁLISIS COMPREHENSIVO DE MODELOS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Crear archivo de reporte\n",
    "        report_file = f\"{output_dir}/reporte_completo.txt\"\n",
    "        with open(report_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"REPORTE COMPLETO DE ANÁLISIS DE MODELOS DE PREDICCIÓN\\n\")\n",
    "            f.write(\"=\"*80 + \"\\n\\n\")\n",
    "        \n",
    "        # 1. ANÁLISIS POR CARACTERÍSTICAS DEL DGP\n",
    "        print(\"\\n1. Analizando características del proceso generador...\")\n",
    "        self.analyze_dgp_characteristics(output_dir)\n",
    "        \n",
    "        # 2. ANÁLISIS POR DISTRIBUCIÓN DE ERRORES\n",
    "        print(\"\\n2. Analizando efecto de distribuciones...\")\n",
    "        self.analyze_distribution_effects(output_dir)\n",
    "        \n",
    "        # 3. ANÁLISIS POR HORIZONTE DE PREDICCIÓN\n",
    "        print(\"\\n3. Analizando horizonte de predicción...\")\n",
    "        self.analyze_horizon_effects(output_dir)\n",
    "        \n",
    "        # 4. ANÁLISIS DE INTERACCIONES COMPLEJAS\n",
    "        print(\"\\n4. Analizando interacciones complejas...\")\n",
    "        self.analyze_interactions(output_dir)\n",
    "        \n",
    "        # 5. ANÁLISIS DE ROBUSTEZ Y ESTABILIDAD\n",
    "        print(\"\\n5. Analizando robustez y estabilidad...\")\n",
    "        self.analyze_robustness(output_dir)\n",
    "        \n",
    "        # 6. ANÁLISIS DE SIGNIFICANCIA ESTADÍSTICA (DIEBOLD-MARIANO)\n",
    "        print(\"\\n6. Realizando tests de Diebold-Mariano...\")\n",
    "        self.analyze_statistical_significance_dm(output_dir)\n",
    "        \n",
    "        # 7. ANÁLISIS POR MODELO INDIVIDUAL\n",
    "        print(\"\\n7. Generando perfiles por modelo...\")\n",
    "        self.analyze_individual_models(output_dir)\n",
    "        \n",
    "        # 8. RECOMENDACIONES Y CONCLUSIONES\n",
    "        print(\"\\n8. Generando recomendaciones...\")\n",
    "        self.generate_recommendations(output_dir)\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"ANÁLISIS COMPLETO. Resultados guardados en: {output_dir}/\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "    def analyze_dgp_characteristics(self, output_dir):\n",
    "        \"\"\"\n",
    "        1. ANÁLISIS DE CARACTERÍSTICAS DEL PROCESO GENERADOR\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        \n",
    "        # 1.1 Efecto de estacionaridad\n",
    "        print(\"  - Analizando efecto de estacionaridad...\")\n",
    "        for model in self.models:\n",
    "            est_mean = self.df_estacionario[model].mean()\n",
    "            no_est_mean = self.df_no_estacionario[model].mean()\n",
    "            diff = no_est_mean - est_mean\n",
    "            pct_change = (diff / est_mean) * 100 if est_mean != 0 else 0\n",
    "            \n",
    "            results.append({\n",
    "                'Modelo': model,\n",
    "                'ECRPS_Estacionario': est_mean,\n",
    "                'ECRPS_No_Estacionario': no_est_mean,\n",
    "                'Diferencia': diff,\n",
    "                'Cambio_%': pct_change\n",
    "            })\n",
    "        \n",
    "        df_estacionaridad = pd.DataFrame(results)\n",
    "        df_estacionaridad = df_estacionaridad.sort_values('Cambio_%')\n",
    "        df_estacionaridad.to_csv(f'{output_dir}/1_efecto_estacionaridad.csv', index=False)\n",
    "        \n",
    "        # Visualización\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # Gráfico de barras comparativas\n",
    "        x = np.arange(len(self.models))\n",
    "        width = 0.35\n",
    "        axes[0].bar(x - width/2, df_estacionaridad['ECRPS_Estacionario'], \n",
    "                   width, label='Estacionario', alpha=0.8)\n",
    "        axes[0].bar(x + width/2, df_estacionaridad['ECRPS_No_Estacionario'], \n",
    "                   width, label='No Estacionario', alpha=0.8)\n",
    "        axes[0].set_xlabel('Modelo')\n",
    "        axes[0].set_ylabel('ECRPS Promedio')\n",
    "        axes[0].set_title('Rendimiento: Estacionario vs No Estacionario')\n",
    "        axes[0].set_xticks(x)\n",
    "        axes[0].set_xticklabels(df_estacionaridad['Modelo'], rotation=45, ha='right')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Gráfico de cambio porcentual\n",
    "        colors = ['green' if x < 0 else 'red' for x in df_estacionaridad['Cambio_%']]\n",
    "        axes[1].barh(df_estacionaridad['Modelo'], df_estacionaridad['Cambio_%'], color=colors, alpha=0.7)\n",
    "        axes[1].set_xlabel('Cambio Porcentual (%)')\n",
    "        axes[1].set_title('Impacto de No Estacionaridad\\n(Negativo = Mejor en No Estacionario)')\n",
    "        axes[1].axvline(x=0, color='black', linestyle='--', linewidth=0.8)\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/1_estacionaridad.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # 1.2 Efecto de no linealidad\n",
    "        print(\"  - Analizando efecto de no linealidad...\")\n",
    "        results_nl = []\n",
    "        for model in self.models:\n",
    "            lin_mean = self.df_estacionario[model].mean()\n",
    "            nl_mean = self.df_no_lineal[model].mean()\n",
    "            diff = nl_mean - lin_mean\n",
    "            pct_change = (diff / lin_mean) * 100 if lin_mean != 0 else 0\n",
    "            \n",
    "            results_nl.append({\n",
    "                'Modelo': model,\n",
    "                'ECRPS_Lineal': lin_mean,\n",
    "                'ECRPS_No_Lineal': nl_mean,\n",
    "                'Diferencia': diff,\n",
    "                'Cambio_%': pct_change\n",
    "            })\n",
    "        \n",
    "        df_linealidad = pd.DataFrame(results_nl)\n",
    "        df_linealidad = df_linealidad.sort_values('Cambio_%')\n",
    "        df_linealidad.to_csv(f'{output_dir}/1_efecto_no_linealidad.csv', index=False)\n",
    "        \n",
    "        # Visualización no linealidad\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        x = np.arange(len(self.models))\n",
    "        axes[0].bar(x - width/2, df_linealidad['ECRPS_Lineal'], \n",
    "                   width, label='Lineal', alpha=0.8)\n",
    "        axes[0].bar(x + width/2, df_linealidad['ECRPS_No_Lineal'], \n",
    "                   width, label='No Lineal', alpha=0.8)\n",
    "        axes[0].set_xlabel('Modelo')\n",
    "        axes[0].set_ylabel('ECRPS Promedio')\n",
    "        axes[0].set_title('Rendimiento: Lineal vs No Lineal')\n",
    "        axes[0].set_xticks(x)\n",
    "        axes[0].set_xticklabels(df_linealidad['Modelo'], rotation=45, ha='right')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        colors = ['green' if x < 0 else 'red' for x in df_linealidad['Cambio_%']]\n",
    "        axes[1].barh(df_linealidad['Modelo'], df_linealidad['Cambio_%'], color=colors, alpha=0.7)\n",
    "        axes[1].set_xlabel('Cambio Porcentual (%)')\n",
    "        axes[1].set_title('Impacto de No Linealidad\\n(Negativo = Mejor en No Lineal)')\n",
    "        axes[1].axvline(x=0, color='black', linestyle='--', linewidth=0.8)\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/1_no_linealidad.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # 1.3 Análisis por tipo de modelo\n",
    "        print(\"  - Analizando efecto del tipo de modelo...\")\n",
    "        self.analyze_model_type_effect(output_dir)\n",
    "        \n",
    "    def analyze_model_type_effect(self, output_dir):\n",
    "        \"\"\"Analiza el efecto del tipo de modelo en el rendimiento\"\"\"\n",
    "        \n",
    "        # Análisis para datos estacionarios\n",
    "        if 'Tipo de Modelo' in self.df_estacionario.columns:\n",
    "            results_type = []\n",
    "            for model in self.models:\n",
    "                for model_type in self.df_estacionario['Tipo de Modelo'].unique():\n",
    "                    subset = self.df_estacionario[self.df_estacionario['Tipo de Modelo'] == model_type]\n",
    "                    if len(subset) > 0:\n",
    "                        results_type.append({\n",
    "                            'Modelo_Predictor': model,\n",
    "                            'Tipo_Proceso': model_type,\n",
    "                            'ECRPS_Mean': subset[model].mean(),\n",
    "                            'ECRPS_Std': subset[model].std(),\n",
    "                            'N_Obs': len(subset)\n",
    "                        })\n",
    "            \n",
    "            df_type = pd.DataFrame(results_type)\n",
    "            df_type.to_csv(f'{output_dir}/1_efecto_tipo_modelo.csv', index=False)\n",
    "            \n",
    "            # Crear heatmap para tipos más comunes\n",
    "            common_types = df_type['Tipo_Proceso'].value_counts().head(10).index\n",
    "            df_type_filtered = df_type[df_type['Tipo_Proceso'].isin(common_types)]\n",
    "            \n",
    "            if len(df_type_filtered) > 0:\n",
    "                pivot = df_type_filtered.pivot_table(\n",
    "                    index='Modelo_Predictor', \n",
    "                    columns='Tipo_Proceso', \n",
    "                    values='ECRPS_Mean'\n",
    "                )\n",
    "                \n",
    "                fig, ax = plt.subplots(figsize=(14, 8))\n",
    "                sns.heatmap(pivot, annot=True, fmt='.4f', cmap='RdYlGn_r', ax=ax, \n",
    "                           cbar_kws={'label': 'ECRPS'})\n",
    "                ax.set_title('Rendimiento por Modelo Predictor y Tipo de Proceso', fontsize=14)\n",
    "                ax.set_xlabel('Tipo de Proceso')\n",
    "                ax.set_ylabel('Modelo Predictor')\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f'{output_dir}/1_heatmap_tipo_modelo.png', dpi=300, bbox_inches='tight')\n",
    "                plt.close()\n",
    "        \n",
    "    def analyze_distribution_effects(self, output_dir):\n",
    "        \"\"\"\n",
    "        2. ANÁLISIS DE EFECTOS DE DISTRIBUCIÓN\n",
    "        \"\"\"\n",
    "        print(\"  - Analizando efectos de distribuciones...\")\n",
    "        \n",
    "        results_dist = []\n",
    "        for model in self.models:\n",
    "            for dist in self.df_all['Distribución'].unique():\n",
    "                if pd.notna(dist):\n",
    "                    subset = self.df_all[self.df_all['Distribución'] == dist]\n",
    "                    if len(subset) > 0:\n",
    "                        results_dist.append({\n",
    "                            'Modelo': model,\n",
    "                            'Distribución': dist,\n",
    "                            'ECRPS_Mean': subset[model].mean(),\n",
    "                            'ECRPS_Std': subset[model].std(),\n",
    "                            'ECRPS_Min': subset[model].min(),\n",
    "                            'ECRPS_Max': subset[model].max()\n",
    "                        })\n",
    "        \n",
    "        df_dist = pd.DataFrame(results_dist)\n",
    "        df_dist.to_csv(f'{output_dir}/2_efecto_distribucion.csv', index=False)\n",
    "        \n",
    "        # Heatmap\n",
    "        if len(df_dist) > 0:\n",
    "            pivot = df_dist.pivot(index='Modelo', columns='Distribución', values='ECRPS_Mean')\n",
    "            \n",
    "            fig, ax = plt.subplots(figsize=(10, 8))\n",
    "            sns.heatmap(pivot, annot=True, fmt='.4f', cmap='RdYlGn_r', ax=ax, cbar_kws={'label': 'ECRPS'})\n",
    "            ax.set_title('Rendimiento por Modelo y Distribución', fontsize=14)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'{output_dir}/2_heatmap_distribucion.png', dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "        \n",
    "        # Análisis por varianza\n",
    "        print(\"  - Analizando efectos de varianza...\")\n",
    "        results_var = []\n",
    "        varianzas_unicas = sorted([v for v in self.df_all['Varianza'].unique() if pd.notna(v)])\n",
    "        \n",
    "        for model in self.models:\n",
    "            for var in varianzas_unicas:\n",
    "                subset = self.df_all[self.df_all['Varianza'] == var]\n",
    "                if len(subset) > 0:\n",
    "                    results_var.append({\n",
    "                        'Modelo': model,\n",
    "                        'Varianza': var,\n",
    "                        'ECRPS_Mean': subset[model].mean(),\n",
    "                        'ECRPS_Std': subset[model].std()\n",
    "                    })\n",
    "        \n",
    "        df_var = pd.DataFrame(results_var)\n",
    "        df_var.to_csv(f'{output_dir}/2_efecto_varianza.csv', index=False)\n",
    "        \n",
    "        # Gráfico de líneas por varianza\n",
    "        if len(df_var) > 0:\n",
    "            fig, ax = plt.subplots(figsize=(12, 8))\n",
    "            for model in self.models:\n",
    "                data = df_var[df_var['Modelo'] == model].sort_values('Varianza')\n",
    "                if len(data) > 0:\n",
    "                    ax.plot(data['Varianza'], data['ECRPS_Mean'], marker='o', label=model, linewidth=2)\n",
    "            \n",
    "            ax.set_xlabel('Varianza', fontsize=12)\n",
    "            ax.set_ylabel('ECRPS Promedio', fontsize=12)\n",
    "            ax.set_title('Rendimiento según Nivel de Varianza', fontsize=14)\n",
    "            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'{output_dir}/2_efecto_varianza.png', dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "        \n",
    "    def analyze_horizon_effects(self, output_dir):\n",
    "        \"\"\"\n",
    "        3. ANÁLISIS DE HORIZONTE DE PREDICCIÓN\n",
    "        \"\"\"\n",
    "        print(\"  - Analizando deterioro por horizonte...\")\n",
    "        \n",
    "        results_horizon = []\n",
    "        pasos_unicos = sorted([p for p in self.df_all['Paso'].unique() if pd.notna(p)])\n",
    "        \n",
    "        for model in self.models:\n",
    "            for paso in pasos_unicos:\n",
    "                subset = self.df_all[self.df_all['Paso'] == paso]\n",
    "                if len(subset) > 0:\n",
    "                    mean_val = subset[model].mean()\n",
    "                    std_val = subset[model].std()\n",
    "                    cv_val = std_val / mean_val if mean_val != 0 and pd.notna(mean_val) else 0\n",
    "                    \n",
    "                    results_horizon.append({\n",
    "                        'Modelo': model,\n",
    "                        'Paso': int(paso),\n",
    "                        'ECRPS_Mean': mean_val,\n",
    "                        'ECRPS_Std': std_val,\n",
    "                        'ECRPS_CV': cv_val\n",
    "                    })\n",
    "        \n",
    "        df_horizon = pd.DataFrame(results_horizon)\n",
    "        df_horizon.to_csv(f'{output_dir}/3_efecto_horizonte.csv', index=False)\n",
    "        \n",
    "        # Gráfico de deterioro\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        \n",
    "        # ECRPS promedio por paso\n",
    "        for model in self.models:\n",
    "            data = df_horizon[df_horizon['Modelo'] == model].sort_values('Paso')\n",
    "            if len(data) > 0:\n",
    "                axes[0].plot(data['Paso'], data['ECRPS_Mean'], marker='o', label=model, linewidth=2)\n",
    "        \n",
    "        axes[0].set_xlabel('Paso de Predicción', fontsize=12)\n",
    "        axes[0].set_ylabel('ECRPS Promedio', fontsize=12)\n",
    "        axes[0].set_title('Deterioro del Rendimiento por Horizonte', fontsize=14)\n",
    "        axes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Tasa de deterioro\n",
    "        deterioro = []\n",
    "        for model in self.models:\n",
    "            data = df_horizon[df_horizon['Modelo'] == model].sort_values('Paso')\n",
    "            if len(data) >= 2:\n",
    "                paso_values = data['Paso'].tolist()\n",
    "                ecrps_paso1 = data.iloc[0]['ECRPS_Mean']\n",
    "                ecrps_paso_final = data.iloc[-1]['ECRPS_Mean']\n",
    "                \n",
    "                if pd.notna(ecrps_paso1) and pd.notna(ecrps_paso_final) and ecrps_paso1 != 0:\n",
    "                    tasa = ((ecrps_paso_final - ecrps_paso1) / ecrps_paso1) * 100\n",
    "                    deterioro.append({'Modelo': model, 'Deterioro_%': tasa})\n",
    "        \n",
    "        if deterioro:\n",
    "            df_deterioro = pd.DataFrame(deterioro).sort_values('Deterioro_%')\n",
    "            colors = ['green' if x < df_deterioro['Deterioro_%'].median() else 'red' \n",
    "                     for x in df_deterioro['Deterioro_%']]\n",
    "            axes[1].barh(df_deterioro['Modelo'], df_deterioro['Deterioro_%'], color=colors, alpha=0.7)\n",
    "            axes[1].set_xlabel(f'Deterioro Paso {pasos_unicos[0]}→{pasos_unicos[-1]} (%)', fontsize=12)\n",
    "            axes[1].set_title('Tasa de Deterioro por Modelo', fontsize=14)\n",
    "            axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/3_horizonte_prediccion.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # Análisis de consistencia de ranking\n",
    "        print(\"  - Analizando consistencia de ranking...\")\n",
    "        ranking_consistency = []\n",
    "        for paso in pasos_unicos:\n",
    "            subset = self.df_all[self.df_all['Paso'] == paso]\n",
    "            if len(subset) > 0:\n",
    "                ranks = subset[self.models].mean().rank()\n",
    "                rank_dict = ranks.to_dict()\n",
    "                rank_dict['Paso'] = int(paso)\n",
    "                ranking_consistency.append(rank_dict)\n",
    "        \n",
    "        df_ranks = pd.DataFrame(ranking_consistency)\n",
    "        df_ranks.to_csv(f'{output_dir}/3_ranking_por_paso.csv', index=False)\n",
    "        \n",
    "    def analyze_interactions(self, output_dir):\n",
    "        \"\"\"\n",
    "        4. ANÁLISIS DE INTERACCIONES COMPLEJAS\n",
    "        \"\"\"\n",
    "        print(\"  - Analizando interacciones Escenario × Distribución...\")\n",
    "        \n",
    "        results_int = []\n",
    "        for model in self.models:\n",
    "            for escenario in self.df_all['Escenario'].unique():\n",
    "                for dist in self.df_all['Distribución'].unique():\n",
    "                    subset = self.df_all[(self.df_all['Escenario'] == escenario) & \n",
    "                                        (self.df_all['Distribución'] == dist)]\n",
    "                    if len(subset) > 0:\n",
    "                        results_int.append({\n",
    "                            'Modelo': model,\n",
    "                            'Escenario': escenario,\n",
    "                            'Distribución': dist,\n",
    "                            'ECRPS_Mean': subset[model].mean()\n",
    "                        })\n",
    "        \n",
    "        df_int = pd.DataFrame(results_int)\n",
    "        df_int.to_csv(f'{output_dir}/4_interacciones.csv', index=False)\n",
    "        \n",
    "        # Heatmap de interacciones para cada modelo\n",
    "        for model in self.models[:3]:  # Solo primeros 3 por espacio\n",
    "            model_data = df_int[df_int['Modelo'] == model]\n",
    "            if len(model_data) > 0:\n",
    "                pivot = model_data.pivot(\n",
    "                    index='Escenario', columns='Distribución', values='ECRPS_Mean')\n",
    "                \n",
    "                fig, ax = plt.subplots(figsize=(10, 6))\n",
    "                sns.heatmap(pivot, annot=True, fmt='.4f', cmap='RdYlGn_r', ax=ax)\n",
    "                ax.set_title(f'Interacción Escenario × Distribución: {model}', fontsize=12)\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f'{output_dir}/4_interaccion_{model.replace(\" \", \"_\")}.png', \n",
    "                           dpi=300, bbox_inches='tight')\n",
    "                plt.close()\n",
    "        \n",
    "        # Interacción triple: Escenario × Varianza × Paso\n",
    "        print(\"  - Analizando interacción triple...\")\n",
    "        results_triple = []\n",
    "        \n",
    "        varianzas_unicas = sorted([v for v in self.df_all['Varianza'].unique() if pd.notna(v)])\n",
    "        pasos_unicos = sorted([p for p in self.df_all['Paso'].unique() if pd.notna(p)])\n",
    "        \n",
    "        for model in self.models:\n",
    "            for escenario in self.df_all['Escenario'].unique():\n",
    "                for var in varianzas_unicas:\n",
    "                    for paso in pasos_unicos:\n",
    "                        subset = self.df_all[\n",
    "                            (self.df_all['Escenario'] == escenario) & \n",
    "                            (self.df_all['Varianza'] == var) &\n",
    "                            (self.df_all['Paso'] == paso)\n",
    "                        ]\n",
    "                        if len(subset) > 0:\n",
    "                            results_triple.append({\n",
    "                                'Modelo': model,\n",
    "                                'Escenario': escenario,\n",
    "                                'Varianza': var,\n",
    "                                'Paso': int(paso),\n",
    "                                'ECRPS_Mean': subset[model].mean()\n",
    "                            })\n",
    "        \n",
    "        df_triple = pd.DataFrame(results_triple)\n",
    "        df_triple.to_csv(f'{output_dir}/4_interaccion_triple.csv', index=False)\n",
    "        \n",
    "    def analyze_robustness(self, output_dir):\n",
    "        \"\"\"\n",
    "        5. ANÁLISIS DE ROBUSTEZ Y ESTABILIDAD\n",
    "        \"\"\"\n",
    "        print(\"  - Calculando métricas de robustez...\")\n",
    "        \n",
    "        results_robust = []\n",
    "        for model in self.models:\n",
    "            ecrps_values = self.df_all[model]\n",
    "            \n",
    "            results_robust.append({\n",
    "                'Modelo': model,\n",
    "                'ECRPS_Mean': ecrps_values.mean(),\n",
    "                'ECRPS_Std': ecrps_values.std(),\n",
    "                'ECRPS_CV': ecrps_values.std() / ecrps_values.mean() if ecrps_values.mean() != 0 else 0,\n",
    "                'ECRPS_Min': ecrps_values.min(),\n",
    "                'ECRPS_Q25': ecrps_values.quantile(0.25),\n",
    "                'ECRPS_Median': ecrps_values.median(),\n",
    "                'ECRPS_Q75': ecrps_values.quantile(0.75),\n",
    "                'ECRPS_Max': ecrps_values.max(),\n",
    "                'ECRPS_IQR': ecrps_values.quantile(0.75) - ecrps_values.quantile(0.25)\n",
    "            })\n",
    "        \n",
    "        df_robust = pd.DataFrame(results_robust)\n",
    "        df_robust = df_robust.sort_values('ECRPS_CV')\n",
    "        df_robust.to_csv(f'{output_dir}/5_robustez.csv', index=False)\n",
    "        \n",
    "        # Gráfico de robustez\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        \n",
    "        # Coeficiente de variación\n",
    "        axes[0, 0].barh(df_robust['Modelo'], df_robust['ECRPS_CV'], alpha=0.7)\n",
    "        axes[0, 0].set_xlabel('Coeficiente de Variación')\n",
    "        axes[0, 0].set_title('Estabilidad (Menor CV = Más Estable)')\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Rango intercuartílico\n",
    "        axes[0, 1].barh(df_robust['Modelo'], df_robust['ECRPS_IQR'], alpha=0.7, color='coral')\n",
    "        axes[0, 1].set_xlabel('Rango Intercuartílico')\n",
    "        axes[0, 1].set_title('Variabilidad (Menor IQR = Más Consistente)')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Boxplot comparativo\n",
    "        data_box = [self.df_all[model] for model in self.models]\n",
    "        bp = axes[1, 0].boxplot(data_box, labels=self.models, patch_artist=True)\n",
    "        for patch in bp['boxes']:\n",
    "            patch.set_facecolor('lightblue')\n",
    "        axes[1, 0].set_ylabel('ECRPS')\n",
    "        axes[1, 0].set_title('Distribución de ECRPS por Modelo')\n",
    "        axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Scatter: Media vs Variabilidad\n",
    "        axes[1, 1].scatter(df_robust['ECRPS_Mean'], df_robust['ECRPS_Std'], \n",
    "                          s=100, alpha=0.6, c=range(len(df_robust)), cmap='viridis')\n",
    "        for idx, row in df_robust.iterrows():\n",
    "            axes[1, 1].annotate(row['Modelo'], \n",
    "                               (row['ECRPS_Mean'], row['ECRPS_Std']),\n",
    "                               fontsize=8, alpha=0.7)\n",
    "        axes[1, 1].set_xlabel('ECRPS Promedio')\n",
    "        axes[1, 1].set_ylabel('Desviación Estándar')\n",
    "        axes[1, 1].set_title('Trade-off Rendimiento vs Estabilidad')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/5_robustez.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # Análisis de peores casos\n",
    "        print(\"  - Identificando peores casos...\")\n",
    "        worst_cases = []\n",
    "        for model in self.models:\n",
    "            df_temp = self.df_all.copy()\n",
    "            df_temp['ECRPS'] = df_temp[model]\n",
    "            worst = df_temp.nlargest(10, 'ECRPS')[\n",
    "                ['Escenario', 'Tipo de Modelo', 'Distribución', 'Varianza', 'Paso', 'ECRPS']\n",
    "            ]\n",
    "            worst['Modelo_Predictor'] = model\n",
    "            worst_cases.append(worst)\n",
    "        \n",
    "        df_worst = pd.concat(worst_cases, ignore_index=True)\n",
    "        df_worst.to_csv(f'{output_dir}/5_peores_casos.csv', index=False)\n",
    "        \n",
    "    def analyze_statistical_significance_dm(self, output_dir):\n",
    "        \"\"\"\n",
    "        6. ANÁLISIS DE SIGNIFICANCIA ESTADÍSTICA CON DIEBOLD-MARIANO\n",
    "        \"\"\"\n",
    "        print(\"  - Realizando tests de Diebold-Mariano...\")\n",
    "        \n",
    "        # Test de Friedman por escenario (para comparación general)\n",
    "        results_friedman = []\n",
    "        for escenario in self.df_all['Escenario'].unique():\n",
    "            subset = self.df_all[self.df_all['Escenario'] == escenario]\n",
    "            data_matrix = subset[self.models].values\n",
    "            \n",
    "            try:\n",
    "                statistic, p_value = friedmanchisquare(*[data_matrix[:, i] for i in range(len(self.models))])\n",
    "                \n",
    "                results_friedman.append({\n",
    "                    'Escenario': escenario,\n",
    "                    'Friedman_Statistic': statistic,\n",
    "                    'P_Value': p_value,\n",
    "                    'Significativo': 'Sí' if p_value < 0.05 else 'No'\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"    Advertencia: Error en test de Friedman para {escenario}: {e}\")\n",
    "        \n",
    "        if results_friedman:\n",
    "            df_friedman = pd.DataFrame(results_friedman)\n",
    "            df_friedman.to_csv(f'{output_dir}/6_test_friedman.csv', index=False)\n",
    "        \n",
    "        # Tests de Diebold-Mariano pareados\n",
    "        print(\"  - Realizando tests pareados de Diebold-Mariano...\")\n",
    "        pairs = list(combinations(self.models, 2))\n",
    "        dm_results = []\n",
    "        \n",
    "        for model1, model2 in pairs:\n",
    "            # Calcular errores (usamos ECRPS directamente como métrica de pérdida)\n",
    "            errors1 = self.df_all[model1].values\n",
    "            errors2 = self.df_all[model2].values\n",
    "            \n",
    "            # Test de Diebold-Mariano\n",
    "            dm_stat, p_value = DieboldMarianoTest.dm_test(errors1, errors2, h=1, crit=\"MSE\")\n",
    "            \n",
    "            mean_diff = self.df_all[model1].mean() - self.df_all[model2].mean()\n",
    "            \n",
    "            # Determinar ganador\n",
    "            if p_value < 0.05:\n",
    "                if mean_diff < 0:\n",
    "                    ganador = model1\n",
    "                else:\n",
    "                    ganador = model2\n",
    "            else:\n",
    "                ganador = 'Empate'\n",
    "            \n",
    "            dm_results.append({\n",
    "                'Modelo_1': model1,\n",
    "                'Modelo_2': model2,\n",
    "                'Diferencia_Media': mean_diff,\n",
    "                'DM_Statistic': dm_stat,\n",
    "                'P_Value': p_value,\n",
    "                'Significativo_0.05': 'Sí' if p_value < 0.05 else 'No',\n",
    "                'Significativo_0.01': 'Sí' if p_value < 0.01 else 'No',\n",
    "                'Ganador': ganador\n",
    "            })\n",
    "        \n",
    "        df_dm = pd.DataFrame(dm_results)\n",
    "        df_dm = df_dm.sort_values('P_Value')\n",
    "        df_dm.to_csv(f'{output_dir}/6_tests_diebold_mariano.csv', index=False)\n",
    "        \n",
    "        # Matriz de p-valores (Diebold-Mariano)\n",
    "        print(\"  - Creando matriz de p-valores...\")\n",
    "        p_matrix = np.ones((len(self.models), len(self.models)))\n",
    "        for i, model1 in enumerate(self.models):\n",
    "            for j, model2 in enumerate(self.models):\n",
    "                if i != j:\n",
    "                    errors1 = self.df_all[model1].values\n",
    "                    errors2 = self.df_all[model2].values\n",
    "                    _, p_val = DieboldMarianoTest.dm_test(errors1, errors2, h=1, crit=\"MSE\")\n",
    "                    p_matrix[i, j] = p_val\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 10))\n",
    "        sns.heatmap(p_matrix, annot=True, fmt='.3f', cmap='RdYlGn', \n",
    "                   xticklabels=self.models, yticklabels=self.models, \n",
    "                   ax=ax, vmin=0, vmax=0.1, cbar_kws={'label': 'P-valor'})\n",
    "        ax.set_title('Matriz de P-valores (Test de Diebold-Mariano)\\nVerde = Diferencia Significativa', \n",
    "                    fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/6_matriz_pvalores_dm.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # Dominancia estadística con Diebold-Mariano\n",
    "        print(\"  - Analizando dominancia estadística...\")\n",
    "        dominance = []\n",
    "        for model in self.models:\n",
    "            wins = 0\n",
    "            losses = 0\n",
    "            ties = 0\n",
    "            for other_model in self.models:\n",
    "                if model != other_model:\n",
    "                    errors1 = self.df_all[model].values\n",
    "                    errors2 = self.df_all[other_model].values\n",
    "                    _, p_val = DieboldMarianoTest.dm_test(errors1, errors2, h=1, crit=\"MSE\")\n",
    "                    mean_diff = self.df_all[model].mean() - self.df_all[other_model].mean()\n",
    "                    \n",
    "                    if p_val < 0.05:\n",
    "                        if mean_diff < 0:  # modelo es mejor (menor ECRPS)\n",
    "                            wins += 1\n",
    "                        else:\n",
    "                            losses += 1\n",
    "                    else:\n",
    "                        ties += 1\n",
    "            \n",
    "            dominance.append({\n",
    "                'Modelo': model,\n",
    "                'Victorias_Significativas': wins,\n",
    "                'Derrotas_Significativas': losses,\n",
    "                'Empates': ties,\n",
    "                'Score_Neto': wins - losses\n",
    "            })\n",
    "        \n",
    "        df_dominance = pd.DataFrame(dominance)\n",
    "        df_dominance = df_dominance.sort_values('Score_Neto', ascending=False)\n",
    "        df_dominance.to_csv(f'{output_dir}/6_dominancia_estadistica_dm.csv', index=False)\n",
    "        \n",
    "        # Visualización de dominancia\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        x = np.arange(len(df_dominance))\n",
    "        width = 0.25\n",
    "        \n",
    "        ax.bar(x - width, df_dominance['Victorias_Significativas'], \n",
    "               width, label='Victorias', color='green', alpha=0.7)\n",
    "        ax.bar(x, df_dominance['Empates'], \n",
    "               width, label='Empates', color='gray', alpha=0.7)\n",
    "        ax.bar(x + width, df_dominance['Derrotas_Significativas'], \n",
    "               width, label='Derrotas', color='red', alpha=0.7)\n",
    "        \n",
    "        ax.set_xlabel('Modelo')\n",
    "        ax.set_ylabel('Número de Comparaciones')\n",
    "        ax.set_title('Dominancia Estadística (Test Diebold-Mariano)')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(df_dominance['Modelo'], rotation=45, ha='right')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/6_dominancia_dm.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # Análisis de Diebold-Mariano por escenario\n",
    "        print(\"  - Analizando DM por escenario...\")\n",
    "        dm_by_scenario = []\n",
    "        for escenario in self.df_all['Escenario'].unique():\n",
    "            subset = self.df_all[self.df_all['Escenario'] == escenario]\n",
    "            \n",
    "            for model1, model2 in combinations(self.models, 2):\n",
    "                errors1 = subset[model1].values\n",
    "                errors2 = subset[model2].values\n",
    "                \n",
    "                if len(errors1) > 0 and len(errors2) > 0:\n",
    "                    dm_stat, p_value = DieboldMarianoTest.dm_test(errors1, errors2, h=1, crit=\"MSE\")\n",
    "                    mean_diff = subset[model1].mean() - subset[model2].mean()\n",
    "                    \n",
    "                    dm_by_scenario.append({\n",
    "                        'Escenario': escenario,\n",
    "                        'Modelo_1': model1,\n",
    "                        'Modelo_2': model2,\n",
    "                        'DM_Statistic': dm_stat,\n",
    "                        'P_Value': p_value,\n",
    "                        'Diferencia_Media': mean_diff,\n",
    "                        'Significativo': 'Sí' if p_value < 0.05 else 'No'\n",
    "                    })\n",
    "        \n",
    "        df_dm_scenario = pd.DataFrame(dm_by_scenario)\n",
    "        df_dm_scenario.to_csv(f'{output_dir}/6_dm_por_escenario.csv', index=False)\n",
    "    \n",
    "    def analyze_individual_models(self, output_dir):\n",
    "        \"\"\"\n",
    "        7. PERFILES INDIVIDUALES POR MODELO\n",
    "        \"\"\"\n",
    "        print(\"  - Generando perfiles individuales...\")\n",
    "        \n",
    "        for model in self.models:\n",
    "            print(f\"    > Analizando {model}...\")\n",
    "            \n",
    "            # Crear subdirectorio para el modelo\n",
    "            model_dir = f\"{output_dir}/perfiles_modelos/{model.replace(' ', '_')}\"\n",
    "            import os\n",
    "            os.makedirs(model_dir, exist_ok=True)\n",
    "            \n",
    "            # Reporte del modelo\n",
    "            report = []\n",
    "            report.append(f\"=\"*80)\n",
    "            report.append(f\"PERFIL DETALLADO: {model}\")\n",
    "            report.append(f\"=\"*80)\n",
    "            report.append(\"\")\n",
    "            \n",
    "            # Estadísticas generales\n",
    "            report.append(\"1. ESTADÍSTICAS GENERALES\")\n",
    "            report.append(\"-\" * 40)\n",
    "            report.append(f\"ECRPS Promedio Global: {self.df_all[model].mean():.6f}\")\n",
    "            report.append(f\"Desviación Estándar: {self.df_all[model].std():.6f}\")\n",
    "            cv = self.df_all[model].std()/self.df_all[model].mean() if self.df_all[model].mean() != 0 else 0\n",
    "            report.append(f\"Coeficiente de Variación: {cv:.4f}\")\n",
    "            report.append(f\"Mínimo: {self.df_all[model].min():.6f}\")\n",
    "            report.append(f\"Mediana: {self.df_all[model].median():.6f}\")\n",
    "            report.append(f\"Máximo: {self.df_all[model].max():.6f}\")\n",
    "            report.append(\"\")\n",
    "            \n",
    "            # Ranking general\n",
    "            mean_scores = self.df_all[self.models].mean()\n",
    "            ranking = mean_scores.rank().astype(int)\n",
    "            report.append(f\"Ranking General: {ranking[model]}° de {len(self.models)}\")\n",
    "            report.append(\"\")\n",
    "            \n",
    "            # Mejor escenario\n",
    "            report.append(\"2. MEJORES ESCENARIOS\")\n",
    "            report.append(\"-\" * 40)\n",
    "            best_idx = self.df_all[model].idxmin()\n",
    "            best_row = self.df_all.loc[best_idx]\n",
    "            report.append(f\"Mejor ECRPS: {best_row[model]:.6f}\")\n",
    "            report.append(f\"  - Escenario: {best_row['Escenario']}\")\n",
    "            if 'Tipo de Modelo' in best_row:\n",
    "                report.append(f\"  - Tipo Modelo: {best_row['Tipo de Modelo']}\")\n",
    "            report.append(f\"  - Distribución: {best_row['Distribución']}\")\n",
    "            report.append(f\"  - Varianza: {best_row['Varianza']}\")\n",
    "            report.append(f\"  - Paso: {best_row['Paso']}\")\n",
    "            report.append(\"\")\n",
    "            \n",
    "            # Peor escenario\n",
    "            report.append(\"3. PEORES ESCENARIOS\")\n",
    "            report.append(\"-\" * 40)\n",
    "            worst_idx = self.df_all[model].idxmax()\n",
    "            worst_row = self.df_all.loc[worst_idx]\n",
    "            report.append(f\"Peor ECRPS: {worst_row[model]:.6f}\")\n",
    "            report.append(f\"  - Escenario: {worst_row['Escenario']}\")\n",
    "            if 'Tipo de Modelo' in worst_row:\n",
    "                report.append(f\"  - Tipo Modelo: {worst_row['Tipo de Modelo']}\")\n",
    "            report.append(f\"  - Distribución: {worst_row['Distribución']}\")\n",
    "            report.append(f\"  - Varianza: {worst_row['Varianza']}\")\n",
    "            report.append(f\"  - Paso: {worst_row['Paso']}\")\n",
    "            report.append(\"\")\n",
    "            \n",
    "            # Rendimiento por escenario\n",
    "            report.append(\"4. RENDIMIENTO POR ESCENARIO\")\n",
    "            report.append(\"-\" * 40)\n",
    "            for escenario in ['Estacionario_Lineal', 'No_Estacionario_Lineal', 'No_Lineal']:\n",
    "                subset = self.df_all[self.df_all['Escenario'] == escenario]\n",
    "                if len(subset) > 0:\n",
    "                    mean_val = subset[model].mean()\n",
    "                    rank = subset[self.models].mean().rank()[model]\n",
    "                    report.append(f\"{escenario}:\")\n",
    "                    report.append(f\"  ECRPS: {mean_val:.6f} (Ranking: {int(rank)}°)\")\n",
    "            report.append(\"\")\n",
    "            \n",
    "            # Fortalezas y debilidades\n",
    "            report.append(\"5. FORTALEZAS Y DEBILIDADES\")\n",
    "            report.append(\"-\" * 40)\n",
    "            \n",
    "            # Por distribución\n",
    "            report.append(\"Por Distribución:\")\n",
    "            dist_performance = []\n",
    "            for dist in self.df_all['Distribución'].unique():\n",
    "                subset = self.df_all[self.df_all['Distribución'] == dist]\n",
    "                if len(subset) > 0:\n",
    "                    mean_val = subset[model].mean()\n",
    "                    rank = subset[self.models].mean().rank()[model]\n",
    "                    dist_performance.append((dist, mean_val, rank))\n",
    "            \n",
    "            if dist_performance:\n",
    "                dist_performance.sort(key=lambda x: x[2])\n",
    "                report.append(f\"  Mejor: {dist_performance[0][0]} (Ranking {int(dist_performance[0][2])}°)\")\n",
    "                report.append(f\"  Peor: {dist_performance[-1][0]} (Ranking {int(dist_performance[-1][2])}°)\")\n",
    "            report.append(\"\")\n",
    "            \n",
    "            # Por varianza\n",
    "            report.append(\"Por Varianza:\")\n",
    "            var_performance = []\n",
    "            for var in sorted(self.df_all['Varianza'].unique()):\n",
    "                subset = self.df_all[self.df_all['Varianza'] == var]\n",
    "                if len(subset) > 0:\n",
    "                    mean_val = subset[model].mean()\n",
    "                    rank = subset[self.models].mean().rank()[model]\n",
    "                    var_performance.append((var, mean_val, rank))\n",
    "            \n",
    "            if var_performance:\n",
    "                var_performance.sort(key=lambda x: x[2])\n",
    "                report.append(f\"  Mejor: Varianza {var_performance[0][0]} (Ranking {int(var_performance[0][2])}°)\")\n",
    "                report.append(f\"  Peor: Varianza {var_performance[-1][0]} (Ranking {int(var_performance[-1][2])}°)\")\n",
    "            report.append(\"\")\n",
    "            \n",
    "            # Comparaciones con Diebold-Mariano\n",
    "            report.append(\"6. COMPARACIONES ESTADÍSTICAS (DIEBOLD-MARIANO)\")\n",
    "            report.append(\"-\" * 40)\n",
    "            \n",
    "            wins = 0\n",
    "            losses = 0\n",
    "            for other_model in self.models:\n",
    "                if model != other_model:\n",
    "                    errors1 = self.df_all[model].values\n",
    "                    errors2 = self.df_all[other_model].values\n",
    "                    _, p_val = DieboldMarianoTest.dm_test(errors1, errors2, h=1, crit=\"MSE\")\n",
    "                    mean_diff = self.df_all[model].mean() - self.df_all[other_model].mean()\n",
    "                    \n",
    "                    if p_val < 0.05:\n",
    "                        if mean_diff < 0:\n",
    "                            wins += 1\n",
    "                        else:\n",
    "                            losses += 1\n",
    "            \n",
    "            report.append(f\"Victorias significativas: {wins}\")\n",
    "            report.append(f\"Derrotas significativas: {losses}\")\n",
    "            report.append(f\"Score neto: {wins - losses}\")\n",
    "            report.append(\"\")\n",
    "            \n",
    "            # Guardar reporte\n",
    "            with open(f\"{model_dir}/perfil_{model.replace(' ', '_')}.txt\", 'w', encoding='utf-8') as f:\n",
    "                f.write('\\n'.join(report))\n",
    "            \n",
    "            # Visualizaciones del modelo\n",
    "            self._create_model_visualizations(model, model_dir)\n",
    "    \n",
    "    def _create_model_visualizations(self, model, model_dir):\n",
    "        \"\"\"Crea visualizaciones específicas para un modelo\"\"\"\n",
    "        \n",
    "        # 1. Distribución de ECRPS\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        \n",
    "        # Histograma\n",
    "        axes[0, 0].hist(self.df_all[model], bins=50, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "        axes[0, 0].axvline(self.df_all[model].mean(), color='red', linestyle='--', \n",
    "                          linewidth=2, label=f'Media: {self.df_all[model].mean():.4f}')\n",
    "        axes[0, 0].axvline(self.df_all[model].median(), color='green', linestyle='--', \n",
    "                          linewidth=2, label=f'Mediana: {self.df_all[model].median():.4f}')\n",
    "        axes[0, 0].set_xlabel('ECRPS')\n",
    "        axes[0, 0].set_ylabel('Frecuencia')\n",
    "        axes[0, 0].set_title(f'Distribución de ECRPS - {model}')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Boxplot por escenario\n",
    "        data_by_scenario = [self.df_all[self.df_all['Escenario'] == esc][model] \n",
    "                           for esc in ['Estacionario_Lineal', 'No_Estacionario_Lineal', 'No_Lineal']]\n",
    "        bp = axes[0, 1].boxplot(data_by_scenario, labels=['Est. Lin.', 'No Est. Lin.', 'No Lin.'], \n",
    "                               patch_artist=True)\n",
    "        for patch, color in zip(bp['boxes'], ['lightblue', 'lightcoral', 'lightgreen']):\n",
    "            patch.set_facecolor(color)\n",
    "        axes[0, 1].set_ylabel('ECRPS')\n",
    "        axes[0, 1].set_title(f'ECRPS por Escenario - {model}')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Rendimiento por paso\n",
    "        paso_data = []\n",
    "        for p in sorted(self.df_all['Paso'].unique()):\n",
    "            subset = self.df_all[self.df_all['Paso'] == p]\n",
    "            if len(subset) > 0:\n",
    "                paso_data.append((p, subset[model].mean()))\n",
    "        \n",
    "        if paso_data:\n",
    "            pasos, means = zip(*paso_data)\n",
    "            axes[1, 0].plot(pasos, means, marker='o', linewidth=2, markersize=8, color='darkblue')\n",
    "            axes[1, 0].set_xlabel('Paso de Predicción')\n",
    "            axes[1, 0].set_ylabel('ECRPS Promedio')\n",
    "            axes[1, 0].set_title(f'Rendimiento por Horizonte - {model}')\n",
    "            axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Heatmap: Distribución × Varianza\n",
    "        pivot_data = []\n",
    "        dist_labels = []\n",
    "        var_labels = sorted(self.df_all['Varianza'].unique())\n",
    "        \n",
    "        for dist in self.df_all['Distribución'].unique():\n",
    "            row = []\n",
    "            for var in var_labels:\n",
    "                subset = self.df_all[(self.df_all['Distribución'] == dist) & \n",
    "                                    (self.df_all['Varianza'] == var)]\n",
    "                if len(subset) > 0:\n",
    "                    row.append(subset[model].mean())\n",
    "                else:\n",
    "                    row.append(np.nan)\n",
    "            if not all(np.isnan(row)):\n",
    "                pivot_data.append(row)\n",
    "                dist_labels.append(dist)\n",
    "        \n",
    "        if pivot_data:\n",
    "            pivot_df = pd.DataFrame(pivot_data, index=dist_labels, columns=var_labels)\n",
    "            \n",
    "            sns.heatmap(pivot_df, annot=True, fmt='.4f', cmap='RdYlGn_r', ax=axes[1, 1],\n",
    "                       cbar_kws={'label': 'ECRPS'})\n",
    "            axes[1, 1].set_title(f'ECRPS: Distribución × Varianza - {model}')\n",
    "            axes[1, 1].set_xlabel('Varianza')\n",
    "            axes[1, 1].set_ylabel('Distribución')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{model_dir}/visualizaciones_{model.replace(\" \", \"_\")}.png', \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # 2. Comparación con otros modelos\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        \n",
    "        means = self.df_all[self.models].mean().sort_values()\n",
    "        colors = ['red' if m == model else 'steelblue' for m in means.index]\n",
    "        bars = ax.barh(means.index, means.values, color=colors, alpha=0.7)\n",
    "        \n",
    "        # Destacar el modelo actual\n",
    "        for i, bar in enumerate(bars):\n",
    "            if means.index[i] == model:\n",
    "                bar.set_edgecolor('black')\n",
    "                bar.set_linewidth(3)\n",
    "        \n",
    "        ax.set_xlabel('ECRPS Promedio')\n",
    "        ax.set_title(f'Comparación Global - {model} (Destacado en Rojo)')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{model_dir}/comparacion_{model.replace(\" \", \"_\")}.png', \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    def generate_recommendations(self, output_dir):\n",
    "        \"\"\"\n",
    "        8. GENERACIÓN DE RECOMENDACIONES\n",
    "        \"\"\"\n",
    "        print(\"  - Generando recomendaciones estratégicas...\")\n",
    "        \n",
    "        recommendations = []\n",
    "        recommendations.append(\"=\"*80)\n",
    "        recommendations.append(\"RECOMENDACIONES Y CONCLUSIONES\")\n",
    "        recommendations.append(\"=\"*80)\n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # 1. Modelo campeón general\n",
    "        overall_best = self.df_all[self.models].mean().idxmin()\n",
    "        overall_worst = self.df_all[self.models].mean().idxmax()\n",
    "        \n",
    "        recommendations.append(\"1. MODELO CAMPEÓN GENERAL\")\n",
    "        recommendations.append(\"-\" * 40)\n",
    "        recommendations.append(f\"Mejor rendimiento promedio: {overall_best}\")\n",
    "        recommendations.append(f\"ECRPS: {self.df_all[overall_best].mean():.6f}\")\n",
    "        recommendations.append(f\"Desviación Estándar: {self.df_all[overall_best].std():.6f}\")\n",
    "        recommendations.append(\"\")\n",
    "        recommendations.append(f\"Peor rendimiento promedio: {overall_worst}\")\n",
    "        recommendations.append(f\"ECRPS: {self.df_all[overall_worst].mean():.6f}\")\n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # 2. Modelos por escenario\n",
    "        recommendations.append(\"2. RECOMENDACIONES POR ESCENARIO\")\n",
    "        recommendations.append(\"-\" * 40)\n",
    "        \n",
    "        for escenario in ['Estacionario_Lineal', 'No_Estacionario_Lineal', 'No_Lineal']:\n",
    "            subset = self.df_all[self.df_all['Escenario'] == escenario]\n",
    "            if len(subset) > 0:\n",
    "                best_model = subset[self.models].mean().idxmin()\n",
    "                best_score = subset[best_model].mean()\n",
    "                \n",
    "                recommendations.append(f\"\\n{escenario}:\")\n",
    "                recommendations.append(f\"  Modelo Recomendado: {best_model}\")\n",
    "                recommendations.append(f\"  ECRPS Promedio: {best_score:.6f}\")\n",
    "        \n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # 3. Modelos por distribución\n",
    "        recommendations.append(\"3. RECOMENDACIONES POR DISTRIBUCIÓN DE ERRORES\")\n",
    "        recommendations.append(\"-\" * 40)\n",
    "        \n",
    "        for dist in self.df_all['Distribución'].unique():\n",
    "            subset = self.df_all[self.df_all['Distribución'] == dist]\n",
    "            if len(subset) > 0:\n",
    "                best_model = subset[self.models].mean().idxmin()\n",
    "                best_score = subset[best_model].mean()\n",
    "                \n",
    "                recommendations.append(f\"\\nDistribución {dist}:\")\n",
    "                recommendations.append(f\"  Modelo Recomendado: {best_model}\")\n",
    "                recommendations.append(f\"  ECRPS Promedio: {best_score:.6f}\")\n",
    "        \n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # 4. Modelos más robustos\n",
    "        recommendations.append(\"4. MODELOS MÁS ROBUSTOS (MENOR VARIABILIDAD)\")\n",
    "        recommendations.append(\"-\" * 40)\n",
    "        \n",
    "        cv_scores = {model: self.df_all[model].std() / self.df_all[model].mean() \n",
    "                    for model in self.models if self.df_all[model].mean() != 0}\n",
    "        cv_sorted = sorted(cv_scores.items(), key=lambda x: x[1])\n",
    "        \n",
    "        for i, (model, cv) in enumerate(cv_sorted[:3], 1):\n",
    "            recommendations.append(f\"{i}. {model}: CV = {cv:.4f}\")\n",
    "        \n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # 5. Modelos por horizonte\n",
    "        recommendations.append(\"5. RECOMENDACIONES POR HORIZONTE DE PREDICCIÓN\")\n",
    "        recommendations.append(\"-\" * 40)\n",
    "        \n",
    "        pasos_unicos = sorted(self.df_all['Paso'].unique())\n",
    "        for paso in [pasos_unicos[0], pasos_unicos[len(pasos_unicos)//2], pasos_unicos[-1]]:\n",
    "            subset = self.df_all[self.df_all['Paso'] == paso]\n",
    "            if len(subset) > 0:\n",
    "                best_model = subset[self.models].mean().idxmin()\n",
    "                best_score = subset[best_model].mean()\n",
    "                \n",
    "                recommendations.append(f\"\\nPaso {paso}:\")\n",
    "                recommendations.append(f\"  Modelo Recomendado: {best_model}\")\n",
    "                recommendations.append(f\"  ECRPS Promedio: {best_score:.6f}\")\n",
    "        \n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # 6. Estrategia de ensamble\n",
    "        recommendations.append(\"6. ESTRATEGIA DE ENSAMBLE SUGERIDA\")\n",
    "        recommendations.append(\"-\" * 40)\n",
    "        \n",
    "        # Top 3 modelos complementarios\n",
    "        top3 = self.df_all[self.models].mean().nsmallest(3)\n",
    "        recommendations.append(\"Combinar los siguientes modelos:\")\n",
    "        for i, (model, score) in enumerate(top3.items(), 1):\n",
    "            recommendations.append(f\"{i}. {model} (ECRPS: {score:.6f})\")\n",
    "        \n",
    "        recommendations.append(\"\")\n",
    "        recommendations.append(\"Justificación:\")\n",
    "        recommendations.append(\"  - Estos modelos muestran el mejor rendimiento promedio\")\n",
    "        recommendations.append(\"  - Un ensamble puede capturar fortalezas complementarias\")\n",
    "        recommendations.append(\"  - Reduce el riesgo de seleccionar un modelo subóptimo\")\n",
    "        \n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # 7. Modelos con dominancia estadística\n",
    "        recommendations.append(\"7. MODELOS CON DOMINANCIA ESTADÍSTICA\")\n",
    "        recommendations.append(\"-\" * 40)\n",
    "        \n",
    "        dominance_scores = []\n",
    "        for model in self.models:\n",
    "            wins = 0\n",
    "            for other_model in self.models:\n",
    "                if model != other_model:\n",
    "                    errors1 = self.df_all[model].values\n",
    "                    errors2 = self.df_all[other_model].values\n",
    "                    _, p_val = DieboldMarianoTest.dm_test(errors1, errors2, h=1, crit=\"MSE\")\n",
    "                    mean_diff = self.df_all[model].mean() - self.df_all[other_model].mean()\n",
    "                    \n",
    "                    if p_val < 0.05 and mean_diff < 0:\n",
    "                        wins += 1\n",
    "            \n",
    "            dominance_scores.append((model, wins))\n",
    "        \n",
    "        dominance_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        recommendations.append(\"Modelos estadísticamente superiores (test Diebold-Mariano):\")\n",
    "        for i, (model, wins) in enumerate(dominance_scores[:5], 1):\n",
    "            recommendations.append(f\"{i}. {model}: {wins} victorias significativas\")\n",
    "        \n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # 8. Reglas de decisión\n",
    "        recommendations.append(\"8. REGLAS DE DECISIÓN SUGERIDAS\")\n",
    "        recommendations.append(\"-\" * 40)\n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # Reglas por escenario\n",
    "        for escenario in ['Estacionario_Lineal', 'No_Estacionario_Lineal', 'No_Lineal']:\n",
    "            subset = self.df_all[self.df_all['Escenario'] == escenario]\n",
    "            if len(subset) > 0:\n",
    "                top2 = subset[self.models].mean().nsmallest(2)\n",
    "                \n",
    "                if escenario == 'Estacionario_Lineal':\n",
    "                    recommendations.append(\"SI el proceso es ESTACIONARIO y LINEAL:\")\n",
    "                elif escenario == 'No_Estacionario_Lineal':\n",
    "                    recommendations.append(\"SI el proceso es NO ESTACIONARIO y LINEAL:\")\n",
    "                else:\n",
    "                    recommendations.append(\"SI el proceso es NO LINEAL:\")\n",
    "                \n",
    "                recommendations.append(f\"  → Primera opción: {top2.index[0]}\")\n",
    "                recommendations.append(f\"  → Segunda opción: {top2.index[1]}\")\n",
    "                recommendations.append(\"\")\n",
    "        \n",
    "        # Reglas por distribución\n",
    "        recommendations.append(\"SI la distribución de errores:\")\n",
    "        for dist in self.df_all['Distribución'].unique():\n",
    "            subset = self.df_all[self.df_all['Distribución'] == dist]\n",
    "            if len(subset) > 0:\n",
    "                best = subset[self.models].mean().idxmin()\n",
    "                recommendations.append(f\"  • Es {dist} → Usar {best}\")\n",
    "        \n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # Reglas por varianza\n",
    "        recommendations.append(\"SI el nivel de varianza:\")\n",
    "        variances = sorted(self.df_all['Varianza'].unique())\n",
    "        if len(variances) >= 2:\n",
    "            low_var = variances[0]\n",
    "            high_var = variances[-1]\n",
    "            \n",
    "            subset_low = self.df_all[self.df_all['Varianza'] == low_var]\n",
    "            subset_high = self.df_all[self.df_all['Varianza'] == high_var]\n",
    "            \n",
    "            best_low = subset_low[self.models].mean().idxmin()\n",
    "            best_high = subset_high[self.models].mean().idxmin()\n",
    "            \n",
    "            recommendations.append(f\"  • Es bajo ({low_var}) → Usar {best_low}\")\n",
    "            recommendations.append(f\"  • Es alto ({high_var}) → Usar {best_high}\")\n",
    "        \n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # 9. Conclusiones finales\n",
    "        recommendations.append(\"9. CONCLUSIONES PRINCIPALES\")\n",
    "        recommendations.append(\"-\" * 40)\n",
    "        recommendations.append(\"\")\n",
    "        recommendations.append(f\"• El modelo {overall_best} muestra el mejor rendimiento general\")\n",
    "        recommendations.append(f\"  con ECRPS promedio de {self.df_all[overall_best].mean():.6f}\")\n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # Análisis de robustez\n",
    "        most_robust = min(cv_scores.items(), key=lambda x: x[1])[0]\n",
    "        recommendations.append(f\"• El modelo más robusto (menor CV) es {most_robust}\")\n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # Comparación estacionario vs no estacionario\n",
    "        est_best = self.df_estacionario[self.models].mean().idxmin()\n",
    "        no_est_best = self.df_no_estacionario[self.models].mean().idxmin()\n",
    "        \n",
    "        if est_best == no_est_best:\n",
    "            recommendations.append(f\"• {est_best} es consistentemente superior en procesos\")\n",
    "            recommendations.append(\"  estacionarios y no estacionarios\")\n",
    "        else:\n",
    "            recommendations.append(f\"• Para procesos estacionarios: preferir {est_best}\")\n",
    "            recommendations.append(f\"• Para procesos no estacionarios: preferir {no_est_best}\")\n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # Análisis de no linealidad\n",
    "        nl_best = self.df_no_lineal[self.models].mean().idxmin()\n",
    "        recommendations.append(f\"• Para procesos no lineales: {nl_best} es la mejor opción\")\n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # Recomendación de ensamble\n",
    "        recommendations.append(\"• Se recomienda implementar un ENSAMBLE de los top 3 modelos\")\n",
    "        recommendations.append(\"  para maximizar robustez y rendimiento\")\n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # Consideraciones prácticas\n",
    "        recommendations.append(\"10. CONSIDERACIONES PRÁCTICAS\")\n",
    "        recommendations.append(\"-\" * 40)\n",
    "        recommendations.append(\"\")\n",
    "        recommendations.append(\"Factores a considerar en la selección:\")\n",
    "        recommendations.append(\"  1. Costo computacional vs ganancia en precisión\")\n",
    "        recommendations.append(\"  2. Robustez ante cambios en la distribución de errores\")\n",
    "        recommendations.append(\"  3. Consistencia a través de horizontes de predicción\")\n",
    "        recommendations.append(\"  4. Facilidad de interpretación y explicabilidad\")\n",
    "        recommendations.append(\"  5. Disponibilidad de recursos para implementación\")\n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # Trade-offs identificados\n",
    "        recommendations.append(\"Trade-offs identificados:\")\n",
    "        \n",
    "        # Mejor vs más robusto\n",
    "        if overall_best != most_robust:\n",
    "            recommendations.append(f\"  • Rendimiento vs Robustez: {overall_best} (mejor) vs {most_robust} (más robusto)\")\n",
    "        \n",
    "        # Modelos especializados\n",
    "        recommendations.append(\"  • Algunos modelos son especialistas en escenarios específicos\")\n",
    "        recommendations.append(\"  • Otros modelos son generalistas con buen rendimiento global\")\n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # Guardar recomendaciones\n",
    "        with open(f'{output_dir}/8_recomendaciones.txt', 'w', encoding='utf-8') as f:\n",
    "            f.write('\\n'.join(recommendations))\n",
    "        \n",
    "        print('\\n'.join(recommendations))\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CÓDIGO DE EJECUCIÓN PRINCIPAL\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Función principal para ejecutar el análisis completo\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ANÁLISIS COMPREHENSIVO DE MODELOS DE PREDICCIÓN PROBABILÍSTICA\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # Crear analizador\n",
    "    try:\n",
    "        analyzer = ModelPerformanceAnalyzer()\n",
    "    except FileNotFoundError:\n",
    "        print(\"\\nERROR: No se encontraron los archivos de datos\")\n",
    "        print(\"Verifica que existan los siguientes archivos:\")\n",
    "        print(\"  - ./Datos/estacionario.xlsx\")\n",
    "        print(\"  - ./Datos/no_estacionario.xlsx\")\n",
    "        print(\"  - ./Datos/no_lineal.xlsx\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"\\nERROR al cargar datos: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return\n",
    "    \n",
    "    # Ejecutar análisis completo\n",
    "    output_directory = 'resultados_analisis_completo'\n",
    "    \n",
    "    try:\n",
    "        analyzer.generate_full_report(output_dir=output_directory)\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"✓ Análisis completado exitosamente\")\n",
    "        print(f\"✓ Todos los resultados guardados en: {output_directory}/\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        print(\"Archivos generados:\")\n",
    "        print(\"  📊 Análisis de características del DGP\")\n",
    "        print(\"  📈 Efectos de distribución y varianza\")\n",
    "        print(\"  🎯 Análisis de horizonte de predicción\")\n",
    "        print(\"  🔄 Interacciones complejas\")\n",
    "        print(\"  💪 Métricas de robustez\")\n",
    "        print(\"  📉 Tests de Diebold-Mariano\")\n",
    "        print(\"  👤 Perfiles individuales por modelo\")\n",
    "        print(\"  💡 Recomendaciones estratégicas\")\n",
    "        print(\"\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ ERROR durante el análisis: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee1784b",
   "metadata": {},
   "source": [
    "# Pre analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f559ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos encontrados en 'Tipo de Modelo':\n",
      "['AR(1)' 'AR(2)' 'MA(1)' 'MA(2)' 'ARMA(1,1)' 'ARMA(2,2)']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paso</th>\n",
       "      <th>Tipo de Modelo</th>\n",
       "      <th>Distribución</th>\n",
       "      <th>Varianza error</th>\n",
       "      <th>AREPD</th>\n",
       "      <th>AV-MCPS</th>\n",
       "      <th>Block Bootstrapping</th>\n",
       "      <th>DeepAR</th>\n",
       "      <th>EnCQR-LSTM</th>\n",
       "      <th>LSPM</th>\n",
       "      <th>LSPMW</th>\n",
       "      <th>MCPS</th>\n",
       "      <th>Sieve Bootstrap</th>\n",
       "      <th>Mejor Modelo</th>\n",
       "      <th>Escenario</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AR(1)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.294667</td>\n",
       "      <td>0.355344</td>\n",
       "      <td>0.248447</td>\n",
       "      <td>0.263419</td>\n",
       "      <td>0.306622</td>\n",
       "      <td>0.440706</td>\n",
       "      <td>0.431452</td>\n",
       "      <td>0.285427</td>\n",
       "      <td>0.248691</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AR(1)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.604540</td>\n",
       "      <td>0.307449</td>\n",
       "      <td>0.254264</td>\n",
       "      <td>0.273001</td>\n",
       "      <td>0.565522</td>\n",
       "      <td>0.470424</td>\n",
       "      <td>0.474111</td>\n",
       "      <td>0.285430</td>\n",
       "      <td>0.254193</td>\n",
       "      <td>Sieve Bootstrap</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>AR(1)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.273622</td>\n",
       "      <td>0.276230</td>\n",
       "      <td>0.258388</td>\n",
       "      <td>0.315765</td>\n",
       "      <td>0.269452</td>\n",
       "      <td>0.520070</td>\n",
       "      <td>0.517876</td>\n",
       "      <td>0.337990</td>\n",
       "      <td>0.258039</td>\n",
       "      <td>Sieve Bootstrap</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>AR(1)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.261423</td>\n",
       "      <td>0.279697</td>\n",
       "      <td>0.254453</td>\n",
       "      <td>0.289443</td>\n",
       "      <td>0.269285</td>\n",
       "      <td>0.287989</td>\n",
       "      <td>0.288111</td>\n",
       "      <td>0.282999</td>\n",
       "      <td>0.254655</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>AR(1)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.626252</td>\n",
       "      <td>0.273680</td>\n",
       "      <td>0.254842</td>\n",
       "      <td>0.272827</td>\n",
       "      <td>0.639437</td>\n",
       "      <td>0.763960</td>\n",
       "      <td>0.753066</td>\n",
       "      <td>0.308347</td>\n",
       "      <td>0.254952</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>1</td>\n",
       "      <td>ARMA(2,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.082513</td>\n",
       "      <td>0.999066</td>\n",
       "      <td>0.953857</td>\n",
       "      <td>1.116455</td>\n",
       "      <td>1.053269</td>\n",
       "      <td>2.030504</td>\n",
       "      <td>2.165650</td>\n",
       "      <td>0.990087</td>\n",
       "      <td>0.954156</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>2</td>\n",
       "      <td>ARMA(2,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.903173</td>\n",
       "      <td>0.971148</td>\n",
       "      <td>0.954440</td>\n",
       "      <td>1.005615</td>\n",
       "      <td>1.518301</td>\n",
       "      <td>1.431610</td>\n",
       "      <td>1.522051</td>\n",
       "      <td>1.141614</td>\n",
       "      <td>0.954065</td>\n",
       "      <td>Sieve Bootstrap</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>3</td>\n",
       "      <td>ARMA(2,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.310542</td>\n",
       "      <td>1.021845</td>\n",
       "      <td>0.976235</td>\n",
       "      <td>1.002865</td>\n",
       "      <td>1.615073</td>\n",
       "      <td>1.026140</td>\n",
       "      <td>1.036051</td>\n",
       "      <td>1.484601</td>\n",
       "      <td>0.962417</td>\n",
       "      <td>Sieve Bootstrap</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>4</td>\n",
       "      <td>ARMA(2,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.324103</td>\n",
       "      <td>0.968827</td>\n",
       "      <td>0.961514</td>\n",
       "      <td>0.977739</td>\n",
       "      <td>1.072897</td>\n",
       "      <td>1.453428</td>\n",
       "      <td>1.530595</td>\n",
       "      <td>1.125230</td>\n",
       "      <td>0.960919</td>\n",
       "      <td>Sieve Bootstrap</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>5</td>\n",
       "      <td>ARMA(2,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.522689</td>\n",
       "      <td>1.011090</td>\n",
       "      <td>0.960863</td>\n",
       "      <td>1.001003</td>\n",
       "      <td>1.123328</td>\n",
       "      <td>1.061991</td>\n",
       "      <td>1.038016</td>\n",
       "      <td>1.179879</td>\n",
       "      <td>0.962942</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Paso Tipo de Modelo Distribución  Varianza error     AREPD   AV-MCPS  \\\n",
       "0       1          AR(1)       normal             0.2  0.294667  0.355344   \n",
       "2       2          AR(1)       normal             0.2  0.604540  0.307449   \n",
       "4       3          AR(1)       normal             0.2  0.273622  0.276230   \n",
       "6       4          AR(1)       normal             0.2  0.261423  0.279697   \n",
       "8       5          AR(1)       normal             0.2  0.626252  0.273680   \n",
       "...   ...            ...          ...             ...       ...       ...   \n",
       "1309    1      ARMA(2,2)      mixture             3.0  1.082513  0.999066   \n",
       "1311    2      ARMA(2,2)      mixture             3.0  1.903173  0.971148   \n",
       "1313    3      ARMA(2,2)      mixture             3.0  2.310542  1.021845   \n",
       "1315    4      ARMA(2,2)      mixture             3.0  1.324103  0.968827   \n",
       "1317    5      ARMA(2,2)      mixture             3.0  1.522689  1.011090   \n",
       "\n",
       "      Block Bootstrapping    DeepAR  EnCQR-LSTM      LSPM     LSPMW      MCPS  \\\n",
       "0                0.248447  0.263419    0.306622  0.440706  0.431452  0.285427   \n",
       "2                0.254264  0.273001    0.565522  0.470424  0.474111  0.285430   \n",
       "4                0.258388  0.315765    0.269452  0.520070  0.517876  0.337990   \n",
       "6                0.254453  0.289443    0.269285  0.287989  0.288111  0.282999   \n",
       "8                0.254842  0.272827    0.639437  0.763960  0.753066  0.308347   \n",
       "...                   ...       ...         ...       ...       ...       ...   \n",
       "1309             0.953857  1.116455    1.053269  2.030504  2.165650  0.990087   \n",
       "1311             0.954440  1.005615    1.518301  1.431610  1.522051  1.141614   \n",
       "1313             0.976235  1.002865    1.615073  1.026140  1.036051  1.484601   \n",
       "1315             0.961514  0.977739    1.072897  1.453428  1.530595  1.125230   \n",
       "1317             0.960863  1.001003    1.123328  1.061991  1.038016  1.179879   \n",
       "\n",
       "      Sieve Bootstrap         Mejor Modelo            Escenario  \n",
       "0            0.248691  Block Bootstrapping  Estacionario_Lineal  \n",
       "2            0.254193      Sieve Bootstrap  Estacionario_Lineal  \n",
       "4            0.258039      Sieve Bootstrap  Estacionario_Lineal  \n",
       "6            0.254655  Block Bootstrapping  Estacionario_Lineal  \n",
       "8            0.254952  Block Bootstrapping  Estacionario_Lineal  \n",
       "...               ...                  ...                  ...  \n",
       "1309         0.954156  Block Bootstrapping  Estacionario_Lineal  \n",
       "1311         0.954065      Sieve Bootstrap  Estacionario_Lineal  \n",
       "1313         0.962417      Sieve Bootstrap  Estacionario_Lineal  \n",
       "1315         0.960919      Sieve Bootstrap  Estacionario_Lineal  \n",
       "1317         0.962942  Block Bootstrapping  Estacionario_Lineal  \n",
       "\n",
       "[600 rows x 15 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "    \n",
    "estacionario = pd.read_excel(\"./Datos/estacionario.xlsx\")\n",
    "\n",
    "estacionario = estacionario.drop_duplicates()\n",
    "estacionario = estacionario[estacionario[\"Paso\"] != \"Promedio\"]\n",
    "\n",
    "def determinar_tipo_modelo_mejorado(row):\n",
    "    \"\"\"\n",
    "    Determina el tipo de modelo (AR, MA, ARMA) y su orden a partir de los valores\n",
    "    en las columnas 'Valores de AR' y 'Valores MA'.\n",
    "    \"\"\"\n",
    "    ar_str = str(row['Valores de AR'])\n",
    "    ma_str = str(row['Valores MA'])\n",
    "    \n",
    "    # Expresión regular para encontrar números (enteros o decimales, positivos o negativos)\n",
    "    regex_numeros = r'-?\\d+\\.?\\d*'\n",
    "    \n",
    "    # Cuenta cuántos números válidos hay en cada string\n",
    "    p = len(re.findall(regex_numeros, ar_str))\n",
    "    q = len(re.findall(regex_numeros, ma_str))\n",
    "    \n",
    "    if p > 0 and q == 0:\n",
    "        return f\"AR({p})\"\n",
    "    elif p == 0 and q > 0:\n",
    "        return f\"MA({q})\"\n",
    "    elif p > 0 and q > 0:\n",
    "        return f\"ARMA({p},{q})\"\n",
    "    else:\n",
    "        return None # O \"Ruido Blanco\" si p=0 y q=0\n",
    "\n",
    "# Aplica la función mejorada para crear la columna \"Tipo de Modelo\"\n",
    "estacionario['Tipo de Modelo'] = estacionario.apply(determinar_tipo_modelo_mejorado, axis=1)\n",
    "\n",
    "# Imprime los valores únicos de la columna Tipo de modelo para verificar\n",
    "print(\"Valores únicos encontrados en 'Tipo de Modelo':\")\n",
    "print(estacionario['Tipo de Modelo'].unique())\n",
    "\n",
    "# Ordena las columnas 'Paso' y 'Tipo de modelo' al inicio\n",
    "cols = estacionario.columns.tolist()\n",
    "# Aseguramos que las columnas existan antes de moverlas\n",
    "if 'Paso' in cols:\n",
    "    cols.insert(0, cols.pop(cols.index('Paso')))\n",
    "if 'Tipo de Modelo' in cols:\n",
    "    cols.insert(1, cols.pop(cols.index('Tipo de Modelo')))\n",
    "\n",
    "estacionario = estacionario.reindex(columns=cols)\n",
    "\n",
    "\n",
    "# Borra las columnas originales 'Valores de AR' y 'Valores MA'\n",
    "estacionario = estacionario.drop(columns=['Valores de AR', 'Valores MA'])\n",
    "estacionario[\"Escenario\"] = \"Estacionario_Lineal\"\n",
    "\n",
    "# Muestra el DataFrame resultante\n",
    "estacionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba423eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paso</th>\n",
       "      <th>Tipo de Modelo</th>\n",
       "      <th>Distribución</th>\n",
       "      <th>Varianza error</th>\n",
       "      <th>AREPD</th>\n",
       "      <th>AV-MCPS</th>\n",
       "      <th>Block Bootstrapping</th>\n",
       "      <th>DeepAR</th>\n",
       "      <th>EnCQR-LSTM</th>\n",
       "      <th>LSPM</th>\n",
       "      <th>LSPMW</th>\n",
       "      <th>MCPS</th>\n",
       "      <th>Sieve Bootstrap</th>\n",
       "      <th>Mejor Modelo</th>\n",
       "      <th>Escenario</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ARIMA(0,1,0)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.860823</td>\n",
       "      <td>0.258474</td>\n",
       "      <td>0.253635</td>\n",
       "      <td>0.319481</td>\n",
       "      <td>0.488711</td>\n",
       "      <td>0.367279</td>\n",
       "      <td>0.360494</td>\n",
       "      <td>0.270816</td>\n",
       "      <td>0.273828</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ARIMA(0,1,0)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.244128</td>\n",
       "      <td>0.528968</td>\n",
       "      <td>0.275061</td>\n",
       "      <td>0.438099</td>\n",
       "      <td>0.322919</td>\n",
       "      <td>0.426187</td>\n",
       "      <td>0.430296</td>\n",
       "      <td>0.576792</td>\n",
       "      <td>0.272952</td>\n",
       "      <td>Sieve Bootstrap</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ARIMA(0,1,0)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.799818</td>\n",
       "      <td>0.864295</td>\n",
       "      <td>0.272406</td>\n",
       "      <td>0.291500</td>\n",
       "      <td>0.396481</td>\n",
       "      <td>0.642530</td>\n",
       "      <td>0.639134</td>\n",
       "      <td>0.269655</td>\n",
       "      <td>0.275661</td>\n",
       "      <td>MCPS</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ARIMA(0,1,0)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.912421</td>\n",
       "      <td>0.481159</td>\n",
       "      <td>0.255186</td>\n",
       "      <td>0.291577</td>\n",
       "      <td>0.495882</td>\n",
       "      <td>0.341570</td>\n",
       "      <td>0.341227</td>\n",
       "      <td>0.533788</td>\n",
       "      <td>0.275948</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ARIMA(0,1,0)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.822771</td>\n",
       "      <td>0.792130</td>\n",
       "      <td>0.257461</td>\n",
       "      <td>0.658698</td>\n",
       "      <td>1.291283</td>\n",
       "      <td>0.981902</td>\n",
       "      <td>0.969842</td>\n",
       "      <td>1.455485</td>\n",
       "      <td>0.338116</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>1</td>\n",
       "      <td>ARIMA(2,1,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>76.766114</td>\n",
       "      <td>5.668568</td>\n",
       "      <td>0.965836</td>\n",
       "      <td>7.254422</td>\n",
       "      <td>13.176312</td>\n",
       "      <td>4.421885</td>\n",
       "      <td>4.173484</td>\n",
       "      <td>20.231134</td>\n",
       "      <td>2.612414</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>2</td>\n",
       "      <td>ARIMA(2,1,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>80.630681</td>\n",
       "      <td>6.161741</td>\n",
       "      <td>0.974398</td>\n",
       "      <td>8.767931</td>\n",
       "      <td>9.287902</td>\n",
       "      <td>1.733689</td>\n",
       "      <td>1.596168</td>\n",
       "      <td>21.251698</td>\n",
       "      <td>1.956761</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>3</td>\n",
       "      <td>ARIMA(2,1,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>86.539087</td>\n",
       "      <td>10.452450</td>\n",
       "      <td>0.982561</td>\n",
       "      <td>24.631292</td>\n",
       "      <td>18.639842</td>\n",
       "      <td>6.195609</td>\n",
       "      <td>5.953120</td>\n",
       "      <td>23.480752</td>\n",
       "      <td>3.623684</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>4</td>\n",
       "      <td>ARIMA(2,1,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>93.057798</td>\n",
       "      <td>13.911382</td>\n",
       "      <td>0.958507</td>\n",
       "      <td>27.567728</td>\n",
       "      <td>17.852720</td>\n",
       "      <td>7.288522</td>\n",
       "      <td>6.952830</td>\n",
       "      <td>28.286507</td>\n",
       "      <td>4.681807</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>5</td>\n",
       "      <td>ARIMA(2,1,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>99.120410</td>\n",
       "      <td>13.899543</td>\n",
       "      <td>0.955009</td>\n",
       "      <td>17.064311</td>\n",
       "      <td>8.945594</td>\n",
       "      <td>4.716275</td>\n",
       "      <td>4.320090</td>\n",
       "      <td>31.056370</td>\n",
       "      <td>4.177879</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Paso Tipo de Modelo Distribución  Varianza error      AREPD    AV-MCPS  \\\n",
       "0      1   ARIMA(0,1,0)       normal             0.2   1.860823   0.258474   \n",
       "1      2   ARIMA(0,1,0)       normal             0.2   1.244128   0.528968   \n",
       "2      3   ARIMA(0,1,0)       normal             0.2   1.799818   0.864295   \n",
       "3      4   ARIMA(0,1,0)       normal             0.2   1.912421   0.481159   \n",
       "4      5   ARIMA(0,1,0)       normal             0.2   2.822771   0.792130   \n",
       "..   ...            ...          ...             ...        ...        ...   \n",
       "834    1   ARIMA(2,1,2)      mixture             3.0  76.766114   5.668568   \n",
       "835    2   ARIMA(2,1,2)      mixture             3.0  80.630681   6.161741   \n",
       "836    3   ARIMA(2,1,2)      mixture             3.0  86.539087  10.452450   \n",
       "837    4   ARIMA(2,1,2)      mixture             3.0  93.057798  13.911382   \n",
       "838    5   ARIMA(2,1,2)      mixture             3.0  99.120410  13.899543   \n",
       "\n",
       "     Block Bootstrapping     DeepAR  EnCQR-LSTM      LSPM     LSPMW  \\\n",
       "0               0.253635   0.319481    0.488711  0.367279  0.360494   \n",
       "1               0.275061   0.438099    0.322919  0.426187  0.430296   \n",
       "2               0.272406   0.291500    0.396481  0.642530  0.639134   \n",
       "3               0.255186   0.291577    0.495882  0.341570  0.341227   \n",
       "4               0.257461   0.658698    1.291283  0.981902  0.969842   \n",
       "..                   ...        ...         ...       ...       ...   \n",
       "834             0.965836   7.254422   13.176312  4.421885  4.173484   \n",
       "835             0.974398   8.767931    9.287902  1.733689  1.596168   \n",
       "836             0.982561  24.631292   18.639842  6.195609  5.953120   \n",
       "837             0.958507  27.567728   17.852720  7.288522  6.952830   \n",
       "838             0.955009  17.064311    8.945594  4.716275  4.320090   \n",
       "\n",
       "          MCPS  Sieve Bootstrap         Mejor Modelo               Escenario  \n",
       "0     0.270816         0.273828  Block Bootstrapping  No_Estacionario_Lineal  \n",
       "1     0.576792         0.272952      Sieve Bootstrap  No_Estacionario_Lineal  \n",
       "2     0.269655         0.275661                 MCPS  No_Estacionario_Lineal  \n",
       "3     0.533788         0.275948  Block Bootstrapping  No_Estacionario_Lineal  \n",
       "4     1.455485         0.338116  Block Bootstrapping  No_Estacionario_Lineal  \n",
       "..         ...              ...                  ...                     ...  \n",
       "834  20.231134         2.612414  Block Bootstrapping  No_Estacionario_Lineal  \n",
       "835  21.251698         1.956761  Block Bootstrapping  No_Estacionario_Lineal  \n",
       "836  23.480752         3.623684  Block Bootstrapping  No_Estacionario_Lineal  \n",
       "837  28.286507         4.681807  Block Bootstrapping  No_Estacionario_Lineal  \n",
       "838  31.056370         4.177879  Block Bootstrapping  No_Estacionario_Lineal  \n",
       "\n",
       "[700 rows x 15 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_estacionario = pd.read_excel(\"./Datos/no_estacionario.xlsx\")\n",
    "no_estacionario.drop(columns=['Valores de AR', 'Valores MA'], inplace=True)\n",
    "no_estacionario[\"Escenario\"] = \"No_Estacionario_Lineal\"\n",
    "no_estacionario = no_estacionario[no_estacionario[\"Paso\"] != \"Promedio\"]\n",
    "no_estacionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e7ce88d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paso</th>\n",
       "      <th>Tipo de Modelo</th>\n",
       "      <th>Distribución</th>\n",
       "      <th>Varianza error</th>\n",
       "      <th>AREPD</th>\n",
       "      <th>AV-MCPS</th>\n",
       "      <th>Block Bootstrapping</th>\n",
       "      <th>DeepAR</th>\n",
       "      <th>EnCQR-LSTM</th>\n",
       "      <th>LSPM</th>\n",
       "      <th>LSPMW</th>\n",
       "      <th>MCPS</th>\n",
       "      <th>Sieve Bootstrap</th>\n",
       "      <th>Mejor Modelo</th>\n",
       "      <th>Escenario</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>SETAR(2,1)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.257043</td>\n",
       "      <td>0.253521</td>\n",
       "      <td>0.251524</td>\n",
       "      <td>0.263274</td>\n",
       "      <td>0.257984</td>\n",
       "      <td>0.285655</td>\n",
       "      <td>0.282110</td>\n",
       "      <td>0.257015</td>\n",
       "      <td>0.251188</td>\n",
       "      <td>Sieve Bootstrap</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>SETAR(2,1)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.305723</td>\n",
       "      <td>0.383340</td>\n",
       "      <td>0.288529</td>\n",
       "      <td>0.297164</td>\n",
       "      <td>0.324101</td>\n",
       "      <td>0.316846</td>\n",
       "      <td>0.319675</td>\n",
       "      <td>0.347319</td>\n",
       "      <td>0.290022</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>SETAR(2,1)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.292055</td>\n",
       "      <td>0.258555</td>\n",
       "      <td>0.287265</td>\n",
       "      <td>0.275374</td>\n",
       "      <td>0.278881</td>\n",
       "      <td>0.320347</td>\n",
       "      <td>0.320181</td>\n",
       "      <td>0.270736</td>\n",
       "      <td>0.262183</td>\n",
       "      <td>AV-MCPS</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>SETAR(2,1)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.298469</td>\n",
       "      <td>0.269290</td>\n",
       "      <td>0.263802</td>\n",
       "      <td>0.255605</td>\n",
       "      <td>0.270449</td>\n",
       "      <td>0.290893</td>\n",
       "      <td>0.290581</td>\n",
       "      <td>0.329900</td>\n",
       "      <td>0.258734</td>\n",
       "      <td>DeepAR</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>SETAR(2,1)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.298007</td>\n",
       "      <td>0.368342</td>\n",
       "      <td>0.501202</td>\n",
       "      <td>0.323900</td>\n",
       "      <td>0.348571</td>\n",
       "      <td>0.326254</td>\n",
       "      <td>0.329508</td>\n",
       "      <td>0.423889</td>\n",
       "      <td>0.442319</td>\n",
       "      <td>AREPD</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>1</td>\n",
       "      <td>SETAR(2,3)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.164445</td>\n",
       "      <td>0.992519</td>\n",
       "      <td>0.962026</td>\n",
       "      <td>0.989297</td>\n",
       "      <td>1.046459</td>\n",
       "      <td>0.971555</td>\n",
       "      <td>1.076860</td>\n",
       "      <td>1.003262</td>\n",
       "      <td>0.961513</td>\n",
       "      <td>Sieve Bootstrap</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>2</td>\n",
       "      <td>SETAR(2,3)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.191648</td>\n",
       "      <td>1.034591</td>\n",
       "      <td>0.986347</td>\n",
       "      <td>1.077081</td>\n",
       "      <td>0.972263</td>\n",
       "      <td>0.957417</td>\n",
       "      <td>0.986525</td>\n",
       "      <td>0.963721</td>\n",
       "      <td>0.984072</td>\n",
       "      <td>LSPM</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>3</td>\n",
       "      <td>SETAR(2,3)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.193252</td>\n",
       "      <td>1.387456</td>\n",
       "      <td>1.012627</td>\n",
       "      <td>0.981861</td>\n",
       "      <td>0.955903</td>\n",
       "      <td>0.987603</td>\n",
       "      <td>0.977201</td>\n",
       "      <td>1.041540</td>\n",
       "      <td>1.009812</td>\n",
       "      <td>EnCQR-LSTM</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>4</td>\n",
       "      <td>SETAR(2,3)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.229893</td>\n",
       "      <td>1.182221</td>\n",
       "      <td>1.124342</td>\n",
       "      <td>0.983326</td>\n",
       "      <td>0.960088</td>\n",
       "      <td>1.036372</td>\n",
       "      <td>0.978720</td>\n",
       "      <td>1.029875</td>\n",
       "      <td>1.103310</td>\n",
       "      <td>EnCQR-LSTM</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>5</td>\n",
       "      <td>SETAR(2,3)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.149135</td>\n",
       "      <td>1.068179</td>\n",
       "      <td>1.046778</td>\n",
       "      <td>0.999776</td>\n",
       "      <td>0.961731</td>\n",
       "      <td>0.961208</td>\n",
       "      <td>0.977492</td>\n",
       "      <td>1.069917</td>\n",
       "      <td>1.059325</td>\n",
       "      <td>LSPM</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Paso Tipo de Modelo Distribución  Varianza error     AREPD   AV-MCPS  \\\n",
       "0      1     SETAR(2,1)       normal             0.2  0.257043  0.253521   \n",
       "1      2     SETAR(2,1)       normal             0.2  0.305723  0.383340   \n",
       "2      3     SETAR(2,1)       normal             0.2  0.292055  0.258555   \n",
       "3      4     SETAR(2,1)       normal             0.2  0.298469  0.269290   \n",
       "4      5     SETAR(2,1)       normal             0.2  0.298007  0.368342   \n",
       "..   ...            ...          ...             ...       ...       ...   \n",
       "834    1     SETAR(2,3)      mixture             3.0  1.164445  0.992519   \n",
       "835    2     SETAR(2,3)      mixture             3.0  1.191648  1.034591   \n",
       "836    3     SETAR(2,3)      mixture             3.0  1.193252  1.387456   \n",
       "837    4     SETAR(2,3)      mixture             3.0  1.229893  1.182221   \n",
       "838    5     SETAR(2,3)      mixture             3.0  1.149135  1.068179   \n",
       "\n",
       "     Block Bootstrapping    DeepAR  EnCQR-LSTM      LSPM     LSPMW      MCPS  \\\n",
       "0               0.251524  0.263274    0.257984  0.285655  0.282110  0.257015   \n",
       "1               0.288529  0.297164    0.324101  0.316846  0.319675  0.347319   \n",
       "2               0.287265  0.275374    0.278881  0.320347  0.320181  0.270736   \n",
       "3               0.263802  0.255605    0.270449  0.290893  0.290581  0.329900   \n",
       "4               0.501202  0.323900    0.348571  0.326254  0.329508  0.423889   \n",
       "..                   ...       ...         ...       ...       ...       ...   \n",
       "834             0.962026  0.989297    1.046459  0.971555  1.076860  1.003262   \n",
       "835             0.986347  1.077081    0.972263  0.957417  0.986525  0.963721   \n",
       "836             1.012627  0.981861    0.955903  0.987603  0.977201  1.041540   \n",
       "837             1.124342  0.983326    0.960088  1.036372  0.978720  1.029875   \n",
       "838             1.046778  0.999776    0.961731  0.961208  0.977492  1.069917   \n",
       "\n",
       "     Sieve Bootstrap         Mejor Modelo               Escenario  \n",
       "0           0.251188      Sieve Bootstrap  No_Lineal_Estacionario  \n",
       "1           0.290022  Block Bootstrapping  No_Lineal_Estacionario  \n",
       "2           0.262183              AV-MCPS  No_Lineal_Estacionario  \n",
       "3           0.258734               DeepAR  No_Lineal_Estacionario  \n",
       "4           0.442319                AREPD  No_Lineal_Estacionario  \n",
       "..               ...                  ...                     ...  \n",
       "834         0.961513      Sieve Bootstrap  No_Lineal_Estacionario  \n",
       "835         0.984072                 LSPM  No_Lineal_Estacionario  \n",
       "836         1.009812           EnCQR-LSTM  No_Lineal_Estacionario  \n",
       "837         1.103310           EnCQR-LSTM  No_Lineal_Estacionario  \n",
       "838         1.059325                 LSPM  No_Lineal_Estacionario  \n",
       "\n",
       "[700 rows x 15 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_lineal = pd.read_excel(\"./Datos/no_lineal.xlsx\")\n",
    "no_lineal = no_lineal[no_lineal[\"Paso\"] != \"Promedio\"]\n",
    "no_lineal[\"Escenario\"] = \"No_Lineal_Estacionario\"\n",
    "no_lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f2c36b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Une los tres DataFrames en uno solo uno debajo de otro\n",
    "df_all = pd.concat([estacionario, no_estacionario, no_lineal], ignore_index=True)\n",
    "# Guarda el DataFrame combinado en un archivo Excel\n",
    "df_all.to_excel(\"./Datos/datos_combinados.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaf7f35",
   "metadata": {},
   "source": [
    "# Analisis con la correcion del profe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ac9a3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio 'resultados_completos_media_mediana' creado.\n",
      "✓ Datos cargados exitosamente.\n",
      "\n",
      "================================================================================\n",
      "--- INICIANDO ANÁLISIS BASADO EN LA MEAN ---\n",
      "================================================================================\n",
      " -> 1. Analizando por estacionariedad (mean)...\n",
      " -> 2. Analizando por linealidad (mean)...\n",
      " -> 3. Generando heatmaps generales (mean)...\n",
      " -> 4. Analizando ECRPS vs Varianza (mean)...\n",
      " -> 5. Analizando ECRPS vs Paso (mean)...\n",
      " -> Analizando robustez y estabilidad (basado en mean)...\n",
      "\n",
      "================================================================================\n",
      "--- INICIANDO ANÁLISIS BASADO EN LA MEDIAN ---\n",
      "================================================================================\n",
      " -> 1. Analizando por estacionariedad (median)...\n",
      " -> 2. Analizando por linealidad (median)...\n",
      " -> 3. Generando heatmaps generales (median)...\n",
      " -> 4. Analizando ECRPS vs Varianza (median)...\n",
      " -> 5. Analizando ECRPS vs Paso (median)...\n",
      " -> Analizando robustez y estabilidad (basado en median)...\n",
      "\n",
      "================================================================================\n",
      "--- INICIANDO ANÁLISIS INDEPENDIENTES DE AGREGACIÓN ---\n",
      "================================================================================\n",
      " -> Generando gráficos de densidad individuales (análisis único)...\n",
      " -> Realizando Test de Diebold-Mariano (análisis único)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pleal\\AppData\\Local\\Temp\\ipykernel_16608\\4105642524.py:199: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  annot_matrix = result_matrix.applymap(lambda x: {1: 'Gana', -1: 'Pierde', 0: 'Empate'}[x])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Análisis completo. Resultados guardados en la carpeta 'resultados_completos_media_mediana'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "from scipy import stats\n",
    "from itertools import combinations\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURACIÓN\n",
    "# ============================================================================\n",
    "RUTA_DATOS = \"./Datos/datos_combinados.xlsx\"\n",
    "CARPETA_RESULTADOS = \"resultados_completos_media_mediana\"\n",
    "MODELOS = ['AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', \n",
    "           'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
    "ESCENARIOS_ESTACIONARIOS = ['Estacionario_Lineal', 'No_Lineal_Estacionario']\n",
    "ESCENARIOS_NO_ESTACIONARIOS = ['No_Estacionario_Lineal']\n",
    "ESCENARIOS_LINEALES = ['Estacionario_Lineal', 'No_Estacionario_Lineal']\n",
    "ESCENARIOS_NO_LINEALES = ['No_Lineal_Estacionario']\n",
    "\n",
    "# ============================================================================\n",
    "# CLASE PARA TEST ESTADÍSTICO\n",
    "# ============================================================================\n",
    "class DieboldMarianoTest:\n",
    "    @staticmethod\n",
    "    def dm_test(errors1, errors2, h=1, power=2):\n",
    "        # Implementación del test... (sin cambios)\n",
    "        errors1, errors2 = np.array(errors1), np.array(errors2)\n",
    "        loss_diff = (errors1**power) - (errors2**power)\n",
    "        mean_diff = np.mean(loss_diff)\n",
    "        n = len(loss_diff)\n",
    "        gamma0 = np.var(loss_diff, ddof=1)\n",
    "        if h > 1:\n",
    "            gamma_sum = sum((1 - k/h) * np.cov(loss_diff[:-k], loss_diff[k:])[0, 1] for k in range(1, h))\n",
    "            variance = (gamma0 + 2 * gamma_sum) / n\n",
    "        else:\n",
    "            variance = gamma0 / n\n",
    "        dm_stat = mean_diff / np.sqrt(variance) if variance > 0 else 0\n",
    "        p_value = 2 * (1 - stats.norm.cdf(np.abs(dm_stat)))\n",
    "        return dm_stat, p_value\n",
    "\n",
    "# ============================================================================\n",
    "# FUNCIONES DE ANÁLISIS Y VISUALIZACIÓN (MODIFICADAS)\n",
    "# ============================================================================\n",
    "def crear_directorio_resultados(nombre_carpeta):\n",
    "    if not os.path.exists(nombre_carpeta):\n",
    "        os.makedirs(nombre_carpeta)\n",
    "        print(f\"Directorio '{nombre_carpeta}' creado.\")\n",
    "\n",
    "def guardar_grafico(nombre_archivo):\n",
    "    ruta_completa = os.path.join(CARPETA_RESULTADOS, nombre_archivo)\n",
    "    plt.savefig(ruta_completa, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def graficar_comparacion_barras(promedios1, promedios2, orden, etiqueta1, etiqueta2, agg_method, nombre_archivo):\n",
    "    \"\"\"Grafica la comparación de barras para media o mediana.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    x = np.arange(len(orden))\n",
    "    width = 0.35\n",
    "    bars1 = ax.bar(x - width/2, promedios1[orden], width, label=etiqueta1, alpha=0.8, color='#3498db')\n",
    "    bars2 = ax.bar(x + width/2, promedios2[orden], width, label=etiqueta2, alpha=0.8, color='#e74c3c')\n",
    "    \n",
    "    ylabel = f'ECRPS {\"Promedio\" if agg_method == \"mean\" else \"Mediano\"} (menor es mejor)'\n",
    "    titulo = f'Comparación de Desempeño ({agg_method.capitalize()})'\n",
    "    \n",
    "    ax.set_xlabel('Modelos', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel(ylabel, fontsize=12, fontweight='bold')\n",
    "    ax.set_title(titulo, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(orden, rotation=45, ha='right')\n",
    "    ax.legend(fontsize=11)\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    for bars in [bars1, bars2]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width() / 2., height, f'{height:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    guardar_grafico(nombre_archivo)\n",
    "\n",
    "def generar_heatmap(data, agg_method, titulo_sufijo, nombre_archivo, figsize=(14, 8)):\n",
    "    \"\"\"Genera un heatmap basado en media o mediana.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    cbar_label = f'ECRPS {\"Promedio\" if agg_method == \"mean\" else \"Mediano\"}'\n",
    "    titulo = f'Heatmap: {titulo_sufijo} ({agg_method.capitalize()})'\n",
    "    \n",
    "    sns.heatmap(data, annot=True, fmt='.3f', cmap='RdYlGn_r',\n",
    "                cbar_kws={'label': cbar_label},\n",
    "                linewidths=0.5, linecolor='gray', ax=ax)\n",
    "    ax.set_title(titulo, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Modelos', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel(data.index.name, fontsize=12, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    guardar_grafico(nombre_archivo)\n",
    "\n",
    "def graficar_evolucion_metrica_por_tipo(df, metrica_eje_x, agg_method, xlabel, nombre_archivo_sufijo):\n",
    "    \"\"\"Genera gráficos de evolución para cada tipo de modelo, usando media o mediana.\"\"\"\n",
    "    valores_unicos = sorted(df[metrica_eje_x].unique())\n",
    "    tipos_modelo_unicos = df['Tipo de Modelo'].unique()\n",
    "    \n",
    "    for tipo in tipos_modelo_unicos:\n",
    "        df_tipo = df[df['Tipo de Modelo'] == tipo]\n",
    "        fig, ax = plt.subplots(figsize=(12, 7))\n",
    "        \n",
    "        for modelo in MODELOS:\n",
    "            agregados = [df_tipo[df_tipo[metrica_eje_x] == val][modelo].agg(agg_method) for val in valores_unicos]\n",
    "            if not all(np.isnan(agregados)):\n",
    "                ax.plot(valores_unicos, agregados, marker='o', linewidth=2, markersize=8, label=modelo, alpha=0.8)\n",
    "        \n",
    "        ylabel = f'ECRPS {\"Promedio\" if agg_method == \"mean\" else \"Mediano\"}'\n",
    "        titulo = f'ECRPS vs {metrica_eje_x} ({agg_method.capitalize()}) - Tipo: {tipo}'\n",
    "        \n",
    "        ax.set_xlabel(xlabel, fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel(ylabel, fontsize=12, fontweight='bold')\n",
    "        ax.set_title(titulo, fontsize=13, fontweight='bold', pad=15)\n",
    "        ax.legend(fontsize=9, loc='best', ncol=2)\n",
    "        ax.grid(True, alpha=0.3, linestyle='--')\n",
    "        if metrica_eje_x == 'Paso':\n",
    "            ax.set_xticks(valores_unicos)\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        nombre_archivo_tipo = f'ecrps_vs_{nombre_archivo_sufijo}_tipo_{tipo.replace(\" \", \"_\").lower()}_{agg_method}.png'\n",
    "        guardar_grafico(nombre_archivo_tipo)\n",
    "\n",
    "def analizar_robustez_estabilidad(df, agg_method):\n",
    "    \"\"\"Calcula y grafica métricas de robustez y estabilidad.\"\"\"\n",
    "    print(f\" -> Analizando robustez y estabilidad (basado en {agg_method})...\")\n",
    "    \n",
    "    if agg_method == 'mean':\n",
    "        # Análisis basado en la media (como antes)\n",
    "        metrics = [{'Modelo': m, 'Centralidad': df[m].mean(), 'Dispersion': df[m].std()} for m in MODELOS]\n",
    "        df_robust = pd.DataFrame(metrics)\n",
    "        label_centralidad = 'ECRPS Promedio (Rendimiento)'\n",
    "        label_dispersion = 'Desviación Estándar (Estabilidad)'\n",
    "        titulo_compromiso = 'Compromiso Rendimiento vs. Estabilidad (Media vs Std)'\n",
    "        \n",
    "    else: # agg_method == 'median'\n",
    "        # Análisis basado en la mediana (más robusto a outliers)\n",
    "        metrics = [{'Modelo': m, 'Centralidad': df[m].median(), 'Dispersion': df[m].quantile(0.75) - df[m].quantile(0.25)} for m in MODELOS]\n",
    "        df_robust = pd.DataFrame(metrics)\n",
    "        label_centralidad = 'ECRPS Mediano (Rendimiento Típico)'\n",
    "        label_dispersion = 'Rango Intercuartílico (IQR - Estabilidad Robusta)'\n",
    "        titulo_compromiso = 'Compromiso Rendimiento vs. Estabilidad (Mediana vs IQR)'\n",
    "\n",
    "    # Gráfico de dispersión Rendimiento vs Estabilidad\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    sns.scatterplot(data=df_robust, x='Centralidad', y='Dispersion', hue='Modelo', s=150, alpha=0.8, ax=ax)\n",
    "    for _, row in df_robust.iterrows():\n",
    "        ax.text(row['Centralidad'], row['Dispersion'], row['Modelo'], fontsize=9, ha='left', va='bottom')\n",
    "    ax.set_xlabel(label_centralidad, fontweight='bold')\n",
    "    ax.set_ylabel(label_dispersion, fontweight='bold')\n",
    "    ax.set_title(titulo_compromiso, fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, linestyle='--', alpha=0.6)\n",
    "    ax.legend(title='Modelos', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    guardar_grafico(f\"6_compromiso_rendimiento_estabilidad_{agg_method}.png\")\n",
    "\n",
    "# --- Funciones que no dependen de la agregación (se ejecutan una sola vez) ---\n",
    "def graficar_densidades_individuales(df):\n",
    "    \"\"\"Crea un gráfico de densidad individual para cada modelo.\"\"\"\n",
    "    print(\" -> Generando gráficos de densidad individuales (análisis único)...\")\n",
    "    all_ecrps_values = df[MODELOS].values.flatten()\n",
    "    xlim_max = np.quantile(all_ecrps_values[~np.isnan(all_ecrps_values)], 0.995)\n",
    "    for modelo in MODELOS:\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        sns.kdeplot(df[modelo].dropna(), fill=True, color='teal', ax=ax, lw=2.5)\n",
    "        mean_val, median_val = df[modelo].mean(), df[modelo].median()\n",
    "        ax.axvline(mean_val, color='red', linestyle='--', label=f'Media: {mean_val:.3f}')\n",
    "        ax.axvline(median_val, color='green', linestyle=':', label=f'Mediana: {median_val:.3f}')\n",
    "        ax.set_title(f'Distribución del ECRPS - Modelo: {modelo}', fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel('ECRPS', fontweight='bold')\n",
    "        ax.set_ylabel('Densidad', fontweight='bold')\n",
    "        ax.set_xlim(left=0, right=xlim_max)\n",
    "        ax.legend()\n",
    "        ax.grid(True, linestyle='--', alpha=0.5)\n",
    "        plt.tight_layout()\n",
    "        guardar_grafico(f\"7_densidad_{modelo.replace(' ', '_').lower()}.png\")\n",
    "\n",
    "def realizar_test_diebold_mariano(df):\n",
    "    \"\"\"Realiza el test de Diebold-Mariano con corrección de Bonferroni.\"\"\"\n",
    "    print(\" -> Realizando Test de Diebold-Mariano (análisis único)...\")\n",
    "    pairs = list(combinations(MODELOS, 2))\n",
    "    alpha_bonferroni = 0.05 / len(pairs)\n",
    "    dm_results = []\n",
    "    for m1, m2 in pairs:\n",
    "        e1, e2 = df[m1].dropna(), df[m2].dropna()\n",
    "        min_len = min(len(e1), len(e2))\n",
    "        _, p_value = DieboldMarianoTest.dm_test(e1[:min_len], e2[:min_len])\n",
    "        winner = 'Empate' if p_value >= alpha_bonferroni else (m1 if df[m1].mean() < df[m2].mean() else m2)\n",
    "        dm_results.append({'Modelo_1': m1, 'Modelo_2': m2, 'Ganador_Bonferroni': winner})\n",
    "    \n",
    "    # Heatmap de resultados\n",
    "    result_matrix = pd.DataFrame(index=MODELOS, columns=MODELOS, data=0)\n",
    "    for _, row in pd.DataFrame(dm_results).iterrows():\n",
    "        if row['Ganador_Bonferroni'] == row['Modelo_1']:\n",
    "            result_matrix.loc[row['Modelo_1'], row['Modelo_2']], result_matrix.loc[row['Modelo_2'], row['Modelo_1']] = 1, -1\n",
    "        elif row['Ganador_Bonferroni'] == row['Modelo_2']:\n",
    "            result_matrix.loc[row['Modelo_1'], row['Modelo_2']], result_matrix.loc[row['Modelo_2'], row['Modelo_1']] = -1, 1\n",
    "\n",
    "    annot_matrix = result_matrix.applymap(lambda x: {1: 'Gana', -1: 'Pierde', 0: 'Empate'}[x])\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    sns.heatmap(result_matrix.astype(float), annot=annot_matrix, fmt='s', cmap=['red', 'lightgray', 'green'], cbar=False, ax=ax)\n",
    "    ax.set_title('Resultado Test Diebold-Mariano (con corrección de Bonferroni)', fontweight='bold')\n",
    "    guardar_grafico(\"8_dm_heatmap_bonferroni.png\")\n",
    "\n",
    "# ============================================================================\n",
    "# SCRIPT PRINCIPAL\n",
    "# ============================================================================\n",
    "def main():\n",
    "    crear_directorio_resultados(CARPETA_RESULTADOS)\n",
    "    try:\n",
    "        df = pd.read_excel(RUTA_DATOS)\n",
    "        print(\"✓ Datos cargados exitosamente.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: No se encontró el archivo en la ruta '{RUTA_DATOS}'.\")\n",
    "        return\n",
    "\n",
    "    # Bucle principal para ejecutar análisis por media y mediana\n",
    "    for agg_method in ['mean', 'median']:\n",
    "        print(f\"\\n{'='*80}\\n--- INICIANDO ANÁLISIS BASADO EN LA {agg_method.upper()} ---\\n{'='*80}\")\n",
    "\n",
    "        # --- ANÁLISIS 1: ESTACIONARIEDAD ---\n",
    "        print(f\" -> 1. Analizando por estacionariedad ({agg_method})...\")\n",
    "        df_est = df[df['Escenario'].isin(ESCENARIOS_ESTACIONARIOS)]\n",
    "        df_no_est = df[df['Escenario'].isin(ESCENARIOS_NO_ESTACIONARIOS)]\n",
    "        agregados_est = df_est[MODELOS].agg(agg_method)\n",
    "        agregados_no_est = df_no_est[MODELOS].agg(agg_method)\n",
    "        orden_est = (agregados_est + agregados_no_est).sort_values().index\n",
    "        graficar_comparacion_barras(agregados_est, agregados_no_est, orden_est, 'Estacionarios', 'No Estacionarios', agg_method, f'1_comparacion_estacionariedad_{agg_method}.png')\n",
    "        \n",
    "        # --- ANÁLISIS 2: LINEALIDAD ---\n",
    "        print(f\" -> 2. Analizando por linealidad ({agg_method})...\")\n",
    "        df_lin = df[df['Escenario'].isin(ESCENARIOS_LINEALES)]\n",
    "        df_no_lin = df[df['Escenario'].isin(ESCENARIOS_NO_LINEALES)]\n",
    "        agregados_lin = df_lin[MODELOS].agg(agg_method)\n",
    "        agregados_no_lin = df_no_lin[MODELOS].agg(agg_method)\n",
    "        orden_lin = (agregados_lin + agregados_no_lin).sort_values().index\n",
    "        graficar_comparacion_barras(agregados_lin, agregados_no_lin, orden_lin, 'Lineales', 'No Lineales', agg_method, f'2_comparacion_linealidad_{agg_method}.png')\n",
    "\n",
    "        # --- ANÁLISIS 3: HEATMAPS GENERALES ---\n",
    "        print(f\" -> 3. Generando heatmaps generales ({agg_method})...\")\n",
    "        heatmap_esc_df = df.groupby('Escenario')[MODELOS].agg(agg_method)\n",
    "        generar_heatmap(heatmap_esc_df, agg_method, 'Desempeño por Escenario', f'3_heatmap_escenario_{agg_method}.png', figsize=(14, 6))\n",
    "        heatmap_dist_df = df.groupby('Distribución')[MODELOS].agg(agg_method)\n",
    "        generar_heatmap(heatmap_dist_df, agg_method, 'Desempeño por Distribución', f'3_heatmap_distribucion_{agg_method}.png')\n",
    "\n",
    "        # --- ANÁLISIS 4 & 5: EVOLUCIÓN VS VARIANZA Y PASO ---\n",
    "        print(f\" -> 4. Analizando ECRPS vs Varianza ({agg_method})...\")\n",
    "        graficar_evolucion_metrica_por_tipo(df, 'Varianza error', agg_method, 'Varianza error', 'varianza')\n",
    "        print(f\" -> 5. Analizando ECRPS vs Paso ({agg_method})...\")\n",
    "        graficar_evolucion_metrica_por_tipo(df, 'Paso', agg_method, 'Paso (Horizonte)', 'paso')\n",
    "        \n",
    "        # --- ANÁLISIS 6: ROBUSTEZ Y ESTABILIDAD ---\n",
    "        analizar_robustez_estabilidad(df, agg_method)\n",
    "\n",
    "    # --- ANÁLISIS QUE SE EJECUTAN UNA SOLA VEZ ---\n",
    "    print(f\"\\n{'='*80}\\n--- INICIANDO ANÁLISIS INDEPENDIENTES DE AGREGACIÓN ---\\n{'='*80}\")\n",
    "    # --- ANÁLISIS 7: DENSIDAD DE ERRORES ---\n",
    "    graficar_densidades_individuales(df)\n",
    "    \n",
    "    # --- ANÁLISIS 8: TEST DE DIEBOLD-MARIANO ---\n",
    "    realizar_test_diebold_mariano(df)\n",
    "    \n",
    "    print(f\"\\n✓ Análisis completo. Resultados guardados en la carpeta '{CARPETA_RESULTADOS}'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

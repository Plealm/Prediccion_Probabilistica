{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b99d120",
   "metadata": {},
   "source": [
    "# Analisis Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b278203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS COMPREHENSIVO DE MODELOS DE PREDICCI√ìN PROBABIL√çSTICA\n",
      "================================================================================\n",
      "\n",
      "Cargando datos...\n",
      "‚úì Estacionario: 1320 filas\n",
      "  Columnas: ['Paso', 'Valores de AR', 'Valores MA', 'Distribuci√≥n', 'Varianza error', 'AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', 'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap', 'Mejor Modelo', 'Escenario']\n",
      "‚úì No Estacionario: 840 filas\n",
      "  Columnas: ['Paso', 'Tipo de Modelo', 'Valores de AR', 'Valores MA', 'Distribuci√≥n', 'Varianza error', 'AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', 'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap', 'Mejor Modelo', 'Escenario']\n",
      "‚úì No Lineal: 840 filas\n",
      "  Columnas: ['Paso', 'Tipo de Modelo', 'Distribuci√≥n', 'Varianza error', 'AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', 'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap', 'Mejor Modelo', 'Escenario']\n",
      "‚úì Tipos de datos convertidos\n",
      "‚úì Filas despu√©s de limpieza: 2600\n",
      "\n",
      "‚úì Datos combinados: 2600 observaciones totales\n",
      "‚úì Columnas finales: ['Paso', 'Valores de AR', 'Valores MA', 'Distribuci√≥n', 'Varianza', 'AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', 'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap', 'Mejor Modelo', 'Escenario', 'Tipo de Modelo']\n",
      "\n",
      "================================================================================\n",
      "INICIANDO AN√ÅLISIS COMPREHENSIVO DE MODELOS\n",
      "================================================================================\n",
      "\n",
      "1. Analizando caracter√≠sticas del proceso generador...\n",
      "  - Analizando efecto de estacionaridad...\n",
      "  - Analizando efecto de no linealidad...\n",
      "  - Analizando efecto del tipo de modelo...\n",
      "\n",
      "2. Analizando efecto de distribuciones...\n",
      "  - Analizando efectos de distribuciones...\n",
      "  - Analizando efectos de varianza...\n",
      "\n",
      "3. Analizando horizonte de predicci√≥n...\n",
      "  - Analizando deterioro por horizonte...\n",
      "  - Analizando consistencia de ranking...\n",
      "\n",
      "4. Analizando interacciones complejas...\n",
      "  - Analizando interacciones Escenario √ó Distribuci√≥n...\n",
      "  - Analizando interacci√≥n triple...\n",
      "\n",
      "5. Analizando robustez y estabilidad...\n",
      "  - Calculando m√©tricas de robustez...\n",
      "  - Identificando peores casos...\n",
      "\n",
      "6. Realizando tests de Diebold-Mariano...\n",
      "  - Realizando tests de Diebold-Mariano...\n",
      "  - Realizando tests pareados de Diebold-Mariano...\n",
      "  - Creando matriz de p-valores...\n",
      "  - Analizando dominancia estad√≠stica...\n",
      "  - Analizando DM por escenario...\n",
      "\n",
      "7. Generando perfiles por modelo...\n",
      "  - Generando perfiles individuales...\n",
      "    > Analizando AREPD...\n",
      "    > Analizando AV-MCPS...\n",
      "    > Analizando Block Bootstrapping...\n",
      "    > Analizando DeepAR...\n",
      "    > Analizando EnCQR-LSTM...\n",
      "    > Analizando LSPM...\n",
      "    > Analizando LSPMW...\n",
      "    > Analizando MCPS...\n",
      "    > Analizando Sieve Bootstrap...\n",
      "\n",
      "8. Generando recomendaciones...\n",
      "  - Generando recomendaciones estrat√©gicas...\n",
      "================================================================================\n",
      "RECOMENDACIONES Y CONCLUSIONES\n",
      "================================================================================\n",
      "\n",
      "1. MODELO CAMPE√ìN GENERAL\n",
      "----------------------------------------\n",
      "Mejor rendimiento promedio: Block Bootstrapping\n",
      "ECRPS: 0.557547\n",
      "Desviaci√≥n Est√°ndar: 0.293355\n",
      "\n",
      "Peor rendimiento promedio: AREPD\n",
      "ECRPS: 3.083010\n",
      "\n",
      "2. RECOMENDACIONES POR ESCENARIO\n",
      "----------------------------------------\n",
      "\n",
      "Estacionario_Lineal:\n",
      "  Modelo Recomendado: Block Bootstrapping\n",
      "  ECRPS Promedio: 0.539612\n",
      "\n",
      "No_Estacionario_Lineal:\n",
      "  Modelo Recomendado: Block Bootstrapping\n",
      "  ECRPS Promedio: 0.542499\n",
      "\n",
      "No_Lineal:\n",
      "  Modelo Recomendado: Block Bootstrapping\n",
      "  ECRPS Promedio: 0.603341\n",
      "\n",
      "3. RECOMENDACIONES POR DISTRIBUCI√ìN DE ERRORES\n",
      "----------------------------------------\n",
      "\n",
      "Distribuci√≥n normal:\n",
      "  Modelo Recomendado: Block Bootstrapping\n",
      "  ECRPS Promedio: 0.567834\n",
      "\n",
      "Distribuci√≥n uniform:\n",
      "  Modelo Recomendado: Block Bootstrapping\n",
      "  ECRPS Promedio: 0.585653\n",
      "\n",
      "Distribuci√≥n exponential:\n",
      "  Modelo Recomendado: Block Bootstrapping\n",
      "  ECRPS Promedio: 0.514920\n",
      "\n",
      "Distribuci√≥n t-student:\n",
      "  Modelo Recomendado: Block Bootstrapping\n",
      "  ECRPS Promedio: 0.547263\n",
      "\n",
      "Distribuci√≥n mixture:\n",
      "  Modelo Recomendado: Block Bootstrapping\n",
      "  ECRPS Promedio: 0.572066\n",
      "\n",
      "4. MODELOS M√ÅS ROBUSTOS (MENOR VARIABILIDAD)\n",
      "----------------------------------------\n",
      "1. Block Bootstrapping: CV = 0.5262\n",
      "2. LSPMW: CV = 0.7688\n",
      "3. LSPM: CV = 0.7896\n",
      "\n",
      "5. RECOMENDACIONES POR HORIZONTE DE PREDICCI√ìN\n",
      "----------------------------------------\n",
      "\n",
      "Paso 1.0:\n",
      "  Modelo Recomendado: Block Bootstrapping\n",
      "  ECRPS Promedio: 0.548020\n",
      "\n",
      "Paso 3.0:\n",
      "  Modelo Recomendado: Block Bootstrapping\n",
      "  ECRPS Promedio: 0.560285\n",
      "\n",
      "Paso 5.0:\n",
      "  Modelo Recomendado: Block Bootstrapping\n",
      "  ECRPS Promedio: 0.554843\n",
      "\n",
      "6. ESTRATEGIA DE ENSAMBLE SUGERIDA\n",
      "----------------------------------------\n",
      "Combinar los siguientes modelos:\n",
      "1. Block Bootstrapping (ECRPS: 0.557547)\n",
      "2. Sieve Bootstrap (ECRPS: 0.614997)\n",
      "3. LSPM (ECRPS: 0.811114)\n",
      "\n",
      "Justificaci√≥n:\n",
      "  - Estos modelos muestran el mejor rendimiento promedio\n",
      "  - Un ensamble puede capturar fortalezas complementarias\n",
      "  - Reduce el riesgo de seleccionar un modelo sub√≥ptimo\n",
      "\n",
      "7. MODELOS CON DOMINANCIA ESTAD√çSTICA\n",
      "----------------------------------------\n",
      "Modelos estad√≠sticamente superiores (test Diebold-Mariano):\n",
      "1. Block Bootstrapping: 7 victorias significativas\n",
      "2. LSPM: 6 victorias significativas\n",
      "3. LSPMW: 5 victorias significativas\n",
      "4. Sieve Bootstrap: 5 victorias significativas\n",
      "5. DeepAR: 3 victorias significativas\n",
      "\n",
      "8. REGLAS DE DECISI√ìN SUGERIDAS\n",
      "----------------------------------------\n",
      "\n",
      "SI el proceso es ESTACIONARIO y LINEAL:\n",
      "  ‚Üí Primera opci√≥n: Block Bootstrapping\n",
      "  ‚Üí Segunda opci√≥n: Sieve Bootstrap\n",
      "\n",
      "SI el proceso es NO ESTACIONARIO y LINEAL:\n",
      "  ‚Üí Primera opci√≥n: Block Bootstrapping\n",
      "  ‚Üí Segunda opci√≥n: Sieve Bootstrap\n",
      "\n",
      "SI el proceso es NO LINEAL:\n",
      "  ‚Üí Primera opci√≥n: Block Bootstrapping\n",
      "  ‚Üí Segunda opci√≥n: DeepAR\n",
      "\n",
      "SI la distribuci√≥n de errores:\n",
      "  ‚Ä¢ Es normal ‚Üí Usar Block Bootstrapping\n",
      "  ‚Ä¢ Es uniform ‚Üí Usar Block Bootstrapping\n",
      "  ‚Ä¢ Es exponential ‚Üí Usar Block Bootstrapping\n",
      "  ‚Ä¢ Es t-student ‚Üí Usar Block Bootstrapping\n",
      "  ‚Ä¢ Es mixture ‚Üí Usar Block Bootstrapping\n",
      "\n",
      "SI el nivel de varianza:\n",
      "  ‚Ä¢ Es bajo (0.2) ‚Üí Usar Block Bootstrapping\n",
      "  ‚Ä¢ Es alto (3.0) ‚Üí Usar Block Bootstrapping\n",
      "\n",
      "9. CONCLUSIONES PRINCIPALES\n",
      "----------------------------------------\n",
      "\n",
      "‚Ä¢ El modelo Block Bootstrapping muestra el mejor rendimiento general\n",
      "  con ECRPS promedio de 0.557547\n",
      "\n",
      "‚Ä¢ El modelo m√°s robusto (menor CV) es Block Bootstrapping\n",
      "\n",
      "‚Ä¢ Block Bootstrapping es consistentemente superior en procesos\n",
      "  estacionarios y no estacionarios\n",
      "\n",
      "‚Ä¢ Para procesos no lineales: Block Bootstrapping es la mejor opci√≥n\n",
      "\n",
      "‚Ä¢ Se recomienda implementar un ENSAMBLE de los top 3 modelos\n",
      "  para maximizar robustez y rendimiento\n",
      "\n",
      "10. CONSIDERACIONES PR√ÅCTICAS\n",
      "----------------------------------------\n",
      "\n",
      "Factores a considerar en la selecci√≥n:\n",
      "  1. Costo computacional vs ganancia en precisi√≥n\n",
      "  2. Robustez ante cambios en la distribuci√≥n de errores\n",
      "  3. Consistencia a trav√©s de horizontes de predicci√≥n\n",
      "  4. Facilidad de interpretaci√≥n y explicabilidad\n",
      "  5. Disponibilidad de recursos para implementaci√≥n\n",
      "\n",
      "Trade-offs identificados:\n",
      "  ‚Ä¢ Algunos modelos son especialistas en escenarios espec√≠ficos\n",
      "  ‚Ä¢ Otros modelos son generalistas con buen rendimiento global\n",
      "\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS COMPLETO. Resultados guardados en: resultados_analisis_completo/\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "‚úì An√°lisis completado exitosamente\n",
      "‚úì Todos los resultados guardados en: resultados_analisis_completo/\n",
      "================================================================================\n",
      "\n",
      "Archivos generados:\n",
      "  üìä An√°lisis de caracter√≠sticas del DGP\n",
      "  üìà Efectos de distribuci√≥n y varianza\n",
      "  üéØ An√°lisis de horizonte de predicci√≥n\n",
      "  üîÑ Interacciones complejas\n",
      "  üí™ M√©tricas de robustez\n",
      "  üìâ Tests de Diebold-Mariano\n",
      "  üë§ Perfiles individuales por modelo\n",
      "  üí° Recomendaciones estrat√©gicas\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import friedmanchisquare\n",
    "from itertools import combinations\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class DieboldMarianoTest:\n",
    "    \"\"\"\n",
    "    Implementaci√≥n del test de Diebold-Mariano para comparar pron√≥sticos\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def dm_test(errors1, errors2, h=1, crit=\"MSE\", power=2):\n",
    "        \"\"\"\n",
    "        Realiza el test de Diebold-Mariano\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        errors1 : array-like\n",
    "            Errores del primer modelo\n",
    "        errors2 : array-like\n",
    "            Errores del segundo modelo\n",
    "        h : int\n",
    "            Horizonte de predicci√≥n (para ajustar autocorrelaci√≥n)\n",
    "        crit : str\n",
    "            Criterio de p√©rdida: \"MSE\", \"MAE\", \"MAPE\"\n",
    "        power : int\n",
    "            Potencia para la funci√≥n de p√©rdida\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        dm_stat : float\n",
    "            Estad√≠stico DM\n",
    "        p_value : float\n",
    "            P-valor (two-tailed)\n",
    "        \"\"\"\n",
    "        errors1 = np.array(errors1)\n",
    "        errors2 = np.array(errors2)\n",
    "        \n",
    "        # Calcular diferencias de p√©rdida\n",
    "        if crit == \"MSE\":\n",
    "            loss_diff = errors1**2 - errors2**2\n",
    "        elif crit == \"MAE\":\n",
    "            loss_diff = np.abs(errors1) - np.abs(errors2)\n",
    "        elif crit == \"MAPE\":\n",
    "            loss_diff = np.abs(errors1) - np.abs(errors2)\n",
    "        else:\n",
    "            loss_diff = errors1**power - errors2**power\n",
    "        \n",
    "        # Media de las diferencias\n",
    "        mean_diff = np.mean(loss_diff)\n",
    "        \n",
    "        # Varianza de las diferencias (ajustada por autocorrelaci√≥n)\n",
    "        n = len(loss_diff)\n",
    "        \n",
    "        # Calcular varianza con correcci√≥n de Newey-West\n",
    "        gamma0 = np.var(loss_diff, ddof=1)\n",
    "        \n",
    "        if h > 1:\n",
    "            gamma_sum = 0\n",
    "            for k in range(1, h):\n",
    "                gamma_k = np.cov(loss_diff[:-k], loss_diff[k:])[0, 1]\n",
    "                gamma_sum += (1 - k/h) * gamma_k\n",
    "            variance = (gamma0 + 2 * gamma_sum) / n\n",
    "        else:\n",
    "            variance = gamma0 / n\n",
    "        \n",
    "        # Estad√≠stico DM\n",
    "        dm_stat = mean_diff / np.sqrt(variance) if variance > 0 else 0\n",
    "        \n",
    "        # P-valor (two-tailed)\n",
    "        p_value = 2 * (1 - stats.norm.cdf(np.abs(dm_stat)))\n",
    "        \n",
    "        return dm_stat, p_value\n",
    "\n",
    "\n",
    "class ModelPerformanceAnalyzer:\n",
    "    \"\"\"\n",
    "    Clase para an√°lisis exhaustivo de rendimiento de modelos de predicci√≥n\n",
    "    en diferentes escenarios de simulaci√≥n.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Inicializa el analizador cargando los datos de los tres escenarios.\n",
    "        \"\"\"\n",
    "        self.models = ['AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', \n",
    "                      'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
    "        \n",
    "        # Cargar datos con las rutas especificadas\n",
    "        print(\"Cargando datos...\")\n",
    "        \n",
    "        try:\n",
    "            self.df_estacionario = pd.read_excel(\"./Datos/estacionario.xlsx\")\n",
    "            self.df_estacionario['Escenario'] = 'Estacionario_Lineal'\n",
    "            print(f\"‚úì Estacionario: {len(self.df_estacionario)} filas\")\n",
    "            print(f\"  Columnas: {self.df_estacionario.columns.tolist()}\")\n",
    "            \n",
    "            self.df_no_estacionario = pd.read_excel(\"./Datos/no_estacionario.xlsx\")\n",
    "            self.df_no_estacionario['Escenario'] = 'No_Estacionario_Lineal'\n",
    "            print(f\"‚úì No Estacionario: {len(self.df_no_estacionario)} filas\")\n",
    "            print(f\"  Columnas: {self.df_no_estacionario.columns.tolist()}\")\n",
    "            \n",
    "            self.df_no_lineal = pd.read_excel(\"./Datos/no_lineal.xlsx\")\n",
    "            self.df_no_lineal['Escenario'] = 'No_Lineal'\n",
    "            print(f\"‚úì No Lineal: {len(self.df_no_lineal)} filas\")\n",
    "            print(f\"  Columnas: {self.df_no_lineal.columns.tolist()}\")\n",
    "            \n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"ERROR: No se encontr√≥ el archivo - {e}\")\n",
    "            print(\"Verifica que los archivos est√©n en la carpeta './Datos/'\")\n",
    "            raise\n",
    "        \n",
    "        # Estandarizar nombres de columnas\n",
    "        self._standardize_columns()\n",
    "        \n",
    "        # Combinar todos los datos\n",
    "        self.df_all = pd.concat([self.df_estacionario, self.df_no_estacionario, \n",
    "                                 self.df_no_lineal], ignore_index=True)\n",
    "        \n",
    "        # Convertir tipos de datos cr√≠ticos\n",
    "        self._convert_data_types()\n",
    "        \n",
    "        print(f\"\\n‚úì Datos combinados: {len(self.df_all)} observaciones totales\")\n",
    "        print(f\"‚úì Columnas finales: {self.df_all.columns.tolist()}\")\n",
    "        \n",
    "    def _standardize_columns(self):\n",
    "        \"\"\"Estandariza nombres de columnas entre datasets\"\"\"\n",
    "        # Para estacionario\n",
    "        if 'Varianza error' in self.df_estacionario.columns:\n",
    "            self.df_estacionario.rename(columns={'Varianza error': 'Varianza'}, inplace=True)\n",
    "        \n",
    "        # Agregar columna 'Tipo de Modelo' si no existe en estacionario\n",
    "        if 'Tipo de Modelo' not in self.df_estacionario.columns:\n",
    "            # Crear tipo de modelo basado en valores AR y MA\n",
    "            def create_model_type(row):\n",
    "                ar_vals = row.get('Valores de AR', '')\n",
    "                ma_vals = row.get('Valores MA', '')\n",
    "                \n",
    "                ar_str = str(ar_vals) if pd.notna(ar_vals) else ''\n",
    "                ma_str = str(ma_vals) if pd.notna(ma_vals) else ''\n",
    "                \n",
    "                # Contar √≥rdenes\n",
    "                ar_order = len([x for x in ar_str.split(',') if x.strip() and x.strip() != '[]']) if ar_str else 0\n",
    "                ma_order = len([x for x in ma_str.split(',') if x.strip() and x.strip() != '[]']) if ma_str else 0\n",
    "                \n",
    "                if ar_order > 0 and ma_order > 0:\n",
    "                    return f'ARMA({ar_order},{ma_order})'\n",
    "                elif ar_order > 0:\n",
    "                    return f'AR({ar_order})'\n",
    "                elif ma_order > 0:\n",
    "                    return f'MA({ma_order})'\n",
    "                else:\n",
    "                    return 'Unknown'\n",
    "            \n",
    "            self.df_estacionario['Tipo de Modelo'] = self.df_estacionario.apply(create_model_type, axis=1)\n",
    "        \n",
    "        # Para no estacionario\n",
    "        if 'Varianza error' in self.df_no_estacionario.columns:\n",
    "            self.df_no_estacionario.rename(columns={'Varianza error': 'Varianza'}, inplace=True)\n",
    "        \n",
    "        # Para no lineal\n",
    "        if 'Varianza error' in self.df_no_lineal.columns:\n",
    "            self.df_no_lineal.rename(columns={'Varianza error': 'Varianza'}, inplace=True)\n",
    "    \n",
    "    def _convert_data_types(self):\n",
    "        \"\"\"Convierte tipos de datos para evitar errores de comparaci√≥n\"\"\"\n",
    "        # Convertir 'Paso' a num√©rico\n",
    "        self.df_all['Paso'] = pd.to_numeric(self.df_all['Paso'], errors='coerce')\n",
    "        \n",
    "        # Convertir 'Varianza' a num√©rico\n",
    "        self.df_all['Varianza'] = pd.to_numeric(self.df_all['Varianza'], errors='coerce')\n",
    "        \n",
    "        # Convertir columnas de modelos a num√©rico\n",
    "        for model in self.models:\n",
    "            self.df_all[model] = pd.to_numeric(self.df_all[model], errors='coerce')\n",
    "        \n",
    "        # Eliminar filas con valores NaN cr√≠ticos\n",
    "        critical_cols = ['Paso', 'Varianza'] + self.models\n",
    "        self.df_all.dropna(subset=critical_cols, inplace=True)\n",
    "        \n",
    "        print(f\"‚úì Tipos de datos convertidos\")\n",
    "        print(f\"‚úì Filas despu√©s de limpieza: {len(self.df_all)}\")\n",
    "        \n",
    "    def generate_full_report(self, output_dir='resultados_analisis'):\n",
    "        \"\"\"\n",
    "        Genera reporte completo respondiendo a todas las preguntas clave.\n",
    "        \"\"\"\n",
    "        import os\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"INICIANDO AN√ÅLISIS COMPREHENSIVO DE MODELOS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Crear archivo de reporte\n",
    "        report_file = f\"{output_dir}/reporte_completo.txt\"\n",
    "        with open(report_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"REPORTE COMPLETO DE AN√ÅLISIS DE MODELOS DE PREDICCI√ìN\\n\")\n",
    "            f.write(\"=\"*80 + \"\\n\\n\")\n",
    "        \n",
    "        # 1. AN√ÅLISIS POR CARACTER√çSTICAS DEL DGP\n",
    "        print(\"\\n1. Analizando caracter√≠sticas del proceso generador...\")\n",
    "        self.analyze_dgp_characteristics(output_dir)\n",
    "        \n",
    "        # 2. AN√ÅLISIS POR DISTRIBUCI√ìN DE ERRORES\n",
    "        print(\"\\n2. Analizando efecto de distribuciones...\")\n",
    "        self.analyze_distribution_effects(output_dir)\n",
    "        \n",
    "        # 3. AN√ÅLISIS POR HORIZONTE DE PREDICCI√ìN\n",
    "        print(\"\\n3. Analizando horizonte de predicci√≥n...\")\n",
    "        self.analyze_horizon_effects(output_dir)\n",
    "        \n",
    "        # 4. AN√ÅLISIS DE INTERACCIONES COMPLEJAS\n",
    "        print(\"\\n4. Analizando interacciones complejas...\")\n",
    "        self.analyze_interactions(output_dir)\n",
    "        \n",
    "        # 5. AN√ÅLISIS DE ROBUSTEZ Y ESTABILIDAD\n",
    "        print(\"\\n5. Analizando robustez y estabilidad...\")\n",
    "        self.analyze_robustness(output_dir)\n",
    "        \n",
    "        # 6. AN√ÅLISIS DE SIGNIFICANCIA ESTAD√çSTICA (DIEBOLD-MARIANO)\n",
    "        print(\"\\n6. Realizando tests de Diebold-Mariano...\")\n",
    "        self.analyze_statistical_significance_dm(output_dir)\n",
    "        \n",
    "        # 7. AN√ÅLISIS POR MODELO INDIVIDUAL\n",
    "        print(\"\\n7. Generando perfiles por modelo...\")\n",
    "        self.analyze_individual_models(output_dir)\n",
    "        \n",
    "        # 8. RECOMENDACIONES Y CONCLUSIONES\n",
    "        print(\"\\n8. Generando recomendaciones...\")\n",
    "        self.generate_recommendations(output_dir)\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"AN√ÅLISIS COMPLETO. Resultados guardados en: {output_dir}/\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "    def analyze_dgp_characteristics(self, output_dir):\n",
    "        \"\"\"\n",
    "        1. AN√ÅLISIS DE CARACTER√çSTICAS DEL PROCESO GENERADOR\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        \n",
    "        # 1.1 Efecto de estacionaridad\n",
    "        print(\"  - Analizando efecto de estacionaridad...\")\n",
    "        for model in self.models:\n",
    "            est_mean = self.df_estacionario[model].mean()\n",
    "            no_est_mean = self.df_no_estacionario[model].mean()\n",
    "            diff = no_est_mean - est_mean\n",
    "            pct_change = (diff / est_mean) * 100 if est_mean != 0 else 0\n",
    "            \n",
    "            results.append({\n",
    "                'Modelo': model,\n",
    "                'ECRPS_Estacionario': est_mean,\n",
    "                'ECRPS_No_Estacionario': no_est_mean,\n",
    "                'Diferencia': diff,\n",
    "                'Cambio_%': pct_change\n",
    "            })\n",
    "        \n",
    "        df_estacionaridad = pd.DataFrame(results)\n",
    "        df_estacionaridad = df_estacionaridad.sort_values('Cambio_%')\n",
    "        df_estacionaridad.to_csv(f'{output_dir}/1_efecto_estacionaridad.csv', index=False)\n",
    "        \n",
    "        # Visualizaci√≥n\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # Gr√°fico de barras comparativas\n",
    "        x = np.arange(len(self.models))\n",
    "        width = 0.35\n",
    "        axes[0].bar(x - width/2, df_estacionaridad['ECRPS_Estacionario'], \n",
    "                   width, label='Estacionario', alpha=0.8)\n",
    "        axes[0].bar(x + width/2, df_estacionaridad['ECRPS_No_Estacionario'], \n",
    "                   width, label='No Estacionario', alpha=0.8)\n",
    "        axes[0].set_xlabel('Modelo')\n",
    "        axes[0].set_ylabel('ECRPS Promedio')\n",
    "        axes[0].set_title('Rendimiento: Estacionario vs No Estacionario')\n",
    "        axes[0].set_xticks(x)\n",
    "        axes[0].set_xticklabels(df_estacionaridad['Modelo'], rotation=45, ha='right')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Gr√°fico de cambio porcentual\n",
    "        colors = ['green' if x < 0 else 'red' for x in df_estacionaridad['Cambio_%']]\n",
    "        axes[1].barh(df_estacionaridad['Modelo'], df_estacionaridad['Cambio_%'], color=colors, alpha=0.7)\n",
    "        axes[1].set_xlabel('Cambio Porcentual (%)')\n",
    "        axes[1].set_title('Impacto de No Estacionaridad\\n(Negativo = Mejor en No Estacionario)')\n",
    "        axes[1].axvline(x=0, color='black', linestyle='--', linewidth=0.8)\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/1_estacionaridad.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # 1.2 Efecto de no linealidad\n",
    "        print(\"  - Analizando efecto de no linealidad...\")\n",
    "        results_nl = []\n",
    "        for model in self.models:\n",
    "            lin_mean = self.df_estacionario[model].mean()\n",
    "            nl_mean = self.df_no_lineal[model].mean()\n",
    "            diff = nl_mean - lin_mean\n",
    "            pct_change = (diff / lin_mean) * 100 if lin_mean != 0 else 0\n",
    "            \n",
    "            results_nl.append({\n",
    "                'Modelo': model,\n",
    "                'ECRPS_Lineal': lin_mean,\n",
    "                'ECRPS_No_Lineal': nl_mean,\n",
    "                'Diferencia': diff,\n",
    "                'Cambio_%': pct_change\n",
    "            })\n",
    "        \n",
    "        df_linealidad = pd.DataFrame(results_nl)\n",
    "        df_linealidad = df_linealidad.sort_values('Cambio_%')\n",
    "        df_linealidad.to_csv(f'{output_dir}/1_efecto_no_linealidad.csv', index=False)\n",
    "        \n",
    "        # Visualizaci√≥n no linealidad\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        x = np.arange(len(self.models))\n",
    "        axes[0].bar(x - width/2, df_linealidad['ECRPS_Lineal'], \n",
    "                   width, label='Lineal', alpha=0.8)\n",
    "        axes[0].bar(x + width/2, df_linealidad['ECRPS_No_Lineal'], \n",
    "                   width, label='No Lineal', alpha=0.8)\n",
    "        axes[0].set_xlabel('Modelo')\n",
    "        axes[0].set_ylabel('ECRPS Promedio')\n",
    "        axes[0].set_title('Rendimiento: Lineal vs No Lineal')\n",
    "        axes[0].set_xticks(x)\n",
    "        axes[0].set_xticklabels(df_linealidad['Modelo'], rotation=45, ha='right')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        colors = ['green' if x < 0 else 'red' for x in df_linealidad['Cambio_%']]\n",
    "        axes[1].barh(df_linealidad['Modelo'], df_linealidad['Cambio_%'], color=colors, alpha=0.7)\n",
    "        axes[1].set_xlabel('Cambio Porcentual (%)')\n",
    "        axes[1].set_title('Impacto de No Linealidad\\n(Negativo = Mejor en No Lineal)')\n",
    "        axes[1].axvline(x=0, color='black', linestyle='--', linewidth=0.8)\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/1_no_linealidad.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # 1.3 An√°lisis por tipo de modelo\n",
    "        print(\"  - Analizando efecto del tipo de modelo...\")\n",
    "        self.analyze_model_type_effect(output_dir)\n",
    "        \n",
    "    def analyze_model_type_effect(self, output_dir):\n",
    "        \"\"\"Analiza el efecto del tipo de modelo en el rendimiento\"\"\"\n",
    "        \n",
    "        # An√°lisis para datos estacionarios\n",
    "        if 'Tipo de Modelo' in self.df_estacionario.columns:\n",
    "            results_type = []\n",
    "            for model in self.models:\n",
    "                for model_type in self.df_estacionario['Tipo de Modelo'].unique():\n",
    "                    subset = self.df_estacionario[self.df_estacionario['Tipo de Modelo'] == model_type]\n",
    "                    if len(subset) > 0:\n",
    "                        results_type.append({\n",
    "                            'Modelo_Predictor': model,\n",
    "                            'Tipo_Proceso': model_type,\n",
    "                            'ECRPS_Mean': subset[model].mean(),\n",
    "                            'ECRPS_Std': subset[model].std(),\n",
    "                            'N_Obs': len(subset)\n",
    "                        })\n",
    "            \n",
    "            df_type = pd.DataFrame(results_type)\n",
    "            df_type.to_csv(f'{output_dir}/1_efecto_tipo_modelo.csv', index=False)\n",
    "            \n",
    "            # Crear heatmap para tipos m√°s comunes\n",
    "            common_types = df_type['Tipo_Proceso'].value_counts().head(10).index\n",
    "            df_type_filtered = df_type[df_type['Tipo_Proceso'].isin(common_types)]\n",
    "            \n",
    "            if len(df_type_filtered) > 0:\n",
    "                pivot = df_type_filtered.pivot_table(\n",
    "                    index='Modelo_Predictor', \n",
    "                    columns='Tipo_Proceso', \n",
    "                    values='ECRPS_Mean'\n",
    "                )\n",
    "                \n",
    "                fig, ax = plt.subplots(figsize=(14, 8))\n",
    "                sns.heatmap(pivot, annot=True, fmt='.4f', cmap='RdYlGn_r', ax=ax, \n",
    "                           cbar_kws={'label': 'ECRPS'})\n",
    "                ax.set_title('Rendimiento por Modelo Predictor y Tipo de Proceso', fontsize=14)\n",
    "                ax.set_xlabel('Tipo de Proceso')\n",
    "                ax.set_ylabel('Modelo Predictor')\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f'{output_dir}/1_heatmap_tipo_modelo.png', dpi=300, bbox_inches='tight')\n",
    "                plt.close()\n",
    "        \n",
    "    def analyze_distribution_effects(self, output_dir):\n",
    "        \"\"\"\n",
    "        2. AN√ÅLISIS DE EFECTOS DE DISTRIBUCI√ìN\n",
    "        \"\"\"\n",
    "        print(\"  - Analizando efectos de distribuciones...\")\n",
    "        \n",
    "        results_dist = []\n",
    "        for model in self.models:\n",
    "            for dist in self.df_all['Distribuci√≥n'].unique():\n",
    "                if pd.notna(dist):\n",
    "                    subset = self.df_all[self.df_all['Distribuci√≥n'] == dist]\n",
    "                    if len(subset) > 0:\n",
    "                        results_dist.append({\n",
    "                            'Modelo': model,\n",
    "                            'Distribuci√≥n': dist,\n",
    "                            'ECRPS_Mean': subset[model].mean(),\n",
    "                            'ECRPS_Std': subset[model].std(),\n",
    "                            'ECRPS_Min': subset[model].min(),\n",
    "                            'ECRPS_Max': subset[model].max()\n",
    "                        })\n",
    "        \n",
    "        df_dist = pd.DataFrame(results_dist)\n",
    "        df_dist.to_csv(f'{output_dir}/2_efecto_distribucion.csv', index=False)\n",
    "        \n",
    "        # Heatmap\n",
    "        if len(df_dist) > 0:\n",
    "            pivot = df_dist.pivot(index='Modelo', columns='Distribuci√≥n', values='ECRPS_Mean')\n",
    "            \n",
    "            fig, ax = plt.subplots(figsize=(10, 8))\n",
    "            sns.heatmap(pivot, annot=True, fmt='.4f', cmap='RdYlGn_r', ax=ax, cbar_kws={'label': 'ECRPS'})\n",
    "            ax.set_title('Rendimiento por Modelo y Distribuci√≥n', fontsize=14)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'{output_dir}/2_heatmap_distribucion.png', dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "        \n",
    "        # An√°lisis por varianza\n",
    "        print(\"  - Analizando efectos de varianza...\")\n",
    "        results_var = []\n",
    "        varianzas_unicas = sorted([v for v in self.df_all['Varianza'].unique() if pd.notna(v)])\n",
    "        \n",
    "        for model in self.models:\n",
    "            for var in varianzas_unicas:\n",
    "                subset = self.df_all[self.df_all['Varianza'] == var]\n",
    "                if len(subset) > 0:\n",
    "                    results_var.append({\n",
    "                        'Modelo': model,\n",
    "                        'Varianza': var,\n",
    "                        'ECRPS_Mean': subset[model].mean(),\n",
    "                        'ECRPS_Std': subset[model].std()\n",
    "                    })\n",
    "        \n",
    "        df_var = pd.DataFrame(results_var)\n",
    "        df_var.to_csv(f'{output_dir}/2_efecto_varianza.csv', index=False)\n",
    "        \n",
    "        # Gr√°fico de l√≠neas por varianza\n",
    "        if len(df_var) > 0:\n",
    "            fig, ax = plt.subplots(figsize=(12, 8))\n",
    "            for model in self.models:\n",
    "                data = df_var[df_var['Modelo'] == model].sort_values('Varianza')\n",
    "                if len(data) > 0:\n",
    "                    ax.plot(data['Varianza'], data['ECRPS_Mean'], marker='o', label=model, linewidth=2)\n",
    "            \n",
    "            ax.set_xlabel('Varianza', fontsize=12)\n",
    "            ax.set_ylabel('ECRPS Promedio', fontsize=12)\n",
    "            ax.set_title('Rendimiento seg√∫n Nivel de Varianza', fontsize=14)\n",
    "            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'{output_dir}/2_efecto_varianza.png', dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "        \n",
    "    def analyze_horizon_effects(self, output_dir):\n",
    "        \"\"\"\n",
    "        3. AN√ÅLISIS DE HORIZONTE DE PREDICCI√ìN\n",
    "        \"\"\"\n",
    "        print(\"  - Analizando deterioro por horizonte...\")\n",
    "        \n",
    "        results_horizon = []\n",
    "        pasos_unicos = sorted([p for p in self.df_all['Paso'].unique() if pd.notna(p)])\n",
    "        \n",
    "        for model in self.models:\n",
    "            for paso in pasos_unicos:\n",
    "                subset = self.df_all[self.df_all['Paso'] == paso]\n",
    "                if len(subset) > 0:\n",
    "                    mean_val = subset[model].mean()\n",
    "                    std_val = subset[model].std()\n",
    "                    cv_val = std_val / mean_val if mean_val != 0 and pd.notna(mean_val) else 0\n",
    "                    \n",
    "                    results_horizon.append({\n",
    "                        'Modelo': model,\n",
    "                        'Paso': int(paso),\n",
    "                        'ECRPS_Mean': mean_val,\n",
    "                        'ECRPS_Std': std_val,\n",
    "                        'ECRPS_CV': cv_val\n",
    "                    })\n",
    "        \n",
    "        df_horizon = pd.DataFrame(results_horizon)\n",
    "        df_horizon.to_csv(f'{output_dir}/3_efecto_horizonte.csv', index=False)\n",
    "        \n",
    "        # Gr√°fico de deterioro\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        \n",
    "        # ECRPS promedio por paso\n",
    "        for model in self.models:\n",
    "            data = df_horizon[df_horizon['Modelo'] == model].sort_values('Paso')\n",
    "            if len(data) > 0:\n",
    "                axes[0].plot(data['Paso'], data['ECRPS_Mean'], marker='o', label=model, linewidth=2)\n",
    "        \n",
    "        axes[0].set_xlabel('Paso de Predicci√≥n', fontsize=12)\n",
    "        axes[0].set_ylabel('ECRPS Promedio', fontsize=12)\n",
    "        axes[0].set_title('Deterioro del Rendimiento por Horizonte', fontsize=14)\n",
    "        axes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Tasa de deterioro\n",
    "        deterioro = []\n",
    "        for model in self.models:\n",
    "            data = df_horizon[df_horizon['Modelo'] == model].sort_values('Paso')\n",
    "            if len(data) >= 2:\n",
    "                paso_values = data['Paso'].tolist()\n",
    "                ecrps_paso1 = data.iloc[0]['ECRPS_Mean']\n",
    "                ecrps_paso_final = data.iloc[-1]['ECRPS_Mean']\n",
    "                \n",
    "                if pd.notna(ecrps_paso1) and pd.notna(ecrps_paso_final) and ecrps_paso1 != 0:\n",
    "                    tasa = ((ecrps_paso_final - ecrps_paso1) / ecrps_paso1) * 100\n",
    "                    deterioro.append({'Modelo': model, 'Deterioro_%': tasa})\n",
    "        \n",
    "        if deterioro:\n",
    "            df_deterioro = pd.DataFrame(deterioro).sort_values('Deterioro_%')\n",
    "            colors = ['green' if x < df_deterioro['Deterioro_%'].median() else 'red' \n",
    "                     for x in df_deterioro['Deterioro_%']]\n",
    "            axes[1].barh(df_deterioro['Modelo'], df_deterioro['Deterioro_%'], color=colors, alpha=0.7)\n",
    "            axes[1].set_xlabel(f'Deterioro Paso {pasos_unicos[0]}‚Üí{pasos_unicos[-1]} (%)', fontsize=12)\n",
    "            axes[1].set_title('Tasa de Deterioro por Modelo', fontsize=14)\n",
    "            axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/3_horizonte_prediccion.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # An√°lisis de consistencia de ranking\n",
    "        print(\"  - Analizando consistencia de ranking...\")\n",
    "        ranking_consistency = []\n",
    "        for paso in pasos_unicos:\n",
    "            subset = self.df_all[self.df_all['Paso'] == paso]\n",
    "            if len(subset) > 0:\n",
    "                ranks = subset[self.models].mean().rank()\n",
    "                rank_dict = ranks.to_dict()\n",
    "                rank_dict['Paso'] = int(paso)\n",
    "                ranking_consistency.append(rank_dict)\n",
    "        \n",
    "        df_ranks = pd.DataFrame(ranking_consistency)\n",
    "        df_ranks.to_csv(f'{output_dir}/3_ranking_por_paso.csv', index=False)\n",
    "        \n",
    "    def analyze_interactions(self, output_dir):\n",
    "        \"\"\"\n",
    "        4. AN√ÅLISIS DE INTERACCIONES COMPLEJAS\n",
    "        \"\"\"\n",
    "        print(\"  - Analizando interacciones Escenario √ó Distribuci√≥n...\")\n",
    "        \n",
    "        results_int = []\n",
    "        for model in self.models:\n",
    "            for escenario in self.df_all['Escenario'].unique():\n",
    "                for dist in self.df_all['Distribuci√≥n'].unique():\n",
    "                    subset = self.df_all[(self.df_all['Escenario'] == escenario) & \n",
    "                                        (self.df_all['Distribuci√≥n'] == dist)]\n",
    "                    if len(subset) > 0:\n",
    "                        results_int.append({\n",
    "                            'Modelo': model,\n",
    "                            'Escenario': escenario,\n",
    "                            'Distribuci√≥n': dist,\n",
    "                            'ECRPS_Mean': subset[model].mean()\n",
    "                        })\n",
    "        \n",
    "        df_int = pd.DataFrame(results_int)\n",
    "        df_int.to_csv(f'{output_dir}/4_interacciones.csv', index=False)\n",
    "        \n",
    "        # Heatmap de interacciones para cada modelo\n",
    "        for model in self.models[:3]:  # Solo primeros 3 por espacio\n",
    "            model_data = df_int[df_int['Modelo'] == model]\n",
    "            if len(model_data) > 0:\n",
    "                pivot = model_data.pivot(\n",
    "                    index='Escenario', columns='Distribuci√≥n', values='ECRPS_Mean')\n",
    "                \n",
    "                fig, ax = plt.subplots(figsize=(10, 6))\n",
    "                sns.heatmap(pivot, annot=True, fmt='.4f', cmap='RdYlGn_r', ax=ax)\n",
    "                ax.set_title(f'Interacci√≥n Escenario √ó Distribuci√≥n: {model}', fontsize=12)\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f'{output_dir}/4_interaccion_{model.replace(\" \", \"_\")}.png', \n",
    "                           dpi=300, bbox_inches='tight')\n",
    "                plt.close()\n",
    "        \n",
    "        # Interacci√≥n triple: Escenario √ó Varianza √ó Paso\n",
    "        print(\"  - Analizando interacci√≥n triple...\")\n",
    "        results_triple = []\n",
    "        \n",
    "        varianzas_unicas = sorted([v for v in self.df_all['Varianza'].unique() if pd.notna(v)])\n",
    "        pasos_unicos = sorted([p for p in self.df_all['Paso'].unique() if pd.notna(p)])\n",
    "        \n",
    "        for model in self.models:\n",
    "            for escenario in self.df_all['Escenario'].unique():\n",
    "                for var in varianzas_unicas:\n",
    "                    for paso in pasos_unicos:\n",
    "                        subset = self.df_all[\n",
    "                            (self.df_all['Escenario'] == escenario) & \n",
    "                            (self.df_all['Varianza'] == var) &\n",
    "                            (self.df_all['Paso'] == paso)\n",
    "                        ]\n",
    "                        if len(subset) > 0:\n",
    "                            results_triple.append({\n",
    "                                'Modelo': model,\n",
    "                                'Escenario': escenario,\n",
    "                                'Varianza': var,\n",
    "                                'Paso': int(paso),\n",
    "                                'ECRPS_Mean': subset[model].mean()\n",
    "                            })\n",
    "        \n",
    "        df_triple = pd.DataFrame(results_triple)\n",
    "        df_triple.to_csv(f'{output_dir}/4_interaccion_triple.csv', index=False)\n",
    "        \n",
    "    def analyze_robustness(self, output_dir):\n",
    "        \"\"\"\n",
    "        5. AN√ÅLISIS DE ROBUSTEZ Y ESTABILIDAD\n",
    "        \"\"\"\n",
    "        print(\"  - Calculando m√©tricas de robustez...\")\n",
    "        \n",
    "        results_robust = []\n",
    "        for model in self.models:\n",
    "            ecrps_values = self.df_all[model]\n",
    "            \n",
    "            results_robust.append({\n",
    "                'Modelo': model,\n",
    "                'ECRPS_Mean': ecrps_values.mean(),\n",
    "                'ECRPS_Std': ecrps_values.std(),\n",
    "                'ECRPS_CV': ecrps_values.std() / ecrps_values.mean() if ecrps_values.mean() != 0 else 0,\n",
    "                'ECRPS_Min': ecrps_values.min(),\n",
    "                'ECRPS_Q25': ecrps_values.quantile(0.25),\n",
    "                'ECRPS_Median': ecrps_values.median(),\n",
    "                'ECRPS_Q75': ecrps_values.quantile(0.75),\n",
    "                'ECRPS_Max': ecrps_values.max(),\n",
    "                'ECRPS_IQR': ecrps_values.quantile(0.75) - ecrps_values.quantile(0.25)\n",
    "            })\n",
    "        \n",
    "        df_robust = pd.DataFrame(results_robust)\n",
    "        df_robust = df_robust.sort_values('ECRPS_CV')\n",
    "        df_robust.to_csv(f'{output_dir}/5_robustez.csv', index=False)\n",
    "        \n",
    "        # Gr√°fico de robustez\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        \n",
    "        # Coeficiente de variaci√≥n\n",
    "        axes[0, 0].barh(df_robust['Modelo'], df_robust['ECRPS_CV'], alpha=0.7)\n",
    "        axes[0, 0].set_xlabel('Coeficiente de Variaci√≥n')\n",
    "        axes[0, 0].set_title('Estabilidad (Menor CV = M√°s Estable)')\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Rango intercuart√≠lico\n",
    "        axes[0, 1].barh(df_robust['Modelo'], df_robust['ECRPS_IQR'], alpha=0.7, color='coral')\n",
    "        axes[0, 1].set_xlabel('Rango Intercuart√≠lico')\n",
    "        axes[0, 1].set_title('Variabilidad (Menor IQR = M√°s Consistente)')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Boxplot comparativo\n",
    "        data_box = [self.df_all[model] for model in self.models]\n",
    "        bp = axes[1, 0].boxplot(data_box, labels=self.models, patch_artist=True)\n",
    "        for patch in bp['boxes']:\n",
    "            patch.set_facecolor('lightblue')\n",
    "        axes[1, 0].set_ylabel('ECRPS')\n",
    "        axes[1, 0].set_title('Distribuci√≥n de ECRPS por Modelo')\n",
    "        axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Scatter: Media vs Variabilidad\n",
    "        axes[1, 1].scatter(df_robust['ECRPS_Mean'], df_robust['ECRPS_Std'], \n",
    "                          s=100, alpha=0.6, c=range(len(df_robust)), cmap='viridis')\n",
    "        for idx, row in df_robust.iterrows():\n",
    "            axes[1, 1].annotate(row['Modelo'], \n",
    "                               (row['ECRPS_Mean'], row['ECRPS_Std']),\n",
    "                               fontsize=8, alpha=0.7)\n",
    "        axes[1, 1].set_xlabel('ECRPS Promedio')\n",
    "        axes[1, 1].set_ylabel('Desviaci√≥n Est√°ndar')\n",
    "        axes[1, 1].set_title('Trade-off Rendimiento vs Estabilidad')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/5_robustez.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # An√°lisis de peores casos\n",
    "        print(\"  - Identificando peores casos...\")\n",
    "        worst_cases = []\n",
    "        for model in self.models:\n",
    "            df_temp = self.df_all.copy()\n",
    "            df_temp['ECRPS'] = df_temp[model]\n",
    "            worst = df_temp.nlargest(10, 'ECRPS')[\n",
    "                ['Escenario', 'Tipo de Modelo', 'Distribuci√≥n', 'Varianza', 'Paso', 'ECRPS']\n",
    "            ]\n",
    "            worst['Modelo_Predictor'] = model\n",
    "            worst_cases.append(worst)\n",
    "        \n",
    "        df_worst = pd.concat(worst_cases, ignore_index=True)\n",
    "        df_worst.to_csv(f'{output_dir}/5_peores_casos.csv', index=False)\n",
    "        \n",
    "    def analyze_statistical_significance_dm(self, output_dir):\n",
    "        \"\"\"\n",
    "        6. AN√ÅLISIS DE SIGNIFICANCIA ESTAD√çSTICA CON DIEBOLD-MARIANO\n",
    "        \"\"\"\n",
    "        print(\"  - Realizando tests de Diebold-Mariano...\")\n",
    "        \n",
    "        # Test de Friedman por escenario (para comparaci√≥n general)\n",
    "        results_friedman = []\n",
    "        for escenario in self.df_all['Escenario'].unique():\n",
    "            subset = self.df_all[self.df_all['Escenario'] == escenario]\n",
    "            data_matrix = subset[self.models].values\n",
    "            \n",
    "            try:\n",
    "                statistic, p_value = friedmanchisquare(*[data_matrix[:, i] for i in range(len(self.models))])\n",
    "                \n",
    "                results_friedman.append({\n",
    "                    'Escenario': escenario,\n",
    "                    'Friedman_Statistic': statistic,\n",
    "                    'P_Value': p_value,\n",
    "                    'Significativo': 'S√≠' if p_value < 0.05 else 'No'\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"    Advertencia: Error en test de Friedman para {escenario}: {e}\")\n",
    "        \n",
    "        if results_friedman:\n",
    "            df_friedman = pd.DataFrame(results_friedman)\n",
    "            df_friedman.to_csv(f'{output_dir}/6_test_friedman.csv', index=False)\n",
    "        \n",
    "        # Tests de Diebold-Mariano pareados\n",
    "        print(\"  - Realizando tests pareados de Diebold-Mariano...\")\n",
    "        pairs = list(combinations(self.models, 2))\n",
    "        dm_results = []\n",
    "        \n",
    "        for model1, model2 in pairs:\n",
    "            # Calcular errores (usamos ECRPS directamente como m√©trica de p√©rdida)\n",
    "            errors1 = self.df_all[model1].values\n",
    "            errors2 = self.df_all[model2].values\n",
    "            \n",
    "            # Test de Diebold-Mariano\n",
    "            dm_stat, p_value = DieboldMarianoTest.dm_test(errors1, errors2, h=1, crit=\"MSE\")\n",
    "            \n",
    "            mean_diff = self.df_all[model1].mean() - self.df_all[model2].mean()\n",
    "            \n",
    "            # Determinar ganador\n",
    "            if p_value < 0.05:\n",
    "                if mean_diff < 0:\n",
    "                    ganador = model1\n",
    "                else:\n",
    "                    ganador = model2\n",
    "            else:\n",
    "                ganador = 'Empate'\n",
    "            \n",
    "            dm_results.append({\n",
    "                'Modelo_1': model1,\n",
    "                'Modelo_2': model2,\n",
    "                'Diferencia_Media': mean_diff,\n",
    "                'DM_Statistic': dm_stat,\n",
    "                'P_Value': p_value,\n",
    "                'Significativo_0.05': 'S√≠' if p_value < 0.05 else 'No',\n",
    "                'Significativo_0.01': 'S√≠' if p_value < 0.01 else 'No',\n",
    "                'Ganador': ganador\n",
    "            })\n",
    "        \n",
    "        df_dm = pd.DataFrame(dm_results)\n",
    "        df_dm = df_dm.sort_values('P_Value')\n",
    "        df_dm.to_csv(f'{output_dir}/6_tests_diebold_mariano.csv', index=False)\n",
    "        \n",
    "        # Matriz de p-valores (Diebold-Mariano)\n",
    "        print(\"  - Creando matriz de p-valores...\")\n",
    "        p_matrix = np.ones((len(self.models), len(self.models)))\n",
    "        for i, model1 in enumerate(self.models):\n",
    "            for j, model2 in enumerate(self.models):\n",
    "                if i != j:\n",
    "                    errors1 = self.df_all[model1].values\n",
    "                    errors2 = self.df_all[model2].values\n",
    "                    _, p_val = DieboldMarianoTest.dm_test(errors1, errors2, h=1, crit=\"MSE\")\n",
    "                    p_matrix[i, j] = p_val\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 10))\n",
    "        sns.heatmap(p_matrix, annot=True, fmt='.3f', cmap='RdYlGn', \n",
    "                   xticklabels=self.models, yticklabels=self.models, \n",
    "                   ax=ax, vmin=0, vmax=0.1, cbar_kws={'label': 'P-valor'})\n",
    "        ax.set_title('Matriz de P-valores (Test de Diebold-Mariano)\\nVerde = Diferencia Significativa', \n",
    "                    fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/6_matriz_pvalores_dm.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # Dominancia estad√≠stica con Diebold-Mariano\n",
    "        print(\"  - Analizando dominancia estad√≠stica...\")\n",
    "        dominance = []\n",
    "        for model in self.models:\n",
    "            wins = 0\n",
    "            losses = 0\n",
    "            ties = 0\n",
    "            for other_model in self.models:\n",
    "                if model != other_model:\n",
    "                    errors1 = self.df_all[model].values\n",
    "                    errors2 = self.df_all[other_model].values\n",
    "                    _, p_val = DieboldMarianoTest.dm_test(errors1, errors2, h=1, crit=\"MSE\")\n",
    "                    mean_diff = self.df_all[model].mean() - self.df_all[other_model].mean()\n",
    "                    \n",
    "                    if p_val < 0.05:\n",
    "                        if mean_diff < 0:  # modelo es mejor (menor ECRPS)\n",
    "                            wins += 1\n",
    "                        else:\n",
    "                            losses += 1\n",
    "                    else:\n",
    "                        ties += 1\n",
    "            \n",
    "            dominance.append({\n",
    "                'Modelo': model,\n",
    "                'Victorias_Significativas': wins,\n",
    "                'Derrotas_Significativas': losses,\n",
    "                'Empates': ties,\n",
    "                'Score_Neto': wins - losses\n",
    "            })\n",
    "        \n",
    "        df_dominance = pd.DataFrame(dominance)\n",
    "        df_dominance = df_dominance.sort_values('Score_Neto', ascending=False)\n",
    "        df_dominance.to_csv(f'{output_dir}/6_dominancia_estadistica_dm.csv', index=False)\n",
    "        \n",
    "        # Visualizaci√≥n de dominancia\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        x = np.arange(len(df_dominance))\n",
    "        width = 0.25\n",
    "        \n",
    "        ax.bar(x - width, df_dominance['Victorias_Significativas'], \n",
    "               width, label='Victorias', color='green', alpha=0.7)\n",
    "        ax.bar(x, df_dominance['Empates'], \n",
    "               width, label='Empates', color='gray', alpha=0.7)\n",
    "        ax.bar(x + width, df_dominance['Derrotas_Significativas'], \n",
    "               width, label='Derrotas', color='red', alpha=0.7)\n",
    "        \n",
    "        ax.set_xlabel('Modelo')\n",
    "        ax.set_ylabel('N√∫mero de Comparaciones')\n",
    "        ax.set_title('Dominancia Estad√≠stica (Test Diebold-Mariano)')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(df_dominance['Modelo'], rotation=45, ha='right')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/6_dominancia_dm.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # An√°lisis de Diebold-Mariano por escenario\n",
    "        print(\"  - Analizando DM por escenario...\")\n",
    "        dm_by_scenario = []\n",
    "        for escenario in self.df_all['Escenario'].unique():\n",
    "            subset = self.df_all[self.df_all['Escenario'] == escenario]\n",
    "            \n",
    "            for model1, model2 in combinations(self.models, 2):\n",
    "                errors1 = subset[model1].values\n",
    "                errors2 = subset[model2].values\n",
    "                \n",
    "                if len(errors1) > 0 and len(errors2) > 0:\n",
    "                    dm_stat, p_value = DieboldMarianoTest.dm_test(errors1, errors2, h=1, crit=\"MSE\")\n",
    "                    mean_diff = subset[model1].mean() - subset[model2].mean()\n",
    "                    \n",
    "                    dm_by_scenario.append({\n",
    "                        'Escenario': escenario,\n",
    "                        'Modelo_1': model1,\n",
    "                        'Modelo_2': model2,\n",
    "                        'DM_Statistic': dm_stat,\n",
    "                        'P_Value': p_value,\n",
    "                        'Diferencia_Media': mean_diff,\n",
    "                        'Significativo': 'S√≠' if p_value < 0.05 else 'No'\n",
    "                    })\n",
    "        \n",
    "        df_dm_scenario = pd.DataFrame(dm_by_scenario)\n",
    "        df_dm_scenario.to_csv(f'{output_dir}/6_dm_por_escenario.csv', index=False)\n",
    "    \n",
    "    def analyze_individual_models(self, output_dir):\n",
    "        \"\"\"\n",
    "        7. PERFILES INDIVIDUALES POR MODELO\n",
    "        \"\"\"\n",
    "        print(\"  - Generando perfiles individuales...\")\n",
    "        \n",
    "        for model in self.models:\n",
    "            print(f\"    > Analizando {model}...\")\n",
    "            \n",
    "            # Crear subdirectorio para el modelo\n",
    "            model_dir = f\"{output_dir}/perfiles_modelos/{model.replace(' ', '_')}\"\n",
    "            import os\n",
    "            os.makedirs(model_dir, exist_ok=True)\n",
    "            \n",
    "            # Reporte del modelo\n",
    "            report = []\n",
    "            report.append(f\"=\"*80)\n",
    "            report.append(f\"PERFIL DETALLADO: {model}\")\n",
    "            report.append(f\"=\"*80)\n",
    "            report.append(\"\")\n",
    "            \n",
    "            # Estad√≠sticas generales\n",
    "            report.append(\"1. ESTAD√çSTICAS GENERALES\")\n",
    "            report.append(\"-\" * 40)\n",
    "            report.append(f\"ECRPS Promedio Global: {self.df_all[model].mean():.6f}\")\n",
    "            report.append(f\"Desviaci√≥n Est√°ndar: {self.df_all[model].std():.6f}\")\n",
    "            cv = self.df_all[model].std()/self.df_all[model].mean() if self.df_all[model].mean() != 0 else 0\n",
    "            report.append(f\"Coeficiente de Variaci√≥n: {cv:.4f}\")\n",
    "            report.append(f\"M√≠nimo: {self.df_all[model].min():.6f}\")\n",
    "            report.append(f\"Mediana: {self.df_all[model].median():.6f}\")\n",
    "            report.append(f\"M√°ximo: {self.df_all[model].max():.6f}\")\n",
    "            report.append(\"\")\n",
    "            \n",
    "            # Ranking general\n",
    "            mean_scores = self.df_all[self.models].mean()\n",
    "            ranking = mean_scores.rank().astype(int)\n",
    "            report.append(f\"Ranking General: {ranking[model]}¬∞ de {len(self.models)}\")\n",
    "            report.append(\"\")\n",
    "            \n",
    "            # Mejor escenario\n",
    "            report.append(\"2. MEJORES ESCENARIOS\")\n",
    "            report.append(\"-\" * 40)\n",
    "            best_idx = self.df_all[model].idxmin()\n",
    "            best_row = self.df_all.loc[best_idx]\n",
    "            report.append(f\"Mejor ECRPS: {best_row[model]:.6f}\")\n",
    "            report.append(f\"  - Escenario: {best_row['Escenario']}\")\n",
    "            if 'Tipo de Modelo' in best_row:\n",
    "                report.append(f\"  - Tipo Modelo: {best_row['Tipo de Modelo']}\")\n",
    "            report.append(f\"  - Distribuci√≥n: {best_row['Distribuci√≥n']}\")\n",
    "            report.append(f\"  - Varianza: {best_row['Varianza']}\")\n",
    "            report.append(f\"  - Paso: {best_row['Paso']}\")\n",
    "            report.append(\"\")\n",
    "            \n",
    "            # Peor escenario\n",
    "            report.append(\"3. PEORES ESCENARIOS\")\n",
    "            report.append(\"-\" * 40)\n",
    "            worst_idx = self.df_all[model].idxmax()\n",
    "            worst_row = self.df_all.loc[worst_idx]\n",
    "            report.append(f\"Peor ECRPS: {worst_row[model]:.6f}\")\n",
    "            report.append(f\"  - Escenario: {worst_row['Escenario']}\")\n",
    "            if 'Tipo de Modelo' in worst_row:\n",
    "                report.append(f\"  - Tipo Modelo: {worst_row['Tipo de Modelo']}\")\n",
    "            report.append(f\"  - Distribuci√≥n: {worst_row['Distribuci√≥n']}\")\n",
    "            report.append(f\"  - Varianza: {worst_row['Varianza']}\")\n",
    "            report.append(f\"  - Paso: {worst_row['Paso']}\")\n",
    "            report.append(\"\")\n",
    "            \n",
    "            # Rendimiento por escenario\n",
    "            report.append(\"4. RENDIMIENTO POR ESCENARIO\")\n",
    "            report.append(\"-\" * 40)\n",
    "            for escenario in ['Estacionario_Lineal', 'No_Estacionario_Lineal', 'No_Lineal']:\n",
    "                subset = self.df_all[self.df_all['Escenario'] == escenario]\n",
    "                if len(subset) > 0:\n",
    "                    mean_val = subset[model].mean()\n",
    "                    rank = subset[self.models].mean().rank()[model]\n",
    "                    report.append(f\"{escenario}:\")\n",
    "                    report.append(f\"  ECRPS: {mean_val:.6f} (Ranking: {int(rank)}¬∞)\")\n",
    "            report.append(\"\")\n",
    "            \n",
    "            # Fortalezas y debilidades\n",
    "            report.append(\"5. FORTALEZAS Y DEBILIDADES\")\n",
    "            report.append(\"-\" * 40)\n",
    "            \n",
    "            # Por distribuci√≥n\n",
    "            report.append(\"Por Distribuci√≥n:\")\n",
    "            dist_performance = []\n",
    "            for dist in self.df_all['Distribuci√≥n'].unique():\n",
    "                subset = self.df_all[self.df_all['Distribuci√≥n'] == dist]\n",
    "                if len(subset) > 0:\n",
    "                    mean_val = subset[model].mean()\n",
    "                    rank = subset[self.models].mean().rank()[model]\n",
    "                    dist_performance.append((dist, mean_val, rank))\n",
    "            \n",
    "            if dist_performance:\n",
    "                dist_performance.sort(key=lambda x: x[2])\n",
    "                report.append(f\"  Mejor: {dist_performance[0][0]} (Ranking {int(dist_performance[0][2])}¬∞)\")\n",
    "                report.append(f\"  Peor: {dist_performance[-1][0]} (Ranking {int(dist_performance[-1][2])}¬∞)\")\n",
    "            report.append(\"\")\n",
    "            \n",
    "            # Por varianza\n",
    "            report.append(\"Por Varianza:\")\n",
    "            var_performance = []\n",
    "            for var in sorted(self.df_all['Varianza'].unique()):\n",
    "                subset = self.df_all[self.df_all['Varianza'] == var]\n",
    "                if len(subset) > 0:\n",
    "                    mean_val = subset[model].mean()\n",
    "                    rank = subset[self.models].mean().rank()[model]\n",
    "                    var_performance.append((var, mean_val, rank))\n",
    "            \n",
    "            if var_performance:\n",
    "                var_performance.sort(key=lambda x: x[2])\n",
    "                report.append(f\"  Mejor: Varianza {var_performance[0][0]} (Ranking {int(var_performance[0][2])}¬∞)\")\n",
    "                report.append(f\"  Peor: Varianza {var_performance[-1][0]} (Ranking {int(var_performance[-1][2])}¬∞)\")\n",
    "            report.append(\"\")\n",
    "            \n",
    "            # Comparaciones con Diebold-Mariano\n",
    "            report.append(\"6. COMPARACIONES ESTAD√çSTICAS (DIEBOLD-MARIANO)\")\n",
    "            report.append(\"-\" * 40)\n",
    "            \n",
    "            wins = 0\n",
    "            losses = 0\n",
    "            for other_model in self.models:\n",
    "                if model != other_model:\n",
    "                    errors1 = self.df_all[model].values\n",
    "                    errors2 = self.df_all[other_model].values\n",
    "                    _, p_val = DieboldMarianoTest.dm_test(errors1, errors2, h=1, crit=\"MSE\")\n",
    "                    mean_diff = self.df_all[model].mean() - self.df_all[other_model].mean()\n",
    "                    \n",
    "                    if p_val < 0.05:\n",
    "                        if mean_diff < 0:\n",
    "                            wins += 1\n",
    "                        else:\n",
    "                            losses += 1\n",
    "            \n",
    "            report.append(f\"Victorias significativas: {wins}\")\n",
    "            report.append(f\"Derrotas significativas: {losses}\")\n",
    "            report.append(f\"Score neto: {wins - losses}\")\n",
    "            report.append(\"\")\n",
    "            \n",
    "            # Guardar reporte\n",
    "            with open(f\"{model_dir}/perfil_{model.replace(' ', '_')}.txt\", 'w', encoding='utf-8') as f:\n",
    "                f.write('\\n'.join(report))\n",
    "            \n",
    "            # Visualizaciones del modelo\n",
    "            self._create_model_visualizations(model, model_dir)\n",
    "    \n",
    "    def _create_model_visualizations(self, model, model_dir):\n",
    "        \"\"\"Crea visualizaciones espec√≠ficas para un modelo\"\"\"\n",
    "        \n",
    "        # 1. Distribuci√≥n de ECRPS\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        \n",
    "        # Histograma\n",
    "        axes[0, 0].hist(self.df_all[model], bins=50, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "        axes[0, 0].axvline(self.df_all[model].mean(), color='red', linestyle='--', \n",
    "                          linewidth=2, label=f'Media: {self.df_all[model].mean():.4f}')\n",
    "        axes[0, 0].axvline(self.df_all[model].median(), color='green', linestyle='--', \n",
    "                          linewidth=2, label=f'Mediana: {self.df_all[model].median():.4f}')\n",
    "        axes[0, 0].set_xlabel('ECRPS')\n",
    "        axes[0, 0].set_ylabel('Frecuencia')\n",
    "        axes[0, 0].set_title(f'Distribuci√≥n de ECRPS - {model}')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Boxplot por escenario\n",
    "        data_by_scenario = [self.df_all[self.df_all['Escenario'] == esc][model] \n",
    "                           for esc in ['Estacionario_Lineal', 'No_Estacionario_Lineal', 'No_Lineal']]\n",
    "        bp = axes[0, 1].boxplot(data_by_scenario, labels=['Est. Lin.', 'No Est. Lin.', 'No Lin.'], \n",
    "                               patch_artist=True)\n",
    "        for patch, color in zip(bp['boxes'], ['lightblue', 'lightcoral', 'lightgreen']):\n",
    "            patch.set_facecolor(color)\n",
    "        axes[0, 1].set_ylabel('ECRPS')\n",
    "        axes[0, 1].set_title(f'ECRPS por Escenario - {model}')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Rendimiento por paso\n",
    "        paso_data = []\n",
    "        for p in sorted(self.df_all['Paso'].unique()):\n",
    "            subset = self.df_all[self.df_all['Paso'] == p]\n",
    "            if len(subset) > 0:\n",
    "                paso_data.append((p, subset[model].mean()))\n",
    "        \n",
    "        if paso_data:\n",
    "            pasos, means = zip(*paso_data)\n",
    "            axes[1, 0].plot(pasos, means, marker='o', linewidth=2, markersize=8, color='darkblue')\n",
    "            axes[1, 0].set_xlabel('Paso de Predicci√≥n')\n",
    "            axes[1, 0].set_ylabel('ECRPS Promedio')\n",
    "            axes[1, 0].set_title(f'Rendimiento por Horizonte - {model}')\n",
    "            axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Heatmap: Distribuci√≥n √ó Varianza\n",
    "        pivot_data = []\n",
    "        dist_labels = []\n",
    "        var_labels = sorted(self.df_all['Varianza'].unique())\n",
    "        \n",
    "        for dist in self.df_all['Distribuci√≥n'].unique():\n",
    "            row = []\n",
    "            for var in var_labels:\n",
    "                subset = self.df_all[(self.df_all['Distribuci√≥n'] == dist) & \n",
    "                                    (self.df_all['Varianza'] == var)]\n",
    "                if len(subset) > 0:\n",
    "                    row.append(subset[model].mean())\n",
    "                else:\n",
    "                    row.append(np.nan)\n",
    "            if not all(np.isnan(row)):\n",
    "                pivot_data.append(row)\n",
    "                dist_labels.append(dist)\n",
    "        \n",
    "        if pivot_data:\n",
    "            pivot_df = pd.DataFrame(pivot_data, index=dist_labels, columns=var_labels)\n",
    "            \n",
    "            sns.heatmap(pivot_df, annot=True, fmt='.4f', cmap='RdYlGn_r', ax=axes[1, 1],\n",
    "                       cbar_kws={'label': 'ECRPS'})\n",
    "            axes[1, 1].set_title(f'ECRPS: Distribuci√≥n √ó Varianza - {model}')\n",
    "            axes[1, 1].set_xlabel('Varianza')\n",
    "            axes[1, 1].set_ylabel('Distribuci√≥n')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{model_dir}/visualizaciones_{model.replace(\" \", \"_\")}.png', \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # 2. Comparaci√≥n con otros modelos\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        \n",
    "        means = self.df_all[self.models].mean().sort_values()\n",
    "        colors = ['red' if m == model else 'steelblue' for m in means.index]\n",
    "        bars = ax.barh(means.index, means.values, color=colors, alpha=0.7)\n",
    "        \n",
    "        # Destacar el modelo actual\n",
    "        for i, bar in enumerate(bars):\n",
    "            if means.index[i] == model:\n",
    "                bar.set_edgecolor('black')\n",
    "                bar.set_linewidth(3)\n",
    "        \n",
    "        ax.set_xlabel('ECRPS Promedio')\n",
    "        ax.set_title(f'Comparaci√≥n Global - {model} (Destacado en Rojo)')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{model_dir}/comparacion_{model.replace(\" \", \"_\")}.png', \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    def generate_recommendations(self, output_dir):\n",
    "        \"\"\"\n",
    "        8. GENERACI√ìN DE RECOMENDACIONES\n",
    "        \"\"\"\n",
    "        print(\"  - Generando recomendaciones estrat√©gicas...\")\n",
    "        \n",
    "        recommendations = []\n",
    "        recommendations.append(\"=\"*80)\n",
    "        recommendations.append(\"RECOMENDACIONES Y CONCLUSIONES\")\n",
    "        recommendations.append(\"=\"*80)\n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # 1. Modelo campe√≥n general\n",
    "        overall_best = self.df_all[self.models].mean().idxmin()\n",
    "        overall_worst = self.df_all[self.models].mean().idxmax()\n",
    "        \n",
    "        recommendations.append(\"1. MODELO CAMPE√ìN GENERAL\")\n",
    "        recommendations.append(\"-\" * 40)\n",
    "        recommendations.append(f\"Mejor rendimiento promedio: {overall_best}\")\n",
    "        recommendations.append(f\"ECRPS: {self.df_all[overall_best].mean():.6f}\")\n",
    "        recommendations.append(f\"Desviaci√≥n Est√°ndar: {self.df_all[overall_best].std():.6f}\")\n",
    "        recommendations.append(\"\")\n",
    "        recommendations.append(f\"Peor rendimiento promedio: {overall_worst}\")\n",
    "        recommendations.append(f\"ECRPS: {self.df_all[overall_worst].mean():.6f}\")\n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # 2. Modelos por escenario\n",
    "        recommendations.append(\"2. RECOMENDACIONES POR ESCENARIO\")\n",
    "        recommendations.append(\"-\" * 40)\n",
    "        \n",
    "        for escenario in ['Estacionario_Lineal', 'No_Estacionario_Lineal', 'No_Lineal']:\n",
    "            subset = self.df_all[self.df_all['Escenario'] == escenario]\n",
    "            if len(subset) > 0:\n",
    "                best_model = subset[self.models].mean().idxmin()\n",
    "                best_score = subset[best_model].mean()\n",
    "                \n",
    "                recommendations.append(f\"\\n{escenario}:\")\n",
    "                recommendations.append(f\"  Modelo Recomendado: {best_model}\")\n",
    "                recommendations.append(f\"  ECRPS Promedio: {best_score:.6f}\")\n",
    "        \n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # 3. Modelos por distribuci√≥n\n",
    "        recommendations.append(\"3. RECOMENDACIONES POR DISTRIBUCI√ìN DE ERRORES\")\n",
    "        recommendations.append(\"-\" * 40)\n",
    "        \n",
    "        for dist in self.df_all['Distribuci√≥n'].unique():\n",
    "            subset = self.df_all[self.df_all['Distribuci√≥n'] == dist]\n",
    "            if len(subset) > 0:\n",
    "                best_model = subset[self.models].mean().idxmin()\n",
    "                best_score = subset[best_model].mean()\n",
    "                \n",
    "                recommendations.append(f\"\\nDistribuci√≥n {dist}:\")\n",
    "                recommendations.append(f\"  Modelo Recomendado: {best_model}\")\n",
    "                recommendations.append(f\"  ECRPS Promedio: {best_score:.6f}\")\n",
    "        \n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # 4. Modelos m√°s robustos\n",
    "        recommendations.append(\"4. MODELOS M√ÅS ROBUSTOS (MENOR VARIABILIDAD)\")\n",
    "        recommendations.append(\"-\" * 40)\n",
    "        \n",
    "        cv_scores = {model: self.df_all[model].std() / self.df_all[model].mean() \n",
    "                    for model in self.models if self.df_all[model].mean() != 0}\n",
    "        cv_sorted = sorted(cv_scores.items(), key=lambda x: x[1])\n",
    "        \n",
    "        for i, (model, cv) in enumerate(cv_sorted[:3], 1):\n",
    "            recommendations.append(f\"{i}. {model}: CV = {cv:.4f}\")\n",
    "        \n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # 5. Modelos por horizonte\n",
    "        recommendations.append(\"5. RECOMENDACIONES POR HORIZONTE DE PREDICCI√ìN\")\n",
    "        recommendations.append(\"-\" * 40)\n",
    "        \n",
    "        pasos_unicos = sorted(self.df_all['Paso'].unique())\n",
    "        for paso in [pasos_unicos[0], pasos_unicos[len(pasos_unicos)//2], pasos_unicos[-1]]:\n",
    "            subset = self.df_all[self.df_all['Paso'] == paso]\n",
    "            if len(subset) > 0:\n",
    "                best_model = subset[self.models].mean().idxmin()\n",
    "                best_score = subset[best_model].mean()\n",
    "                \n",
    "                recommendations.append(f\"\\nPaso {paso}:\")\n",
    "                recommendations.append(f\"  Modelo Recomendado: {best_model}\")\n",
    "                recommendations.append(f\"  ECRPS Promedio: {best_score:.6f}\")\n",
    "        \n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # 6. Estrategia de ensamble\n",
    "        recommendations.append(\"6. ESTRATEGIA DE ENSAMBLE SUGERIDA\")\n",
    "        recommendations.append(\"-\" * 40)\n",
    "        \n",
    "        # Top 3 modelos complementarios\n",
    "        top3 = self.df_all[self.models].mean().nsmallest(3)\n",
    "        recommendations.append(\"Combinar los siguientes modelos:\")\n",
    "        for i, (model, score) in enumerate(top3.items(), 1):\n",
    "            recommendations.append(f\"{i}. {model} (ECRPS: {score:.6f})\")\n",
    "        \n",
    "        recommendations.append(\"\")\n",
    "        recommendations.append(\"Justificaci√≥n:\")\n",
    "        recommendations.append(\"  - Estos modelos muestran el mejor rendimiento promedio\")\n",
    "        recommendations.append(\"  - Un ensamble puede capturar fortalezas complementarias\")\n",
    "        recommendations.append(\"  - Reduce el riesgo de seleccionar un modelo sub√≥ptimo\")\n",
    "        \n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # 7. Modelos con dominancia estad√≠stica\n",
    "        recommendations.append(\"7. MODELOS CON DOMINANCIA ESTAD√çSTICA\")\n",
    "        recommendations.append(\"-\" * 40)\n",
    "        \n",
    "        dominance_scores = []\n",
    "        for model in self.models:\n",
    "            wins = 0\n",
    "            for other_model in self.models:\n",
    "                if model != other_model:\n",
    "                    errors1 = self.df_all[model].values\n",
    "                    errors2 = self.df_all[other_model].values\n",
    "                    _, p_val = DieboldMarianoTest.dm_test(errors1, errors2, h=1, crit=\"MSE\")\n",
    "                    mean_diff = self.df_all[model].mean() - self.df_all[other_model].mean()\n",
    "                    \n",
    "                    if p_val < 0.05 and mean_diff < 0:\n",
    "                        wins += 1\n",
    "            \n",
    "            dominance_scores.append((model, wins))\n",
    "        \n",
    "        dominance_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        recommendations.append(\"Modelos estad√≠sticamente superiores (test Diebold-Mariano):\")\n",
    "        for i, (model, wins) in enumerate(dominance_scores[:5], 1):\n",
    "            recommendations.append(f\"{i}. {model}: {wins} victorias significativas\")\n",
    "        \n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # 8. Reglas de decisi√≥n\n",
    "        recommendations.append(\"8. REGLAS DE DECISI√ìN SUGERIDAS\")\n",
    "        recommendations.append(\"-\" * 40)\n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # Reglas por escenario\n",
    "        for escenario in ['Estacionario_Lineal', 'No_Estacionario_Lineal', 'No_Lineal']:\n",
    "            subset = self.df_all[self.df_all['Escenario'] == escenario]\n",
    "            if len(subset) > 0:\n",
    "                top2 = subset[self.models].mean().nsmallest(2)\n",
    "                \n",
    "                if escenario == 'Estacionario_Lineal':\n",
    "                    recommendations.append(\"SI el proceso es ESTACIONARIO y LINEAL:\")\n",
    "                elif escenario == 'No_Estacionario_Lineal':\n",
    "                    recommendations.append(\"SI el proceso es NO ESTACIONARIO y LINEAL:\")\n",
    "                else:\n",
    "                    recommendations.append(\"SI el proceso es NO LINEAL:\")\n",
    "                \n",
    "                recommendations.append(f\"  ‚Üí Primera opci√≥n: {top2.index[0]}\")\n",
    "                recommendations.append(f\"  ‚Üí Segunda opci√≥n: {top2.index[1]}\")\n",
    "                recommendations.append(\"\")\n",
    "        \n",
    "        # Reglas por distribuci√≥n\n",
    "        recommendations.append(\"SI la distribuci√≥n de errores:\")\n",
    "        for dist in self.df_all['Distribuci√≥n'].unique():\n",
    "            subset = self.df_all[self.df_all['Distribuci√≥n'] == dist]\n",
    "            if len(subset) > 0:\n",
    "                best = subset[self.models].mean().idxmin()\n",
    "                recommendations.append(f\"  ‚Ä¢ Es {dist} ‚Üí Usar {best}\")\n",
    "        \n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # Reglas por varianza\n",
    "        recommendations.append(\"SI el nivel de varianza:\")\n",
    "        variances = sorted(self.df_all['Varianza'].unique())\n",
    "        if len(variances) >= 2:\n",
    "            low_var = variances[0]\n",
    "            high_var = variances[-1]\n",
    "            \n",
    "            subset_low = self.df_all[self.df_all['Varianza'] == low_var]\n",
    "            subset_high = self.df_all[self.df_all['Varianza'] == high_var]\n",
    "            \n",
    "            best_low = subset_low[self.models].mean().idxmin()\n",
    "            best_high = subset_high[self.models].mean().idxmin()\n",
    "            \n",
    "            recommendations.append(f\"  ‚Ä¢ Es bajo ({low_var}) ‚Üí Usar {best_low}\")\n",
    "            recommendations.append(f\"  ‚Ä¢ Es alto ({high_var}) ‚Üí Usar {best_high}\")\n",
    "        \n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # 9. Conclusiones finales\n",
    "        recommendations.append(\"9. CONCLUSIONES PRINCIPALES\")\n",
    "        recommendations.append(\"-\" * 40)\n",
    "        recommendations.append(\"\")\n",
    "        recommendations.append(f\"‚Ä¢ El modelo {overall_best} muestra el mejor rendimiento general\")\n",
    "        recommendations.append(f\"  con ECRPS promedio de {self.df_all[overall_best].mean():.6f}\")\n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # An√°lisis de robustez\n",
    "        most_robust = min(cv_scores.items(), key=lambda x: x[1])[0]\n",
    "        recommendations.append(f\"‚Ä¢ El modelo m√°s robusto (menor CV) es {most_robust}\")\n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # Comparaci√≥n estacionario vs no estacionario\n",
    "        est_best = self.df_estacionario[self.models].mean().idxmin()\n",
    "        no_est_best = self.df_no_estacionario[self.models].mean().idxmin()\n",
    "        \n",
    "        if est_best == no_est_best:\n",
    "            recommendations.append(f\"‚Ä¢ {est_best} es consistentemente superior en procesos\")\n",
    "            recommendations.append(\"  estacionarios y no estacionarios\")\n",
    "        else:\n",
    "            recommendations.append(f\"‚Ä¢ Para procesos estacionarios: preferir {est_best}\")\n",
    "            recommendations.append(f\"‚Ä¢ Para procesos no estacionarios: preferir {no_est_best}\")\n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # An√°lisis de no linealidad\n",
    "        nl_best = self.df_no_lineal[self.models].mean().idxmin()\n",
    "        recommendations.append(f\"‚Ä¢ Para procesos no lineales: {nl_best} es la mejor opci√≥n\")\n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # Recomendaci√≥n de ensamble\n",
    "        recommendations.append(\"‚Ä¢ Se recomienda implementar un ENSAMBLE de los top 3 modelos\")\n",
    "        recommendations.append(\"  para maximizar robustez y rendimiento\")\n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # Consideraciones pr√°cticas\n",
    "        recommendations.append(\"10. CONSIDERACIONES PR√ÅCTICAS\")\n",
    "        recommendations.append(\"-\" * 40)\n",
    "        recommendations.append(\"\")\n",
    "        recommendations.append(\"Factores a considerar en la selecci√≥n:\")\n",
    "        recommendations.append(\"  1. Costo computacional vs ganancia en precisi√≥n\")\n",
    "        recommendations.append(\"  2. Robustez ante cambios en la distribuci√≥n de errores\")\n",
    "        recommendations.append(\"  3. Consistencia a trav√©s de horizontes de predicci√≥n\")\n",
    "        recommendations.append(\"  4. Facilidad de interpretaci√≥n y explicabilidad\")\n",
    "        recommendations.append(\"  5. Disponibilidad de recursos para implementaci√≥n\")\n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # Trade-offs identificados\n",
    "        recommendations.append(\"Trade-offs identificados:\")\n",
    "        \n",
    "        # Mejor vs m√°s robusto\n",
    "        if overall_best != most_robust:\n",
    "            recommendations.append(f\"  ‚Ä¢ Rendimiento vs Robustez: {overall_best} (mejor) vs {most_robust} (m√°s robusto)\")\n",
    "        \n",
    "        # Modelos especializados\n",
    "        recommendations.append(\"  ‚Ä¢ Algunos modelos son especialistas en escenarios espec√≠ficos\")\n",
    "        recommendations.append(\"  ‚Ä¢ Otros modelos son generalistas con buen rendimiento global\")\n",
    "        recommendations.append(\"\")\n",
    "        \n",
    "        # Guardar recomendaciones\n",
    "        with open(f'{output_dir}/8_recomendaciones.txt', 'w', encoding='utf-8') as f:\n",
    "            f.write('\\n'.join(recommendations))\n",
    "        \n",
    "        print('\\n'.join(recommendations))\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# C√ìDIGO DE EJECUCI√ìN PRINCIPAL\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Funci√≥n principal para ejecutar el an√°lisis completo\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"AN√ÅLISIS COMPREHENSIVO DE MODELOS DE PREDICCI√ìN PROBABIL√çSTICA\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # Crear analizador\n",
    "    try:\n",
    "        analyzer = ModelPerformanceAnalyzer()\n",
    "    except FileNotFoundError:\n",
    "        print(\"\\nERROR: No se encontraron los archivos de datos\")\n",
    "        print(\"Verifica que existan los siguientes archivos:\")\n",
    "        print(\"  - ./Datos/estacionario.xlsx\")\n",
    "        print(\"  - ./Datos/no_estacionario.xlsx\")\n",
    "        print(\"  - ./Datos/no_lineal.xlsx\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"\\nERROR al cargar datos: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return\n",
    "    \n",
    "    # Ejecutar an√°lisis completo\n",
    "    output_directory = 'resultados_analisis_completo'\n",
    "    \n",
    "    try:\n",
    "        analyzer.generate_full_report(output_dir=output_directory)\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"‚úì An√°lisis completado exitosamente\")\n",
    "        print(f\"‚úì Todos los resultados guardados en: {output_directory}/\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        print(\"Archivos generados:\")\n",
    "        print(\"  üìä An√°lisis de caracter√≠sticas del DGP\")\n",
    "        print(\"  üìà Efectos de distribuci√≥n y varianza\")\n",
    "        print(\"  üéØ An√°lisis de horizonte de predicci√≥n\")\n",
    "        print(\"  üîÑ Interacciones complejas\")\n",
    "        print(\"  üí™ M√©tricas de robustez\")\n",
    "        print(\"  üìâ Tests de Diebold-Mariano\")\n",
    "        print(\"  üë§ Perfiles individuales por modelo\")\n",
    "        print(\"  üí° Recomendaciones estrat√©gicas\")\n",
    "        print(\"\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå ERROR durante el an√°lisis: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee1784b",
   "metadata": {},
   "source": [
    "# Pre analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f559ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores √∫nicos encontrados en 'Tipo de Modelo':\n",
      "['AR(1)' 'AR(2)' 'MA(1)' 'MA(2)' 'ARMA(1,1)' 'ARMA(2,2)']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paso</th>\n",
       "      <th>Tipo de Modelo</th>\n",
       "      <th>Distribuci√≥n</th>\n",
       "      <th>Varianza error</th>\n",
       "      <th>AREPD</th>\n",
       "      <th>AV-MCPS</th>\n",
       "      <th>Block Bootstrapping</th>\n",
       "      <th>DeepAR</th>\n",
       "      <th>EnCQR-LSTM</th>\n",
       "      <th>LSPM</th>\n",
       "      <th>LSPMW</th>\n",
       "      <th>MCPS</th>\n",
       "      <th>Sieve Bootstrap</th>\n",
       "      <th>Mejor Modelo</th>\n",
       "      <th>Escenario</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AR(1)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.294667</td>\n",
       "      <td>0.355344</td>\n",
       "      <td>0.248447</td>\n",
       "      <td>0.263419</td>\n",
       "      <td>0.306622</td>\n",
       "      <td>0.440706</td>\n",
       "      <td>0.431452</td>\n",
       "      <td>0.285427</td>\n",
       "      <td>0.248691</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AR(1)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.604540</td>\n",
       "      <td>0.307449</td>\n",
       "      <td>0.254264</td>\n",
       "      <td>0.273001</td>\n",
       "      <td>0.565522</td>\n",
       "      <td>0.470424</td>\n",
       "      <td>0.474111</td>\n",
       "      <td>0.285430</td>\n",
       "      <td>0.254193</td>\n",
       "      <td>Sieve Bootstrap</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>AR(1)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.273622</td>\n",
       "      <td>0.276230</td>\n",
       "      <td>0.258388</td>\n",
       "      <td>0.315765</td>\n",
       "      <td>0.269452</td>\n",
       "      <td>0.520070</td>\n",
       "      <td>0.517876</td>\n",
       "      <td>0.337990</td>\n",
       "      <td>0.258039</td>\n",
       "      <td>Sieve Bootstrap</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>AR(1)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.261423</td>\n",
       "      <td>0.279697</td>\n",
       "      <td>0.254453</td>\n",
       "      <td>0.289443</td>\n",
       "      <td>0.269285</td>\n",
       "      <td>0.287989</td>\n",
       "      <td>0.288111</td>\n",
       "      <td>0.282999</td>\n",
       "      <td>0.254655</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>AR(1)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.626252</td>\n",
       "      <td>0.273680</td>\n",
       "      <td>0.254842</td>\n",
       "      <td>0.272827</td>\n",
       "      <td>0.639437</td>\n",
       "      <td>0.763960</td>\n",
       "      <td>0.753066</td>\n",
       "      <td>0.308347</td>\n",
       "      <td>0.254952</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>1</td>\n",
       "      <td>ARMA(2,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.082513</td>\n",
       "      <td>0.999066</td>\n",
       "      <td>0.953857</td>\n",
       "      <td>1.116455</td>\n",
       "      <td>1.053269</td>\n",
       "      <td>2.030504</td>\n",
       "      <td>2.165650</td>\n",
       "      <td>0.990087</td>\n",
       "      <td>0.954156</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>2</td>\n",
       "      <td>ARMA(2,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.903173</td>\n",
       "      <td>0.971148</td>\n",
       "      <td>0.954440</td>\n",
       "      <td>1.005615</td>\n",
       "      <td>1.518301</td>\n",
       "      <td>1.431610</td>\n",
       "      <td>1.522051</td>\n",
       "      <td>1.141614</td>\n",
       "      <td>0.954065</td>\n",
       "      <td>Sieve Bootstrap</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>3</td>\n",
       "      <td>ARMA(2,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.310542</td>\n",
       "      <td>1.021845</td>\n",
       "      <td>0.976235</td>\n",
       "      <td>1.002865</td>\n",
       "      <td>1.615073</td>\n",
       "      <td>1.026140</td>\n",
       "      <td>1.036051</td>\n",
       "      <td>1.484601</td>\n",
       "      <td>0.962417</td>\n",
       "      <td>Sieve Bootstrap</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>4</td>\n",
       "      <td>ARMA(2,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.324103</td>\n",
       "      <td>0.968827</td>\n",
       "      <td>0.961514</td>\n",
       "      <td>0.977739</td>\n",
       "      <td>1.072897</td>\n",
       "      <td>1.453428</td>\n",
       "      <td>1.530595</td>\n",
       "      <td>1.125230</td>\n",
       "      <td>0.960919</td>\n",
       "      <td>Sieve Bootstrap</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>5</td>\n",
       "      <td>ARMA(2,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.522689</td>\n",
       "      <td>1.011090</td>\n",
       "      <td>0.960863</td>\n",
       "      <td>1.001003</td>\n",
       "      <td>1.123328</td>\n",
       "      <td>1.061991</td>\n",
       "      <td>1.038016</td>\n",
       "      <td>1.179879</td>\n",
       "      <td>0.962942</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows √ó 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Paso Tipo de Modelo Distribuci√≥n  Varianza error     AREPD   AV-MCPS  \\\n",
       "0       1          AR(1)       normal             0.2  0.294667  0.355344   \n",
       "2       2          AR(1)       normal             0.2  0.604540  0.307449   \n",
       "4       3          AR(1)       normal             0.2  0.273622  0.276230   \n",
       "6       4          AR(1)       normal             0.2  0.261423  0.279697   \n",
       "8       5          AR(1)       normal             0.2  0.626252  0.273680   \n",
       "...   ...            ...          ...             ...       ...       ...   \n",
       "1309    1      ARMA(2,2)      mixture             3.0  1.082513  0.999066   \n",
       "1311    2      ARMA(2,2)      mixture             3.0  1.903173  0.971148   \n",
       "1313    3      ARMA(2,2)      mixture             3.0  2.310542  1.021845   \n",
       "1315    4      ARMA(2,2)      mixture             3.0  1.324103  0.968827   \n",
       "1317    5      ARMA(2,2)      mixture             3.0  1.522689  1.011090   \n",
       "\n",
       "      Block Bootstrapping    DeepAR  EnCQR-LSTM      LSPM     LSPMW      MCPS  \\\n",
       "0                0.248447  0.263419    0.306622  0.440706  0.431452  0.285427   \n",
       "2                0.254264  0.273001    0.565522  0.470424  0.474111  0.285430   \n",
       "4                0.258388  0.315765    0.269452  0.520070  0.517876  0.337990   \n",
       "6                0.254453  0.289443    0.269285  0.287989  0.288111  0.282999   \n",
       "8                0.254842  0.272827    0.639437  0.763960  0.753066  0.308347   \n",
       "...                   ...       ...         ...       ...       ...       ...   \n",
       "1309             0.953857  1.116455    1.053269  2.030504  2.165650  0.990087   \n",
       "1311             0.954440  1.005615    1.518301  1.431610  1.522051  1.141614   \n",
       "1313             0.976235  1.002865    1.615073  1.026140  1.036051  1.484601   \n",
       "1315             0.961514  0.977739    1.072897  1.453428  1.530595  1.125230   \n",
       "1317             0.960863  1.001003    1.123328  1.061991  1.038016  1.179879   \n",
       "\n",
       "      Sieve Bootstrap         Mejor Modelo            Escenario  \n",
       "0            0.248691  Block Bootstrapping  Estacionario_Lineal  \n",
       "2            0.254193      Sieve Bootstrap  Estacionario_Lineal  \n",
       "4            0.258039      Sieve Bootstrap  Estacionario_Lineal  \n",
       "6            0.254655  Block Bootstrapping  Estacionario_Lineal  \n",
       "8            0.254952  Block Bootstrapping  Estacionario_Lineal  \n",
       "...               ...                  ...                  ...  \n",
       "1309         0.954156  Block Bootstrapping  Estacionario_Lineal  \n",
       "1311         0.954065      Sieve Bootstrap  Estacionario_Lineal  \n",
       "1313         0.962417      Sieve Bootstrap  Estacionario_Lineal  \n",
       "1315         0.960919      Sieve Bootstrap  Estacionario_Lineal  \n",
       "1317         0.962942  Block Bootstrapping  Estacionario_Lineal  \n",
       "\n",
       "[600 rows x 15 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "    \n",
    "estacionario = pd.read_excel(\"./Datos/estacionario.xlsx\")\n",
    "\n",
    "estacionario = estacionario.drop_duplicates()\n",
    "estacionario = estacionario[estacionario[\"Paso\"] != \"Promedio\"]\n",
    "\n",
    "def determinar_tipo_modelo_mejorado(row):\n",
    "    \"\"\"\n",
    "    Determina el tipo de modelo (AR, MA, ARMA) y su orden a partir de los valores\n",
    "    en las columnas 'Valores de AR' y 'Valores MA'.\n",
    "    \"\"\"\n",
    "    ar_str = str(row['Valores de AR'])\n",
    "    ma_str = str(row['Valores MA'])\n",
    "    \n",
    "    # Expresi√≥n regular para encontrar n√∫meros (enteros o decimales, positivos o negativos)\n",
    "    regex_numeros = r'-?\\d+\\.?\\d*'\n",
    "    \n",
    "    # Cuenta cu√°ntos n√∫meros v√°lidos hay en cada string\n",
    "    p = len(re.findall(regex_numeros, ar_str))\n",
    "    q = len(re.findall(regex_numeros, ma_str))\n",
    "    \n",
    "    if p > 0 and q == 0:\n",
    "        return f\"AR({p})\"\n",
    "    elif p == 0 and q > 0:\n",
    "        return f\"MA({q})\"\n",
    "    elif p > 0 and q > 0:\n",
    "        return f\"ARMA({p},{q})\"\n",
    "    else:\n",
    "        return None # O \"Ruido Blanco\" si p=0 y q=0\n",
    "\n",
    "# Aplica la funci√≥n mejorada para crear la columna \"Tipo de Modelo\"\n",
    "estacionario['Tipo de Modelo'] = estacionario.apply(determinar_tipo_modelo_mejorado, axis=1)\n",
    "\n",
    "# Imprime los valores √∫nicos de la columna Tipo de modelo para verificar\n",
    "print(\"Valores √∫nicos encontrados en 'Tipo de Modelo':\")\n",
    "print(estacionario['Tipo de Modelo'].unique())\n",
    "\n",
    "# Ordena las columnas 'Paso' y 'Tipo de modelo' al inicio\n",
    "cols = estacionario.columns.tolist()\n",
    "# Aseguramos que las columnas existan antes de moverlas\n",
    "if 'Paso' in cols:\n",
    "    cols.insert(0, cols.pop(cols.index('Paso')))\n",
    "if 'Tipo de Modelo' in cols:\n",
    "    cols.insert(1, cols.pop(cols.index('Tipo de Modelo')))\n",
    "\n",
    "estacionario = estacionario.reindex(columns=cols)\n",
    "\n",
    "\n",
    "# Borra las columnas originales 'Valores de AR' y 'Valores MA'\n",
    "estacionario = estacionario.drop(columns=['Valores de AR', 'Valores MA'])\n",
    "estacionario[\"Escenario\"] = \"Estacionario_Lineal\"\n",
    "\n",
    "# Muestra el DataFrame resultante\n",
    "estacionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba423eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paso</th>\n",
       "      <th>Tipo de Modelo</th>\n",
       "      <th>Distribuci√≥n</th>\n",
       "      <th>Varianza error</th>\n",
       "      <th>AREPD</th>\n",
       "      <th>AV-MCPS</th>\n",
       "      <th>Block Bootstrapping</th>\n",
       "      <th>DeepAR</th>\n",
       "      <th>EnCQR-LSTM</th>\n",
       "      <th>LSPM</th>\n",
       "      <th>LSPMW</th>\n",
       "      <th>MCPS</th>\n",
       "      <th>Sieve Bootstrap</th>\n",
       "      <th>Mejor Modelo</th>\n",
       "      <th>Escenario</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ARIMA(0,1,0)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.860823</td>\n",
       "      <td>0.258474</td>\n",
       "      <td>0.253635</td>\n",
       "      <td>0.319481</td>\n",
       "      <td>0.488711</td>\n",
       "      <td>0.367279</td>\n",
       "      <td>0.360494</td>\n",
       "      <td>0.270816</td>\n",
       "      <td>0.273828</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ARIMA(0,1,0)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.244128</td>\n",
       "      <td>0.528968</td>\n",
       "      <td>0.275061</td>\n",
       "      <td>0.438099</td>\n",
       "      <td>0.322919</td>\n",
       "      <td>0.426187</td>\n",
       "      <td>0.430296</td>\n",
       "      <td>0.576792</td>\n",
       "      <td>0.272952</td>\n",
       "      <td>Sieve Bootstrap</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ARIMA(0,1,0)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.799818</td>\n",
       "      <td>0.864295</td>\n",
       "      <td>0.272406</td>\n",
       "      <td>0.291500</td>\n",
       "      <td>0.396481</td>\n",
       "      <td>0.642530</td>\n",
       "      <td>0.639134</td>\n",
       "      <td>0.269655</td>\n",
       "      <td>0.275661</td>\n",
       "      <td>MCPS</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ARIMA(0,1,0)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.912421</td>\n",
       "      <td>0.481159</td>\n",
       "      <td>0.255186</td>\n",
       "      <td>0.291577</td>\n",
       "      <td>0.495882</td>\n",
       "      <td>0.341570</td>\n",
       "      <td>0.341227</td>\n",
       "      <td>0.533788</td>\n",
       "      <td>0.275948</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ARIMA(0,1,0)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.822771</td>\n",
       "      <td>0.792130</td>\n",
       "      <td>0.257461</td>\n",
       "      <td>0.658698</td>\n",
       "      <td>1.291283</td>\n",
       "      <td>0.981902</td>\n",
       "      <td>0.969842</td>\n",
       "      <td>1.455485</td>\n",
       "      <td>0.338116</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>1</td>\n",
       "      <td>ARIMA(2,1,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>76.766114</td>\n",
       "      <td>5.668568</td>\n",
       "      <td>0.965836</td>\n",
       "      <td>7.254422</td>\n",
       "      <td>13.176312</td>\n",
       "      <td>4.421885</td>\n",
       "      <td>4.173484</td>\n",
       "      <td>20.231134</td>\n",
       "      <td>2.612414</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>2</td>\n",
       "      <td>ARIMA(2,1,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>80.630681</td>\n",
       "      <td>6.161741</td>\n",
       "      <td>0.974398</td>\n",
       "      <td>8.767931</td>\n",
       "      <td>9.287902</td>\n",
       "      <td>1.733689</td>\n",
       "      <td>1.596168</td>\n",
       "      <td>21.251698</td>\n",
       "      <td>1.956761</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>3</td>\n",
       "      <td>ARIMA(2,1,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>86.539087</td>\n",
       "      <td>10.452450</td>\n",
       "      <td>0.982561</td>\n",
       "      <td>24.631292</td>\n",
       "      <td>18.639842</td>\n",
       "      <td>6.195609</td>\n",
       "      <td>5.953120</td>\n",
       "      <td>23.480752</td>\n",
       "      <td>3.623684</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>4</td>\n",
       "      <td>ARIMA(2,1,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>93.057798</td>\n",
       "      <td>13.911382</td>\n",
       "      <td>0.958507</td>\n",
       "      <td>27.567728</td>\n",
       "      <td>17.852720</td>\n",
       "      <td>7.288522</td>\n",
       "      <td>6.952830</td>\n",
       "      <td>28.286507</td>\n",
       "      <td>4.681807</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>5</td>\n",
       "      <td>ARIMA(2,1,2)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>99.120410</td>\n",
       "      <td>13.899543</td>\n",
       "      <td>0.955009</td>\n",
       "      <td>17.064311</td>\n",
       "      <td>8.945594</td>\n",
       "      <td>4.716275</td>\n",
       "      <td>4.320090</td>\n",
       "      <td>31.056370</td>\n",
       "      <td>4.177879</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Estacionario_Lineal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows √ó 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Paso Tipo de Modelo Distribuci√≥n  Varianza error      AREPD    AV-MCPS  \\\n",
       "0      1   ARIMA(0,1,0)       normal             0.2   1.860823   0.258474   \n",
       "1      2   ARIMA(0,1,0)       normal             0.2   1.244128   0.528968   \n",
       "2      3   ARIMA(0,1,0)       normal             0.2   1.799818   0.864295   \n",
       "3      4   ARIMA(0,1,0)       normal             0.2   1.912421   0.481159   \n",
       "4      5   ARIMA(0,1,0)       normal             0.2   2.822771   0.792130   \n",
       "..   ...            ...          ...             ...        ...        ...   \n",
       "834    1   ARIMA(2,1,2)      mixture             3.0  76.766114   5.668568   \n",
       "835    2   ARIMA(2,1,2)      mixture             3.0  80.630681   6.161741   \n",
       "836    3   ARIMA(2,1,2)      mixture             3.0  86.539087  10.452450   \n",
       "837    4   ARIMA(2,1,2)      mixture             3.0  93.057798  13.911382   \n",
       "838    5   ARIMA(2,1,2)      mixture             3.0  99.120410  13.899543   \n",
       "\n",
       "     Block Bootstrapping     DeepAR  EnCQR-LSTM      LSPM     LSPMW  \\\n",
       "0               0.253635   0.319481    0.488711  0.367279  0.360494   \n",
       "1               0.275061   0.438099    0.322919  0.426187  0.430296   \n",
       "2               0.272406   0.291500    0.396481  0.642530  0.639134   \n",
       "3               0.255186   0.291577    0.495882  0.341570  0.341227   \n",
       "4               0.257461   0.658698    1.291283  0.981902  0.969842   \n",
       "..                   ...        ...         ...       ...       ...   \n",
       "834             0.965836   7.254422   13.176312  4.421885  4.173484   \n",
       "835             0.974398   8.767931    9.287902  1.733689  1.596168   \n",
       "836             0.982561  24.631292   18.639842  6.195609  5.953120   \n",
       "837             0.958507  27.567728   17.852720  7.288522  6.952830   \n",
       "838             0.955009  17.064311    8.945594  4.716275  4.320090   \n",
       "\n",
       "          MCPS  Sieve Bootstrap         Mejor Modelo               Escenario  \n",
       "0     0.270816         0.273828  Block Bootstrapping  No_Estacionario_Lineal  \n",
       "1     0.576792         0.272952      Sieve Bootstrap  No_Estacionario_Lineal  \n",
       "2     0.269655         0.275661                 MCPS  No_Estacionario_Lineal  \n",
       "3     0.533788         0.275948  Block Bootstrapping  No_Estacionario_Lineal  \n",
       "4     1.455485         0.338116  Block Bootstrapping  No_Estacionario_Lineal  \n",
       "..         ...              ...                  ...                     ...  \n",
       "834  20.231134         2.612414  Block Bootstrapping  No_Estacionario_Lineal  \n",
       "835  21.251698         1.956761  Block Bootstrapping  No_Estacionario_Lineal  \n",
       "836  23.480752         3.623684  Block Bootstrapping  No_Estacionario_Lineal  \n",
       "837  28.286507         4.681807  Block Bootstrapping  No_Estacionario_Lineal  \n",
       "838  31.056370         4.177879  Block Bootstrapping  No_Estacionario_Lineal  \n",
       "\n",
       "[700 rows x 15 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_estacionario = pd.read_excel(\"./Datos/no_estacionario.xlsx\")\n",
    "no_estacionario.drop(columns=['Valores de AR', 'Valores MA'], inplace=True)\n",
    "no_estacionario[\"Escenario\"] = \"No_Estacionario_Lineal\"\n",
    "no_estacionario = no_estacionario[no_estacionario[\"Paso\"] != \"Promedio\"]\n",
    "no_estacionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e7ce88d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paso</th>\n",
       "      <th>Tipo de Modelo</th>\n",
       "      <th>Distribuci√≥n</th>\n",
       "      <th>Varianza error</th>\n",
       "      <th>AREPD</th>\n",
       "      <th>AV-MCPS</th>\n",
       "      <th>Block Bootstrapping</th>\n",
       "      <th>DeepAR</th>\n",
       "      <th>EnCQR-LSTM</th>\n",
       "      <th>LSPM</th>\n",
       "      <th>LSPMW</th>\n",
       "      <th>MCPS</th>\n",
       "      <th>Sieve Bootstrap</th>\n",
       "      <th>Mejor Modelo</th>\n",
       "      <th>Escenario</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>SETAR(2,1)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.257043</td>\n",
       "      <td>0.253521</td>\n",
       "      <td>0.251524</td>\n",
       "      <td>0.263274</td>\n",
       "      <td>0.257984</td>\n",
       "      <td>0.285655</td>\n",
       "      <td>0.282110</td>\n",
       "      <td>0.257015</td>\n",
       "      <td>0.251188</td>\n",
       "      <td>Sieve Bootstrap</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>SETAR(2,1)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.305723</td>\n",
       "      <td>0.383340</td>\n",
       "      <td>0.288529</td>\n",
       "      <td>0.297164</td>\n",
       "      <td>0.324101</td>\n",
       "      <td>0.316846</td>\n",
       "      <td>0.319675</td>\n",
       "      <td>0.347319</td>\n",
       "      <td>0.290022</td>\n",
       "      <td>Block Bootstrapping</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>SETAR(2,1)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.292055</td>\n",
       "      <td>0.258555</td>\n",
       "      <td>0.287265</td>\n",
       "      <td>0.275374</td>\n",
       "      <td>0.278881</td>\n",
       "      <td>0.320347</td>\n",
       "      <td>0.320181</td>\n",
       "      <td>0.270736</td>\n",
       "      <td>0.262183</td>\n",
       "      <td>AV-MCPS</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>SETAR(2,1)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.298469</td>\n",
       "      <td>0.269290</td>\n",
       "      <td>0.263802</td>\n",
       "      <td>0.255605</td>\n",
       "      <td>0.270449</td>\n",
       "      <td>0.290893</td>\n",
       "      <td>0.290581</td>\n",
       "      <td>0.329900</td>\n",
       "      <td>0.258734</td>\n",
       "      <td>DeepAR</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>SETAR(2,1)</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.298007</td>\n",
       "      <td>0.368342</td>\n",
       "      <td>0.501202</td>\n",
       "      <td>0.323900</td>\n",
       "      <td>0.348571</td>\n",
       "      <td>0.326254</td>\n",
       "      <td>0.329508</td>\n",
       "      <td>0.423889</td>\n",
       "      <td>0.442319</td>\n",
       "      <td>AREPD</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>1</td>\n",
       "      <td>SETAR(2,3)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.164445</td>\n",
       "      <td>0.992519</td>\n",
       "      <td>0.962026</td>\n",
       "      <td>0.989297</td>\n",
       "      <td>1.046459</td>\n",
       "      <td>0.971555</td>\n",
       "      <td>1.076860</td>\n",
       "      <td>1.003262</td>\n",
       "      <td>0.961513</td>\n",
       "      <td>Sieve Bootstrap</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>2</td>\n",
       "      <td>SETAR(2,3)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.191648</td>\n",
       "      <td>1.034591</td>\n",
       "      <td>0.986347</td>\n",
       "      <td>1.077081</td>\n",
       "      <td>0.972263</td>\n",
       "      <td>0.957417</td>\n",
       "      <td>0.986525</td>\n",
       "      <td>0.963721</td>\n",
       "      <td>0.984072</td>\n",
       "      <td>LSPM</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>3</td>\n",
       "      <td>SETAR(2,3)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.193252</td>\n",
       "      <td>1.387456</td>\n",
       "      <td>1.012627</td>\n",
       "      <td>0.981861</td>\n",
       "      <td>0.955903</td>\n",
       "      <td>0.987603</td>\n",
       "      <td>0.977201</td>\n",
       "      <td>1.041540</td>\n",
       "      <td>1.009812</td>\n",
       "      <td>EnCQR-LSTM</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>4</td>\n",
       "      <td>SETAR(2,3)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.229893</td>\n",
       "      <td>1.182221</td>\n",
       "      <td>1.124342</td>\n",
       "      <td>0.983326</td>\n",
       "      <td>0.960088</td>\n",
       "      <td>1.036372</td>\n",
       "      <td>0.978720</td>\n",
       "      <td>1.029875</td>\n",
       "      <td>1.103310</td>\n",
       "      <td>EnCQR-LSTM</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>5</td>\n",
       "      <td>SETAR(2,3)</td>\n",
       "      <td>mixture</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.149135</td>\n",
       "      <td>1.068179</td>\n",
       "      <td>1.046778</td>\n",
       "      <td>0.999776</td>\n",
       "      <td>0.961731</td>\n",
       "      <td>0.961208</td>\n",
       "      <td>0.977492</td>\n",
       "      <td>1.069917</td>\n",
       "      <td>1.059325</td>\n",
       "      <td>LSPM</td>\n",
       "      <td>No_Lineal_Estacionario</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows √ó 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Paso Tipo de Modelo Distribuci√≥n  Varianza error     AREPD   AV-MCPS  \\\n",
       "0      1     SETAR(2,1)       normal             0.2  0.257043  0.253521   \n",
       "1      2     SETAR(2,1)       normal             0.2  0.305723  0.383340   \n",
       "2      3     SETAR(2,1)       normal             0.2  0.292055  0.258555   \n",
       "3      4     SETAR(2,1)       normal             0.2  0.298469  0.269290   \n",
       "4      5     SETAR(2,1)       normal             0.2  0.298007  0.368342   \n",
       "..   ...            ...          ...             ...       ...       ...   \n",
       "834    1     SETAR(2,3)      mixture             3.0  1.164445  0.992519   \n",
       "835    2     SETAR(2,3)      mixture             3.0  1.191648  1.034591   \n",
       "836    3     SETAR(2,3)      mixture             3.0  1.193252  1.387456   \n",
       "837    4     SETAR(2,3)      mixture             3.0  1.229893  1.182221   \n",
       "838    5     SETAR(2,3)      mixture             3.0  1.149135  1.068179   \n",
       "\n",
       "     Block Bootstrapping    DeepAR  EnCQR-LSTM      LSPM     LSPMW      MCPS  \\\n",
       "0               0.251524  0.263274    0.257984  0.285655  0.282110  0.257015   \n",
       "1               0.288529  0.297164    0.324101  0.316846  0.319675  0.347319   \n",
       "2               0.287265  0.275374    0.278881  0.320347  0.320181  0.270736   \n",
       "3               0.263802  0.255605    0.270449  0.290893  0.290581  0.329900   \n",
       "4               0.501202  0.323900    0.348571  0.326254  0.329508  0.423889   \n",
       "..                   ...       ...         ...       ...       ...       ...   \n",
       "834             0.962026  0.989297    1.046459  0.971555  1.076860  1.003262   \n",
       "835             0.986347  1.077081    0.972263  0.957417  0.986525  0.963721   \n",
       "836             1.012627  0.981861    0.955903  0.987603  0.977201  1.041540   \n",
       "837             1.124342  0.983326    0.960088  1.036372  0.978720  1.029875   \n",
       "838             1.046778  0.999776    0.961731  0.961208  0.977492  1.069917   \n",
       "\n",
       "     Sieve Bootstrap         Mejor Modelo               Escenario  \n",
       "0           0.251188      Sieve Bootstrap  No_Lineal_Estacionario  \n",
       "1           0.290022  Block Bootstrapping  No_Lineal_Estacionario  \n",
       "2           0.262183              AV-MCPS  No_Lineal_Estacionario  \n",
       "3           0.258734               DeepAR  No_Lineal_Estacionario  \n",
       "4           0.442319                AREPD  No_Lineal_Estacionario  \n",
       "..               ...                  ...                     ...  \n",
       "834         0.961513      Sieve Bootstrap  No_Lineal_Estacionario  \n",
       "835         0.984072                 LSPM  No_Lineal_Estacionario  \n",
       "836         1.009812           EnCQR-LSTM  No_Lineal_Estacionario  \n",
       "837         1.103310           EnCQR-LSTM  No_Lineal_Estacionario  \n",
       "838         1.059325                 LSPM  No_Lineal_Estacionario  \n",
       "\n",
       "[700 rows x 15 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_lineal = pd.read_excel(\"./Datos/no_lineal.xlsx\")\n",
    "no_lineal = no_lineal[no_lineal[\"Paso\"] != \"Promedio\"]\n",
    "no_lineal[\"Escenario\"] = \"No_Lineal_Estacionario\"\n",
    "no_lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f2c36b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Une los tres DataFrames en uno solo uno debajo de otro\n",
    "df_all = pd.concat([estacionario, no_estacionario, no_lineal], ignore_index=True)\n",
    "# Guarda el DataFrame combinado en un archivo Excel\n",
    "df_all.to_excel(\"./Datos/datos_combinados.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaf7f35",
   "metadata": {},
   "source": [
    "# Analisis con la correcion del profe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ac9a3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio 'resultados_completos_media_mediana' creado.\n",
      "‚úì Datos cargados exitosamente.\n",
      "\n",
      "================================================================================\n",
      "--- INICIANDO AN√ÅLISIS BASADO EN LA MEAN ---\n",
      "================================================================================\n",
      " -> 1. Analizando por estacionariedad (mean)...\n",
      " -> 2. Analizando por linealidad (mean)...\n",
      " -> 3. Generando heatmaps generales (mean)...\n",
      " -> 4. Analizando ECRPS vs Varianza (mean)...\n",
      " -> 5. Analizando ECRPS vs Paso (mean)...\n",
      " -> Analizando robustez y estabilidad (basado en mean)...\n",
      "\n",
      "================================================================================\n",
      "--- INICIANDO AN√ÅLISIS BASADO EN LA MEDIAN ---\n",
      "================================================================================\n",
      " -> 1. Analizando por estacionariedad (median)...\n",
      " -> 2. Analizando por linealidad (median)...\n",
      " -> 3. Generando heatmaps generales (median)...\n",
      " -> 4. Analizando ECRPS vs Varianza (median)...\n",
      " -> 5. Analizando ECRPS vs Paso (median)...\n",
      " -> Analizando robustez y estabilidad (basado en median)...\n",
      "\n",
      "================================================================================\n",
      "--- INICIANDO AN√ÅLISIS INDEPENDIENTES DE AGREGACI√ìN ---\n",
      "================================================================================\n",
      " -> Generando gr√°ficos de densidad individuales (an√°lisis √∫nico)...\n",
      " -> Realizando Test de Diebold-Mariano (an√°lisis √∫nico)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pleal\\AppData\\Local\\Temp\\ipykernel_16608\\4105642524.py:199: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  annot_matrix = result_matrix.applymap(lambda x: {1: 'Gana', -1: 'Pierde', 0: 'Empate'}[x])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì An√°lisis completo. Resultados guardados en la carpeta 'resultados_completos_media_mediana'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "from scipy import stats\n",
    "from itertools import combinations\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURACI√ìN\n",
    "# ============================================================================\n",
    "RUTA_DATOS = \"./Datos/datos_combinados.xlsx\"\n",
    "CARPETA_RESULTADOS = \"resultados_completos_media_mediana\"\n",
    "MODELOS = ['AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', \n",
    "           'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
    "ESCENARIOS_ESTACIONARIOS = ['Estacionario_Lineal', 'No_Lineal_Estacionario']\n",
    "ESCENARIOS_NO_ESTACIONARIOS = ['No_Estacionario_Lineal']\n",
    "ESCENARIOS_LINEALES = ['Estacionario_Lineal', 'No_Estacionario_Lineal']\n",
    "ESCENARIOS_NO_LINEALES = ['No_Lineal_Estacionario']\n",
    "\n",
    "# ============================================================================\n",
    "# CLASE PARA TEST ESTAD√çSTICO\n",
    "# ============================================================================\n",
    "class DieboldMarianoTest:\n",
    "    @staticmethod\n",
    "    def dm_test(errors1, errors2, h=1, power=2):\n",
    "        # Implementaci√≥n del test... (sin cambios)\n",
    "        errors1, errors2 = np.array(errors1), np.array(errors2)\n",
    "        loss_diff = (errors1**power) - (errors2**power)\n",
    "        mean_diff = np.mean(loss_diff)\n",
    "        n = len(loss_diff)\n",
    "        gamma0 = np.var(loss_diff, ddof=1)\n",
    "        if h > 1:\n",
    "            gamma_sum = sum((1 - k/h) * np.cov(loss_diff[:-k], loss_diff[k:])[0, 1] for k in range(1, h))\n",
    "            variance = (gamma0 + 2 * gamma_sum) / n\n",
    "        else:\n",
    "            variance = gamma0 / n\n",
    "        dm_stat = mean_diff / np.sqrt(variance) if variance > 0 else 0\n",
    "        p_value = 2 * (1 - stats.norm.cdf(np.abs(dm_stat)))\n",
    "        return dm_stat, p_value\n",
    "\n",
    "# ============================================================================\n",
    "# FUNCIONES DE AN√ÅLISIS Y VISUALIZACI√ìN (MODIFICADAS)\n",
    "# ============================================================================\n",
    "def crear_directorio_resultados(nombre_carpeta):\n",
    "    if not os.path.exists(nombre_carpeta):\n",
    "        os.makedirs(nombre_carpeta)\n",
    "        print(f\"Directorio '{nombre_carpeta}' creado.\")\n",
    "\n",
    "def guardar_grafico(nombre_archivo):\n",
    "    ruta_completa = os.path.join(CARPETA_RESULTADOS, nombre_archivo)\n",
    "    plt.savefig(ruta_completa, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def graficar_comparacion_barras(promedios1, promedios2, orden, etiqueta1, etiqueta2, agg_method, nombre_archivo):\n",
    "    \"\"\"Grafica la comparaci√≥n de barras para media o mediana.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    x = np.arange(len(orden))\n",
    "    width = 0.35\n",
    "    bars1 = ax.bar(x - width/2, promedios1[orden], width, label=etiqueta1, alpha=0.8, color='#3498db')\n",
    "    bars2 = ax.bar(x + width/2, promedios2[orden], width, label=etiqueta2, alpha=0.8, color='#e74c3c')\n",
    "    \n",
    "    ylabel = f'ECRPS {\"Promedio\" if agg_method == \"mean\" else \"Mediano\"} (menor es mejor)'\n",
    "    titulo = f'Comparaci√≥n de Desempe√±o ({agg_method.capitalize()})'\n",
    "    \n",
    "    ax.set_xlabel('Modelos', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel(ylabel, fontsize=12, fontweight='bold')\n",
    "    ax.set_title(titulo, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(orden, rotation=45, ha='right')\n",
    "    ax.legend(fontsize=11)\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    for bars in [bars1, bars2]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width() / 2., height, f'{height:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    guardar_grafico(nombre_archivo)\n",
    "\n",
    "def generar_heatmap(data, agg_method, titulo_sufijo, nombre_archivo, figsize=(14, 8)):\n",
    "    \"\"\"Genera un heatmap basado en media o mediana.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    cbar_label = f'ECRPS {\"Promedio\" if agg_method == \"mean\" else \"Mediano\"}'\n",
    "    titulo = f'Heatmap: {titulo_sufijo} ({agg_method.capitalize()})'\n",
    "    \n",
    "    sns.heatmap(data, annot=True, fmt='.3f', cmap='RdYlGn_r',\n",
    "                cbar_kws={'label': cbar_label},\n",
    "                linewidths=0.5, linecolor='gray', ax=ax)\n",
    "    ax.set_title(titulo, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Modelos', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel(data.index.name, fontsize=12, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    guardar_grafico(nombre_archivo)\n",
    "\n",
    "def graficar_evolucion_metrica_por_tipo(df, metrica_eje_x, agg_method, xlabel, nombre_archivo_sufijo):\n",
    "    \"\"\"Genera gr√°ficos de evoluci√≥n para cada tipo de modelo, usando media o mediana.\"\"\"\n",
    "    valores_unicos = sorted(df[metrica_eje_x].unique())\n",
    "    tipos_modelo_unicos = df['Tipo de Modelo'].unique()\n",
    "    \n",
    "    for tipo in tipos_modelo_unicos:\n",
    "        df_tipo = df[df['Tipo de Modelo'] == tipo]\n",
    "        fig, ax = plt.subplots(figsize=(12, 7))\n",
    "        \n",
    "        for modelo in MODELOS:\n",
    "            agregados = [df_tipo[df_tipo[metrica_eje_x] == val][modelo].agg(agg_method) for val in valores_unicos]\n",
    "            if not all(np.isnan(agregados)):\n",
    "                ax.plot(valores_unicos, agregados, marker='o', linewidth=2, markersize=8, label=modelo, alpha=0.8)\n",
    "        \n",
    "        ylabel = f'ECRPS {\"Promedio\" if agg_method == \"mean\" else \"Mediano\"}'\n",
    "        titulo = f'ECRPS vs {metrica_eje_x} ({agg_method.capitalize()}) - Tipo: {tipo}'\n",
    "        \n",
    "        ax.set_xlabel(xlabel, fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel(ylabel, fontsize=12, fontweight='bold')\n",
    "        ax.set_title(titulo, fontsize=13, fontweight='bold', pad=15)\n",
    "        ax.legend(fontsize=9, loc='best', ncol=2)\n",
    "        ax.grid(True, alpha=0.3, linestyle='--')\n",
    "        if metrica_eje_x == 'Paso':\n",
    "            ax.set_xticks(valores_unicos)\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        nombre_archivo_tipo = f'ecrps_vs_{nombre_archivo_sufijo}_tipo_{tipo.replace(\" \", \"_\").lower()}_{agg_method}.png'\n",
    "        guardar_grafico(nombre_archivo_tipo)\n",
    "\n",
    "def analizar_robustez_estabilidad(df, agg_method):\n",
    "    \"\"\"Calcula y grafica m√©tricas de robustez y estabilidad.\"\"\"\n",
    "    print(f\" -> Analizando robustez y estabilidad (basado en {agg_method})...\")\n",
    "    \n",
    "    if agg_method == 'mean':\n",
    "        # An√°lisis basado en la media (como antes)\n",
    "        metrics = [{'Modelo': m, 'Centralidad': df[m].mean(), 'Dispersion': df[m].std()} for m in MODELOS]\n",
    "        df_robust = pd.DataFrame(metrics)\n",
    "        label_centralidad = 'ECRPS Promedio (Rendimiento)'\n",
    "        label_dispersion = 'Desviaci√≥n Est√°ndar (Estabilidad)'\n",
    "        titulo_compromiso = 'Compromiso Rendimiento vs. Estabilidad (Media vs Std)'\n",
    "        \n",
    "    else: # agg_method == 'median'\n",
    "        # An√°lisis basado en la mediana (m√°s robusto a outliers)\n",
    "        metrics = [{'Modelo': m, 'Centralidad': df[m].median(), 'Dispersion': df[m].quantile(0.75) - df[m].quantile(0.25)} for m in MODELOS]\n",
    "        df_robust = pd.DataFrame(metrics)\n",
    "        label_centralidad = 'ECRPS Mediano (Rendimiento T√≠pico)'\n",
    "        label_dispersion = 'Rango Intercuart√≠lico (IQR - Estabilidad Robusta)'\n",
    "        titulo_compromiso = 'Compromiso Rendimiento vs. Estabilidad (Mediana vs IQR)'\n",
    "\n",
    "    # Gr√°fico de dispersi√≥n Rendimiento vs Estabilidad\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    sns.scatterplot(data=df_robust, x='Centralidad', y='Dispersion', hue='Modelo', s=150, alpha=0.8, ax=ax)\n",
    "    for _, row in df_robust.iterrows():\n",
    "        ax.text(row['Centralidad'], row['Dispersion'], row['Modelo'], fontsize=9, ha='left', va='bottom')\n",
    "    ax.set_xlabel(label_centralidad, fontweight='bold')\n",
    "    ax.set_ylabel(label_dispersion, fontweight='bold')\n",
    "    ax.set_title(titulo_compromiso, fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, linestyle='--', alpha=0.6)\n",
    "    ax.legend(title='Modelos', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    guardar_grafico(f\"6_compromiso_rendimiento_estabilidad_{agg_method}.png\")\n",
    "\n",
    "# --- Funciones que no dependen de la agregaci√≥n (se ejecutan una sola vez) ---\n",
    "def graficar_densidades_individuales(df):\n",
    "    \"\"\"Crea un gr√°fico de densidad individual para cada modelo.\"\"\"\n",
    "    print(\" -> Generando gr√°ficos de densidad individuales (an√°lisis √∫nico)...\")\n",
    "    all_ecrps_values = df[MODELOS].values.flatten()\n",
    "    xlim_max = np.quantile(all_ecrps_values[~np.isnan(all_ecrps_values)], 0.995)\n",
    "    for modelo in MODELOS:\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        sns.kdeplot(df[modelo].dropna(), fill=True, color='teal', ax=ax, lw=2.5)\n",
    "        mean_val, median_val = df[modelo].mean(), df[modelo].median()\n",
    "        ax.axvline(mean_val, color='red', linestyle='--', label=f'Media: {mean_val:.3f}')\n",
    "        ax.axvline(median_val, color='green', linestyle=':', label=f'Mediana: {median_val:.3f}')\n",
    "        ax.set_title(f'Distribuci√≥n del ECRPS - Modelo: {modelo}', fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel('ECRPS', fontweight='bold')\n",
    "        ax.set_ylabel('Densidad', fontweight='bold')\n",
    "        ax.set_xlim(left=0, right=xlim_max)\n",
    "        ax.legend()\n",
    "        ax.grid(True, linestyle='--', alpha=0.5)\n",
    "        plt.tight_layout()\n",
    "        guardar_grafico(f\"7_densidad_{modelo.replace(' ', '_').lower()}.png\")\n",
    "\n",
    "def realizar_test_diebold_mariano(df):\n",
    "    \"\"\"Realiza el test de Diebold-Mariano con correcci√≥n de Bonferroni.\"\"\"\n",
    "    print(\" -> Realizando Test de Diebold-Mariano (an√°lisis √∫nico)...\")\n",
    "    pairs = list(combinations(MODELOS, 2))\n",
    "    alpha_bonferroni = 0.05 / len(pairs)\n",
    "    dm_results = []\n",
    "    for m1, m2 in pairs:\n",
    "        e1, e2 = df[m1].dropna(), df[m2].dropna()\n",
    "        min_len = min(len(e1), len(e2))\n",
    "        _, p_value = DieboldMarianoTest.dm_test(e1[:min_len], e2[:min_len])\n",
    "        winner = 'Empate' if p_value >= alpha_bonferroni else (m1 if df[m1].mean() < df[m2].mean() else m2)\n",
    "        dm_results.append({'Modelo_1': m1, 'Modelo_2': m2, 'Ganador_Bonferroni': winner})\n",
    "    \n",
    "    # Heatmap de resultados\n",
    "    result_matrix = pd.DataFrame(index=MODELOS, columns=MODELOS, data=0)\n",
    "    for _, row in pd.DataFrame(dm_results).iterrows():\n",
    "        if row['Ganador_Bonferroni'] == row['Modelo_1']:\n",
    "            result_matrix.loc[row['Modelo_1'], row['Modelo_2']], result_matrix.loc[row['Modelo_2'], row['Modelo_1']] = 1, -1\n",
    "        elif row['Ganador_Bonferroni'] == row['Modelo_2']:\n",
    "            result_matrix.loc[row['Modelo_1'], row['Modelo_2']], result_matrix.loc[row['Modelo_2'], row['Modelo_1']] = -1, 1\n",
    "\n",
    "    annot_matrix = result_matrix.applymap(lambda x: {1: 'Gana', -1: 'Pierde', 0: 'Empate'}[x])\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    sns.heatmap(result_matrix.astype(float), annot=annot_matrix, fmt='s', cmap=['red', 'lightgray', 'green'], cbar=False, ax=ax)\n",
    "    ax.set_title('Resultado Test Diebold-Mariano (con correcci√≥n de Bonferroni)', fontweight='bold')\n",
    "    guardar_grafico(\"8_dm_heatmap_bonferroni.png\")\n",
    "\n",
    "# ============================================================================\n",
    "# SCRIPT PRINCIPAL\n",
    "# ============================================================================\n",
    "def main():\n",
    "    crear_directorio_resultados(CARPETA_RESULTADOS)\n",
    "    try:\n",
    "        df = pd.read_excel(RUTA_DATOS)\n",
    "        print(\"‚úì Datos cargados exitosamente.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: No se encontr√≥ el archivo en la ruta '{RUTA_DATOS}'.\")\n",
    "        return\n",
    "\n",
    "    # Bucle principal para ejecutar an√°lisis por media y mediana\n",
    "    for agg_method in ['mean', 'median']:\n",
    "        print(f\"\\n{'='*80}\\n--- INICIANDO AN√ÅLISIS BASADO EN LA {agg_method.upper()} ---\\n{'='*80}\")\n",
    "\n",
    "        # --- AN√ÅLISIS 1: ESTACIONARIEDAD ---\n",
    "        print(f\" -> 1. Analizando por estacionariedad ({agg_method})...\")\n",
    "        df_est = df[df['Escenario'].isin(ESCENARIOS_ESTACIONARIOS)]\n",
    "        df_no_est = df[df['Escenario'].isin(ESCENARIOS_NO_ESTACIONARIOS)]\n",
    "        agregados_est = df_est[MODELOS].agg(agg_method)\n",
    "        agregados_no_est = df_no_est[MODELOS].agg(agg_method)\n",
    "        orden_est = (agregados_est + agregados_no_est).sort_values().index\n",
    "        graficar_comparacion_barras(agregados_est, agregados_no_est, orden_est, 'Estacionarios', 'No Estacionarios', agg_method, f'1_comparacion_estacionariedad_{agg_method}.png')\n",
    "        \n",
    "        # --- AN√ÅLISIS 2: LINEALIDAD ---\n",
    "        print(f\" -> 2. Analizando por linealidad ({agg_method})...\")\n",
    "        df_lin = df[df['Escenario'].isin(ESCENARIOS_LINEALES)]\n",
    "        df_no_lin = df[df['Escenario'].isin(ESCENARIOS_NO_LINEALES)]\n",
    "        agregados_lin = df_lin[MODELOS].agg(agg_method)\n",
    "        agregados_no_lin = df_no_lin[MODELOS].agg(agg_method)\n",
    "        orden_lin = (agregados_lin + agregados_no_lin).sort_values().index\n",
    "        graficar_comparacion_barras(agregados_lin, agregados_no_lin, orden_lin, 'Lineales', 'No Lineales', agg_method, f'2_comparacion_linealidad_{agg_method}.png')\n",
    "\n",
    "        # --- AN√ÅLISIS 3: HEATMAPS GENERALES ---\n",
    "        print(f\" -> 3. Generando heatmaps generales ({agg_method})...\")\n",
    "        heatmap_esc_df = df.groupby('Escenario')[MODELOS].agg(agg_method)\n",
    "        generar_heatmap(heatmap_esc_df, agg_method, 'Desempe√±o por Escenario', f'3_heatmap_escenario_{agg_method}.png', figsize=(14, 6))\n",
    "        heatmap_dist_df = df.groupby('Distribuci√≥n')[MODELOS].agg(agg_method)\n",
    "        generar_heatmap(heatmap_dist_df, agg_method, 'Desempe√±o por Distribuci√≥n', f'3_heatmap_distribucion_{agg_method}.png')\n",
    "\n",
    "        # --- AN√ÅLISIS 4 & 5: EVOLUCI√ìN VS VARIANZA Y PASO ---\n",
    "        print(f\" -> 4. Analizando ECRPS vs Varianza ({agg_method})...\")\n",
    "        graficar_evolucion_metrica_por_tipo(df, 'Varianza error', agg_method, 'Varianza error', 'varianza')\n",
    "        print(f\" -> 5. Analizando ECRPS vs Paso ({agg_method})...\")\n",
    "        graficar_evolucion_metrica_por_tipo(df, 'Paso', agg_method, 'Paso (Horizonte)', 'paso')\n",
    "        \n",
    "        # --- AN√ÅLISIS 6: ROBUSTEZ Y ESTABILIDAD ---\n",
    "        analizar_robustez_estabilidad(df, agg_method)\n",
    "\n",
    "    # --- AN√ÅLISIS QUE SE EJECUTAN UNA SOLA VEZ ---\n",
    "    print(f\"\\n{'='*80}\\n--- INICIANDO AN√ÅLISIS INDEPENDIENTES DE AGREGACI√ìN ---\\n{'='*80}\")\n",
    "    # --- AN√ÅLISIS 7: DENSIDAD DE ERRORES ---\n",
    "    graficar_densidades_individuales(df)\n",
    "    \n",
    "    # --- AN√ÅLISIS 8: TEST DE DIEBOLD-MARIANO ---\n",
    "    realizar_test_diebold_mariano(df)\n",
    "    \n",
    "    print(f\"\\n‚úì An√°lisis completo. Resultados guardados en la carpeta '{CARPETA_RESULTADOS}'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
